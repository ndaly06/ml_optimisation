{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports the required packages\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "import urllib.request\n",
    "from html.parser import HTMLParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://paperswithcode.com/sota'\n",
    "heading = 'h4'\n",
    "\n",
    "# return headings method\n",
    "def return_headings(url, heading):\n",
    "    \n",
    "    html_doc = requests.get(url).content\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    \n",
    "    # searches for all h4 headings\n",
    "    headings = soup.findAll(heading)\n",
    "    \n",
    "    # empty area headings list\n",
    "    area_headings = []\n",
    "    \n",
    "    # appends each area heading to the area_headings list\n",
    "    for div in headings:\n",
    "        area_headings.append(div.text)\n",
    "\n",
    "    # removes the white space from the headings list\n",
    "    area_headings = list(map(str.strip,area_headings))\n",
    "\n",
    "    # list comphrension for lower casing each string in the area_headings list\n",
    "    area_headings = [x.lower() for x in area_headings]\n",
    "\n",
    "    # replaces the white space with an dash in the area_headings list\n",
    "    area_headings = [x.replace(\" \", \"-\") for x in area_headings]\n",
    "    \n",
    "    return area_headings\n",
    "\n",
    "# print(return_headings(url, heading))\n",
    "\n",
    "result = return_headings(url, heading)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "url = 'https://paperswithcode.com/sota'\n",
    "html_doc = requests.get(url).content\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "\n",
    "# searches for all h4 headings\n",
    "headings = soup.findAll('h4')\n",
    "\n",
    "# empty area headings list\n",
    "area_headings = []\n",
    "\n",
    "# appends each area heading to the area_headings list\n",
    "for div in headings:\n",
    "    area_headings.append(div.text)\n",
    "\n",
    "# removes the white space from the headings list\n",
    "area_headings = list(map(str.strip,area_headings))\n",
    "\n",
    "# list comphrension for lower casing each string in the area_headings list\n",
    "area_headings = [x.lower() for x in area_headings]\n",
    "\n",
    "# replaces the white space with an dash in the area_headings list\n",
    "area_headings = [x.replace(\" \", \"-\") for x in area_headings]\n",
    "\n",
    "print(area_headings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialises the Chrome webdriver\n",
    "driver = webdriver.Chrome()\n",
    "    \n",
    "# iterates through each of the area headings\n",
    "for i in range(len(area_headings) - 1):\n",
    "    # print(area_headings[i])\n",
    "\n",
    "    # directs the driver to the respective paperswithcode area page\n",
    "    driver.get(\"https://paperswithcode.com/area/\"+ area_headings[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialises the Chrome webdriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"https://paperswithcode.com/area/\"+ area_headings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "task_headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialises the Chrome webdriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# directs the driver to the paperswithcode webpage\n",
    "driver.get(\"https://paperswithcode.com/sota\")\n",
    "\n",
    "#\n",
    "a_elements = []\n",
    "\n",
    "content_blocks = driver.find_elements_by_class_name(\"col-md-12\")\n",
    "\n",
    "for block in content_blocks:\n",
    "    elements = block.find_elements_by_tag_name(\"h4\")\n",
    "    for el in elements:\n",
    "        a_elements.append(el)\n",
    "\n",
    "print(a_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://paperswithcode.com/\")\n",
    "\n",
    "# scrolls the down the page\n",
    "SCROLL_PAUSE_TIME = 2\n",
    "\n",
    "# Get scroll height\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "while True:\n",
    "    # Scroll down to bottom\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "    # Wait to load page\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "    # Calculate new scroll height and compare with last scroll height\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get('https://paperswithcode.com/')\n",
    "\n",
    "titles = [item.get_attribute('data-title') for item in driver.find_elements_by_css_selector('[data-title]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_container = soup.find(\"div\", {\"class\": \"col-lg-9 item-content\"})\n",
    "\n",
    "name = recipe_container.find('h1').get_text().strip()\n",
    "\n",
    "paragraph = recipe_container.find('p').get_text().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
