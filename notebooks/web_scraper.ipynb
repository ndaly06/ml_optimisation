{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports the required packages\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "import urllib.request\n",
    "from html.parser import HTMLParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Computer Vision', 'Natural Language Processing', 'Medical', 'Methodology', 'Miscellaneous', 'Speech', 'Playing Games', 'Graphs', 'Time Series', 'Audio', 'Robots', 'Music', 'Computer Code', 'Reasoning', 'Knowledge Base', 'Adversarial']\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "url = 'https://paperswithcode.com/sota'\n",
    "\n",
    "#\n",
    "html_doc = requests.get(url).content\n",
    "\n",
    "#\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "\n",
    "#\n",
    "headings = soup.findAll('h4')\n",
    "\n",
    "# empty area headings list\n",
    "area_headings = []\n",
    "\n",
    "# appends each area heading to the area_headings list\n",
    "for div in headings:\n",
    "    area_headings.append(div.text)\n",
    "\n",
    "# removes the white space from the headings list\n",
    "area_headings = list(map(str.strip,area_headings))\n",
    "\n",
    "print(area_headings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['computer_vision', 'natural_language_processing', 'medical', 'methodology', 'miscellaneous', 'speech', 'playing_games', 'graphs', 'time_series', 'audio', 'robots', 'music', 'computer_code', 'reasoning', 'knowledge_base', 'adversarial']\n"
     ]
    }
   ],
   "source": [
    "# list comphrension for lower casing each string in the area_headings list\n",
    "area_headings = [x.lower() for x in area_headings]\n",
    "\n",
    "# replaces the white space with an underscore in the area_headings list\n",
    "area_headings = [x.replace(\" \", \"_\") for x in area_headings]\n",
    "\n",
    "print(area_headings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# initialises the Chrome webdriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# directs the driver to the paperswithcode webpage\n",
    "driver.get(\"https://paperswithcode.com/sota\")\n",
    "\n",
    "#\n",
    "a_elements = []\n",
    "\n",
    "content_blocks = driver.find_elements_by_class_name(\"col-md-12\")\n",
    "\n",
    "for block in content_blocks:\n",
    "    elements = block.find_elements_by_tag_name(\"h4\")\n",
    "    for el in elements:\n",
    "        a_elements.append(el)\n",
    "\n",
    "print(a_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"07f55115644925b9dd24726212de83aa\", element=\"0.29520283922263113-1\")>]\n"
     ]
    }
   ],
   "source": [
    "print(elems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Computer Vision', 'Natural Language Processing', 'Medical', 'Methodology', 'Miscellaneous', 'Speech', 'Playing Games', 'Graphs', 'Time Series', 'Audio', 'Robots', 'Music', 'Computer Code', 'Reasoning', 'Knowledge Base', 'Adversarial']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\nComputer Vision\\n', '\\nNatural Language Processing\\n', '\\nMedical\\n', '\\nMethodology\\n', '\\nMiscellaneous\\n', '\\nSpeech\\n', '\\nPlaying Games\\n', '\\nGraphs\\n', '\\nTime Series\\n', '\\nAudio\\n', '\\nRobots\\n', '\\nMusic\\n', '\\nComputer Code\\n', '\\nReasoning\\n', '\\nKnowledge Base\\n', '\\nAdversarial\\n']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Computer Vision', 'Natural Language Processing', 'Medical', 'Methodology', 'Miscellaneous', 'Speech', 'Playing Games', 'Graphs', 'Time Series', 'Audio', 'Robots', 'Music', 'Computer Code', 'Reasoning', 'Knowledge Base', 'Adversarial']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'soup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9c13d73d06fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'^h[4]$'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'soup' is not defined"
     ]
    }
   ],
   "source": [
    "# initialises the Chrome webdriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# directs the driver to the paperswithcode webpage\n",
    "driver.get(\"https://paperswithcode.com/sota\")\n",
    "\n",
    "# clicks browse state-of-the-art button\n",
    "# driver.find_element_by_css_selector('#navbarSupportedContent > ul > li:nth-child(2) > div > a > button').click()\n",
    "\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://paperswithcode.com/\")\n",
    "\n",
    "# scrolls the down the page\n",
    "SCROLL_PAUSE_TIME = 2\n",
    "\n",
    "# Get scroll height\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "while True:\n",
    "    # Scroll down to bottom\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "    # Wait to load page\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "    # Calculate new scroll height and compare with last scroll height\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://paperswithcode.com/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get('https://paperswithcode.com/')\n",
    "\n",
    "titles = [item.get_attribute('data-title') for item in driver.find_elements_by_css_selector('[data-title]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col-lg-9 item-content\n",
    "\n",
    "s.xpath('//div[@class=\"example\"]/h1/text()').extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "\n",
    "url = 'https://paperswithcode.com/'\n",
    "html_doc = requests.get(url).content\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_container = soup.find(\"div\", {\"class\": \"col-lg-9 item-content\"})\n",
    "\n",
    "name = recipe_container.find('h1').get_text().strip()\n",
    "\n",
    "paragraph = recipe_container.find('p').get_text().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCNet: Non-local Networks Meet Squeeze-Excitation Networks and Beyond\n"
     ]
    }
   ],
   "source": [
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 Apr 2019\n",
      "                    \n",
      "\n",
      "                    \n",
      "                        • xvjiarui/GCNet\n",
      "                        \n",
      "                        \n",
      "                            \n",
      "                            •  \n",
      "In this paper, we take advantage of this finding to create a simplified network based on a query-independent formulation, which maintains the accuracy of NLNet but with significantly less computation.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                 SOTA for\n",
      "                \n",
      "                    Object Detection\n",
      "                    on COCO\n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "OBJECT DETECTION\n",
      "OBJECT RECOGNITION\n"
     ]
    }
   ],
   "source": [
    "print(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
