{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports the required packages\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import pickle\n",
    "import time\n",
    "from IPython.display import display_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads in the tables.txt file\n",
    "tables_data = open('/Users/nialdaly/Documents/ml_optimisation/data/tables.txt', \"r\")\n",
    "\n",
    "# extracts the html from the model tables\n",
    "tables_data = pd.read_html(tables_data)\n",
    "\n",
    "# displays the first \n",
    "tables_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/paper/detecting-oriented-text-in-natural-images-by'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reads in the paper_paths text file\n",
    "with open ('/Users/nialdaly/Documents/ml_optimisation/data/paper_paths.txt', 'rb') as fp:\n",
    "    paper_paths = pickle.load(fp)\n",
    "\n",
    "# displays the first element in the paper_paths list\n",
    "paper_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Detecting Oriented Text in Natural Images by Linking Segments'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reads in the paper_titles text file\n",
    "with open ('/Users/nialdaly/Documents/ml_optimisation/data/paper_titles.txt', 'rb') as fp:\n",
    "    paper_titles = pickle.load(fp)\n",
    "\n",
    "# displays the first element in the paper_paths list\n",
    "paper_titles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://arxiv.org/pdf/1703.06520v3.pdf'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reads in the paper_urls text file\n",
    "with open ('/Users/nialdaly/Documents/ml_optimisation/data/paper_urls.txt', 'rb') as fp:\n",
    "    paper_urls = pickle.load(fp)\n",
    "\n",
    "# displays the first element in the paper_paths list\n",
    "paper_urls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 10, 10)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "len(tables_data), len(paper_titles), len(paper_urls), len(paper_paths[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# initialises an empty model data dataframe\n",
    "model_data = pd.DataFrame(columns=['Task','Dataset','Model',\n",
    "                          'metric name','Metric value',\n",
    "                          'Global rank', 'remove', 'paper', 'paper_path', 'paper_url']\n",
    "                )\n",
    "\n",
    "#\n",
    "for i in range(len(tables_data)):\n",
    "    \n",
    "    #\n",
    "#     paper_models = pd.read_html(str(tables_data))[i]\n",
    "    paper_models = tables_data[i]\n",
    "    \n",
    "    #\n",
    "    paper_models['paper'] = paper_titles[i]\n",
    "    paper_models['paper_path'] = paper_paths[i]\n",
    "    paper_models['paper_url'] = paper_urls[i]\n",
    "    \n",
    "    #\n",
    "    model_data = pd.concat([model_data, paper_models], sort=True)\n",
    "    \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Global rank</th>\n",
       "      <th>Metric name</th>\n",
       "      <th>Metric value</th>\n",
       "      <th>Model</th>\n",
       "      <th>Remove</th>\n",
       "      <th>Task</th>\n",
       "      <th>metric name</th>\n",
       "      <th>paper</th>\n",
       "      <th>paper_path</th>\n",
       "      <th>paper_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IC15</td>\n",
       "      <td># 10</td>\n",
       "      <td>F-Measure</td>\n",
       "      <td>75.61%</td>\n",
       "      <td>SegLink</td>\n",
       "      <td>-</td>\n",
       "      <td>Scene Text Detection</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Detecting Oriented Text in Natural Images by L...</td>\n",
       "      <td>/paper/detecting-oriented-text-in-natural-imag...</td>\n",
       "      <td>https://arxiv.org/pdf/1703.06520v3.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SCUT-CTW1500</td>\n",
       "      <td># 5</td>\n",
       "      <td>F-Measure</td>\n",
       "      <td>40.8%</td>\n",
       "      <td>SegLink</td>\n",
       "      <td>-</td>\n",
       "      <td>Curved Text Detection</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Detecting Oriented Text in Natural Images by L...</td>\n",
       "      <td>/paper/detecting-oriented-text-in-natural-imag...</td>\n",
       "      <td>https://arxiv.org/pdf/1703.06520v3.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SNLI</td>\n",
       "      <td># 36</td>\n",
       "      <td>% Test Accuracy</td>\n",
       "      <td>84.6</td>\n",
       "      <td>300D NSE encoders</td>\n",
       "      <td>-</td>\n",
       "      <td>Natural Language Inference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neural Semantic Encoders</td>\n",
       "      <td>/paper/neural-semantic-encoders</td>\n",
       "      <td>https://arxiv.org/pdf/1607.04315v3.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SNLI</td>\n",
       "      <td># 44</td>\n",
       "      <td>% Train Accuracy</td>\n",
       "      <td>86.2</td>\n",
       "      <td>300D NSE encoders</td>\n",
       "      <td>-</td>\n",
       "      <td>Natural Language Inference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neural Semantic Encoders</td>\n",
       "      <td>/paper/neural-semantic-encoders</td>\n",
       "      <td>https://arxiv.org/pdf/1607.04315v3.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SNLI</td>\n",
       "      <td># 1</td>\n",
       "      <td>Parameters</td>\n",
       "      <td>3.0m</td>\n",
       "      <td>300D NSE encoders</td>\n",
       "      <td>-</td>\n",
       "      <td>Natural Language Inference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neural Semantic Encoders</td>\n",
       "      <td>/paper/neural-semantic-encoders</td>\n",
       "      <td>https://arxiv.org/pdf/1607.04315v3.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dataset Global rank       Metric name Metric value              Model  \\\n",
       "0          IC15        # 10         F-Measure       75.61%            SegLink   \n",
       "1  SCUT-CTW1500         # 5         F-Measure        40.8%            SegLink   \n",
       "2          SNLI        # 36   % Test Accuracy         84.6  300D NSE encoders   \n",
       "3          SNLI        # 44  % Train Accuracy         86.2  300D NSE encoders   \n",
       "4          SNLI         # 1        Parameters         3.0m  300D NSE encoders   \n",
       "\n",
       "  Remove                        Task metric name  \\\n",
       "0      -        Scene Text Detection         NaN   \n",
       "1      -       Curved Text Detection         NaN   \n",
       "2      -  Natural Language Inference         NaN   \n",
       "3      -  Natural Language Inference         NaN   \n",
       "4      -  Natural Language Inference         NaN   \n",
       "\n",
       "                                               paper  \\\n",
       "0  Detecting Oriented Text in Natural Images by L...   \n",
       "1  Detecting Oriented Text in Natural Images by L...   \n",
       "2                           Neural Semantic Encoders   \n",
       "3                           Neural Semantic Encoders   \n",
       "4                           Neural Semantic Encoders   \n",
       "\n",
       "                                          paper_path  \\\n",
       "0  /paper/detecting-oriented-text-in-natural-imag...   \n",
       "1  /paper/detecting-oriented-text-in-natural-imag...   \n",
       "2                    /paper/neural-semantic-encoders   \n",
       "3                    /paper/neural-semantic-encoders   \n",
       "4                    /paper/neural-semantic-encoders   \n",
       "\n",
       "                                paper_url  \n",
       "0  https://arxiv.org/pdf/1703.06520v3.pdf  \n",
       "1  https://arxiv.org/pdf/1703.06520v3.pdf  \n",
       "2  https://arxiv.org/pdf/1607.04315v3.pdf  \n",
       "3  https://arxiv.org/pdf/1607.04315v3.pdf  \n",
       "4  https://arxiv.org/pdf/1607.04315v3.pdf  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resets the index on the model_data dataframe \n",
    "model_data = model_data.reset_index(drop=True)\n",
    "\n",
    "# drops the remove column on the model_data dataframe\n",
    "model_data = model_data.drop('remove', 1)\n",
    "\n",
    "model_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports the model_data dataframe to csv\n",
    "model_data.to_csv('/Users/nialdaly/Documents/ml_optimisation/data/pw_code_model_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads the paper_titles.txt file\n",
    "# paper_data = open('/Users/nialdaly/Desktop/paper_titles.txt', \"r\")\n",
    "\n",
    "# #\n",
    "# paper_data = paper_data.read().split('\\n')\n",
    "\n",
    "# # removes the empty strings from the paper_data list \n",
    "# paper_data = [x for x in paper_data if x]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1319"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paper_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/paper/face-alignment-across-large-poses-a-3d',\n",
       " '/paper/outrageously-large-neural-networks-the',\n",
       " '/paper/beyond-a-gaussian-denoiser-residual-learning',\n",
       " '/paper/learning-to-compose-task-specific-tree',\n",
       " '/paper/horizonnet-learning-room-layout-with-1d',\n",
       " '/paper/natural-language-inference-with-hierarchical',\n",
       " '/paper/hyperbolic-representation-learning-for-fast',\n",
       " '/paper/a-large-annotated-corpus-for-learning-natural',\n",
       " '/paper/deep-fried-convnets',\n",
       " '/paper/multilingual-part-of-speech-tagging-with',\n",
       " '/paper/position-aware-attention-and-supervised-data',\n",
       " '/paper/cgans-with-projection-discriminator',\n",
       " '/paper/cutting-the-error-by-half-investigation-of',\n",
       " '/paper/tucker-tensor-factorization-for-knowledge',\n",
       " '/paper/higher-order-conditional-random-fields-in',\n",
       " '/paper/shape-robust-text-detection-with-progressive',\n",
       " '/paper/multimodal-speech-emotion-recognition-and',\n",
       " '/paper/distractor-aware-siamese-networks-for-visual',\n",
       " '/paper/a-large-self-annotated-corpus-for-sarcasm',\n",
       " '/paper/a-bert-baseline-for-the-natural-questions',\n",
       " '/paper/east-an-efficient-and-accurate-scene-text',\n",
       " '/paper/towards-faster-training-of-global-covariance',\n",
       " '/paper/striving-for-simplicity-the-all-convolutional',\n",
       " '/paper/corners-for-layout-end-to-end-layout-recovery',\n",
       " '/paper/committees-of-deep-feedforward-networks',\n",
       " '/paper/face-attention-network-an-effective-face',\n",
       " '/paper/exploiting-document-knowledge-for-aspect',\n",
       " '/paper/eraserelu-a-simple-way-to-ease-the-training',\n",
       " '/paper/learning-latent-dynamics-for-planning-from',\n",
       " '/paper/fast-accurate-and-lightweight-super-1',\n",
       " '/paper/hypernetworks',\n",
       " '/paper/attention-based-ensemble-for-deep-metric',\n",
       " '/paper/recurrent-neural-network-regularization',\n",
       " '/paper/spectral-representations-for-convolutional-1',\n",
       " '/paper/learned-in-translation-contextualized-word',\n",
       " '/paper/attentional-encoder-network-for-targeted',\n",
       " '/paper/transformation-networks-for-target-oriented',\n",
       " '/paper/image-reconstruction-with-predictive-filter',\n",
       " '/paper/bag-of-tricks-for-efficient-text',\n",
       " '/paper/transferring-rich-deep-features-for-facial',\n",
       " '/paper/a-qualitative-comparison-of-coqa-squad-20-and',\n",
       " '/paper/large-kernel-matters-improve-semantic',\n",
       " '/paper/aspect-level-sentiment-classification-with-1',\n",
       " '/paper/jasper-an-end-to-end-convolutional-neural',\n",
       " '/paper/modeling-semantics-with-gated-graph-neural-1',\n",
       " '/paper/generating-long-sequences-with-sparse',\n",
       " '/paper/transfer-learning-for-sequence-tagging-with',\n",
       " '/paper/the-one-hundred-layers-tiramisu-fully',\n",
       " '/paper/contextlocnet-context-aware-deep-network',\n",
       " '/paper/multi-task-learning-as-multi-objective',\n",
       " '/paper/road-extraction-by-deep-residual-u-net',\n",
       " '/paper/multiple-human-parsing-in-the-wild',\n",
       " '/paper/a-parallel-hierarchical-model-for-machine',\n",
       " '/paper/sesr-single-image-super-resolution-with',\n",
       " '/paper/on-tree-based-neural-sentence-modeling',\n",
       " '/paper/letter-based-speech-recognition-with-gated',\n",
       " '/paper/random-erasing-data-augmentation',\n",
       " '/paper/parsing-as-language-modeling',\n",
       " '/paper/enhancenet-single-image-super-resolution',\n",
       " '/paper/3d-mri-brain-tumor-segmentation-using',\n",
       " '/paper/the-microsoft-2016-conversational-speech',\n",
       " '/paper/reading-wikipedia-to-answer-open-domain',\n",
       " '/paper/deep-recurrent-generative-decoder-for-1',\n",
       " '/paper/graph-structured-representations-for-visual',\n",
       " '/paper/zigzag-learning-for-weakly-supervised-object',\n",
       " '/paper/deep-networks-with-stochastic-depth',\n",
       " '/paper/an-actor-critic-algorithm-for-sequence',\n",
       " '/paper/deep-models-of-interactions-across-sets',\n",
       " '/paper/path-aggregation-network-for-instance',\n",
       " '/paper/dialoguernn-an-attentive-rnn-for-emotion',\n",
       " '/paper/a-convolutional-encoder-model-for-neural',\n",
       " '/paper/u-net-machine-reading-comprehension-with',\n",
       " '/paper/dual-agent-gans-for-photorealistic-and',\n",
       " '/paper/residual-dense-network-for-image-super',\n",
       " '/paper/stacked-hourglass-networks-for-human-pose',\n",
       " '/paper/all-but-the-top-simple-and-effective',\n",
       " '/paper/sjtu-nlp-at-semeval-2018-task-9-neural-1',\n",
       " '/paper/coarse-to-fine-attention-models-for-document',\n",
       " '/paper/invertible-conditional-gans-for-image-editing',\n",
       " '/paper/hyperdense-net-a-hyper-densely-connected-cnn',\n",
       " '/paper/look-at-boundary-a-boundary-aware-face',\n",
       " '/paper/neural-aggregation-network-for-video-face',\n",
       " '/paper/multi-context-attention-for-human-pose',\n",
       " '/paper/achieving-human-parity-in-conversational',\n",
       " '/paper/discriminative-neural-sentence-modeling-by',\n",
       " '/paper/deep-contextualized-word-representations-1',\n",
       " '/paper/regularized-evolution-for-image-classifier',\n",
       " '/paper/efficient-architecture-search-by-network',\n",
       " '/paper/deepim-deep-iterative-matching-for-6d-pose',\n",
       " '/paper/unimelb-at-semeval-2016-tasks-4a-and-4b-an',\n",
       " '/paper/batch-normalized-maxout-network-in-network',\n",
       " '/paper/arttrack-articulated-multi-person-tracking-in',\n",
       " '/paper/kepler-keypoint-and-pose-estimation-of',\n",
       " '/paper/reinforced-self-attention-network-a-hybrid-of',\n",
       " '/paper/drop-an-octave-reducing-spatial-redundancy-in',\n",
       " '/paper/pronet-learning-to-propose-object-specific',\n",
       " '/paper/robust-face-detection-via-learning-small',\n",
       " '/paper/reinforced-mnemonic-reader-for-machine',\n",
       " '/paper/amr-parsing-with-an-incremental-joint-model',\n",
       " '/paper/pairwise-word-interaction-modeling-with-deep',\n",
       " '/paper/holistic-instance-level-human-parsing',\n",
       " '/paper/high-accuracy-rule-based-question',\n",
       " '/paper/universum-prescription-regularization-using',\n",
       " '/paper/ensure-the-correctness-of-the-summary',\n",
       " '/paper/spider-a-large-scale-human-labeled-dataset',\n",
       " '/paper/large-scale-fine-grained-categorization-and',\n",
       " '/paper/breaking-the-softmax-bottleneck-a-high-rank',\n",
       " '/paper/ghostvlad-for-set-based-face-recognition',\n",
       " '/paper/challenges-in-data-to-document-generation',\n",
       " '/paper/a-simple-and-effective-approach-to-the-story-1',\n",
       " '/paper/invariant-information-distillation-for',\n",
       " '/paper/variational-autoencoders-for-collaborative',\n",
       " '/paper/tnt-nlg-system-1-using-a-statistical-nlg-to',\n",
       " '/paper/joint-3d-face-reconstruction-and-dense-face',\n",
       " '/paper/discriminative-transfer-learning-with-tree',\n",
       " '/paper/understanding-back-translation-at-scale',\n",
       " '/paper/grammar-as-a-foreign-language',\n",
       " '/paper/high-level-semantic-feature-detectiona-new',\n",
       " '/paper/a-simple-way-to-initialize-recurrent-networks',\n",
       " '/paper/kernelized-synaptic-weight-matrices',\n",
       " '/paper/convolutional-2d-knowledge-graph-embeddings',\n",
       " '/paper/infogan-interpretable-representation-learning',\n",
       " '/paper/discriminative-correlation-filter-with',\n",
       " '/paper/learning-to-reason-end-to-end-module-networks',\n",
       " '/paper/generating-high-fidelity-images-with-subscale',\n",
       " '/paper/dialogue-learning-with-human-teaching-and',\n",
       " '/paper/glow-generative-flow-with-invertible-1x1',\n",
       " '/paper/context-encoding-for-semantic-segmentation',\n",
       " '/paper/pixelcnn-improving-the-pixelcnn-with',\n",
       " '/paper/image-super-resolution-via-rl-csc-when',\n",
       " '/paper/generalizing-pooling-functions-in',\n",
       " '/paper/a-novel-focal-tversky-loss-function-with',\n",
       " '/paper/emo2vec-learning-generalized-emotion',\n",
       " '/paper/conditional-random-fields-as-recurrent-neural',\n",
       " '/paper/pcl-proposal-cluster-learning-for-weakly',\n",
       " '/paper/semi-supervised-word-sense-disambiguation-1',\n",
       " '/paper/simple-recurrent-units-for-highly',\n",
       " '/paper/massively-multilingual-sentence-embeddings',\n",
       " '/paper/3d-face-morphable-models-in-the-wild',\n",
       " '/paper/revisiting-semi-supervised-learning-with',\n",
       " '/paper/flow-guided-feature-aggregation-for-video',\n",
       " '/paper/explaining-and-harnessing-adversarial',\n",
       " '/paper/10000-times-accelerated-robust-subset',\n",
       " '/paper/gcnet-non-local-networks-meet-squeeze',\n",
       " '/paper/attention-u-net-learning-where-to-look-for',\n",
       " '/paper/deep-exploration-via-bootstrapped-dqn',\n",
       " '/paper/adversarial-training-methods-for-semi',\n",
       " '/paper/unsupervised-machine-translation-using',\n",
       " '/paper/soft-proposal-networks-for-weakly-supervised',\n",
       " '/paper/learning-deep-cnn-denoiser-prior-for-image',\n",
       " '/paper/pragmatically-informative-text-generation',\n",
       " '/paper/jointly-learning-to-label-sentences-and',\n",
       " '/paper/esrgan-enhanced-super-resolution-generative',\n",
       " '/paper/monoise-modeling-noise-using-a-modular',\n",
       " '/paper/enhancing-sentence-embedding-with-generalized',\n",
       " '/paper/cascade-r-cnn-delving-into-high-quality',\n",
       " '/paper/mastering-chess-and-shogi-by-self-play-with-a',\n",
       " '/paper/learning-recurrent-span-representations-for',\n",
       " '/paper/multicolumn-networks-for-face-recognition',\n",
       " '/paper/fractional-max-pooling',\n",
       " '/paper/multi-task-graph-autoencoders',\n",
       " '/paper/predictive-business-process-monitoring-with',\n",
       " '/paper/linguistically-informed-self-attention-for',\n",
       " '/paper/weakly-supervised-cascaded-convolutional',\n",
       " '/paper/distributed-prioritized-experience-replay',\n",
       " '/paper/non-autoregressive-neural-machine-translation-1',\n",
       " '/paper/a-fully-progressive-approach-to-single-image',\n",
       " '/paper/reasoning-about-entailment-with-neural',\n",
       " '/paper/very-deep-multilingual-convolutional-neural',\n",
       " '/paper/fine-grained-head-pose-estimation-without',\n",
       " '/paper/deep-self-taught-learning-for-weakly',\n",
       " '/paper/incorporating-glosses-into-neural-word-sense',\n",
       " '/paper/fpnn-field-probing-neural-networks-for-3d',\n",
       " '/paper/pay-less-attention-with-lightweight-and',\n",
       " '/paper/realtime-multi-person-2d-pose-estimation',\n",
       " '/paper/contextualized-word-representations-for',\n",
       " '/paper/multi-oriented-scene-text-detection-via',\n",
       " '/paper/do-we-really-need-to-collect-millions-of',\n",
       " '/paper/recurrent-residual-convolutional-neural',\n",
       " '/paper/universal-sentence-encoder',\n",
       " '/paper/pointpillars-fast-encoders-for-object',\n",
       " '/paper/bottom-up-abstractive-summarization',\n",
       " '/paper/mask-r-cnn',\n",
       " '/paper/an-energy-and-gpu-computation-efficient',\n",
       " '/paper/supervised-and-semi-supervised-text',\n",
       " '/paper/retrieve-rerank-and-rewrite-soft-template',\n",
       " '/paper/structure-infused-copy-mechanisms-for-1',\n",
       " '/paper/deep-back-projection-networks-for-super',\n",
       " '/paper/graph-convolutional-networks-for-text',\n",
       " '/paper/lr-gan-layered-recursive-generative',\n",
       " '/paper/a-discriminatively-learned-cnn-embedding-for',\n",
       " '/paper/count-based-exploration-in-feature-space-for',\n",
       " '/paper/bert-pre-training-of-deep-bidirectional',\n",
       " '/paper/deep-biaffine-attention-for-neural-dependency',\n",
       " '/paper/anonymous-walk-embeddings',\n",
       " '/paper/bidirectional-attention-flow-for-machine',\n",
       " '/paper/models-matter-so-does-training-an-empirical',\n",
       " '/paper/neural-semantic-encoders',\n",
       " '/paper/adaptively-connected-neural-networks',\n",
       " '/paper/inferencing-based-on-unsupervised-learning-of',\n",
       " '/paper/deep-high-resolution-representation-learning',\n",
       " '/paper/effective-lstms-for-target-dependent',\n",
       " '/paper/cesi-canonicalizing-open-knowledge-bases',\n",
       " '/paper/deep-triplet-quantization',\n",
       " '/paper/face-detection-with-end-to-end-integration-of',\n",
       " '/paper/photographic-image-synthesis-with-cascaded',\n",
       " '/paper/recurrent-attention-network-on-memory-for',\n",
       " '/paper/practical-bayesian-optimization-of-machine-1',\n",
       " '/paper/scaling-memory-augmented-neural-networks-with',\n",
       " '/paper/efficient-piecewise-training-of-deep',\n",
       " '/paper/deep-residual-networks-with-exponential',\n",
       " '/paper/read-verify-machine-reading-comprehension',\n",
       " '/paper/first-order-generative-adversarial-networks',\n",
       " '/paper/what-can-help-pedestrian-detection',\n",
       " '/paper/tacotron-towards-end-to-end-speech-synthesis',\n",
       " '/paper/deepvisage-making-face-recognition-simple-yet',\n",
       " '/paper/densepose-dense-human-pose-estimation-in-the',\n",
       " '/paper/learning-what-and-where-to-draw',\n",
       " '/paper/weakly-supervised-deep-detection-networks',\n",
       " '/paper/measuring-the-evolution-of-a-scientific-field',\n",
       " '/paper/high-quality-facial-photo-sketch-synthesis',\n",
       " '/paper/sentence-similarity-learning-by-lexical',\n",
       " '/paper/easy-transfer-learning-by-exploiting-intra',\n",
       " '/paper/direct-output-connection-for-a-high-rank',\n",
       " '/paper/optical-flow-estimation-using-a-spatial',\n",
       " '/paper/the-reactor-a-fast-and-sample-efficient-actor',\n",
       " '/paper/context-based-approach-for-second-language',\n",
       " '/paper/spatial-pyramid-pooling-in-deep-convolutional',\n",
       " '/paper/refinenet-multi-path-refinement-networks-for',\n",
       " '/paper/on-the-role-of-text-preprocessing-in-neural',\n",
       " '/paper/bottom-up-and-top-down-attention-for-image',\n",
       " '/paper/pyramidbox-a-context-assisted-single-shot',\n",
       " '/paper/pose-invariant-face-alignment-with-a-single',\n",
       " '/paper/learning-efficient-single-stage-pedestrian',\n",
       " '/paper/shortcut-stacked-sentence-encoders-for-multi',\n",
       " '/paper/recurrent-entity-networks-with-delayed-memory-1',\n",
       " '/paper/an-improved-neural-network-model-for-joint',\n",
       " '/paper/mobilenets-efficient-convolutional-neural',\n",
       " '/paper/large-scale-simple-question-answering-with',\n",
       " '/paper/learning-complexity-aware-cascades-for-deep',\n",
       " '/paper/pointfusion-deep-sensor-fusion-for-3d',\n",
       " '/paper/count-based-exploration-with-neural-density',\n",
       " '/paper/language-modeling-with-gated-convolutional',\n",
       " '/paper/semantic-sentence-matching-with-densely',\n",
       " '/paper/nice-non-linear-independent-components',\n",
       " '/paper/jointly-predicting-predicates-and-arguments-1',\n",
       " '/paper/semantic-instance-segmentation-with-a',\n",
       " '/paper/story-comprehension-for-predicting-what',\n",
       " '/paper/translations-as-additional-contexts-for',\n",
       " '/paper/spidercnn-deep-learning-on-point-sets-with',\n",
       " '/paper/an-all-in-one-convolutional-neural-network',\n",
       " '/paper/understanding-humans-in-crowded-scenes-deep',\n",
       " '/paper/fots-fast-oriented-text-spotting-with-a',\n",
       " '/paper/complex-embeddings-for-simple-link-prediction',\n",
       " '/paper/acquisition-of-localization-confidence-for',\n",
       " '/paper/stochastic-pooling-for-regularization-of-deep',\n",
       " '/paper/style-aggregated-network-for-facial-landmark',\n",
       " '/paper/end-to-end-sequence-labeling-via-bi',\n",
       " '/paper/knowledge-guided-deep-fractal-neural-networks',\n",
       " '/paper/multi-range-reasoning-for-machine',\n",
       " '/paper/stochastic-answer-networks-for-machine',\n",
       " '/paper/arcface-additive-angular-margin-loss-for-deep',\n",
       " '/paper/pointnet-deep-learning-on-point-sets-for-3d',\n",
       " '/paper/fast-slow-recurrent-neural-networks',\n",
       " '/paper/deep-fusion-lstms-for-text-semantic-matching',\n",
       " '/paper/revisiting-unreasonable-effectiveness-of-data',\n",
       " '/paper/snips-voice-platform-an-embedded-spoken',\n",
       " '/paper/you-only-look-once-unified-real-time-object',\n",
       " '/paper/multiposenet-fast-multi-person-pose',\n",
       " '/paper/w2f-a-weakly-supervised-to-fully-supervised',\n",
       " '/paper/conditional-random-fields-as-recurrent-neural-1',\n",
       " '/paper/inception-v4-inception-resnet-and-the-impact',\n",
       " '/paper/do-convnets-learn-correspondence',\n",
       " '/paper/generative-partition-networks-for-multi',\n",
       " '/paper/submanifold-sparse-convolutional-networks',\n",
       " '/paper/wider-face-a-face-detection-benchmark',\n",
       " '/paper/conditional-image-generation-with-pixelcnn',\n",
       " '/paper/grounded-textual-entailment',\n",
       " '/paper/filtered-channel-features-for-pedestrian',\n",
       " '/paper/sentiment-analysis-by-capsules',\n",
       " '/paper/utilizing-bert-for-aspect-based-sentiment',\n",
       " '/paper/dilated-recurrent-neural-networks',\n",
       " '/paper/high-fidelity-image-generation-with-fewer',\n",
       " '/paper/a-fast-and-accurate-unconstrained-face',\n",
       " '/paper/part-based-r-cnns-for-fine-grained-category',\n",
       " '/paper/approaching-neural-grammatical-error-1',\n",
       " '/paper/multi-digit-number-recognition-from-street',\n",
       " '/paper/context-aware-representations-for-knowledge',\n",
       " '/paper/bisenet-bilateral-segmentation-network-for',\n",
       " '/paper/learning-a-discriminative-feature-network-for',\n",
       " '/paper/learning-natural-language-inference-with-lstm',\n",
       " '/paper/seqface-make-full-use-of-sequence-information',\n",
       " '/paper/how-far-are-we-from-solving-the-2d-3d-face',\n",
       " '/paper/skip-gram-language-modeling-using-sparse-non',\n",
       " '/paper/a-neural-transition-based-model-for-nested',\n",
       " '/paper/conditional-image-synthesis-with-auxiliary',\n",
       " '/paper/the-arcade-learning-environment-an-evaluation',\n",
       " '/paper/edinburgh-neural-machine-translation-systems',\n",
       " '/paper/deep-image-retrieval-learning-global',\n",
       " '/paper/m2det-a-single-shot-object-detector-based-on',\n",
       " '/paper/gradient-harmonized-single-stage-detector',\n",
       " '/paper/blitznet-a-real-time-deep-network-for-scene',\n",
       " '/paper/recognizing-disguised-faces-in-the-wild',\n",
       " '/paper/meta-transfer-learning-for-few-shot-learning',\n",
       " '/paper/neural-ranking-models-with-weak-supervision',\n",
       " '/paper/convolutional-networks-on-graphs-for-learning',\n",
       " '/paper/multi-person-pose-estimation-with-local-joint',\n",
       " '/paper/gated-orthogonal-recurrent-units-on-learning',\n",
       " '/paper/cut-to-the-chase-a-context-zoom-in-network',\n",
       " '/paper/dynamic-routing-between-capsules',\n",
       " '/paper/focused-hierarchical-rnns-for-conditional',\n",
       " '/paper/ncrf-an-open-source-neural-sequence-labeling',\n",
       " '/paper/face-detection-using-improved-faster-rcnn',\n",
       " '/paper/learning-semantic-sentence-embeddings-using',\n",
       " '/paper/calibrating-energy-based-generative',\n",
       " '/paper/improving-neural-language-models-with-a',\n",
       " '/paper/pixel2mesh-generating-3d-mesh-models-from',\n",
       " '/paper/impala-scalable-distributed-deep-rl-with',\n",
       " '/paper/generating-multiple-objects-at-spatially',\n",
       " '/paper/overfeat-integrated-recognition-localization',\n",
       " '/paper/making-neural-qa-as-simple-as-possible-but',\n",
       " '/paper/massively-parallel-methods-for-deep',\n",
       " '/paper/text-understanding-with-the-attention-sum',\n",
       " '/paper/fully-convolutional-speech-recognition',\n",
       " '/paper/stacked-attention-networks-for-image-question',\n",
       " '/paper/scalable-person-re-identification-a-benchmark',\n",
       " '/paper/deep-recurrent-neural-networks-for-acoustic',\n",
       " '/paper/exploring-question-understanding-and',\n",
       " '/paper/a-hierarchical-deep-architecture-and-mini',\n",
       " '/paper/instance-level-human-parsing-via-part',\n",
       " '/paper/long-term-feature-banks-for-detailed-video',\n",
       " '/paper/au-r-cnn-encoding-expert-prior-knowledge-into',\n",
       " '/paper/semi-supervised-classification-with-graph',\n",
       " '/paper/an-analysis-of-neural-language-modeling-at',\n",
       " '/paper/deep-label-distribution-learning-with-label',\n",
       " '/paper/scaling-neural-machine-translation',\n",
       " '/paper/subunets-end-to-end-hand-shape-and-continuous',\n",
       " '/paper/layoutnet-reconstructing-the-3d-room-layout',\n",
       " '/paper/mode-seeking-generative-adversarial-networks',\n",
       " '/paper/long-text-generation-via-adversarial-training',\n",
       " '/paper/improved-variational-autoencoders-for-text',\n",
       " '/paper/is-faster-r-cnn-doing-well-for-pedestrian',\n",
       " '/paper/casenet-deep-category-aware-semantic-edge',\n",
       " '/paper/scale-aware-fast-r-cnn-for-pedestrian',\n",
       " '/paper/light-gated-recurrent-units-for-speech',\n",
       " '/paper/quo-vadis-action-recognition-a-new-model-and',\n",
       " '/paper/aspect-based-sentiment-analysis-using-bitmask',\n",
       " '/paper/hybrid-recommender-system-based-on',\n",
       " '/paper/face-search-at-scale-80-million-gallery',\n",
       " '/paper/deep-convolutional-decision-jungle-for-image',\n",
       " '/paper/mildnet-a-lightweight-single-scaled-deep',\n",
       " '/paper/multi-perspective-context-matching-for',\n",
       " '/paper/a-language-model-based-evaluator-for-sentence',\n",
       " '/paper/learning-context-sensitive-convolutional',\n",
       " '/paper/parsing-r-cnn-for-instance-level-human',\n",
       " '/paper/anytime-stereo-image-depth-estimation-on',\n",
       " '/paper/query-reduction-networks-for-question',\n",
       " '/paper/unsupervised-statistical-machine-translation',\n",
       " '/paper/a-neural-autoregressive-approach-to',\n",
       " '/paper/training-region-based-object-detectors-with',\n",
       " '/paper/image-super-resolution-via-feature-augmented',\n",
       " '/paper/fusionnet-fusing-via-fully-aware-attention',\n",
       " '/paper/a-unified-multi-scale-deep-convolutional',\n",
       " '/paper/memnet-a-persistent-memory-network-for-image',\n",
       " '/paper/deep-semantic-role-labeling-with-self',\n",
       " '/paper/high-performance-visual-tracking-with-siamese',\n",
       " '/paper/hardness-aware-deep-metric-learning',\n",
       " '/paper/contextual-inter-modal-attention-for-multi',\n",
       " '/paper/joint-maximum-purity-forest-with-application',\n",
       " '/paper/min-entropy-latent-model-for-weakly',\n",
       " '/paper/unsupervised-neural-machine-translation-1',\n",
       " '/paper/scibert-pretrained-contextualized-embeddings',\n",
       " '/paper/compressed-video-action-recognition',\n",
       " '/paper/learning-to-make-predictions-on-graphs-with',\n",
       " '/paper/embedding-entities-and-relations-for-learning',\n",
       " '/paper/deformable-convnets-v2-more-deformable-better',\n",
       " '/paper/hierarchical-question-image-co-attention-for',\n",
       " '/paper/perceptual-losses-for-real-time-style',\n",
       " '/paper/quality-aware-network-for-set-to-set',\n",
       " '/paper/convolutional-sequence-to-sequence-learning',\n",
       " '/paper/commonsense-for-generative-multi-hop-question',\n",
       " '/paper/feature-pyramid-networks-for-object-detection',\n",
       " '/paper/deep-learning-face-representation-by-joint',\n",
       " '/paper/image-captioning-and-visual-question',\n",
       " '/paper/learning-to-cluster-for-proposal-free',\n",
       " '/paper/abstractive-sentence-summarization-with',\n",
       " '/paper/fast-online-object-tracking-and-segmentation',\n",
       " '/paper/learning-deep-parsimonious-representations',\n",
       " '/paper/adversarial-autoencoders',\n",
       " '/paper/icnet-for-real-time-semantic-segmentation-on',\n",
       " '/paper/liteflownet-a-lightweight-convolutional',\n",
       " '/paper/deepprior-improving-fast-and-accurate-3d-hand',\n",
       " '/paper/iarm-inter-aspect-relation-modeling-with',\n",
       " '/paper/image-transformer',\n",
       " '/paper/crim-at-semeval-2018-task-9-a-hybrid-approach',\n",
       " '/paper/pose2seg-detection-free-human-instance',\n",
       " '/paper/person-re-identification-by-local-maximal',\n",
       " '/paper/r2cnn-rotational-region-cnn-for-orientation',\n",
       " '/paper/to-boost-or-not-to-boost-on-the-limits-of',\n",
       " '/paper/towards-a-neural-statistician',\n",
       " '/paper/learning-convolutional-neural-networks-for',\n",
       " '/paper/fully-convolutional-networks-for-semantic-1',\n",
       " '/paper/softer-nms-rethinking-bounding-box-regression',\n",
       " '/paper/full-resolution-residual-networks-for',\n",
       " '/paper/improved-language-modeling-by-decoding-the',\n",
       " '/paper/a-question-focused-multi-factor-attention',\n",
       " '/paper/neural-nearest-neighbors-networks',\n",
       " '/paper/lets-keep-it-simple-using-simple',\n",
       " '/paper/mutan-multimodal-tucker-fusion-for-visual',\n",
       " '/paper/a-deep-ensemble-model-with-slot-alignment-for',\n",
       " '/paper/margin-based-parallel-corpus-mining-with',\n",
       " '/paper/compositional-sequence-labeling-models-for',\n",
       " '/paper/count-based-exploration-with-the-successor',\n",
       " '/paper/l2-constrained-softmax-loss-for',\n",
       " '/paper/learning-values-across-many-orders-of',\n",
       " '/paper/hierarchical-attention-networks-for-document',\n",
       " '/paper/dialogue-act-recognition-via-crf-attentive',\n",
       " '/paper/deep-laplacian-pyramid-networks-for-fast-and',\n",
       " '/paper/parsenet-looking-wider-to-see-better',\n",
       " '/paper/glue-a-multi-task-benchmark-and-analysis',\n",
       " '/paper/starmap-for-category-agnostic-keypoint-and',\n",
       " '/paper/self-attention-with-relative-position',\n",
       " '/paper/recovering-realistic-texture-in-image-super',\n",
       " '/paper/passage-re-ranking-with-bert',\n",
       " '/paper/a-structured-learning-approach-to-temporal',\n",
       " '/paper/temporal-ensembling-for-semi-supervised',\n",
       " '/paper/deep-multi-center-learning-for-face-alignment',\n",
       " '/paper/exploiting-temporal-information-for-3d-pose',\n",
       " '/paper/an-auto-encoder-matching-model-for-learning',\n",
       " '/paper/deep-relevance-ranking-using-enhanced',\n",
       " '/paper/canonical-tensor-decomposition-for-knowledge',\n",
       " '/paper/ganfit-generative-adversarial-network-fitting',\n",
       " '/paper/attention-over-attention-neural-networks-for',\n",
       " '/paper/the-neural-hype-and-comparisons-against-weak',\n",
       " '/paper/diverse-image-to-image-translation-via',\n",
       " '/paper/pointrcnn-3d-object-proposal-generation-and',\n",
       " '/paper/graph2seq-graph-to-sequence-learning-with',\n",
       " '/paper/camera-style-adaptation-for-person-re',\n",
       " '/paper/partially-shuffling-the-training-data-to',\n",
       " '/paper/semi-amortized-variational-autoencoders',\n",
       " '/paper/pushing-the-bounds-of-dropout',\n",
       " '/paper/190406472',\n",
       " '/paper/attngan-fine-grained-text-to-image-generation',\n",
       " '/paper/towards-a-better-match-in-siamese-network',\n",
       " '/paper/simple-baseline-for-visual-question-answering',\n",
       " '/paper/sentence-state-lstm-for-text-representation',\n",
       " '/paper/convolutional-sequence-modeling-revisited',\n",
       " '/paper/recurrent-relational-networks',\n",
       " '/paper/interactive-attention-networks-for-aspect',\n",
       " '/paper/non-local-neural-networks',\n",
       " '/paper/triplet-probabilistic-embedding-for-face',\n",
       " '/paper/simple-baselines-for-human-pose-estimation',\n",
       " '/paper/neural-architecture-search-with-reinforcement',\n",
       " '/paper/focal-loss-for-dense-object-detection',\n",
       " '/paper/nonlinear-3d-face-morphable-model',\n",
       " '/paper/density-estimation-using-real-nvp',\n",
       " '/paper/seven-ways-to-improve-example-based-single',\n",
       " '/paper/natural-language-comprehension-with-the',\n",
       " '/paper/unsupervised-data-augmentation',\n",
       " '/paper/deepcut-joint-subset-partition-and-labeling',\n",
       " '/paper/real-time-seamless-single-shot-6d-object-pose',\n",
       " '/paper/in-order-transition-based-constituent-parsing-1',\n",
       " '/paper/apac-augmented-pattern-classification-with',\n",
       " '/paper/seqgan-sequence-generative-adversarial-nets',\n",
       " '/paper/from-pos-tagging-to-dependency-parsing-for',\n",
       " '/paper/aggregated-residual-transformations-for-deep',\n",
       " '/paper/model-unit-exploration-for-sequence-to',\n",
       " '/paper/modeling-relationships-in-referential',\n",
       " '/paper/a-span-selection-model-for-semantic-role',\n",
       " '/paper/deep-learning-over-multi-field-categorical',\n",
       " '/paper/v2v-posenet-voxel-to-voxel-prediction-network',\n",
       " '/paper/words-or-characters-fine-grained-gating-for',\n",
       " '/paper/hd-cnn-hierarchical-deep-convolutional-neural',\n",
       " '/paper/bass-net-band-adaptive-spectral-spatial',\n",
       " '/paper/convolutional-neural-networks-on-graphs-with',\n",
       " '/paper/decoders-matter-for-semantic-segmentation',\n",
       " '/paper/evolution-strategies-as-a-scalable',\n",
       " '/paper/centernet-object-detection-with-keypoint',\n",
       " '/paper/shufflenet-an-extremely-efficient',\n",
       " '/paper/xdeepfm-combining-explicit-and-implicit',\n",
       " '/paper/in-defense-of-the-triplet-loss-for-person-re',\n",
       " '/paper/semi-supervised-learning-for-face-sketch',\n",
       " '/paper/a-closer-look-at-few-shot-classification',\n",
       " '/paper/a-thorough-examination-of-the-cnndaily-mail',\n",
       " '/paper/recurrent-back-projection-network-for-video',\n",
       " '/paper/one-billion-word-benchmark-for-measuring',\n",
       " '/paper/sequence-to-sequence-learning-with-neural',\n",
       " '/paper/enhanced-lstm-for-natural-language-inference',\n",
       " '/paper/cms-rcnn-contextual-multi-scale-region-based',\n",
       " '/paper/unsupervised-neural-machine-translation',\n",
       " '/paper/facial-landmarks-detection-by-self-iterative',\n",
       " '/paper/beyond-skip-connections-top-down-modulation',\n",
       " '/paper/hi-fi-hierarchical-feature-integration-for',\n",
       " '/paper/neural-text-generation-from-structured-data',\n",
       " '/paper/parameterized-convolutional-neural-networks',\n",
       " '/paper/asynchronous-methods-for-deep-reinforcement',\n",
       " '/paper/speedaccuracy-trade-offs-for-modern',\n",
       " '/paper/learning-to-draw-samples-with-application-to',\n",
       " '/paper/a-multi-stage-memory-augmented-neural-network',\n",
       " '/paper/pwc-net-cnns-for-optical-flow-using-pyramid',\n",
       " '/paper/an-integral-pose-regression-system-for-the',\n",
       " '/paper/deep-reinforcement-learning-with-double-q',\n",
       " '/paper/evaluation-of-deep-convolutional-nets-for',\n",
       " '/paper/dependency-or-span-end-to-end-uniform',\n",
       " '/paper/tips-and-tricks-for-visual-question-answering',\n",
       " '/paper/strong-baselines-for-neural-semi-supervised',\n",
       " '/paper/stochastic-answer-networks-for-natural',\n",
       " '/paper/finding-function-in-form-compositional-1',\n",
       " '/paper/towards-neural-phrase-based-machine',\n",
       " '/paper/building-state-of-the-art-distant-speech',\n",
       " '/paper/compositional-coding-capsule-network-with-k',\n",
       " '/paper/multi-passage-machine-reading-comprehension',\n",
       " '/paper/exploring-joint-neural-model-for-sentence',\n",
       " '/paper/positional-encoding-to-control-output',\n",
       " '/paper/a-fast-unified-model-for-parsing-and-sentence',\n",
       " '/paper/dictionary-learning-for-massive-matrix',\n",
       " '/paper/zero-shot-super-resolution-using-deep',\n",
       " '/paper/learning-phrase-representations-using-rnn',\n",
       " '/paper/sdnet-contextualized-attention-based-deep',\n",
       " '/paper/detail-revealing-deep-video-super-resolution',\n",
       " '/paper/molecular-graph-convolutions-moving-beyond',\n",
       " '/paper/stargan-unified-generative-adversarial',\n",
       " '/paper/vpgnet-vanishing-point-guided-network-for',\n",
       " '/paper/multi-evidence-filtering-and-fusion-for-multi',\n",
       " '/paper/learning-general-purpose-distributed-sentence',\n",
       " '/paper/segmental-recurrent-neural-networks-for-end',\n",
       " '/paper/selective-encoding-for-abstractive-sentence-1',\n",
       " '/paper/fine-tune-bert-for-extractive-summarization',\n",
       " '/paper/voicefilter-targeted-voice-separation-by',\n",
       " '/paper/densely-connected-convolutional-networks',\n",
       " '/paper/multi-view-dynamic-facial-action-unit',\n",
       " '/paper/dialogue-act-sequence-labeling-using',\n",
       " '/paper/deep-contextualized-word-representations',\n",
       " '/paper/fera-2017-addressing-head-pose-in-the-third',\n",
       " '/paper/modelling-interaction-of-sentence-pair-with',\n",
       " '/paper/spatial-aggregation-of-holistically-nested-1',\n",
       " '/paper/a-character-level-decoder-without-explicit',\n",
       " '/paper/a-light-cnn-for-deep-face-representation-with',\n",
       " '/paper/deepfm-a-factorization-machine-based-neural',\n",
       " '/paper/discourse-marker-augmented-network-with',\n",
       " '/paper/deeply-learned-face-representations-are',\n",
       " '/paper/git-loss-for-deep-face-recognition',\n",
       " '/paper/trellis-networks-for-sequence-modeling',\n",
       " '/paper/convkn-at-semeval-2016-task-3-answer-and',\n",
       " '/paper/reseg-a-recurrent-neural-network-based-model',\n",
       " '/paper/learning-spatial-temporal-regularized',\n",
       " '/paper/stacked-what-where-auto-encoders',\n",
       " '/paper/the-relativistic-discriminator-a-key-element',\n",
       " '/paper/the-best-of-both-worlds-combining-recent',\n",
       " '/paper/dr-bilstm-dependent-reading-bidirectional',\n",
       " '/paper/data-to-text-generation-with-content',\n",
       " '/paper/left-center-right-separated-neural-network',\n",
       " '/paper/convolutional-kernel-networks',\n",
       " '/paper/person-re-identification-by-deep-joint',\n",
       " '/paper/road-reality-oriented-adaptation-for-semantic',\n",
       " '/paper/semantic-image-synthesis-with-spatially',\n",
       " '/paper/multiresolution-recurrent-neural-networks-an',\n",
       " '/paper/multiway-attention-networks-for-modeling',\n",
       " '/paper/scale-aware-trident-networks-for-object',\n",
       " '/paper/training-very-deep-networks',\n",
       " '/paper/personlab-person-pose-estimation-and-instance',\n",
       " '/paper/deformable-convolutional-networks',\n",
       " '/paper/local-decorrelation-for-improved-pedestrian',\n",
       " '/paper/pyramid-scene-parsing-network',\n",
       " '/paper/neural-3d-mesh-renderer',\n",
       " '/paper/attention-boosted-sequential-inference-model',\n",
       " '/paper/classical-structured-prediction-losses-for',\n",
       " '/paper/the-lovasz-softmax-loss-a-tractable-surrogate-2',\n",
       " '/paper/large-scale-image-retrieval-with-attentive',\n",
       " '/paper/a-focused-dynamic-attention-model-for-visual',\n",
       " '/paper/end-to-end-neural-coreference-resolution',\n",
       " '/paper/maxout-networks',\n",
       " '/paper/fused-dnn-a-deep-neural-network-fusion',\n",
       " '/paper/generative-image-modeling-using-spatial-lstms',\n",
       " '/paper/weakly-supervised-localization-using-deep',\n",
       " '/paper/vqa-visual-question-answering',\n",
       " '/paper/kelp-at-semeval-2016-task-3-learning-semantic',\n",
       " '/paper/event2mind-commonsense-inference-on-events',\n",
       " '/paper/memen-multi-layer-embedding-with-memory',\n",
       " '/paper/bidirectional-recurrent-convolutional',\n",
       " '/paper/picture-it-in-your-mind-generating-high-level',\n",
       " '/paper/deep-semantic-role-labeling-what-works-and',\n",
       " '/paper/foveabox-beyond-anchor-based-object-detector',\n",
       " '/paper/learning-for-video-super-resolution-through',\n",
       " '/paper/learning-activation-functions-to-improve-deep',\n",
       " '/paper/coarse-grain-fine-grain-coattention-network',\n",
       " '/paper/an-empirical-study-of-building-a-strong',\n",
       " '/paper/incremental-learning-in-person-re',\n",
       " '/paper/predicting-city-safety-perception-based-on-1',\n",
       " '/paper/look-across-elapse-disentangled',\n",
       " '/paper/reaching-human-level-performance-in-automatic',\n",
       " '/paper/line-large-scale-information-network',\n",
       " '/paper/semi-parametric-image-synthesis',\n",
       " '/paper/finding-remo-related-memory-object-a-simple',\n",
       " '/paper/a-c-lstm-neural-network-for-text',\n",
       " '/paper/detecting-people-in-artwork-with-cnns',\n",
       " '/paper/recurrent-neural-network-based-sentence',\n",
       " '/paper/looking-back-at-labels-a-class-based-domain',\n",
       " '/paper/learning-to-remember-rare-events',\n",
       " '/paper/nprf-a-neural-pseudo-relevance-feedback',\n",
       " '/paper/semi-supervised-multitask-learning-for',\n",
       " '/paper/improving-the-coverage-and-the-generalization',\n",
       " '/paper/beyond-deep-residual-learning-for-image',\n",
       " '/paper/feedback-network-for-image-super-resolution',\n",
       " '/paper/integral-human-pose-regression',\n",
       " '/paper/neural-machine-translation-in-linear-time',\n",
       " '/paper/noise-contrastive-estimation-and-negative',\n",
       " '/paper/neural-machine-translation-by-jointly',\n",
       " '/paper/3d-point-capsule-networks',\n",
       " '/paper/knowledge-based-word-sense-disambiguation',\n",
       " '/paper/dynamic-coattention-networks-for-question',\n",
       " '/paper/a-multi-sentiment-resource-enhanced-attention',\n",
       " '/paper/pifpaf-composite-fields-for-human-pose',\n",
       " '/paper/mesh-tensorflow-deep-learning-for',\n",
       " '/paper/an-amr-aligner-tuned-by-transition-based',\n",
       " '/paper/investigating-capsule-networks-with-dynamic',\n",
       " '/paper/autoaugment-learning-augmentation-policies',\n",
       " '/paper/lagging-inference-networks-and-posterior',\n",
       " '/paper/can-active-memory-replace-attention',\n",
       " '/paper/linguistic-input-features-improve-neural',\n",
       " '/paper/image-to-image-translation-with-conditional',\n",
       " '/paper/yolov3-an-incremental-improvement',\n",
       " '/paper/the-ibm-2015-english-conversational-telephone',\n",
       " '/paper/making-the-v-in-vqa-matter-elevating-the-role',\n",
       " '/paper/mean-teachers-are-better-role-models-weight',\n",
       " '/paper/neural-body-fitting-unifying-deep-learning',\n",
       " '/paper/multi-style-generative-reading-comprehension',\n",
       " '/paper/adaptive-input-representations-for-neural',\n",
       " '/paper/consistent-rank-logits-for-ordinal-regression',\n",
       " '/paper/hyperface-a-deep-multi-task-learning',\n",
       " '/paper/variational-bayesian-multiple-instance',\n",
       " '/paper/deepmatching-hierarchical-deformable-dense',\n",
       " '/paper/deep-convolutional-neural-networks-as-generic',\n",
       " '/paper/msg-gan-multi-scale-gradients-gan-for-more',\n",
       " '/paper/denet-scalable-real-time-object-detection',\n",
       " '/paper/sphereface-deep-hypersphere-embedding-for',\n",
       " '/paper/3d-r2n2-a-unified-approach-for-single-and',\n",
       " '/paper/a-context-based-approach-for-dialogue-act',\n",
       " '/paper/cycada-cycle-consistent-adversarial-domain',\n",
       " '/paper/joint-embedding-of-words-and-labels-for-text',\n",
       " '/paper/adversarial-discriminative-domain-adaptation',\n",
       " '/paper/fine-tune-bert-for-extractive-summarization-1',\n",
       " '/paper/image-super-resolution-using-deep',\n",
       " '/paper/virtual-adversarial-training-a-regularization',\n",
       " '/paper/the-variational-fair-autoencoder',\n",
       " '/paper/implicit-3d-orientation-learning-for-6d',\n",
       " '/paper/residual-dense-network-for-image-restoration',\n",
       " '/paper/part-level-convolutional-neural-networks-for',\n",
       " '/paper/the-evolved-transformer',\n",
       " '/paper/frame-recurrent-video-super-resolution',\n",
       " '/paper/gpipe-efficient-training-of-giant-neural',\n",
       " '/paper/cloze-driven-pretraining-of-self-attention',\n",
       " '/paper/analysis-of-convolutional-neural-networks-for',\n",
       " '/paper/exploration-a-study-of-count-based',\n",
       " '/paper/precise-detection-in-densely-packed-scenes',\n",
       " '/paper/improving-neural-parsing-by-disentangling',\n",
       " '/paper/attention-regularized-sequence-to-sequence',\n",
       " '/paper/cnn-based-segmentation-of-medical-imaging',\n",
       " '/paper/selective-refinement-network-for-high',\n",
       " '/paper/finding-tiny-faces',\n",
       " '/paper/purpose-and-polarity-of-citation-towards-nlp',\n",
       " '/paper/graph-convolutional-matrix-completion',\n",
       " '/paper/aggregate-channel-features-for-multi-view',\n",
       " '/paper/long-short-term-memory-neural-networks-for',\n",
       " '/paper/end-to-end-memory-networks',\n",
       " '/paper/anmm-ranking-short-answer-texts-with',\n",
       " '/paper/expr-at-semeval-2018-task-9-a-combined',\n",
       " '/paper/fully-convolutional-networks-for-semantic',\n",
       " '/paper/segnet-a-deep-convolutional-encoder-decoder',\n",
       " '/paper/graph-attention-networks',\n",
       " '/paper/joint-3d-proposal-generation-and-object',\n",
       " '/paper/near-human-level-performance-in-grammatical-1',\n",
       " '/paper/graph-convolution-over-pruned-dependency',\n",
       " '/paper/attribute-aware-attention-model-for-fine',\n",
       " '/paper/improving-neural-networks-by-preventing-co',\n",
       " '/paper/a-corpus-for-multilingual-document',\n",
       " '/paper/xception-deep-learning-with-depthwise',\n",
       " '/paper/towards-3d-human-pose-estimation-in-the-wild',\n",
       " '/paper/fcos-fully-convolutional-one-stage-object',\n",
       " '/paper/cross-domain-weakly-supervised-object',\n",
       " '/paper/pose-driven-deep-convolutional-model-for',\n",
       " '/paper/training-with-exploration-improves-a-greedy',\n",
       " '/paper/gated-graph-sequence-neural-networks',\n",
       " '/paper/image-restoration-using-convolutional-auto',\n",
       " '/paper/sliced-wasserstein-generative-models-1',\n",
       " '/paper/improved-precision-and-recall-metric-for',\n",
       " '/paper/brain-tumor-segmentation-with-deep-neural',\n",
       " '/paper/rotational-unit-of-memory',\n",
       " '/paper/an-updated-duet-model-for-passage-re-ranking',\n",
       " '/paper/photo-realistic-single-image-super-resolution',\n",
       " '/paper/one-shot-instance-segmentation',\n",
       " '/paper/semi-supervised-target-level-sentiment',\n",
       " '/paper/detecting-oriented-text-in-natural-images-by',\n",
       " '/paper/a-deep-relevance-matching-model-for-ad-hoc',\n",
       " '/paper/scalable-bayesian-optimization-using-deep',\n",
       " '/paper/improving-neural-machine-translation-models',\n",
       " '/paper/neural-network-language-modeling-with-letter',\n",
       " '/paper/geometric-deep-learning-on-graphs-and',\n",
       " '/paper/catena-causal-and-temporal-relation',\n",
       " '/paper/group-normalization',\n",
       " '/paper/deep-representation-learning-with-part-loss',\n",
       " '/paper/hypernyms-under-siege-linguistically',\n",
       " '/paper/the-lovasz-softmax-loss-a-tractable-surrogate',\n",
       " '/paper/a-general-pipeline-for-3d-detection-of',\n",
       " '/paper/predicting-semantic-relations-using-global',\n",
       " '/paper/brain-tumor-segmentation-and-radiomics',\n",
       " '/paper/deep-interest-network-for-click-through-rate',\n",
       " '/paper/learning-symmetry-consistent-deep-cnns-for',\n",
       " '/paper/deep-networks-with-internal-selective-1',\n",
       " '/paper/unsupervised-feature-learning-with-c-svddnet',\n",
       " '/paper/deep-graph-infomax',\n",
       " '/paper/deep-learning-based-image-super-resolution',\n",
       " '/paper/mixing-context-granularities-for-improved',\n",
       " '/paper/adapt-at-semeval-2018-task-9-skip-gram-word',\n",
       " '/paper/neural-sequence-learning-models-for-word',\n",
       " '/paper/deep-recurrent-models-with-fast-forward',\n",
       " '/paper/pixelcnn-models-with-auxiliary-variables-for',\n",
       " '/paper/neural-belief-tracker-data-driven-dialogue',\n",
       " '/paper/face-anti-spoofing-based-on-color-texture',\n",
       " '/paper/supervised-transformer-network-for-efficient',\n",
       " '/paper/i-know-what-you-want-semantic-learning-for',\n",
       " '/paper/learning-natural-language-inference-using',\n",
       " '/paper/retinamask-learning-to-predict-masks-improves',\n",
       " '/paper/stackgan-realistic-image-synthesis-with',\n",
       " '/paper/contactdb-analyzing-and-predicting-grasp',\n",
       " '/paper/ffdnet-toward-a-fast-and-flexible-solution',\n",
       " '/paper/compressing-word-embeddings-via-deep',\n",
       " '/paper/fast-r-cnn',\n",
       " '/paper/structural-embedding-of-syntactic-trees-for',\n",
       " '/paper/dsfd-dual-shot-face-detector',\n",
       " '/paper/squeeze-and-excitation-networks',\n",
       " '/paper/phrase-based-neural-unsupervised-machine',\n",
       " '/paper/matrix-completion-on-graphs',\n",
       " '/paper/dsod-learning-deeply-supervised-object',\n",
       " '/paper/neural-natural-language-inference-models',\n",
       " '/paper/going-further-with-point-pair-features',\n",
       " '/paper/sequence-to-sequence-learning-as-beam-search',\n",
       " '/paper/deep-learning-for-answer-sentence-selection',\n",
       " '/paper/syncspeccnn-synchronized-spectral-cnn-for-3d',\n",
       " '/paper/unlabeled-samples-generated-by-gan-improve',\n",
       " '/paper/temporal-relational-reasoning-in-videos',\n",
       " '/paper/implicit-quantile-networks-for-distributional',\n",
       " '/paper/neural-quality-estimation-of-grammatical',\n",
       " '/paper/understanding-convolution-for-semantic',\n",
       " '/paper/supervised-learning-of-universal-sentence',\n",
       " '/paper/the-pytorch-kaldi-speech-recognition-toolkit',\n",
       " '/paper/the-qt21himl-combined-machine-translation',\n",
       " '/paper/wavenet-a-generative-model-for-raw-audio',\n",
       " '/paper/analogical-inference-for-multi-relational',\n",
       " '/paper/diffusion-convolutional-recurrent-neural',\n",
       " '/paper/rethinking-atrous-convolution-for-semantic',\n",
       " '/paper/purely-sequence-trained-neural-networks-for',\n",
       " '/paper/dual-attention-network-for-scene-segmentation',\n",
       " '/paper/training-deep-autoencoders-for-collaborative',\n",
       " '/paper/estimating-individual-treatment-effect',\n",
       " '/paper/ring-loss-convex-feature-normalization-for',\n",
       " '/paper/targeted-aspect-based-sentiment-analysis-via',\n",
       " '/paper/splatnet-sparse-lattice-networks-for-point',\n",
       " '/paper/target-sensitive-memory-networks-for-aspect',\n",
       " '/paper/gated-attention-readers-for-text',\n",
       " '/paper/flowqa-grasping-flow-in-history-for',\n",
       " '/paper/rethinking-the-inception-architecture-for',\n",
       " '/paper/efficient-yet-deep-convolutional-neural',\n",
       " '/paper/v-net-fully-convolutional-neural-networks-for',\n",
       " '/paper/dissimilarity-coefficient-based-weakly',\n",
       " '/paper/quantized-densely-connected-u-nets-for',\n",
       " '/paper/large-scale-image-segmentation-with',\n",
       " '/paper/greedy-search-for-descriptive-spatial-face',\n",
       " '/paper/efficient-neural-architecture-search-via-1',\n",
       " '/paper/adversarially-learned-inference',\n",
       " '/paper/exploiting-coarse-to-fine-task-transfer-for-1',\n",
       " '/paper/simplifying-graph-convolutional-networks',\n",
       " '/paper/revisiting-distributional-correspondence',\n",
       " '/paper/detecting-cancer-metastases-on-gigapixel',\n",
       " '/paper/efficient-multi-scale-3d-cnn-with-fully',\n",
       " '/paper/shorten-spatial-spectral-rnn-with-parallel',\n",
       " '/paper/character-level-convolutional-networks-for',\n",
       " '/paper/prototypical-networks-for-few-shot-learning',\n",
       " '/paper/posecnn-a-convolutional-neural-network-for-6d',\n",
       " '/paper/a-style-based-generator-architecture-for',\n",
       " '/paper/distilling-an-ensemble-of-greedy-dependency',\n",
       " '/paper/deeplab-semantic-image-segmentation-with-deep',\n",
       " '/paper/online-and-linear-time-attention-by-enforcing',\n",
       " '/paper/training-recurrent-answering-units-with-joint',\n",
       " '/paper/res2net-a-new-multi-scale-backbone',\n",
       " '/paper/improving-deep-neural-networks-with',\n",
       " '/paper/speech-recognition-with-deep-recurrent-neural',\n",
       " '/paper/pose-robust-face-recognition-via-deep',\n",
       " '/paper/visual-domain-adaptation-with-manifold',\n",
       " '/paper/aspect-level-sentiment-classification-with',\n",
       " '/paper/what-do-recurrent-neural-network-grammars',\n",
       " '/paper/multimodal-residual-learning-for-visual-qa',\n",
       " '/paper/deterministic-non-autoregressive-neural',\n",
       " '/paper/re-ranking-person-re-identification-with-k',\n",
       " '/paper/an-effective-approach-to-unsupervised-machine',\n",
       " '/paper/roarnet-a-robust-3d-object-detection-based-on',\n",
       " '/paper/large-scale-evolution-of-image-classifiers',\n",
       " '/paper/darts-differentiable-architecture-search',\n",
       " '/paper/human-pose-regression-by-combining-indirect',\n",
       " '/paper/orthogonal-deep-features-decomposition-for',\n",
       " '/paper/image-restoration-using-very-deep',\n",
       " '/paper/cascade-contextual-sarcasm-detection-in',\n",
       " '/paper/self-adaptive-hierarchical-sentence-model',\n",
       " '/paper/invariant-information-clustering-for',\n",
       " '/paper/cell-aware-stacked-lstms-for-modeling',\n",
       " '/paper/multi-view-silhouette-and-depth-decomposition',\n",
       " '/paper/constituency-parsing-with-a-self-attentive',\n",
       " '/paper/recurrent-scale-approximation-for-object',\n",
       " '/paper/unpaired-image-to-image-translation-using',\n",
       " '/paper/efficient-and-robust-question-answering-from',\n",
       " '/paper/pose-guided-structured-region-ensemble',\n",
       " '/paper/associative-embedding-end-to-end-learning-for',\n",
       " '/paper/multi-task-bayesian-optimization',\n",
       " '/paper/real-time-single-image-and-video-super',\n",
       " '/paper/hierarchical-multiscale-recurrent-neural',\n",
       " '/paper/empower-sequence-labeling-with-task-aware',\n",
       " '/paper/practical-text-classification-with-large-pre',\n",
       " '/paper/there-are-many-consistent-explanations-of',\n",
       " '/paper/deeply-recursive-convolutional-network-for',\n",
       " '/paper/universal-transformers',\n",
       " '/paper/real-time-video-super-resolution-with-spatio',\n",
       " '/paper/scalable-person-re-identification-on',\n",
       " '/paper/linguistic-knowledge-as-memory-for-recurrent',\n",
       " '/paper/coco-gan-generation-by-parts-via-conditional',\n",
       " '/paper/deep-joint-entity-disambiguation-with-local',\n",
       " '/paper/technical-report-for-e2e-nlg-challenge',\n",
       " '/paper/improved-training-of-wasserstein-gans',\n",
       " '/paper/deepercut-a-deeper-stronger-and-faster-multi',\n",
       " '/paper/asymmetric-tri-training-for-unsupervised',\n",
       " '/paper/a-fully-attention-based-information-retriever',\n",
       " '/paper/improving-end-to-end-speech-recognition-with-1',\n",
       " '/paper/simple-and-effective-multi-paragraph-reading',\n",
       " '/paper/capsule-graph-neural-network',\n",
       " '/paper/semantic-image-segmentation-with-deep',\n",
       " '/paper/spatial-as-deep-spatial-cnn-for-traffic-scene',\n",
       " '/paper/artificial-error-generation-with-machine',\n",
       " '/paper/cross-lingual-language-model-pretraining',\n",
       " '/paper/semi-supervised-learning-with-ladder-networks',\n",
       " '/paper/text-classification-improved-by-integrating',\n",
       " '/paper/competitive-multi-scale-convolution',\n",
       " '/paper/multigrain-a-unified-image-embedding-for',\n",
       " '/paper/pi-rec-progressive-image-reconstruction-1',\n",
       " '/paper/glad-global-local-alignment-descriptor-for',\n",
       " '/paper/encoder-decoder-with-atrous-separable',\n",
       " '/paper/iterative-alternating-neural-attention-for',\n",
       " '/paper/bb8-a-scalable-accurate-robust-to-partial',\n",
       " '/paper/deep-speech-scaling-up-end-to-end-speech',\n",
       " '/paper/learning-with-recursive-perceptual',\n",
       " '/paper/tracking-the-world-state-with-recurrent',\n",
       " '/paper/structural-neural-encoders-for-amr-to-text',\n",
       " '/paper/icon-interactive-conversational-memory',\n",
       " '/paper/learning-spatial-aware-regressions-for-visual',\n",
       " '/paper/structured-training-for-neural-network',\n",
       " '/paper/exploring-randomly-wired-neural-networks-for',\n",
       " '/paper/pixel-recurrent-neural-networks',\n",
       " '/paper/ruminating-reader-reasoning-with-gated-multi',\n",
       " '/paper/an-application-of-cascaded-3d-fully',\n",
       " '/paper/learning-latent-opinions-for-aspect-level',\n",
       " '/paper/a-position-aware-bidirectional-attention',\n",
       " '/paper/class-splitting-generative-adversarial',\n",
       " '/paper/noise-reduction-and-targeted-exploration-in',\n",
       " '/paper/sgpn-similarity-group-proposal-network-for-3d',\n",
       " '/paper/attention-is-all-you-need',\n",
       " '/paper/deep-cnn-ensembles-and-suggestive-annotations',\n",
       " '/paper/self-supervised-learning-of-3d-human-pose',\n",
       " '/paper/cosface-large-margin-cosine-loss-for-deep',\n",
       " '/paper/unsupervised-training-for-3d-morphable-model',\n",
       " '/paper/facenet-a-unified-embedding-for-face',\n",
       " '/paper/viewpoints-and-keypoints',\n",
       " '/paper/dynamic-neural-turing-machine-with-soft-and',\n",
       " '/paper/end-to-end-answer-chunk-extraction-and',\n",
       " '/paper/swiden-convolutional-neural-networks-for',\n",
       " '/paper/hierarchical-neural-networks-for-sequential',\n",
       " '/paper/image-super-resolution-using-very-deep',\n",
       " '/paper/proxylessnas-direct-neural-architecture',\n",
       " '/paper/multi-grained-attention-network-for-aspect',\n",
       " '/paper/learning-from-simulated-and-unsupervised',\n",
       " '/paper/bilateral-multi-perspective-matching-for',\n",
       " '/paper/large-pose-3d-face-reconstruction-from-a',\n",
       " '/paper/a-graph-to-sequence-model-for-amr-to-text',\n",
       " '/paper/dynamic-entity-representation-with-max',\n",
       " '/paper/multimodal-sentiment-analysis-using',\n",
       " '/paper/yolact-real-time-instance-segmentation',\n",
       " '/paper/multi-level-wavelet-cnn-for-image-restoration',\n",
       " '/paper/matching-networks-for-one-shot-learning',\n",
       " '/paper/factorization-tricks-for-lstm-networks',\n",
       " '/paper/partially-shuffling-the-training-data-to-1',\n",
       " '/paper/wide-residual-networks',\n",
       " '/paper/multi-granular-sequence-encoding-via-dilated',\n",
       " '/paper/pedestrian-detection-aided-by-deep-learning',\n",
       " '/paper/the-ibm-2016-english-conversational-telephone',\n",
       " '/paper/densefusion-6d-object-pose-estimation-by',\n",
       " '/paper/multi-scale-context-aggregation-by-dilated',\n",
       " '/paper/apollo-at-semeval-2018-task-9-detecting',\n",
       " '/paper/addressing-the-rare-word-problem-in-neural',\n",
       " '/paper/a-multipath-network-for-object-detection',\n",
       " '/paper/person-re-identification-past-present-and',\n",
       " '/paper/from-neural-re-ranking-to-neural-ranking',\n",
       " '/paper/hydraplus-net-attentive-deep-features-for',\n",
       " '/paper/190409925',\n",
       " '/paper/attention-based-lstm-for-aspect-level',\n",
       " '/paper/m-walk-learning-to-walk-over-graphs-using',\n",
       " '/paper/coupled-generative-adversarial-networks',\n",
       " '/paper/estimating-6d-pose-from-localizing-designated',\n",
       " '/paper/a-multilayer-convolutional-encoder-decoder',\n",
       " '/paper/190408900',\n",
       " '/paper/revisiting-lstm-networks-for-semi-supervised',\n",
       " '/paper/incentivizing-exploration-in-reinforcement',\n",
       " '/paper/how-to-train-your-maml',\n",
       " '/paper/single-shot-refinement-neural-network-for',\n",
       " '/paper/r-fcn-object-detection-via-region-based-fully',\n",
       " '/paper/bridging-saliency-detection-to-weakly',\n",
       " '/paper/unsupervised-neural-machine-translation-with-1',\n",
       " '/paper/simple-and-accurate-dependency-parsing-using',\n",
       " '/paper/a-curriculum-domain-adaptation-approach-to',\n",
       " '/paper/deep-pyramid-convolutional-neural-networks',\n",
       " '/paper/improved-training-of-end-to-end-attention',\n",
       " '/paper/covariance-pooling-for-facial-expression',\n",
       " '/paper/deeply-supervised-nets',\n",
       " '/paper/findings-of-the-e2e-nlg-challenge',\n",
       " '/paper/going-deeper-with-convolutions',\n",
       " '/paper/parameter-re-initialization-through-cyclical',\n",
       " '/paper/dynamic-self-attention-computing-attention',\n",
       " '/paper/smarnet-teaching-machines-to-read-and',\n",
       " '/paper/can-syntax-help-improving-an-lstm-based',\n",
       " '/paper/hierarchical-attention-based-position-aware',\n",
       " '/paper/datastories-at-semeval-2017-task-4-deep-lstm',\n",
       " '/paper/generating-images-from-captions-with',\n",
       " '/paper/detecting-curve-text-in-the-wild-new-dataset',\n",
       " '/paper/global-locally-self-attentive-dialogue-state',\n",
       " '/paper/latent-alignment-and-variational-attention',\n",
       " '/paper/small-scale-pedestrian-detection-based-on',\n",
       " '/paper/attentive-pooling-networks',\n",
       " '/paper/product-based-neural-networks-for-user',\n",
       " '/paper/nlp_hz-at-semeval-2018-task-9-a-nearest',\n",
       " '/paper/morphosyntactic-tagging-with-a-meta-bilstm',\n",
       " '/paper/dualgan-unsupervised-dual-learning-for-image',\n",
       " '/paper/graphite-iterative-generative-modeling-of',\n",
       " '/paper/learning-deep-context-aware-features-over',\n",
       " '/paper/machine-comprehension-using-match-lstm-and',\n",
       " '/paper/on-first-order-meta-learning-algorithms',\n",
       " '/paper/beyond-part-models-person-retrieval-with',\n",
       " '/paper/sliced-recurrent-neural-networks',\n",
       " '/paper/global-hypothesis-generation-for-6d-object',\n",
       " '/paper/cinic-10-is-not-imagenet-or-cifar-10',\n",
       " '/paper/learning-feature-pyramids-for-human-pose',\n",
       " '/paper/learning-to-generate-reviews-and-discovering',\n",
       " '/paper/weighted-transformer-network-for-machine',\n",
       " '/paper/bilinear-cnn-models-for-fine-grained-visual',\n",
       " '/paper/300-sparsans-at-semeval-2018-task-9-hypernymy',\n",
       " '/paper/sentihood-targeted-aspect-based-sentiment',\n",
       " '/paper/aspect-based-sentiment-analysis-with-gated',\n",
       " '/paper/illuminating-pedestrians-via-simultaneous',\n",
       " '/paper/unitary-evolution-recurrent-neural-networks',\n",
       " '/paper/bridging-category-level-and-instance-level',\n",
       " '/paper/learning-a-single-convolutional-super',\n",
       " '/paper/very-deep-convolutional-networks-for-text',\n",
       " '/paper/simple-embedding-for-link-prediction-in',\n",
       " '/paper/evaluation-of-output-embeddings-for-fine',\n",
       " '/paper/soft-layer-specific-multi-task-summarization-1',\n",
       " '/paper/turing-at-semeval-2017-task-8-sequential',\n",
       " '/paper/fcns-in-the-wild-pixel-level-adversarial-and',\n",
       " '/paper/finding-a-needle-in-the-haystack-attention',\n",
       " '/paper/a-simple-method-for-commonsense-reasoning',\n",
       " '/paper/multi-column-deep-neural-networks-for-image',\n",
       " '/paper/high-resolution-image-synthesis-and-semantic',\n",
       " '/paper/batch-normalization-accelerating-deep-network',\n",
       " '/paper/path-level-network-transformation-for',\n",
       " '/paper/a-distributional-perspective-on-reinforcement',\n",
       " '/paper/timeception-for-complex-action-recognition',\n",
       " '/paper/a-novel-neural-network-model-for-joint-pos',\n",
       " '/paper/learning-discriminative-features-with',\n",
       " '/paper/automatic-skin-lesion-segmentation-with-fully',\n",
       " '/paper/fast-and-accurate-single-image-super',\n",
       " '/paper/few-example-object-detection-with-model',\n",
       " '/paper/rmdl-random-multimodel-deep-learning-for',\n",
       " '/paper/deep-speech-2-end-to-end-speech-recognition',\n",
       " '/paper/taking-a-deeper-look-at-pedestrians',\n",
       " '/paper/abstractive-text-classification-using',\n",
       " '/paper/semi-supervised-sequence-modeling-with-cross',\n",
       " '/paper/scut-fbp5500-a-diverse-benchmark-dataset-for',\n",
       " '/paper/densely-connected-attention-propagation-for',\n",
       " '/paper/large-scale-gan-training-for-high-fidelity',\n",
       " '/paper/a-fast-rcnn-hard-positive-generation-via',\n",
       " '/paper/neural-network-matrix-factorization',\n",
       " '/paper/stacked-generative-adversarial-networks',\n",
       " '/paper/semantic-instance-segmentation-via-deep',\n",
       " '/paper/micronnet-a-highly-compact-deep-convolutional',\n",
       " '/paper/multi-task-deep-neural-networks-for-natural',\n",
       " '/paper/ssd-6d-making-rgb-based-3d-detection-and-6d',\n",
       " '/paper/face-recognition-using-deep-multi-pose',\n",
       " '/paper/couplenet-coupling-global-structure-with',\n",
       " '/paper/boxsup-exploiting-bounding-boxes-to-supervise',\n",
       " '/paper/compare-compress-and-propagate-enhancing',\n",
       " '/paper/on-gradient-regularizers-for-mmd-gans',\n",
       " '/paper/towards-universal-dialogue-state-tracking',\n",
       " '/paper/deep-pyramidal-residual-networks',\n",
       " '/paper/renet-a-recurrent-neural-network-based',\n",
       " '/paper/regularizing-and-optimizing-lstm-language',\n",
       " '/paper/dula-net-a-dual-projection-network-for',\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "paper_paths = open('/Users/nialdaly/Desktop/papers.txt', \"r\")\n",
    "\n",
    "#\n",
    "paper_paths = paper_paths.read().split('\\n')\n",
    "\n",
    "# remove duplicates from the subtasks_dataset list\n",
    "paper_paths  = list(set(paper_paths))\n",
    "\n",
    "# removes the empty strings from the paper_paths list \n",
    "paper_paths = [x for x in paper_paths if x]\n",
    "\n",
    "paper_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1320"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paper_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# model_data = display_html(model_data, raw = True)\n",
    "\n",
    "# dfs = pd.read_html(model_data, header=0)\n",
    "\n",
    "# dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = display_html(model_data, raw = True)\n",
    "\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                  Task Dataset  Model Metric name  Metric value Global rank  \\\n",
       " 0  Text Classification  TREC-6  TBCNN       Error             4         # 4   \n",
       " \n",
       "   Remove  \n",
       " 0      -  ,                     Task                     Dataset  \\\n",
       " 0   Constituency Parsing               Penn Treebank   \n",
       " 1     Language Modelling  Penn Treebank (Word Level)   \n",
       " 2     Language Modelling  Penn Treebank (Word Level)   \n",
       " 3     Language Modelling  Penn Treebank (Word Level)   \n",
       " 4     Language Modelling  Penn Treebank (Word Level)   \n",
       " 5     Language Modelling  Penn Treebank (Word Level)   \n",
       " 6     Language Modelling  Penn Treebank (Word Level)   \n",
       " 7     Language Modelling                  WikiText-2   \n",
       " 8     Language Modelling                  WikiText-2   \n",
       " 9     Language Modelling                  WikiText-2   \n",
       " 10    Language Modelling                  WikiText-2   \n",
       " 11    Language Modelling                  WikiText-2   \n",
       " 12    Language Modelling                  WikiText-2   \n",
       " \n",
       "                              Model            Metric name Metric value  \\\n",
       " 0   LSTM Encoder-Decoder + LSTM-LM               F1 score        94.47   \n",
       " 1                     AWD-LSTM-DOC  Validation perplexity        54.12   \n",
       " 2                     AWD-LSTM-DOC        Test perplexity        52.38   \n",
       " 3                     AWD-LSTM-DOC                 Params          23M   \n",
       " 4                  AWD-LSTM-DOC x5  Validation perplexity        48.63   \n",
       " 5                  AWD-LSTM-DOC x5        Test perplexity        47.17   \n",
       " 6                  AWD-LSTM-DOC x5                 Params         185M   \n",
       " 7                  AWD-LSTM-DOC x5  Validation perplexity        54.19   \n",
       " 8                  AWD-LSTM-DOC x5        Test perplexity        53.09   \n",
       " 9                  AWD-LSTM-DOC x5       Number of params         185M   \n",
       " 10                    AWD-LSTM-DOC  Validation perplexity        60.29   \n",
       " 11                    AWD-LSTM-DOC        Test perplexity        58.03   \n",
       " 12                    AWD-LSTM-DOC       Number of params          37M   \n",
       " \n",
       "    Global rank Remove  \n",
       " 0          # 4      -  \n",
       " 1          # 8      -  \n",
       " 2          # 8      -  \n",
       " 3          # 1      -  \n",
       " 4          # 4      -  \n",
       " 5          # 3      -  \n",
       " 6          # 1      -  \n",
       " 7          # 6      -  \n",
       " 8          # 7      -  \n",
       " 9          # 1      -  \n",
       " 10         # 8      -  \n",
       " 11         # 9      -  \n",
       " 12         # 1      -  ,                          Task Dataset  \\\n",
       " 0  Natural Language Inference    SNLI   \n",
       " 1  Natural Language Inference    SNLI   \n",
       " 2  Natural Language Inference    SNLI   \n",
       " 3  Natural Language Inference    SNLI   \n",
       " 4  Natural Language Inference    SNLI   \n",
       " 5  Natural Language Inference    SNLI   \n",
       " 6  Natural Language Inference    SNLI   \n",
       " 7  Natural Language Inference    SNLI   \n",
       " 8  Natural Language Inference    SNLI   \n",
       " \n",
       "                                                Model       Metric name  \\\n",
       " 0                     600D (300+300) BiLSTM encoders   % Test Accuracy   \n",
       " 1                     600D (300+300) BiLSTM encoders  % Train Accuracy   \n",
       " 2                     600D (300+300) BiLSTM encoders        Parameters   \n",
       " 3  600D (300+300) BiLSTM encoders with intra-atte...   % Test Accuracy   \n",
       " 4  600D (300+300) BiLSTM encoders with intra-atte...  % Train Accuracy   \n",
       " 5  600D (300+300) BiLSTM encoders with intra-atte...        Parameters   \n",
       " 6  600D (300+300) BiLSTM encoders with intra-atte...   % Test Accuracy   \n",
       " 7  600D (300+300) BiLSTM encoders with intra-atte...  % Train Accuracy   \n",
       " 8  600D (300+300) BiLSTM encoders with intra-atte...        Parameters   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0         83.3        # 41      -  \n",
       " 1         86.4        # 43      -  \n",
       " 2         2.0m         # 1      -  \n",
       " 3         84.2        # 38      -  \n",
       " 4         84.5        # 50      -  \n",
       " 5         2.8m         # 1      -  \n",
       " 6         85.0        # 35      -  \n",
       " 7         85.9        # 45      -  \n",
       " 8         2.8m         # 1      -  ,                   Task Dataset                                 Model  \\\n",
       " 0   Question Answering  QASent                                  LSTM   \n",
       " 1   Question Answering  QASent                                  LSTM   \n",
       " 2   Question Answering  QASent  LSTM (lexical overlap + dist output)   \n",
       " 3   Question Answering  QASent  LSTM (lexical overlap + dist output)   \n",
       " 4   Question Answering  QASent                        Attentive LSTM   \n",
       " 5   Question Answering  QASent                        Attentive LSTM   \n",
       " 6   Question Answering  WikiQA                        Attentive LSTM   \n",
       " 7   Question Answering  WikiQA                        Attentive LSTM   \n",
       " 8   Question Answering  WikiQA  LSTM (lexical overlap + dist output)   \n",
       " 9   Question Answering  WikiQA  LSTM (lexical overlap + dist output)   \n",
       " 10  Question Answering  WikiQA                                  LSTM   \n",
       " 11  Question Answering  WikiQA                                  LSTM   \n",
       " \n",
       "    Metric name  Metric value Global rank Remove  \n",
       " 0          MAP        0.6436         # 5      -  \n",
       " 1          MRR        0.7235         # 5      -  \n",
       " 2          MAP        0.7228         # 2      -  \n",
       " 3          MRR        0.7986         # 2      -  \n",
       " 4          MAP        0.7339         # 1      -  \n",
       " 5          MRR        0.8117         # 1      -  \n",
       " 6          MAP        0.6886         # 6      -  \n",
       " 7          MRR        0.7069         # 6      -  \n",
       " 8          MAP        0.6820         # 7      -  \n",
       " 9          MRR        0.6988         # 8      -  \n",
       " 10         MAP        0.6552         # 9      -  \n",
       " 11         MRR        0.6747        # 10      -  ,                    Task     Dataset                        Model  \\\n",
       " 0  Hand Pose Estimation  ICVL Hands  Dense Pixel-wise Estimation   \n",
       " 1  Hand Pose Estimation  MSRA Hands  Dense Pixel-wise Estimation   \n",
       " 2  Hand Pose Estimation   NYU Hands  Dense Pixel-wise Estimation   \n",
       " \n",
       "         Metric name  Metric value Global rank Remove  \n",
       " 0  Average 3D Error           7.3         # 3      -  \n",
       " 1  Average 3D Error           7.2         # 1      -  \n",
       " 2  Average 3D Error          10.2         # 2      -  ,                       Task         Dataset   Model Metric name  Metric value  \\\n",
       " 0  Collaborative Filtering          Douban  sRGCNN        RMSE         0.801   \n",
       " 1  Collaborative Filtering        Flixster  sRGCNN        RMSE         0.926   \n",
       " 2  Collaborative Filtering  MovieLens 100K  sRGCNN        RMSE         0.929   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 5      -  \n",
       " 1         # 3      -  \n",
       " 2         # 3      -  ,                                    Task                Dataset Model  \\\n",
       " 0  Semi-Supervised Image Classification  CIFAR-10, 4000 Labels  SWSA   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0    Accuracy            95         # 1      -  ,                                     Task                       Dataset Model  \\\n",
       " 0  Open Knowledge Graph Canonicalization  Noun Phrase Canonicalization  CESI   \n",
       " 1  Open Knowledge Graph Canonicalization  Noun Phrase Canonicalization  CESI   \n",
       " 2  Open Knowledge Graph Canonicalization  Noun Phrase Canonicalization  CESI   \n",
       " \n",
       "          Metric name  Metric value Global rank Remove  \n",
       " 0       Base Dataset          98.2         # 1      -  \n",
       " 1  Ambiguous dataset          99.8         # 1      -  \n",
       " 2          ReVerb45k          99.9         # 1      -  ,                      Task                    Dataset            Model  \\\n",
       " 0  Common Sense Reasoning  Winograd Schema Challenge  Word-LM-partial   \n",
       " 1  Common Sense Reasoning  Winograd Schema Challenge  Char-LM-partial   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0       Score          62.6         # 2      -  \n",
       " 1       Score          57.9         # 3      -  ,                            Task           Dataset                     Model  \\\n",
       " 0  Conditional Image Generation  ImageNet 128x128  Projection Discriminator   \n",
       " 1  Conditional Image Generation  ImageNet 128x128  Projection Discriminator   \n",
       " \n",
       "        Metric name  Metric value Global rank Remove  \n",
       " 0              FID         27.62         # 5      -  \n",
       " 1  Inception score         36.80         # 5      -  ,                  Task Dataset                                 Model  \\\n",
       " 0  Question Answering  WikiQA  PairwiseRank + Multi-Perspective CNN   \n",
       " 1  Question Answering  WikiQA  PairwiseRank + Multi-Perspective CNN   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0         MAP         0.701         # 5      -  \n",
       " 1         MRR         0.718         # 5      -  ,                       Task         Dataset         Model Metric name  \\\n",
       " 0  Collaborative Filtering          Douban         GC-MC        RMSE   \n",
       " 1  Collaborative Filtering        Flixster         GC-MC        RMSE   \n",
       " 2  Collaborative Filtering  MovieLens 100K         GC-MC        RMSE   \n",
       " 3  Collaborative Filtering  MovieLens 100K  GC-MC + feat        RMSE   \n",
       " 4  Collaborative Filtering   MovieLens 10M         GC-MC        RMSE   \n",
       " 5  Collaborative Filtering    MovieLens 1M         GC-MC        RMSE   \n",
       " 6  Collaborative Filtering      YahooMusic         GC-MC        RMSE   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         0.734         # 3      -  \n",
       " 1         0.917         # 2      -  \n",
       " 2         0.910         # 2      -  \n",
       " 3         0.905         # 1      -  \n",
       " 4         0.777         # 4      -  \n",
       " 5         0.832         # 4      -  \n",
       " 6        20.500         # 2      -  ,                        Task      Dataset Model Metric name  Metric value  \\\n",
       " 0  3D Object Reconstruction  Data3D−R2N2   PSG      Avg F1         48.58   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 3      -  ,                Task                 Dataset                     Model  \\\n",
       " 0  Image Generation                CIFAR-10  WGAN-GP + TT Update Rule   \n",
       " 1  Image Generation  LSUN Bedroom 256 x 256  WGAN-GP + TT Update Rule   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0         FID          24.8         # 3      -  \n",
       " 1         FID           9.5         # 4      -  ,                               Task     Dataset Model  Metric name  \\\n",
       " 0  Real-Time Semantic Segmentation  Cityscapes  ENet         mIoU   \n",
       " 1  Real-Time Semantic Segmentation  Cityscapes  ENet    Time (ms)   \n",
       " 2  Real-Time Semantic Segmentation  Cityscapes  ENet  Frame (fps)   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        58.3%        # 10      -  \n",
       " 1           13         # 1      -  \n",
       " 2         76.9         # 1      -  ,                                  Task          Dataset  \\\n",
       " 0  Weakly Supervised Object Detection         ImageNet   \n",
       " 1  Weakly Supervised Object Detection  PASCAL VOC 2007   \n",
       " 2  Weakly Supervised Object Detection  PASCAL VOC 2012   \n",
       " \n",
       "                                    Model Metric name  Metric value  \\\n",
       " 0  Online Instance Classifier Refinement         MAP           6.0   \n",
       " 1                       OICR-Ens + FRCNN         MAP          47.0   \n",
       " 2                       OICR-Ens + FRCNN         MAP          42.5   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 4      -  \n",
       " 1         # 7      -  \n",
       " 2         # 5      -  ,                   Task                           Dataset    Model Metric name  \\\n",
       " 0  Text Classification                           AG News      CNN       Error   \n",
       " 1  Text Classification                           DBpedia      CNN       Error   \n",
       " 2   Sentiment Analysis                              IMDb  oh-LSTM    Accuracy   \n",
       " 3   Sentiment Analysis        Yelp Binary classification      CNN       Error   \n",
       " 4   Sentiment Analysis  Yelp Fine-grained classification      CNN       Error   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          6.57         # 4      -  \n",
       " 1          0.84         # 5      -  \n",
       " 2         94.10         # 6      -  \n",
       " 3          2.90         # 6      -  \n",
       " 4         32.39         # 6      -  ,                         Task           Dataset   Model   Metric name  \\\n",
       " 0  Word Sense Disambiguation  Knowledge-based:  WSD-TM           All   \n",
       " 1  Word Sense Disambiguation  Knowledge-based:  WSD-TM    Senseval 2   \n",
       " 2  Word Sense Disambiguation  Knowledge-based:  WSD-TM    Senseval 3   \n",
       " 3  Word Sense Disambiguation  Knowledge-based:  WSD-TM  SemEval 2007   \n",
       " 4  Word Sense Disambiguation  Knowledge-based:  WSD-TM  SemEval 2013   \n",
       " 5  Word Sense Disambiguation  Knowledge-based:  WSD-TM  SemEval 2015   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0         66.9         # 1      -  \n",
       " 1     **69.0**         # 5      -  \n",
       " 2     **66.9**         # 5      -  \n",
       " 3     **55.6**         # 5      -  \n",
       " 4         65.3         # 2      -  \n",
       " 5         69.6         # 1      -  ,               Task        Dataset    Model Metric name  Metric value  \\\n",
       " 0  Text Generation  Chinese Poems  RankGAN      BLEU-2         0.812   \n",
       " 1  Text Generation  COCO Captions  RankGAN      BLEU-2         0.850   \n",
       " 2  Text Generation  COCO Captions  RankGAN      BLEU-3         0.672   \n",
       " 3  Text Generation  COCO Captions  RankGAN      BLEU-4         0.557   \n",
       " 4  Text Generation  COCO Captions  RankGAN      BLEU-5         0.544   \n",
       " 5  Text Generation  EMNLP2017 WMT  RankGAN      BLEU-2         0.778   \n",
       " 6  Text Generation  EMNLP2017 WMT  RankGAN      BLEU-3         0.478   \n",
       " 7  Text Generation  EMNLP2017 WMT  RankGAN      BLEU-4         0.411   \n",
       " 8  Text Generation  EMNLP2017 WMT  RankGAN      BLEU-5         0.463   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  \n",
       " 1         # 2      -  \n",
       " 2         # 2      -  \n",
       " 3         # 2      -  \n",
       " 4         # 2      -  \n",
       " 5         # 3      -  \n",
       " 6         # 3      -  \n",
       " 7         # 3      -  \n",
       " 8         # 2      -  ,              Task        Dataset          Model Metric name Metric value  \\\n",
       " 0  Age Estimation  ChaLearn 2015  DLDL+VGG-Face         MAE         3.51   \n",
       " 1  Age Estimation   MORPH Album2  DLDL+VGG-Face         MAE    2.42±0.01   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 2      -  ,            Task                         Dataset              Model  \\\n",
       " 0   Atari Games                Atari 2600 Alien  DDQN+Pop-Art noop   \n",
       " 1   Atari Games               Atari 2600 Amidar  DDQN+Pop-Art noop   \n",
       " 2   Atari Games              Atari 2600 Assault  DDQN+Pop-Art noop   \n",
       " 3   Atari Games              Atari 2600 Asterix  DDQN+Pop-Art noop   \n",
       " 4   Atari Games            Atari 2600 Asteroids  DDQN+Pop-Art noop   \n",
       " 5   Atari Games             Atari 2600 Atlantis  DDQN+Pop-Art noop   \n",
       " 6   Atari Games           Atari 2600 Bank Heist  DDQN+Pop-Art noop   \n",
       " 7   Atari Games          Atari 2600 Battle Zone  DDQN+Pop-Art noop   \n",
       " 8   Atari Games           Atari 2600 Beam Rider  DDQN+Pop-Art noop   \n",
       " 9   Atari Games              Atari 2600 Berzerk  DDQN+Pop-Art noop   \n",
       " 10  Atari Games              Atari 2600 Bowling  DDQN+Pop-Art noop   \n",
       " 11  Atari Games               Atari 2600 Boxing  DDQN+Pop-Art noop   \n",
       " 12  Atari Games             Atari 2600 Breakout  DDQN+Pop-Art noop   \n",
       " 13  Atari Games            Atari 2600 Centipede  DDQN+Pop-Art noop   \n",
       " 14  Atari Games      Atari 2600 Chopper Command  DDQN+Pop-Art noop   \n",
       " 15  Atari Games        Atari 2600 Crazy Climber  DDQN+Pop-Art noop   \n",
       " 16  Atari Games         Atari 2600 Demon Attack  DDQN+Pop-Art noop   \n",
       " 17  Atari Games          Atari 2600 Double Dunk  DDQN+Pop-Art noop   \n",
       " 18  Atari Games               Atari 2600 Enduro  DDQN+Pop-Art noop   \n",
       " 19  Atari Games        Atari 2600 Fishing Derby  DDQN+Pop-Art noop   \n",
       " 20  Atari Games              Atari 2600 Freeway  DDQN+Pop-Art noop   \n",
       " 21  Atari Games            Atari 2600 Frostbite  DDQN+Pop-Art noop   \n",
       " 22  Atari Games               Atari 2600 Gopher  DDQN+Pop-Art noop   \n",
       " 23  Atari Games             Atari 2600 Gravitar  DDQN+Pop-Art noop   \n",
       " 24  Atari Games                 Atari 2600 HERO  DDQN+Pop-Art noop   \n",
       " 25  Atari Games           Atari 2600 Ice Hockey  DDQN+Pop-Art noop   \n",
       " 26  Atari Games           Atari 2600 James Bond  DDQN+Pop-Art noop   \n",
       " 27  Atari Games             Atari 2600 Kangaroo  DDQN+Pop-Art noop   \n",
       " 28  Atari Games                Atari 2600 Krull  DDQN+Pop-Art noop   \n",
       " 29  Atari Games       Atari 2600 Kung-Fu Master  DDQN+Pop-Art noop   \n",
       " 30  Atari Games  Atari 2600 Montezuma's Revenge  DDQN+Pop-Art noop   \n",
       " 31  Atari Games           Atari 2600 Ms. Pacman  DDQN+Pop-Art noop   \n",
       " 32  Atari Games       Atari 2600 Name This Game  DDQN+Pop-Art noop   \n",
       " 33  Atari Games                 Atari 2600 Pong  DDQN+Pop-Art noop   \n",
       " 34  Atari Games          Atari 2600 Private Eye  DDQN+Pop-Art noop   \n",
       " 35  Atari Games               Atari 2600 Q*Bert  DDQN+Pop-Art noop   \n",
       " 36  Atari Games           Atari 2600 River Raid  DDQN+Pop-Art noop   \n",
       " 37  Atari Games          Atari 2600 Road Runner  DDQN+Pop-Art noop   \n",
       " 38  Atari Games             Atari 2600 Robotank  DDQN+Pop-Art noop   \n",
       " 39  Atari Games             Atari 2600 Seaquest  DDQN+Pop-Art noop   \n",
       " 40  Atari Games       Atari 2600 Space Invaders  DDQN+Pop-Art noop   \n",
       " 41  Atari Games          Atari 2600 Star Gunner  DDQN+Pop-Art noop   \n",
       " 42  Atari Games               Atari 2600 Tennis  DDQN+Pop-Art noop   \n",
       " 43  Atari Games           Atari 2600 Time Pilot  DDQN+Pop-Art noop   \n",
       " 44  Atari Games            Atari 2600 Tutankham  DDQN+Pop-Art noop   \n",
       " 45  Atari Games          Atari 2600 Up and Down  DDQN+Pop-Art noop   \n",
       " 46  Atari Games              Atari 2600 Venture  DDQN+Pop-Art noop   \n",
       " 47  Atari Games        Atari 2600 Video Pinball  DDQN+Pop-Art noop   \n",
       " 48  Atari Games        Atari 2600 Wizard of Wor  DDQN+Pop-Art noop   \n",
       " 49  Atari Games               Atari 2600 Zaxxon  DDQN+Pop-Art noop   \n",
       " \n",
       "    Metric name  Metric value Global rank Remove  \n",
       " 0        Score        3213.5         # 6      -  \n",
       " 1        Score         782.5         # 9      -  \n",
       " 2        Score        9011.6         # 5      -  \n",
       " 3        Score       18919.5        # 10      -  \n",
       " 4        Score        2869.3         # 5      -  \n",
       " 5        Score      340076.0        # 14      -  \n",
       " 6        Score        1103.3         # 6      -  \n",
       " 7        Score        8220.0        # 21      -  \n",
       " 8        Score        8299.4        # 17      -  \n",
       " 9        Score        1199.6         # 8      -  \n",
       " 10       Score         102.1         # 1      -  \n",
       " 11       Score          99.3         # 3      -  \n",
       " 12       Score         344.1        # 17      -  \n",
       " 13       Score       49065.8         # 1      -  \n",
       " 14       Score         775.0        # 21      -  \n",
       " 15       Score      119679.0        # 11      -  \n",
       " 16       Score       63644.9        # 11      -  \n",
       " 17       Score         -11.5        # 16      -  \n",
       " 18       Score        2002.1         # 8      -  \n",
       " 19       Score          45.1         # 2      -  \n",
       " 20       Score          33.4         # 4      -  \n",
       " 21       Score        3469.6         # 9      -  \n",
       " 22       Score       56218.2         # 4      -  \n",
       " 23       Score         483.5         # 8      -  \n",
       " 24       Score       14225.2        # 18      -  \n",
       " 25       Score          -4.1        # 15      -  \n",
       " 26       Score         507.5        # 17      -  \n",
       " 27       Score       13150.0         # 5      -  \n",
       " 28       Score        9745.1         # 4      -  \n",
       " 29       Score       34393.0         # 8      -  \n",
       " 30       Score           0.0        # 23      -  \n",
       " 31       Score        4963.8         # 4      -  \n",
       " 32       Score       15851.2         # 2      -  \n",
       " 33       Score          20.6         # 3      -  \n",
       " 34       Score         286.7        # 12      -  \n",
       " 35       Score        5236.8        # 20      -  \n",
       " 36       Score       12530.8        # 10      -  \n",
       " 37       Score       47770.0        # 11      -  \n",
       " 38       Score          64.3         # 4      -  \n",
       " 39       Score       10932.3         # 9      -  \n",
       " 40       Score        2589.7        # 13      -  \n",
       " 41       Score         589.0        # 21      -  \n",
       " 42       Score          12.1         # 4      -  \n",
       " 43       Score        4870.0        # 18      -  \n",
       " 44       Score         183.9         # 9      -  \n",
       " 45       Score       22474.4        # 12      -  \n",
       " 46       Score        1172.0         # 4      -  \n",
       " 47       Score       56287.0        # 18      -  \n",
       " 48       Score         483.0        # 21      -  \n",
       " 49       Score       14402.0         # 4      -  ,                             Task                          Dataset       Model  \\\n",
       " 0  Few-Shot Image Classification  Mini-ImageNet - 5-Shot Learning  Baseline++   \n",
       " \n",
       "   Metric name Metric value Global rank Remove  \n",
       " 0    Accuracy       66.43%         # 6      -  ,                          Task                     Dataset  Model  \\\n",
       " 0            Image Generation                    CIFAR-10    ALI   \n",
       " 1  Image-to-Image Translation  Cityscapes Labels-to-Photo  BiGAN   \n",
       " 2  Image-to-Image Translation  Cityscapes Labels-to-Photo  BiGAN   \n",
       " 3  Image-to-Image Translation  Cityscapes Labels-to-Photo  BiGAN   \n",
       " 4  Image-to-Image Translation  Cityscapes Photo-to-Labels  BiGAN   \n",
       " 5  Image-to-Image Translation  Cityscapes Photo-to-Labels  BiGAN   \n",
       " 6  Image-to-Image Translation  Cityscapes Photo-to-Labels  BiGAN   \n",
       " \n",
       "           Metric name Metric value Global rank Remove  \n",
       " 0     Inception score         5.34        # 13      -  \n",
       " 1           Class IOU         0.02         # 5      -  \n",
       " 2  Per-class Accuracy           6%         # 4      -  \n",
       " 3  Per-pixel Accuracy          19%         # 9      -  \n",
       " 4  Per-pixel Accuracy          41%         # 5      -  \n",
       " 5  Per-class Accuracy          13%         # 3      -  \n",
       " 6           Class IOU         0.07         # 4      -  ,                              Task   Dataset         Model    Metric name  \\\n",
       " 0  Open-Domain Question Answering    Quasar  Denoising QA  EM (Quasar-T)   \n",
       " 1  Open-Domain Question Answering    Quasar  Denoising QA  F1 (Quasar-T)   \n",
       " 2  Open-Domain Question Answering  SearchQA  Denoising QA    Unigram Acc   \n",
       " 3  Open-Domain Question Answering  SearchQA  Denoising QA      N-gram F1   \n",
       " 4  Open-Domain Question Answering  SearchQA  Denoising QA             EM   \n",
       " 5  Open-Domain Question Answering  SearchQA  Denoising QA             F1   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0         42.2         # 1      -  \n",
       " 1         49.3         # 1      -  \n",
       " 2            -         # 5      -  \n",
       " 3            -         # 6      -  \n",
       " 4         58.8         # 1      -  \n",
       " 5         64.5         # 1      -  ,                  Task         Dataset Model        Metric name  Metric value  \\\n",
       " 0  Hypernym Discovery  Medical domain  EXPR                MAP         13.77   \n",
       " 1  Hypernym Discovery  Medical domain  EXPR                MRR         40.76   \n",
       " 2  Hypernym Discovery  Medical domain  EXPR  [email protected]         12.76   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 5      -  \n",
       " 1         # 3      -  \n",
       " 2         # 5      -  ,                        Task        Dataset Model Metric name  Metric value  \\\n",
       " 0  Person Re-Identification  DukeMTMC-reID   OIM      Rank-1          68.1   \n",
       " 1  Person Re-Identification  DukeMTMC-reID   OIM         MAP          47.4   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 15      -  \n",
       " 1        # 15      -  ,                       Task Dataset Model Metric name Metric value Global rank  \\\n",
       " 0  Occluded Face Detection    MAFA  AOFD         MAP        77.3%         # 2   \n",
       " \n",
       "   Remove  \n",
       " 0      -  ,                  Task           Dataset         Model Metric name  \\\n",
       " 0  Question Answering  CNN / Daily Mail  GA+MAGE (32)         CNN   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          78.6         # 1      -  ,                  Task   Dataset  \\\n",
       " 0  Question Answering  SQuAD2.0   \n",
       " 1  Question Answering  SQuAD2.0   \n",
       " \n",
       "                                                Model Metric name  \\\n",
       " 0  Reinforced Mnemonic Reader + Answer Verifier (...          EM   \n",
       " 1  Reinforced Mnemonic Reader + Answer Verifier (...          F1   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0        71.767        # 62      -  \n",
       " 1        74.295        # 70      -  ,                      Task     Dataset    Model  \\\n",
       " 0  Visual Object Tracking  VOT2017/18  SiamRPN   \n",
       " \n",
       "                       Metric name  Metric value Global rank Remove  \n",
       " 0  Expected Average Overlap (EAO)         0.244         # 9      -  ,                    Task   Dataset            Model Metric name  Metric value  \\\n",
       " 0  Image Classification  CINIC-10           VGG-16    Accuracy         87.77   \n",
       " 1  Image Classification  CINIC-10        ResNet-18    Accuracy         90.27   \n",
       " 2  Image Classification  CINIC-10     DenseNet-121    Accuracy         91.26   \n",
       " 3  Image Classification  CINIC-10  ResNeXt29_2x64d    Accuracy         91.45   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 4      -  \n",
       " 1         # 3      -  \n",
       " 2         # 2      -  \n",
       " 3         # 1      -  ,                    Task    Dataset     Model         Metric name  \\\n",
       " 0  Image Classification   CIFAR-10  DCNN+GFE  Percentage correct   \n",
       " 1  Image Classification  CIFAR-100  DCNN+GFE  Percentage correct   \n",
       " 2  Image Classification      MNIST  DCNN+GFE    Percentage error   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          89.1        # 45      -  \n",
       " 1          67.7        # 31      -  \n",
       " 2           0.5         # 5      -  ,                        Task   Dataset  Model         Metric name Metric value  \\\n",
       " 0      Image Classification  CIFAR-10  MCDNN  Percentage correct         88.8   \n",
       " 1  Traffic Sign Recognition     GTSRB  MCDNN          Error rate       11.21%   \n",
       " 2  Traffic Sign Recognition     GTSRB  MCDNN            Accuracy        99.5%   \n",
       " 3      Image Classification     MNIST  MCDNN    Percentage error          0.2   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 47      -  \n",
       " 1         # 1      -  \n",
       " 2         # 1      -  \n",
       " 3         # 2      -  ,                       Task                              Dataset    Model  \\\n",
       " 0   Image Super-Resolution                BSD100 - 4x upscaling    ESPCN   \n",
       " 1   Image Super-Resolution                BSD100 - 4x upscaling    ESPCN   \n",
       " 2   Image Super-Resolution                BSD100 - 4x upscaling    ESPCN   \n",
       " 3   Image Super-Resolution                 Set14 - 4x upscaling    ESPCN   \n",
       " 4   Image Super-Resolution                 Set14 - 4x upscaling    ESPCN   \n",
       " 5   Image Super-Resolution                 Set14 - 4x upscaling    ESPCN   \n",
       " 6   Image Super-Resolution                  Set5 - 4x upscaling    ESPCN   \n",
       " 7   Image Super-Resolution                  Set5 - 4x upscaling    ESPCN   \n",
       " 8   Image Super-Resolution                  Set5 - 4x upscaling    ESPCN   \n",
       " 9   Video Super-Resolution  Ultra Video Group HD - 4x upscaling    ESPCN   \n",
       " 10  Video Super-Resolution  Ultra Video Group HD - 4x upscaling  bicubic   \n",
       " 11  Video Super-Resolution                  Vid4 - 4x upscaling    ESPCN   \n",
       " 12  Video Super-Resolution                  Vid4 - 4x upscaling    ESPCN   \n",
       " 13  Video Super-Resolution                  Vid4 - 4x upscaling    ESPCN   \n",
       " 14  Video Super-Resolution               Xiph HD - 4x upscaling  bicubic   \n",
       " 15  Video Super-Resolution               Xiph HD - 4x upscaling    ESPCN   \n",
       " \n",
       "      Metric name  Metric value Global rank Remove  \n",
       " 0           PSNR       27.0200        # 24      -  \n",
       " 1           SSIM        0.7442         # 4      -  \n",
       " 2            MOS        2.0100         # 4      -  \n",
       " 3           PSNR       27.6600        # 28      -  \n",
       " 4           SSIM        0.8004         # 3      -  \n",
       " 5            MOS        2.5200         # 4      -  \n",
       " 6           PSNR       30.7600        # 25      -  \n",
       " 7           SSIM        0.8784        # 24      -  \n",
       " 8            MOS        2.8900         # 4      -  \n",
       " 9   Average PSNR       37.9100         # 1      -  \n",
       " 10  Average PSNR       36.2000         # 3      -  \n",
       " 11          PSNR       25.0600         # 8      -  \n",
       " 12          SSIM        0.7394         # 5      -  \n",
       " 13         MOVIE        6.5400         # 3      -  \n",
       " 14  Average PSNR       30.3000         # 3      -  \n",
       " 15  Average PSNR       31.6700         # 1      -  ,                    Task        Dataset            Model Metric name  \\\n",
       " 0  Constituency Parsing  Penn Treebank  Stack-only RNNG    F1 score   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          93.6         # 8      -  ,                  Task   Dataset                        Model Metric name  \\\n",
       " 0  Question Answering  SQuAD1.1   OTF dict+spelling (single)          EM   \n",
       " 1  Question Answering  SQuAD1.1   OTF dict+spelling (single)          F1   \n",
       " 2  Question Answering  SQuAD1.1        OTF spelling (single)          EM   \n",
       " 3  Question Answering  SQuAD1.1        OTF spelling (single)          F1   \n",
       " 4  Question Answering  SQuAD1.1  OTF spelling+lemma (single)          EM   \n",
       " 5  Question Answering  SQuAD1.1  OTF spelling+lemma (single)          F1   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0        64.083       # 127      -  \n",
       " 1        73.056       # 131      -  \n",
       " 2        62.897       # 129      -  \n",
       " 3        72.016       # 132      -  \n",
       " 4        62.604       # 130      -  \n",
       " 5        71.968       # 133      -  ,                               Task    Dataset     Model Metric name  \\\n",
       " 0  Aspect-Based Sentiment Analysis  Sentihood  LSTM-LOC      Aspect   \n",
       " 1  Aspect-Based Sentiment Analysis  Sentihood  LSTM-LOC   Sentiment   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          69.3         # 5      -  \n",
       " 1          81.9         # 5      -  ,              Task                      Dataset Model Metric name  \\\n",
       " 0  Face Detection  Annotated Faces in the Wild   DPM          AP   \n",
       " 1  Face Detection                         FDDB   DPM          AP   \n",
       " 2  Face Detection                  PASCAL Face   DPM          AP   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0        0.9721         # 8      -  \n",
       " 1        0.8640         # 8      -  \n",
       " 2        0.9029         # 7      -  ,                  Task       Dataset         Model            Metric name  \\\n",
       " 0  Language Modelling  WikiText-103  Temporal CNN  Validation perplexity   \n",
       " 1  Language Modelling  WikiText-103  Temporal CNN        Test perplexity   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0            -         # 8      -  \n",
       " 1         45.2        # 12      -  ,              Task      Dataset      Model Metric name  Metric value  \\\n",
       " 0  Drug Discovery  HIV dataset  GraphConv         AUC         0.822   \n",
       " 1  Drug Discovery          MUV  GraphConv         AUC         0.836   \n",
       " 2  Drug Discovery         PCBA  GraphConv         AUC         0.855   \n",
       " 3  Drug Discovery        Tox21  GraphConv         AUC         0.846   \n",
       " 4  Drug Discovery      ToxCast  GraphConv         AUC         0.754   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  \n",
       " 1         # 2      -  \n",
       " 2         # 2      -  \n",
       " 3         # 2      -  \n",
       " 4         # 2      -  ,                    Task Dataset                             Model  \\\n",
       " 0  Image Classification  STL-10  Multi-Task Bayesian Optimization   \n",
       " \n",
       "           Metric name  Metric value Global rank Remove  \n",
       " 0  Percentage correct          70.1         # 9      -  ,                   Task   Dataset Model Metric name Metric value Global rank  \\\n",
       " 0  Node Classification  Citeseer   GAT    Accuracy        72.5%         # 2   \n",
       " 1  Node Classification      Cora   GAT    Accuracy        83.0%         # 2   \n",
       " 2  Node Classification    Pubmed   GAT    Accuracy       79.00%         # 4   \n",
       " \n",
       "   Remove  \n",
       " 0      -  \n",
       " 1      -  \n",
       " 2      -  ,                  Task  Dataset                                        Model  \\\n",
       " 0  Sentiment Analysis  SemEval  LSTMs+CNNs ensemble with multiple conv. ops   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0    F1-score         0.685         # 1      -  ,                  Task Dataset                                 Model  \\\n",
       " 0  6D Pose Estimation  T-LESS  RetinaNet+Augmented Autoencoders+ICP   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0    Accuracy         57.14         # 1      -  ,                                  Task          Dataset                 Model  \\\n",
       " 0  Weakly Supervised Object Detection         ImageNet  PCL-OB-G-Ens + FRCNN   \n",
       " 1  Weakly Supervised Object Detection  PASCAL VOC 2007  PCL-OB-G-Ens + FRCNN   \n",
       " 2  Weakly Supervised Object Detection  PASCAL VOC 2012  PCL-OB-G-Ens + FRCNN   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0         MAP          19.6         # 1      -  \n",
       " 1         MAP          48.8         # 4      -  \n",
       " 2         MAP          44.2         # 3      -  ,                      Task     Dataset      Model  \\\n",
       " 0  Visual Object Tracking  VOT2017/18  DaSiamRPN   \n",
       " \n",
       "                       Metric name  Metric value Global rank Remove  \n",
       " 0  Expected Average Overlap (EAO)         0.326         # 5      -  ,                    Task        Dataset      Model           Metric name  \\\n",
       " 0  3D Part Segmentation  ShapeNet-Part  PointConv     Class Average IoU   \n",
       " 1  3D Part Segmentation  ShapeNet-Part  PointConv  Instance Average IoU   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          82.8         # 1      -  \n",
       " 1          85.7         # 2      -  ,                              Task               Dataset   Model Metric name  \\\n",
       " 0  Named Entity Recognition (NER)  CoNLL 2003 (English)  NCRF++          F1   \n",
       " 1          Part-Of-Speech Tagging         Penn Treebank  NCRF++    Accuracy   \n",
       " 2                        Chunking         Penn Treebank  NCRF++    F1 score   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         91.35        # 14      -  \n",
       " 1         97.49         # 7      -  \n",
       " 2         95.06         # 5      -  ,                           Task                 Dataset  \\\n",
       " 0  Cross-Lingual Bitext Mining  BUCC French-to-English   \n",
       " 1  Cross-Lingual Bitext Mining  BUCC German-to-English   \n",
       " \n",
       "                               Model Metric name  Metric value Global rank  \\\n",
       " 0  Multilingual Sentence Embeddings    F1 score         92.89         # 2   \n",
       " 1  Multilingual Sentence Embeddings    F1 score         95.58         # 2   \n",
       " \n",
       "   Remove  \n",
       " 0      -  \n",
       " 1      -  ,                                     Task       Dataset   Model  \\\n",
       " 0  Dense Pixel Correspondence Estimation      HPatches  SPyNet   \n",
       " 1  Dense Pixel Correspondence Estimation      HPatches  SPyNet   \n",
       " 2  Dense Pixel Correspondence Estimation      HPatches  SPyNet   \n",
       " 3  Dense Pixel Correspondence Estimation      HPatches  SPyNet   \n",
       " 4  Dense Pixel Correspondence Estimation      HPatches  SPyNet   \n",
       " 5                Optical Flow Estimation  Sintel-clean  Spynet   \n",
       " 6                Optical Flow Estimation  Sintel-final  Spynet   \n",
       " \n",
       "                Metric name  Metric value Global rank Remove  \n",
       " 0         Viewpoint I AEPE         36.94         # 5      -  \n",
       " 1        Viewpoint II AEPE         50.92         # 5      -  \n",
       " 2       Viewpoint III AEPE         54.29         # 5      -  \n",
       " 3        Viewpoint IV AEPE         62.60         # 5      -  \n",
       " 4         Viewpoint V AEPE         72.57         # 5      -  \n",
       " 5  Average End-Point Error          6.64         # 3      -  \n",
       " 6  Average End-Point Error          8.36         # 3      -  ,                       Task Dataset  Model Metric name Metric value  \\\n",
       " 0  Document Classification    Cora  ACNet    Accuracy        83.5%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  ,                         Task Dataset Model      Metric name Metric value  \\\n",
       " 0  Facial Landmark Detection    300W   FPN  Mean Error Rate       0.1043   \n",
       " 1        Face Identification   IJB-A   FPN         Accuracy        91.4%   \n",
       " 2          Face Verification   IJB-A   FPN   TAR @ FAR=0.01        90.1%   \n",
       " 3        Face Identification   IJB-B   FPN         Accuracy        91.1%   \n",
       " 4          Face Verification   IJB-B   FPN   TAR @ FAR=0.01        96.5%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 2      -  \n",
       " 2         # 8      -  \n",
       " 3         # 1      -  \n",
       " 4         # 1      -  ,                      Task                Dataset  Model Metric name  \\\n",
       " 0  Image Super-Resolution  BSD100 - 4x upscaling  RED30        PSNR   \n",
       " 1  Image Super-Resolution  BSD100 - 4x upscaling  RED30        SSIM   \n",
       " 2  Image Super-Resolution    Set5 - 4x upscaling  RED30        PSNR   \n",
       " 3  Image Super-Resolution    Set5 - 4x upscaling  RED30        SSIM   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0       27.4000        # 17      -  \n",
       " 1        0.7290        # 21      -  \n",
       " 2       31.5100        # 17      -  \n",
       " 3        0.8869        # 20      -  ,                   Task      Dataset      Model Metric name Metric value  \\\n",
       " 0  Node Classification  BlogCatalog  Struc2vec    Accuracy       22.80%   \n",
       " 1  Node Classification  BlogCatalog  Struc2vec    Macro-F1        0.216   \n",
       " 2  Node Classification    Wikipedia  Struc2vec    Accuracy       21.10%   \n",
       " 3  Node Classification    Wikipedia  Struc2vec    Macro-F1        0.190   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  \n",
       " 1         # 2      -  \n",
       " 2         # 2      -  \n",
       " 3         # 2      -  ,                          Task Dataset  \\\n",
       " 0  Natural Language Inference    SNLI   \n",
       " 1  Natural Language Inference    SNLI   \n",
       " 2  Natural Language Inference    SNLI   \n",
       " \n",
       "                                               Model       Metric name  \\\n",
       " 0  300D Directional self-attention network encoders   % Test Accuracy   \n",
       " 1  300D Directional self-attention network encoders  % Train Accuracy   \n",
       " 2  300D Directional self-attention network encoders        Parameters   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0         85.6        # 31      -  \n",
       " 1         91.1        # 27      -  \n",
       " 2         2.4m         # 1      -  ,                  Task   Dataset                 Model Metric name  \\\n",
       " 0  Question Answering  SQuAD1.1  r-net (single model)          EM   \n",
       " 1  Question Answering  SQuAD1.1  r-net (single model)          F1   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0        76.461        # 60      -  \n",
       " 1        84.265        # 61      -  ,                                 Task       Dataset   Model Metric name  \\\n",
       " 0  Fine-Grained Image Classification  CUB-200-2011  RA-CNN    Accuracy   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        85.3%         # 7      -  ,                          Task Dataset                   Model  \\\n",
       " 0  Natural Language Inference    SNLI                    SLRC   \n",
       " 1  Natural Language Inference    SNLI                    SLRC   \n",
       " 2  Natural Language Inference    SNLI                    SLRC   \n",
       " 3  Natural Language Inference    SNLI  SJRC (BERT-Large +SRL)   \n",
       " 4  Natural Language Inference    SNLI  SJRC (BERT-Large +SRL)   \n",
       " 5  Natural Language Inference    SNLI  SJRC (BERT-Large +SRL)   \n",
       " \n",
       "         Metric name Metric value Global rank Remove  \n",
       " 0   % Test Accuracy         89.1         # 8      -  \n",
       " 1  % Train Accuracy         89.1        # 37      -  \n",
       " 2        Parameters         6.1m         # 1      -  \n",
       " 3   % Test Accuracy         91.3         # 1      -  \n",
       " 4  % Train Accuracy         95.7         # 6      -  \n",
       " 5        Parameters         308m         # 1      -  ,                           Task        Dataset               Model Metric name  \\\n",
       " 0  Grammatical Error Detection            FCE  Bi-LSTM + charattn        F0.5   \n",
       " 1       Part-Of-Speech Tagging  Penn Treebank  Bi-LSTM + charattn    Accuracy   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         41.88         # 5      -  \n",
       " 1         97.27        # 11      -  ,                      Task              Dataset    Model Metric name  \\\n",
       " 0  Video Super-Resolution  Vid4 - 4x upscaling  SOF-VSR        PSNR   \n",
       " 1  Video Super-Resolution  Vid4 - 4x upscaling  SOF-VSR        SSIM   \n",
       " 2  Video Super-Resolution  Vid4 - 4x upscaling  SOF-VSR       MOVIE   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0        26.010         # 4      -  \n",
       " 1         0.771         # 7      -  \n",
       " 2         4.320         # 1      -  ,                Task Dataset                   Model      Metric name  \\\n",
       " 0  Object Detection    COCO   FoveaBox + ResNet-101  Bounding Box AP   \n",
       " 1  Object Detection    COCO  FoveaBox + ResNeXt-101  Bounding Box AP   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          40.6        # 23      -  \n",
       " 1          42.1        # 18      -  ,                   Task              Dataset      Model Metric name  \\\n",
       " 0  3D Object Detection      KITTI Cars Easy  PC-CNN-V2          AP   \n",
       " 1  3D Object Detection      KITTI Cars Hard  PC-CNN-V2          AP   \n",
       " 2  3D Object Detection  KITTI Cars Moderate  PC-CNN-V2          AP   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0       84.33%         # 1      -  \n",
       " 1       64.83%         # 4      -  \n",
       " 2       73.80%         # 3      -  ,                    Task    Dataset   Model         Metric name  Metric value  \\\n",
       " 0  Image Classification  CIFAR-100  HD-CNN  Percentage correct         67.40   \n",
       " 1  Image Classification  CIFAR-100  HD-CNN    Percentage error         32.62   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 33      -  \n",
       " 1        # 10      -  ,                    Task     Dataset        Model       Metric name  \\\n",
       " 0  Hand Pose Estimation  ICVL Hands  DeepPrior++  Average 3D Error   \n",
       " 1  Hand Pose Estimation  MSRA Hands  DeepPrior++  Average 3D Error   \n",
       " 2  Hand Pose Estimation   NYU Hands  DeepPrior++  Average 3D Error   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0           8.1         # 5      -  \n",
       " 1           9.5         # 4      -  \n",
       " 2          12.3         # 4      -  ,               Task        Dataset   Model Metric name  Metric value  \\\n",
       " 0  Image Denoising  BSD68 sigma15  FFDNet        PSNR         31.63   \n",
       " 1  Image Denoising  BSD68 sigma25  FFDNet        PSNR         29.19   \n",
       " 2  Image Denoising  BSD68 sigma50  FFDNet        PSNR         26.29   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 4      -  \n",
       " 1         # 4      -  \n",
       " 2         # 5      -  ,            Task                         Dataset Model Metric name  \\\n",
       " 0   Atari Games                Atari 2600 Alien   IQN       Score   \n",
       " 1   Atari Games               Atari 2600 Amidar   IQN       Score   \n",
       " 2   Atari Games              Atari 2600 Assault   IQN       Score   \n",
       " 3   Atari Games              Atari 2600 Asterix   IQN       Score   \n",
       " 4   Atari Games            Atari 2600 Asteroids   IQN       Score   \n",
       " 5   Atari Games             Atari 2600 Atlantis   IQN       Score   \n",
       " 6   Atari Games           Atari 2600 Bank Heist   IQN       Score   \n",
       " 7   Atari Games          Atari 2600 Battle Zone   IQN       Score   \n",
       " 8   Atari Games           Atari 2600 Beam Rider   IQN       Score   \n",
       " 9   Atari Games              Atari 2600 Berzerk   IQN       Score   \n",
       " 10  Atari Games              Atari 2600 Bowling   IQN       Score   \n",
       " 11  Atari Games               Atari 2600 Boxing   IQN       Score   \n",
       " 12  Atari Games             Atari 2600 Breakout   IQN       Score   \n",
       " 13  Atari Games            Atari 2600 Centipede   IQN       Score   \n",
       " 14  Atari Games      Atari 2600 Chopper Command   IQN       Score   \n",
       " 15  Atari Games        Atari 2600 Crazy Climber   IQN       Score   \n",
       " 16  Atari Games             Atari 2600 Defender   IQN       Score   \n",
       " 17  Atari Games         Atari 2600 Demon Attack   IQN       Score   \n",
       " 18  Atari Games          Atari 2600 Double Dunk   IQN       Score   \n",
       " 19  Atari Games               Atari 2600 Enduro   IQN       Score   \n",
       " 20  Atari Games        Atari 2600 Fishing Derby   IQN       Score   \n",
       " 21  Atari Games              Atari 2600 Freeway   IQN       Score   \n",
       " 22  Atari Games            Atari 2600 Frostbite   IQN       Score   \n",
       " 23  Atari Games               Atari 2600 Gopher   IQN       Score   \n",
       " 24  Atari Games             Atari 2600 Gravitar   IQN       Score   \n",
       " 25  Atari Games                 Atari 2600 HERO   IQN       Score   \n",
       " 26  Atari Games           Atari 2600 Ice Hockey   IQN       Score   \n",
       " 27  Atari Games           Atari 2600 James Bond   IQN       Score   \n",
       " 28  Atari Games             Atari 2600 Kangaroo   IQN       Score   \n",
       " 29  Atari Games                Atari 2600 Krull   IQN       Score   \n",
       " 30  Atari Games       Atari 2600 Kung-Fu Master   IQN       Score   \n",
       " 31  Atari Games  Atari 2600 Montezuma's Revenge   IQN       Score   \n",
       " 32  Atari Games           Atari 2600 Ms. Pacman   IQN       Score   \n",
       " 33  Atari Games       Atari 2600 Name This Game   IQN       Score   \n",
       " 34  Atari Games              Atari 2600 Phoenix   IQN       Score   \n",
       " 35  Atari Games             Atari 2600 Pitfall!   IQN       Score   \n",
       " 36  Atari Games                 Atari 2600 Pong   IQN       Score   \n",
       " 37  Atari Games          Atari 2600 Private Eye   IQN       Score   \n",
       " 38  Atari Games               Atari 2600 Q*Bert   IQN       Score   \n",
       " 39  Atari Games           Atari 2600 River Raid   IQN       Score   \n",
       " 40  Atari Games          Atari 2600 Road Runner   IQN       Score   \n",
       " 41  Atari Games             Atari 2600 Robotank   IQN       Score   \n",
       " 42  Atari Games             Atari 2600 Seaquest   IQN       Score   \n",
       " 43  Atari Games               Atari 2600 Skiing   IQN       Score   \n",
       " 44  Atari Games              Atari 2600 Solaris   IQN       Score   \n",
       " 45  Atari Games       Atari 2600 Space Invaders   IQN       Score   \n",
       " 46  Atari Games          Atari 2600 Star Gunner   IQN       Score   \n",
       " 47  Atari Games             Atari 2600 Surround   IQN       Score   \n",
       " 48  Atari Games               Atari 2600 Tennis   IQN       Score   \n",
       " 49  Atari Games           Atari 2600 Time Pilot   IQN       Score   \n",
       " 50  Atari Games            Atari 2600 Tutankham   IQN       Score   \n",
       " 51  Atari Games          Atari 2600 Up and Down   IQN       Score   \n",
       " 52  Atari Games              Atari 2600 Venture   IQN       Score   \n",
       " 53  Atari Games        Atari 2600 Video Pinball   IQN       Score   \n",
       " 54  Atari Games        Atari 2600 Wizard of Wor   IQN       Score   \n",
       " 55  Atari Games         Atari 2600 Yars Revenge   IQN       Score   \n",
       " 56  Atari Games               Atari 2600 Zaxxon   IQN       Score   \n",
       " \n",
       "     Metric value Global rank Remove  \n",
       " 0         7022.0         # 1      -  \n",
       " 1         2946.0         # 1      -  \n",
       " 2        29091.0         # 1      -  \n",
       " 3       342016.0         # 4      -  \n",
       " 4         2898.0         # 4      -  \n",
       " 5       978200.0         # 3      -  \n",
       " 6         1416.0         # 3      -  \n",
       " 7        42244.0         # 1      -  \n",
       " 8        42776.0         # 1      -  \n",
       " 9         1053.0         # 9      -  \n",
       " 10          86.5         # 2      -  \n",
       " 11          99.8         # 1      -  \n",
       " 12         734.0         # 4      -  \n",
       " 13       11561.0         # 2      -  \n",
       " 14       16836.0         # 1      -  \n",
       " 15      179082.0         # 2      -  \n",
       " 16       53537.0         # 1      -  \n",
       " 17      128580.0         # 2      -  \n",
       " 18           5.6         # 3      -  \n",
       " 19        2359.0         # 2      -  \n",
       " 20          33.8         # 5      -  \n",
       " 21          34.0         # 1      -  \n",
       " 22        4324.0         # 5      -  \n",
       " 23      118365.0         # 1      -  \n",
       " 24         911.0         # 2      -  \n",
       " 25       28386.0         # 5      -  \n",
       " 26           0.2         # 3      -  \n",
       " 27       35108.0         # 1      -  \n",
       " 28       15487.0         # 2      -  \n",
       " 29       10707.0         # 2      -  \n",
       " 30       73512.0         # 1      -  \n",
       " 31           0.0        # 23      -  \n",
       " 32        6349.0         # 2      -  \n",
       " 33       22682.0         # 1      -  \n",
       " 34       56599.0         # 2      -  \n",
       " 35           0.0         # 1      -  \n",
       " 36          21.0         # 1      -  \n",
       " 37         200.0        # 16      -  \n",
       " 38       25750.0         # 1      -  \n",
       " 39       17765.0         # 3      -  \n",
       " 40       57900.0         # 5      -  \n",
       " 41          62.5         # 7      -  \n",
       " 42       30140.0         # 4      -  \n",
       " 43       -9289.0         # 1      -  \n",
       " 44        8007.0         # 1      -  \n",
       " 45       28888.0         # 1      -  \n",
       " 46       74677.0         # 7      -  \n",
       " 47           9.4         # 1      -  \n",
       " 48          23.6         # 1      -  \n",
       " 49       12236.0         # 3      -  \n",
       " 50         293.0         # 1      -  \n",
       " 51       88148.0         # 2      -  \n",
       " 52        1318.0         # 3      -  \n",
       " 53      698045.0         # 3      -  \n",
       " 54       31190.0         # 1      -  \n",
       " 55       28379.0         # 1      -  \n",
       " 56       21772.0         # 3      -  ,                   Task   Dataset                         Model Metric name  \\\n",
       " 0  Multi-Human Parsing  MHP v1.0                            DL      AP 0.5   \n",
       " 1       Lane Detection  TuSimple  Discriminative loss function    Accuracy   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0       47.76%         # 4      -  \n",
       " 1       96.40%         # 3      -  ,                  Task   Dataset                      Model Metric name  \\\n",
       " 0  Question Answering  SQuAD1.1      SEDT+BiDAF (ensemble)          EM   \n",
       " 1  Question Answering  SQuAD1.1      SEDT+BiDAF (ensemble)          F1   \n",
       " 2  Question Answering  SQuAD1.1  SEDT+BiDAF (single model)          EM   \n",
       " 3  Question Answering  SQuAD1.1  SEDT+BiDAF (single model)          F1   \n",
       " 4  Question Answering  SQuAD1.1        SEDT (single model)          EM   \n",
       " 5  Question Answering  SQuAD1.1        SEDT (single model)          F1   \n",
       " 6  Question Answering  SQuAD1.1      SEDT (ensemble model)          EM   \n",
       " 7  Question Answering  SQuAD1.1      SEDT (ensemble model)          F1   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0        73.723        # 84      -  \n",
       " 1        81.530        # 86      -  \n",
       " 2        68.478       # 113      -  \n",
       " 3        77.971       # 115      -  \n",
       " 4        68.163       # 116      -  \n",
       " 5        77.527       # 119      -  \n",
       " 6        74.090        # 80      -  \n",
       " 7        81.761        # 83      -  ,                              Task  Dataset     Model Metric name Metric value  \\\n",
       " 0  Multimodal Emotion Recognition  IEMOCAP  CHFusion          F1        55.3%   \n",
       " 1   Multimodal Sentiment Analysis     MOSI  CHFusion    Accuracy        76.5%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 4      -  ,                   Task  Dataset  Model Metric name  Metric value Global rank  \\\n",
       " 0  Text Classification  TREC-50  Rules       Error           2.8         # 1   \n",
       " \n",
       "   Remove  \n",
       " 0      -  ,                  Task        Dataset       Model Metric name  Metric value  \\\n",
       " 0  Dependency Parsing  Penn Treebank  Arc-hybrid         POS         97.30   \n",
       " 1  Dependency Parsing  Penn Treebank  Arc-hybrid         UAS         93.56   \n",
       " 2  Dependency Parsing  Penn Treebank  Arc-hybrid         LAS         91.42   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 3      -  \n",
       " 1         # 8      -  \n",
       " 2         # 8      -  ,                        Task      Dataset    Model Metric name  Metric value  \\\n",
       " 0  Person Re-Identification  Market-1501  Re-rank      Rank-1         77.11   \n",
       " 1  Person Re-Identification  Market-1501  Re-rank         MAP         63.63   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 21      -  \n",
       " 1        # 16      -  ,                       Task              Dataset Model Metric name  \\\n",
       " 0  Relation Classification  SemEval-2010 Task 8   TRE          F1   \n",
       " 1      Relation Extraction               TACRED   TRE          F1   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          87.1         # 1      -  \n",
       " 1          67.4         # 1      -  ,                             Task Dataset        Model Metric name  \\\n",
       " 0  Facial Expression Recognition     MMI  DeXpression    Accuracy   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0       98.63%         # 1      -  ,                Task Dataset          Model      Metric name  Metric value  \\\n",
       " 0  Object Detection    COCO  GHM-C + GHM-R  Bounding Box AP          41.6   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 20      -  ,                Task Dataset            Model      Metric name  Metric value  \\\n",
       " 0  Object Detection    COCO  ExtremeNet (MS)  Bounding Box AP          43.2   \n",
       " 1  Object Detection    COCO       ExtremeNet  Bounding Box AP          43.7   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 14      -  \n",
       " 1        # 12      -  ,                       Task                  Dataset    Model Metric name  \\\n",
       " 0   Image Super-Resolution    BSD100 - 4x upscaling  DnCNN-3        PSNR   \n",
       " 1   Image Super-Resolution    BSD100 - 4x upscaling  DnCNN-3        SSIM   \n",
       " 2          Image Denoising            BSD68 sigma10    DnCNN        PSNR   \n",
       " 3          Image Denoising            BSD68 sigma15    DnCNN        PSNR   \n",
       " 4          Image Denoising            BSD68 sigma25    DnCNN        PSNR   \n",
       " 5          Image Denoising            BSD68 sigma30    DnCNN        PSNR   \n",
       " 6          Image Denoising            BSD68 sigma50    DnCNN        PSNR   \n",
       " 7          Image Denoising            BSD68 sigma70    DnCNN        PSNR   \n",
       " 8   Image Super-Resolution     Set14 - 4x upscaling  DnCNN-3        PSNR   \n",
       " 9   Image Super-Resolution     Set14 - 4x upscaling  DnCNN-3        SSIM   \n",
       " 10  Image Super-Resolution      Set5 - 4x upscaling  DnCNN-3        PSNR   \n",
       " 11  Image Super-Resolution      Set5 - 4x upscaling  DnCNN-3        SSIM   \n",
       " 12  Image Super-Resolution  Urban100 - 4x upscaling  DnCNN-3        PSNR   \n",
       " 13  Image Super-Resolution  Urban100 - 4x upscaling  DnCNN-3        SSIM   \n",
       " 14         Image Denoising         Urban100 sigma50    DnCNN        PSNR   \n",
       " 15         Image Denoising         Urban100 sigma70    DnCNN        PSNR   \n",
       " \n",
       "     Metric value Global rank Remove  \n",
       " 0        27.2900        # 19      -  \n",
       " 1         0.7253        # 23      -  \n",
       " 2        36.3100         # 2      -  \n",
       " 3        31.7300         # 3      -  \n",
       " 4        29.2300         # 3      -  \n",
       " 5        30.4000         # 2      -  \n",
       " 6        26.2300         # 6      -  \n",
       " 7        26.5600         # 2      -  \n",
       " 8        28.0400        # 22      -  \n",
       " 9         0.7672        # 24      -  \n",
       " 10       31.4000        # 19      -  \n",
       " 11        0.8845        # 21      -  \n",
       " 12       25.2000        # 20      -  \n",
       " 13        0.7521        # 19      -  \n",
       " 14       26.2800         # 6      -  \n",
       " 15       24.3600         # 4      -  ,                    Task                       Dataset  \\\n",
       " 0  Novel View Synthesis    KITTI Novel View Synthesis   \n",
       " 1  Novel View Synthesis                  ShapeNet Car   \n",
       " 2  Novel View Synthesis                ShapeNet Chair   \n",
       " 3  Novel View Synthesis  Synthia Novel View Synthesis   \n",
       " \n",
       "                       Model Metric name  Metric value Global rank Remove  \n",
       " 0  Multi-view to Novel View        SSIM         0.626         # 1      -  \n",
       " 1  Multi-view to Novel View        SSIM         0.923         # 1      -  \n",
       " 2  Multi-view to Novel View        SSIM         0.895         # 1      -  \n",
       " 3  Multi-view to Novel View        SSIM         0.697         # 1      -  ,                                 Task       Dataset   Model Metric name  \\\n",
       " 0  Fine-Grained Image Classification  CUB-200-2011  PS-CNN    Accuracy   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        76.6%         # 9      -  ,                  Task  Dataset  Model Metric name  Metric value Global rank  \\\n",
       " 0  Question Answering  WikiHop  BiDAF        Test          42.9         # 4   \n",
       " \n",
       "   Remove  \n",
       " 0      -  ,                    Task                           Dataset  \\\n",
       " 0    Sentiment Analysis                Amazon Review Full   \n",
       " 1    Sentiment Analysis                Amazon Review Full   \n",
       " 2    Sentiment Analysis            Amazon Review Polarity   \n",
       " 3    Sentiment Analysis            Amazon Review Polarity   \n",
       " 4   Text Classification                           DBpedia   \n",
       " 5   Text Classification                           DBpedia   \n",
       " 6    Sentiment Analysis                              IMDb   \n",
       " 7    Sentiment Analysis                              IMDb   \n",
       " 8    Sentiment Analysis        Yelp Binary classification   \n",
       " 9    Sentiment Analysis        Yelp Binary classification   \n",
       " 10   Sentiment Analysis  Yelp Fine-grained classification   \n",
       " 11   Sentiment Analysis  Yelp Fine-grained classification   \n",
       " \n",
       "                       Model Metric name  Metric value Global rank Remove  \n",
       " 0                BERT large    Accuracy         65.83         # 1      -  \n",
       " 1   BERT large finetune UDA    Accuracy         62.88         # 4      -  \n",
       " 2   BERT large finetune UDA    Accuracy         96.50         # 3      -  \n",
       " 3                BERT large    Accuracy         97.37         # 1      -  \n",
       " 4            BERT large UDA       Error          1.09        # 10      -  \n",
       " 5                BERT large       Error          0.68         # 1      -  \n",
       " 6   BERT large finetune UDA    Accuracy         95.80         # 1      -  \n",
       " 7                BERT large    Accuracy         95.49         # 3      -  \n",
       " 8   BERT large finetune UDA       Error          2.05         # 2      -  \n",
       " 9                BERT large       Error          1.89         # 1      -  \n",
       " 10               BERT large       Error         29.32         # 1      -  \n",
       " 11  BERT large finetune UDA       Error         32.08         # 5      -  ,                              Task  Dataset                 Model Metric name  \\\n",
       " 0  Citation Intent Classification  ACL-ARC  Structural-scaffolds          F1   \n",
       " 1         Sentence Classification  ACL-ARC  Structural-scaffolds          F1   \n",
       " 2         Sentence Classification  SciCite  Structural-scaffolds          F1   \n",
       " 3  Citation Intent Classification  SciCite  Structural-Scaffolds          F1   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          67.9         # 1      -  \n",
       " 1          67.9         # 1      -  \n",
       " 2          84.0         # 3      -  \n",
       " 3          84.0         # 2      -  ,                  Task Dataset           Model Metric name  Metric value  \\\n",
       " 0  Action Recognition  HMDB51  Two-Stream I3D    Accuracy          80.9   \n",
       " 1  Action Recognition  UCF101  Two-Stream I3D    Accuracy          93.4   \n",
       " \n",
       "   Global rank  Extradata Remove  \n",
       " 0         # 1        NaN      -  \n",
       " 1         # 1        NaN      -  ,                  Task      Dataset                 Model  \\\n",
       " 0  Speech Recognition  Librispeech  VoiceFilter: bi-LSTM   \n",
       " \n",
       "              Metric name  Metric value Global rank Remove  \n",
       " 0  Word Error Rate (WER)          11.1         # 1      -  ,                    Task   Dataset   Model         Metric name  Metric value  \\\n",
       " 0  Image Classification  CIFAR-10  FLSCNN  Percentage correct         75.90   \n",
       " 1  Image Classification     MNIST  FLSCNN    Percentage error          0.40   \n",
       " 2  Image Classification      SVHN  FLSCNN    Percentage error          3.96   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 60      -  \n",
       " 1         # 4      -  \n",
       " 2        # 22      -  ,                Task          Dataset Model Metric name Metric value  \\\n",
       " 0  Object Detection  PASCAL VOC 2007  FRCN         MAP        70.0%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 16      -  ,                    Task  Dataset Model           Metric name  Metric value  \\\n",
       " 0  Pedestrian Detection  Caltech  LDCF  Reasonable Miss Rate          24.8   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 19      -  ,                       Task                     Dataset  Model  \\\n",
       " 0       Question Answering        Children's Book Test  GPT-2   \n",
       " 1       Question Answering        Children's Book Test  GPT-2   \n",
       " 2   Document Summarization            CNN / Daily Mail  GPT-2   \n",
       " 3   Document Summarization            CNN / Daily Mail  GPT-2   \n",
       " 4   Document Summarization            CNN / Daily Mail  GPT-2   \n",
       " 5       Language Modelling                     enwiki8  GPT-2   \n",
       " 6       Language Modelling                     enwiki8  GPT-2   \n",
       " 7       Language Modelling            One Billion Word  GPT-2   \n",
       " 8       Language Modelling            One Billion Word  GPT-2   \n",
       " 9       Language Modelling  Penn Treebank (Word Level)  GPT-2   \n",
       " 10      Language Modelling  Penn Treebank (Word Level)  GPT-2   \n",
       " 11      Language Modelling                       Text8  GPT-2   \n",
       " 12      Language Modelling                WikiText-103  GPT-2   \n",
       " 13      Language Modelling                WikiText-103  GPT-2   \n",
       " 14      Language Modelling                  WikiText-2  GPT-2   \n",
       " 15      Language Modelling                  WikiText-2  GPT-2   \n",
       " 16  Common Sense Reasoning   Winograd Schema Challenge  GPT-2   \n",
       " \n",
       "                 Metric name Metric value Global rank  Extradata Remove  \n",
       " 0               Accuracy-CN       93.30%         # 1        NaN      -  \n",
       " 1               Accuracy-NE       89.05%         # 1        NaN      -  \n",
       " 2                   ROUGE-1        29.34         # 4        NaN      -  \n",
       " 3                   ROUGE-2         8.27         # 4        NaN      -  \n",
       " 4                   ROUGE-L        26.58         # 4        NaN      -  \n",
       " 5   Bit per Character (BPC)         0.93         # 1        NaN      -  \n",
       " 6          Number of params        1542M         # 1        NaN      -  \n",
       " 7                       PPL        42.16        # 13        NaN      -  \n",
       " 8          Number of params        1.54B         # 1        NaN      -  \n",
       " 9           Test perplexity        35.76         # 1        NaN      -  \n",
       " 10                   Params        1542M         # 1        NaN      -  \n",
       " 11  Bit per Character (BPC)         0.98         # 1        NaN      -  \n",
       " 12          Test perplexity        17.48         # 1        NaN      -  \n",
       " 13         Number of params        1542M         # 1        NaN      -  \n",
       " 14          Test perplexity        18.34         # 1        NaN      -  \n",
       " 15         Number of params        1542M         # 1        NaN      -  \n",
       " 16                    Score        70.70         # 1        NaN      -  ,                  Task        Dataset          Model Metric name  Metric value  \\\n",
       " 0  Dependency Parsing  Penn Treebank  Deep Biaffine         POS         97.30   \n",
       " 1  Dependency Parsing  Penn Treebank  Deep Biaffine         UAS         95.44   \n",
       " 2  Dependency Parsing  Penn Treebank  Deep Biaffine         LAS         93.76   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 3      -  \n",
       " 1         # 2      -  \n",
       " 2         # 2      -  ,                      Task   Dataset  Model       Metric name  Metric value  \\\n",
       " 0  3D Face Reconstruction  Florence  itwmm  Average 3D Error          1.82   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 3      -  ,                      Task           Dataset          Model Metric name  \\\n",
       " 0  Document Summarization  CNN / Daily Mail  Bottom-Up Sum         PPL   \n",
       " 1  Document Summarization  CNN / Daily Mail  Bottom-Up Sum     ROUGE-1   \n",
       " 2  Document Summarization  CNN / Daily Mail  Bottom-Up Sum     ROUGE-2   \n",
       " 3  Document Summarization  CNN / Daily Mail  Bottom-Up Sum     ROUGE-L   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         32.75         # 2      -  \n",
       " 1         41.22         # 2      -  \n",
       " 2         18.68         # 2      -  \n",
       " 3         38.34         # 2      -  ,                    Task         Dataset                  Model  \\\n",
       " 0  Image Classification        ImageNet  MultiGrain R50-AA-500   \n",
       " 1  Image Classification        ImageNet  MultiGrain R50-AA-500   \n",
       " 2  Image Classification        ImageNet  MultiGrain R50-AA-224   \n",
       " 3  Image Classification        ImageNet  MultiGrain R50-AA-224   \n",
       " 4       Image Retrieval  INRIA Holidays   MultiGrain R50 @ 500   \n",
       " 5       Image Retrieval  INRIA Holidays   MultiGrain R50 @ 800   \n",
       " \n",
       "       Metric name Metric value Global rank Remove  \n",
       " 0  Top 1 Accuracy        79.4%        # 10      -  \n",
       " 1  Top 5 Accuracy        94.8%         # 7      -  \n",
       " 2  Top 1 Accuracy        78.2%        # 17      -  \n",
       " 3  Top 5 Accuracy        93.9%        # 12      -  \n",
       " 4        Mean mAP        91.8%         # 2      -  \n",
       " 5        Mean mAP        92.5%         # 1      -  ,                  Task           Dataset              Model Metric name  \\\n",
       " 0  Question Answering  CNN / Daily Mail   Impatient Reader         CNN   \n",
       " 1  Question Answering  CNN / Daily Mail   Impatient Reader  Daily Mail   \n",
       " 2  Question Answering  CNN / Daily Mail   Attentive Reader         CNN   \n",
       " 3  Question Answering  CNN / Daily Mail   Attentive Reader  Daily Mail   \n",
       " 4  Question Answering  CNN / Daily Mail  MemNNs (ensemble)         CNN   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          63.8        # 15      -  \n",
       " 1          68.0        # 10      -  \n",
       " 2          63.0        # 16      -  \n",
       " 3          69.0         # 8      -  \n",
       " 4          69.4        # 13      -  ,                         Task                 Dataset        Model  \\\n",
       " 0   Text-to-Image Generation                    COCO  StackGAN-v1   \n",
       " 1   Text-to-Image Generation                    COCO  StackGAN-v1   \n",
       " 2   Text-to-Image Generation                    COCO  StackGAN-v2   \n",
       " 3   Text-to-Image Generation                    COCO  StackGAN-v2   \n",
       " 4   Text-to-Image Generation                     CUB  StackGAN-v2   \n",
       " 5   Text-to-Image Generation                     CUB  StackGAN-v2   \n",
       " 6   Text-to-Image Generation                     CUB  StackGAN-v1   \n",
       " 7   Text-to-Image Generation                     CUB  StackGAN-v1   \n",
       " 8           Image Generation  LSUN Bedroom 256 x 256  StackGAN-v2   \n",
       " 9   Text-to-Image Generation      Oxford 102 Flowers  StackGAN-v2   \n",
       " 10  Text-to-Image Generation      Oxford 102 Flowers  StackGAN-v2   \n",
       " 11  Text-to-Image Generation      Oxford 102 Flowers  StackGAN-v1   \n",
       " 12  Text-to-Image Generation      Oxford 102 Flowers  StackGAN-v1   \n",
       " \n",
       "         Metric name  Metric value Global rank Remove  \n",
       " 0               FID         74.05         # 3      -  \n",
       " 1   Inception score          8.45         # 4      -  \n",
       " 2               FID         81.59         # 4      -  \n",
       " 3   Inception score          8.30         # 5      -  \n",
       " 4               FID         15.30         # 1      -  \n",
       " 5   Inception score          3.82         # 2      -  \n",
       " 6               FID         51.89         # 2      -  \n",
       " 7   Inception score          3.70         # 3      -  \n",
       " 8               FID         35.61         # 6      -  \n",
       " 9               FID         48.68         # 1      -  \n",
       " 10  Inception score          3.26         # 1      -  \n",
       " 11              FID         55.28         # 2      -  \n",
       " 12  Inception score          3.20         # 2      -  ,                  Task   Dataset    Model       Metric name Metric value  \\\n",
       " 0  Face Anti-Spoofing  MSU-MFSD  GFA-CNN  Equal Error Rate         7.5%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  ,                            Task        Dataset                Model  \\\n",
       " 0  Ad-Hoc Information Retrieval  TREC Robust04  FNRM-RankProb_Embed   \n",
       " 1  Ad-Hoc Information Retrieval  TREC Robust04      FNRM-Rank_Embed   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0         MAP        0.2837         # 6      -  \n",
       " 1         MAP        0.2811         # 7      -  ,                   Task                 Dataset     Model Metric name  \\\n",
       " 0  Machine Translation  WMT2014 English-German  SliceNet  BLEU score   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          26.1        # 11      -  ,                  Task Dataset Model               Metric name Metric value  \\\n",
       " 0  Question Answering    bAbi   RUM  Accuracy (trained on 1k)        73.2%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 4      -  ,                 Task                    Dataset                 Model  \\\n",
       " 0  Face Verification  Labeled Faces in the Wild               SeqFace   \n",
       " 1  Face Verification           YouTube Faces DB  SeqFace, 1 ResNet-64   \n",
       " \n",
       "   Metric name Metric value Global rank Remove  \n",
       " 0    Accuracy       99.03%        # 10      -  \n",
       " 1    Accuracy        98.12         # 1      -  ,                   Task                   Dataset  \\\n",
       " 0  Machine Translation  IWSLT2015 German-English   \n",
       " \n",
       "                                   Model Metric name  Metric value Global rank  \\\n",
       " 0  Word-level CNN w/attn, input feeding  BLEU score          24.0        # 14   \n",
       " \n",
       "   Remove  \n",
       " 0      -  ,                   Task      Dataset     Model Metric name Metric value  \\\n",
       " 0  Node Classification  BlogCatalog  node2vec    Accuracy       21.50%   \n",
       " 1  Node Classification  BlogCatalog  node2vec    Macro-F1        0.206   \n",
       " 2  Node Classification    Wikipedia  node2vec    Accuracy       19.10%   \n",
       " 3  Node Classification    Wikipedia  node2vec    Macro-F1        0.179   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 4      -  \n",
       " 1         # 4      -  \n",
       " 2         # 4      -  \n",
       " 3         # 4      -  ,                                 Task       Dataset      Model Metric name  \\\n",
       " 0  Fine-Grained Image Classification  CUB-200-2011  Part RCNN    Accuracy   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        76.4%        # 10      -  ,              Task     Dataset    Model        Metric name Metric value  \\\n",
       " 0  Edge Detection  Cityscapes  CASENet  Maximum F-measure        71.3%   \n",
       " 1  Edge Detection  Cityscapes  CASENet                 AP        70.8%   \n",
       " 2  Edge Detection         SBD  CASENet  Maximum F-measure        71.4%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 1      -  \n",
       " 2         # 1      -  ,                Task              Dataset     Model Metric name  Metric value  \\\n",
       " 0  Image Generation  CelebA-HQ 1024x1024  StyleGAN         FID          5.06   \n",
       " 1  Image Generation                 FFHQ  StyleGAN         FID          4.43   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 2      -  ,                Task Dataset                       Model      Metric name  \\\n",
       " 0  Object Detection    COCO  FCOS_ResNeXt-101-64x4d-FPN  Bounding Box AP   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          43.2        # 14      -  ,                Task   Dataset              Model    Metric name  Metric value  \\\n",
       " 0  Image Generation  CIFAR-10  Image Transformer  Model Entropy          2.89   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 7      -  ,           Task                         Dataset       Model Metric name  \\\n",
       " 0  Atari Games              Atari 2600 Freeway     Sarsa-ε       Score   \n",
       " 1  Atari Games              Atari 2600 Freeway  Sarsa-φ-EB       Score   \n",
       " 2  Atari Games            Atari 2600 Frostbite  Sarsa-φ-EB       Score   \n",
       " 3  Atari Games            Atari 2600 Frostbite     Sarsa-ε       Score   \n",
       " 4  Atari Games  Atari 2600 Montezuma's Revenge  Sarsa-φ-EB       Score   \n",
       " 5  Atari Games  Atari 2600 Montezuma's Revenge     Sarsa-ε       Score   \n",
       " 6  Atari Games               Atari 2600 Q*Bert  Sarsa-φ-EB       Score   \n",
       " 7  Atari Games               Atari 2600 Q*Bert     Sarsa-ε       Score   \n",
       " 8  Atari Games              Atari 2600 Venture  Sarsa-φ-EB       Score   \n",
       " 9  Atari Games              Atari 2600 Venture     Sarsa-ε       Score   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          29.9        # 12      -  \n",
       " 1           0.0        # 23      -  \n",
       " 2        2770.1        # 10      -  \n",
       " 3        1394.3        # 15      -  \n",
       " 4        2745.4         # 5      -  \n",
       " 5         399.5         # 7      -  \n",
       " 6        4111.8        # 22      -  \n",
       " 7        3895.3        # 23      -  \n",
       " 8        1169.2         # 5      -  \n",
       " 9           0.0        # 27      -  ,                       Task         Dataset  \\\n",
       " 0  Collaborative Filtering          Douban   \n",
       " 1  Collaborative Filtering        Flixster   \n",
       " 2  Collaborative Filtering  MovieLens 100K   \n",
       " 3  Collaborative Filtering      YahooMusic   \n",
       " \n",
       "                                  Model Metric name  Metric value Global rank  \\\n",
       " 0  Factorized Exchangeable Autoencoder        RMSE         0.738         # 4   \n",
       " 1  Factorized Exchangeable Autoencoder        RMSE         0.908         # 1   \n",
       " 2   Self-Supervised Exchangeable Model        RMSE         0.910         # 2   \n",
       " 3  Factorized Exchangeable Autoencoder        RMSE        20.000         # 1   \n",
       " \n",
       "   Remove  \n",
       " 0      -  \n",
       " 1      -  \n",
       " 2      -  \n",
       " 3      -  ,                Task Dataset          Model      Metric name  Metric value  \\\n",
       " 0  Object Detection    COCO  Cascade R-CNN  Bounding Box AP          42.8   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 15      -  ,                  Task                            Dataset  \\\n",
       " 0  Sentiment Analysis        SST-2 Binary classification   \n",
       " 1  Sentiment Analysis  SST-5 Fine-grained classification   \n",
       " \n",
       "                         Model Metric name  Metric value Global rank Remove  \n",
       " 0  Joined Model Multi-tasking    Accuracy         54.72        # 23      -  \n",
       " 1  Joined Model Multi-tasking    Accuracy         44.82        # 15      -  ,                              Task                    Dataset         Model  \\\n",
       " 0  Age-Invariant Face Recognition                     CACDVS       MFM-CNN   \n",
       " 1  Age-Invariant Face Recognition                       CAFR     Light CNN   \n",
       " 2               Face Verification  Labeled Faces in the Wild  Light CNN-29   \n",
       " 3               Face Verification                   MegaFace  Light CNN-29   \n",
       " 4             Face Identification                   MegaFace  Light CNN-29   \n",
       " 5               Face Verification           YouTube Faces DB  Light CNN-29   \n",
       " \n",
       "   Metric name Metric value Global rank Remove  \n",
       " 0    Accuracy       97.95%         # 5      -  \n",
       " 1    Accuracy       73.56%         # 2      -  \n",
       " 2    Accuracy       99.33%         # 7      -  \n",
       " 3    Accuracy      85.133%         # 6      -  \n",
       " 4    Accuracy      73.749%         # 4      -  \n",
       " 5    Accuracy       95.54%         # 5      -  ,                  Task    Dataset                             Model  \\\n",
       " 0  Keypoint Detection  Pascal3D+  ConvNet + deformable shape model   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0    Mean PCK          82.5         # 1      -  ,                  Task          Dataset                       Model  \\\n",
       " 0  Question Answering           Reverb  Memory Networks (ensemble)   \n",
       " 1  Question Answering  SimpleQuestions  Memory Networks (ensemble)   \n",
       " 2  Question Answering     WebQuestions  Memory Networks (ensemble)   \n",
       " \n",
       "   Metric name Metric value Global rank Remove  \n",
       " 0    Accuracy          68%         # 2      -  \n",
       " 1          F1        63.9%         # 1      -  \n",
       " 2          F1        42.2%         # 1      -  ,               Task          Dataset  \\\n",
       " 0  Pose Estimation  ITOP front-view   \n",
       " 1  Pose Estimation    ITOP top-view   \n",
       " \n",
       "                                         Model Metric name  Metric value  \\\n",
       " 0  Multi-task learning + viewpoint invariance    Mean mAP          77.4   \n",
       " 1  Multi-task learning + viewpoint invariance    Mean mAP          75.5   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  \n",
       " 1         # 2      -  ,                    Task   Dataset          Model     Metric name Metric value  \\\n",
       " 0  Image Classification  ImageNet  MobileNet-224  Top 1 Accuracy        70.6%   \n",
       " 1  Image Classification  ImageNet  MobileNet-224  Top 5 Accuracy        89.5%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 21      -  \n",
       " 1        # 17      -  ,                              Task       Dataset   Model  \\\n",
       " 0  Age-Invariant Face Recognition        CACDVS  OE-CNN   \n",
       " 1  Age-Invariant Face Recognition  MORPH Album2  OE-CNN   \n",
       " \n",
       "                Metric name Metric value Global rank Remove  \n",
       " 0                 Accuracy       99.20%         # 3      -  \n",
       " 1  Rank-1 Recognition Rate       98.55%         # 3      -  ,                    Task    Dataset          Model         Metric name  \\\n",
       " 0  Image Classification   CIFAR-10  CoPaNet-R-164  Percentage correct   \n",
       " 1  Image Classification   CIFAR-10  CoPaNet-R-164    Percentage error   \n",
       " 2  Image Classification  CIFAR-100  CoPaNet-R-164  Percentage correct   \n",
       " 3  Image Classification  CIFAR-100  CoPaNet-R-164    Percentage error   \n",
       " 4  Image Classification       SVHN  CoPaNet-R-164    Percentage error   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         96.62         # 8      -  \n",
       " 1          3.38         # 8      -  \n",
       " 2         81.10         # 9      -  \n",
       " 3         18.90         # 5      -  \n",
       " 4          1.58         # 3      -  ,                      Task                  Dataset   Model Metric name  \\\n",
       " 0  Image Super-Resolution    BSD100 - 4x upscaling  SRMDNF        PSNR   \n",
       " 1  Image Super-Resolution    BSD100 - 4x upscaling  SRMDNF        SSIM   \n",
       " 2  Image Super-Resolution     Set14 - 4x upscaling  SRMDNF        PSNR   \n",
       " 3  Image Super-Resolution     Set14 - 4x upscaling  SRMDNF        SSIM   \n",
       " 4  Image Super-Resolution      Set5 - 4x upscaling  SRMDNF        PSNR   \n",
       " 5  Image Super-Resolution      Set5 - 4x upscaling  SRMDNF        SSIM   \n",
       " 6  Image Super-Resolution  Urban100 - 4x upscaling  SRMDNF        PSNR   \n",
       " 7  Image Super-Resolution  Urban100 - 4x upscaling  SRMDNF        SSIM   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0        27.490        # 12      -  \n",
       " 1         0.734        # 16      -  \n",
       " 2        28.350        # 15      -  \n",
       " 3         0.777        # 18      -  \n",
       " 4        31.960        # 11      -  \n",
       " 5         0.893        # 14      -  \n",
       " 6        25.680        # 13      -  \n",
       " 7         0.773        # 12      -  ,                   Task             Dataset Model Metric name Metric value  \\\n",
       " 0  Multi-Human Parsing  PASCAL-Person-Part   MNC      AP 0.5       38.80%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 3      -  ,                    Task  Dataset         Model           Metric name  \\\n",
       " 0  Pedestrian Detection  Caltech  CompACT-Deep  Reasonable Miss Rate   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         11.75        # 14      -  ,                      Task                  Dataset Model Metric name  \\\n",
       " 0  Image Super-Resolution    BSD100 - 4x upscaling  BSRN        PSNR   \n",
       " 1  Image Super-Resolution    BSD100 - 4x upscaling  BSRN        SSIM   \n",
       " 2  Image Super-Resolution     Set14 - 4x upscaling  BSRN        PSNR   \n",
       " 3  Image Super-Resolution     Set14 - 4x upscaling  BSRN        SSIM   \n",
       " 4  Image Super-Resolution      Set5 - 4x upscaling  BSRN        PSNR   \n",
       " 5  Image Super-Resolution      Set5 - 4x upscaling  BSRN        SSIM   \n",
       " 6  Image Super-Resolution  Urban100 - 4x upscaling  BSRN        PSNR   \n",
       " 7  Image Super-Resolution  Urban100 - 4x upscaling  BSRN        SSIM   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0       27.5700         # 9      -  \n",
       " 1        0.7353        # 13      -  \n",
       " 2       28.5600         # 9      -  \n",
       " 3        0.7803        # 15      -  \n",
       " 4       32.1400         # 7      -  \n",
       " 5        0.8937        # 12      -  \n",
       " 6       26.0300        # 11      -  \n",
       " 7        0.7835        # 10      -  ,                  Task       Dataset                         Model Metric name  \\\n",
       " 0  Question Answering        Reverb  Weakly Supervised Embeddings    Accuracy   \n",
       " 1  Question Answering  WebQuestions  Weakly Supervised Embeddings          F1   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0          73%         # 1      -  \n",
       " 1        29.7%         # 3      -  ,                  Task   Dataset  Model Metric name  Metric value Global rank  \\\n",
       " 0  Question Answering  SQuAD1.1  FABIR          EM        67.744       # 120   \n",
       " 1  Question Answering  SQuAD1.1  FABIR          F1        77.605       # 117   \n",
       " \n",
       "   Remove  \n",
       " 0      -  \n",
       " 1      -  ,                Task     Dataset                          Model Metric name  \\\n",
       " 0  Stance Detection  RumourEval  Bahuleyan and Vechtomova 2017    Accuracy   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          0.78         # 2      -  ,                               Task                         Dataset Model  \\\n",
       " 0  Aspect-Based Sentiment Analysis  SemEval 2014 Task 4 Sub Task 2  PBAN   \n",
       " 1  Aspect-Based Sentiment Analysis  SemEval 2014 Task 4 Sub Task 2  PBAN   \n",
       " \n",
       "         Metric name  Metric value Global rank Remove  \n",
       " 0  Restaurant (Acc)         81.16        # 10      -  \n",
       " 1      Laptop (Acc)         74.12        # 13      -  ,                            Task Dataset                  Model    Metric name  \\\n",
       " 0  Multi-Person Pose Estimation    COCO  Pose Residual Network             AP   \n",
       " 1            Keypoint Detection    COCO  Pose Residual Network  Validation AP   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         0.697         # 2      -  \n",
       " 1        69.600         # 4      -  ,                                  Task          Dataset             Model  \\\n",
       " 0  Weakly Supervised Object Detection  PASCAL VOC 2007  WSD+PGE+PGA+FSD2   \n",
       " 1  Weakly Supervised Object Detection  PASCAL VOC 2012  WSD+PGE+PGA+FSD2   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0         MAP          52.4         # 2      -  \n",
       " 1         MAP          47.8         # 2      -  ,                Task         Dataset                Model    Metric name  \\\n",
       " 0  Image Generation  ImageNet 64x64  Parallel Multiscale  Bits per byte   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0           3.7         # 4      -  ,                     Task         Dataset        Model Metric name  \\\n",
       " 0  Semantic Segmentation  PASCAL Context  DUpsampling        mIoU   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          52.5         # 3      -  ,                  Task   Dataset                         Model Metric name  \\\n",
       " 0  Question Answering  SQuAD1.1      Conductor-net (ensemble)          EM   \n",
       " 1  Question Answering  SQuAD1.1      Conductor-net (ensemble)          F1   \n",
       " 2  Question Answering  SQuAD1.1  Conductor-net (single model)          EM   \n",
       " 3  Question Answering  SQuAD1.1  Conductor-net (single model)          F1   \n",
       " 4  Question Answering  SQuAD1.1        Conductor-net (single)          EM   \n",
       " 5  Question Answering  SQuAD1.1        Conductor-net (single)          F1   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0        76.996        # 56      -  \n",
       " 1        84.630        # 55      -  \n",
       " 2        74.405        # 77      -  \n",
       " 3        82.742        # 74      -  \n",
       " 4        73.240        # 87      -  \n",
       " 5        81.933        # 81      -  ,                  Task         Dataset         Model        Metric name  \\\n",
       " 0  Hypernym Discovery         General  300-sparsans                MAP   \n",
       " 1  Hypernym Discovery         General  300-sparsans                MRR   \n",
       " 2  Hypernym Discovery         General  300-sparsans  [email protected]   \n",
       " 3  Hypernym Discovery  Medical domain  300-sparsans                MAP   \n",
       " 4  Hypernym Discovery  Medical domain  300-sparsans                MRR   \n",
       " 5  Hypernym Discovery  Medical domain  300-sparsans  [email protected]   \n",
       " 6  Hypernym Discovery    Music domain  300-sparsans                MAP   \n",
       " 7  Hypernym Discovery    Music domain  300-sparsans                MRR   \n",
       " 8  Hypernym Discovery    Music domain  300-sparsans  [email protected]   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          8.95         # 4      -  \n",
       " 1         19.44         # 4      -  \n",
       " 2          8.63         # 4      -  \n",
       " 3         20.75         # 3      -  \n",
       " 4         40.60         # 4      -  \n",
       " 5         21.43         # 3      -  \n",
       " 6         29.54         # 3      -  \n",
       " 7         46.43         # 3      -  \n",
       " 8         28.86         # 3      -  ,                      Task                  Dataset Model Metric name  \\\n",
       " 0  Image Super-Resolution    BSD100 - 4x upscaling  SESR        PSNR   \n",
       " 1  Image Super-Resolution    BSD100 - 4x upscaling  SESR        SSIM   \n",
       " 2  Image Super-Resolution     Set14 - 4x upscaling  SESR        PSNR   \n",
       " 3  Image Super-Resolution     Set14 - 4x upscaling  SESR        SSIM   \n",
       " 4  Image Super-Resolution      Set5 - 4x upscaling  SESR        PSNR   \n",
       " 5  Image Super-Resolution      Set5 - 4x upscaling  SESR        SSIM   \n",
       " 6  Image Super-Resolution  Urban100 - 4x upscaling  SESR        PSNR   \n",
       " 7  Image Super-Resolution  Urban100 - 4x upscaling  SESR        SSIM   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0        27.420        # 15      -  \n",
       " 1         0.737        # 11      -  \n",
       " 2        28.320        # 16      -  \n",
       " 3         0.784        # 12      -  \n",
       " 4        31.840        # 13      -  \n",
       " 5         0.891        # 16      -  \n",
       " 6        25.420        # 17      -  \n",
       " 7         0.771        # 14      -  ,                              Task       Dataset       Model  \\\n",
       " 0  Age-Invariant Face Recognition        CACDVS         AIM   \n",
       " 1  Age-Invariant Face Recognition        CACDVS  AIM + CAFR   \n",
       " 2  Age-Invariant Face Recognition          CAFR         AIM   \n",
       " 3  Age-Invariant Face Recognition        FG-NET         AIM   \n",
       " 4               Face Verification         IJB-C         AIM   \n",
       " 5  Age-Invariant Face Recognition  MORPH Album2  AIM + CAFR   \n",
       " 6  Age-Invariant Face Recognition  MORPH Album2         AIM   \n",
       " \n",
       "                Metric name Metric value Global rank Remove  \n",
       " 0                 Accuracy       99.38%         # 2      -  \n",
       " 1                 Accuracy       99.76%         # 1      -  \n",
       " 2                 Accuracy       84.81%         # 1      -  \n",
       " 3                 Accuracy       93.20%         # 1      -  \n",
       " 4           TAR @ FAR=0.01       93.50%         # 1      -  \n",
       " 5  Rank-1 Recognition Rate       99.65%         # 1      -  \n",
       " 6  Rank-1 Recognition Rate       99.13%         # 2      -  ,                          Task   Dataset                     Model Metric name  \\\n",
       " 0  Natural Language Inference  MultiNLI  Multi-task BiLSTM + Attn     Matched   \n",
       " 1  Natural Language Inference  MultiNLI  Multi-task BiLSTM + Attn  Mismatched   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          72.2         # 4      -  \n",
       " 1          72.1         # 4      -  ,              Task Dataset  Model  Metric name  Metric value Global rank Remove\n",
       " 0  Drug Discovery     QM9  MPNNs  Error ratio          0.68         # 1      -,                          Task Dataset  \\\n",
       " 0  Natural Language Inference    SNLI   \n",
       " 1  Natural Language Inference    SNLI   \n",
       " 2  Natural Language Inference    SNLI   \n",
       " 3  Natural Language Inference    SNLI   \n",
       " 4  Natural Language Inference    SNLI   \n",
       " 5  Natural Language Inference    SNLI   \n",
       " \n",
       "                                                Model       Metric name  \\\n",
       " 0                       300D NTI-SLSTM-LSTM encoders   % Test Accuracy   \n",
       " 1                       300D NTI-SLSTM-LSTM encoders  % Train Accuracy   \n",
       " 2                       300D NTI-SLSTM-LSTM encoders        Parameters   \n",
       " 3  300D Full tree matching NTI-SLSTM-LSTM w/ glob...   % Test Accuracy   \n",
       " 4  300D Full tree matching NTI-SLSTM-LSTM w/ glob...  % Train Accuracy   \n",
       " 5  300D Full tree matching NTI-SLSTM-LSTM w/ glob...        Parameters   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0         83.4        # 40      -  \n",
       " 1         82.5        # 53      -  \n",
       " 2         4.0m         # 1      -  \n",
       " 3         87.3        # 19      -  \n",
       " 4         88.5        # 39      -  \n",
       " 5         3.2m         # 1      -  ,                        Task          Dataset                    Model  \\\n",
       " 0  Person Re-Identification    DukeMTMC-reID  SVDNet + Random Erasing   \n",
       " 1  Person Re-Identification    DukeMTMC-reID  SVDNet + Random Erasing   \n",
       " 2  Person Re-Identification    DukeMTMC-reID  TriNet + Random Erasing   \n",
       " 3  Person Re-Identification    DukeMTMC-reID  TriNet + Random Erasing   \n",
       " 4      Image Classification    Fashion-MNIST           Random Erasing   \n",
       " 5          Object Detection  PASCAL VOC 2007                    I+ORE   \n",
       " \n",
       "         Metric name Metric value Global rank Remove  \n",
       " 0            Rank-1         79.3         # 6      -  \n",
       " 1               MAP         62.4         # 5      -  \n",
       " 2            Rank-1         73.0        # 10      -  \n",
       " 3               MAP         56.6         # 9      -  \n",
       " 4  Percentage error         3.65         # 1      -  \n",
       " 5               MAP        76.2%        # 11      -  ,                     Task    Dataset                Model Metric name  \\\n",
       " 0   Mortality Prediction  MIMIC-III           Linear SVM    F1 score   \n",
       " 1   Mortality Prediction  MIMIC-III           Linear SVM   Precision   \n",
       " 2   Mortality Prediction  MIMIC-III           Linear SVM      Recall   \n",
       " 3   Mortality Prediction  MIMIC-III  Linear Discriminant    F1 score   \n",
       " 4   Mortality Prediction  MIMIC-III  Linear Discriminant   Precision   \n",
       " 5   Mortality Prediction  MIMIC-III  Linear Discriminant      Recall   \n",
       " 6   Mortality Prediction  MIMIC-III                 K-NN    F1 score   \n",
       " 7   Mortality Prediction  MIMIC-III                 K-NN   Precision   \n",
       " 8   Mortality Prediction  MIMIC-III                 K-NN      Recall   \n",
       " 9   Mortality Prediction  MIMIC-III  Logistic regression    F1 score   \n",
       " 10  Mortality Prediction  MIMIC-III  Logistic regression   Precision   \n",
       " 11  Mortality Prediction  MIMIC-III  Logistic regression      Recall   \n",
       " 12  Mortality Prediction  MIMIC-III        Random Forest    F1 score   \n",
       " 13  Mortality Prediction  MIMIC-III        Random Forest   Precision   \n",
       " 14  Mortality Prediction  MIMIC-III        Random Forest      Recall   \n",
       " 15  Mortality Prediction  MIMIC-III         Gaussian SVM    F1 score   \n",
       " 16  Mortality Prediction  MIMIC-III         Gaussian SVM   Precision   \n",
       " 17  Mortality Prediction  MIMIC-III         Gaussian SVM      Recall   \n",
       " 18  Mortality Prediction  MIMIC-III        Decision Tree    F1 score   \n",
       " 19  Mortality Prediction  MIMIC-III        Decision Tree   Precision   \n",
       " 20  Mortality Prediction  MIMIC-III        Decision Tree      Recall   \n",
       " 21  Mortality Prediction  MIMIC-III        Boosted Trees    F1 score   \n",
       " 22  Mortality Prediction  MIMIC-III        Boosted Trees   Precision   \n",
       " 23  Mortality Prediction  MIMIC-III        Boosted Trees      Recall   \n",
       " \n",
       "     Metric value Global rank Remove  \n",
       " 0           0.70         # 8      -  \n",
       " 1           0.80         # 5      -  \n",
       " 2           0.63         # 8      -  \n",
       " 3           0.71         # 7      -  \n",
       " 4           0.78         # 6      -  \n",
       " 5           0.66         # 7      -  \n",
       " 6           0.82         # 5      -  \n",
       " 7           0.80         # 5      -  \n",
       " 8           0.85         # 4      -  \n",
       " 9           0.72         # 6      -  \n",
       " 10          0.77         # 7      -  \n",
       " 11          0.67         # 6      -  \n",
       " 12          0.97         # 1      -  \n",
       " 13          0.97         # 1      -  \n",
       " 14          0.97         # 1      -  \n",
       " 15          0.96         # 2      -  \n",
       " 16          0.95         # 2      -  \n",
       " 17          0.96         # 2      -  \n",
       " 18          0.91         # 3      -  \n",
       " 19          0.90         # 4      -  \n",
       " 20          0.92         # 3      -  \n",
       " 21          0.87         # 4      -  \n",
       " 22          0.91         # 3      -  \n",
       " 23          0.83         # 5      -  ,                          Task          Dataset  \\\n",
       " 0            Object Detection             COCO   \n",
       " 1            Object Detection             COCO   \n",
       " 2            Object Detection             COCO   \n",
       " 3  Real-Time Object Detection             COCO   \n",
       " 4  Real-Time Object Detection             COCO   \n",
       " 5            Object Detection  PASCAL VOC 2007   \n",
       " 6  Real-Time Object Detection  PASCAL VOC 2007   \n",
       " 7  Real-Time Object Detection  PASCAL VOC 2007   \n",
       " \n",
       "                                      Model      Metric name Metric value  \\\n",
       " 0   RefineDet512 + VoVNet-57 (multi-scale)  Bounding Box AP         43.6   \n",
       " 1  RefineDet512 + VoVNet-57 (sinlge-scale)  Bounding Box AP         39.2   \n",
       " 2        RefineDet320 + VoVNet-57 backbone  Bounding Box AP         33.9   \n",
       " 3        VoVNet-57 + RefineDet320 backbone              MAP        33.9%   \n",
       " 4        VoVNet-57 + RefineDet320 backbone              FPS         21.2   \n",
       " 5                 DSOD300 + VoVNet-27-slim              MAP        74.8%   \n",
       " 6                 DSOD300 + VoVNet-27-slim              MAP        74.8%   \n",
       " 7                 DSOD300 + VoVNet-27-slim              FPS           71   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 13      -  \n",
       " 1        # 27      -  \n",
       " 2        # 33      -  \n",
       " 3         # 4      -  \n",
       " 4         # 5      -  \n",
       " 5        # 12      -  \n",
       " 6         # 4      -  \n",
       " 7         # 1      -  ,                    Task  Dataset     Model           Metric name  \\\n",
       " 0  Pedestrian Detection  Caltech  F-DNN+SS  Reasonable Miss Rate   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          8.18        # 10      -  ,                  Task Dataset Model Metric name  Metric value Global rank  \\\n",
       " 0  Question Answering  TrecQA  aNMM         MAP         0.750         # 3   \n",
       " 1  Question Answering  TrecQA  aNMM         MRR         0.811         # 3   \n",
       " \n",
       "   Remove  \n",
       " 0      -  \n",
       " 1      -  ,                    Task   Dataset                Model     Metric name  \\\n",
       " 0  Image Classification  ImageNet  Inception ResNet V2  Top 1 Accuracy   \n",
       " 1  Image Classification  ImageNet  Inception ResNet V2  Top 5 Accuracy   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        80.1%         # 8      -  \n",
       " 1        95.1%         # 6      -  ,                  Task Dataset                  Model    Metric name  \\\n",
       " 0  Question Answering    CoQA  FlowQA (single model)      In-domain   \n",
       " 1  Question Answering    CoQA  FlowQA (single model)  Out-of-domain   \n",
       " 2  Question Answering    CoQA  FlowQA (single model)        Overall   \n",
       " 3  Question Answering    QuAC  FlowQA (single model)             F1   \n",
       " 4  Question Answering    QuAC  FlowQA (single model)           HEQQ   \n",
       " 5  Question Answering    QuAC  FlowQA (single model)           HEQD   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          76.3         # 5      -  \n",
       " 1          71.8         # 5      -  \n",
       " 2          75.0         # 5      -  \n",
       " 3          64.1         # 1      -  \n",
       " 4          59.6         # 1      -  \n",
       " 5           5.8         # 1      -  ,                  Task                     Dataset Model Metric name  \\\n",
       " 0  Sentiment Analysis          Amazon Review Full  SRNN    Accuracy   \n",
       " 1  Sentiment Analysis      Amazon Review Polarity  SRNN    Accuracy   \n",
       " 2  Sentiment Analysis  Yelp Binary classification  SRNN       Error   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         61.65         # 6      -  \n",
       " 1         95.26         # 6      -  \n",
       " 2          3.96        # 10      -  ,                   Task                 Dataset                     Model  \\\n",
       " 0  Machine Translation  WMT2014 English-French  Evolved Transformer Base   \n",
       " 1  Machine Translation  WMT2014 English-French   Evolved Transformer Big   \n",
       " 2  Machine Translation  WMT2014 English-German  Evolved Transformer Base   \n",
       " 3  Machine Translation  WMT2014 English-German   Evolved Transformer Big   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0  BLEU score          40.6         # 9      -  \n",
       " 1  BLEU score          41.3         # 6      -  \n",
       " 2  BLEU score          28.4         # 7      -  \n",
       " 3  BLEU score          29.3         # 3      -  ,                        Task Dataset          Model      Metric name  \\\n",
       " 0  Text-to-Image Generation    COCO   AttnGAN + OP              FID   \n",
       " 1  Text-to-Image Generation    COCO   AttnGAN + OP  Inception score   \n",
       " 2  Text-to-Image Generation    COCO  StackGAN + OP              FID   \n",
       " 3  Text-to-Image Generation    COCO  StackGAN + OP  Inception score   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         33.35         # 1      -  \n",
       " 1         24.76         # 2      -  \n",
       " 2         55.30         # 2      -  \n",
       " 3         12.12         # 3      -  ,                    Task   Dataset Model         Metric name  Metric value  \\\n",
       " 0  Image Classification  CIFAR-10   CKN  Percentage correct         82.20   \n",
       " 1  Image Classification     MNIST   CKN    Percentage error          0.40   \n",
       " 2  Image Classification    STL-10   CKN  Percentage correct         62.32   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 54      -  \n",
       " 1         # 4      -  \n",
       " 2        # 14      -  ,                         Task  \\\n",
       " 0  Visual Question Answering   \n",
       " \n",
       "                                              Dataset    Model  \\\n",
       " 0  COCO Visual Question Answering (VQA) real imag...  CNN-RNN   \n",
       " \n",
       "           Metric name  Metric value Global rank Remove  \n",
       " 0  Percentage correct          59.5         # 6      -  ,                   Task                 Dataset  \\\n",
       " 0  Machine Translation  WMT2016 English-German   \n",
       " 1  Machine Translation  WMT2016 German-English   \n",
       " \n",
       "                              Model Metric name  Metric value Global rank  \\\n",
       " 0  Unsupervised S2S with attention  BLEU score          9.64         # 5   \n",
       " 1  Unsupervised S2S with attention  BLEU score         13.33         # 5   \n",
       " \n",
       "   Remove  \n",
       " 0      -  \n",
       " 1      -  ,                    Task Dataset  \\\n",
       " 0  Image Classification   MNIST   \n",
       " \n",
       "                                                Model       Metric name  \\\n",
       " 0  Sparse Activity and Sparse Connectivity in Sup...  Percentage error   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0           0.8         # 8      -  ,                                  Task          Dataset  \\\n",
       " 0  Weakly Supervised Object Detection  PASCAL VOC 2007   \n",
       " 1  Weakly Supervised Object Detection  PASCAL VOC 2012   \n",
       " \n",
       "                        Model Metric name  Metric value Global rank Remove  \n",
       " 0  Deep Self-Taught Learning         MAP          43.7         # 9      -  \n",
       " 1  Deep Self-Taught Learning         MAP          38.3         # 7      -  ,                            Task            Dataset                 Model  \\\n",
       " 0            Keypoint Detection               COCO  Part Affinity Fields   \n",
       " 1  Multi-Person Pose Estimation  MPII Multi-Person  Part Affinity Fields   \n",
       " \n",
       "      Metric name Metric value Global rank Remove  \n",
       " 0  Validation AP         60.5         # 7      -  \n",
       " 1             AP        75.6%         # 4      -  ,                                Task          Dataset   Model      Metric name  \\\n",
       " 0             Semantic Segmentation           ADE20K  PSPNet  Validation mIoU   \n",
       " 1             Semantic Segmentation           ADE20K  PSPNet       Test Score   \n",
       " 2             Semantic Segmentation           CamVid  PSPNet         Mean IoU   \n",
       " 3   Real-Time Semantic Segmentation           CamVid  PSPNet             mIoU   \n",
       " 4   Real-Time Semantic Segmentation           CamVid  PSPNet        Time (ms)   \n",
       " 5   Real-Time Semantic Segmentation           CamVid  PSPNet      Frame (fps)   \n",
       " 6             Semantic Segmentation       Cityscapes  PSPNet         Mean IoU   \n",
       " 7   Real-Time Semantic Segmentation       Cityscapes  PSPNet             mIoU   \n",
       " 8   Real-Time Semantic Segmentation       Cityscapes  PSPNet        Time (ms)   \n",
       " 9   Real-Time Semantic Segmentation       Cityscapes  PSPNet      Frame (fps)   \n",
       " 10            Semantic Segmentation  PASCAL VOC 2012  PSPNet         Mean IoU   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         44.94         # 1      -  \n",
       " 1        0.5538         # 3      -  \n",
       " 2         69.1%         # 1      -  \n",
       " 3         69.1%         # 1      -  \n",
       " 4           185         # 2      -  \n",
       " 5           5.4         # 2      -  \n",
       " 6         81.2%         # 5      -  \n",
       " 7         81.2%         # 1      -  \n",
       " 8          1288         # 7      -  \n",
       " 9          0.78         # 9      -  \n",
       " 10        85.4%         # 5      -  ,                Task          Dataset             Model Metric name  \\\n",
       " 0  Object Detection  PASCAL VOC 2007  SPP (Overfeat-7)         MAP   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0       82.44%         # 4      -  ,                               Task                         Dataset Model  \\\n",
       " 0  Aspect-Based Sentiment Analysis  SemEval 2014 Task 4 Sub Task 2  HAPN   \n",
       " 1  Aspect-Based Sentiment Analysis  SemEval 2014 Task 4 Sub Task 2  HAPN   \n",
       " \n",
       "         Metric name  Metric value Global rank Remove  \n",
       " 0  Restaurant (Acc)         82.23         # 3      -  \n",
       " 1      Laptop (Acc)         77.27        # 23      -  ,              Task Dataset                          Model      Metric name  \\\n",
       " 0  Face Alignment    COFW  DenseU-Net + Dual Transformer  Mean Error Rate   \n",
       " 1  Face Alignment    IBUG  DenseU-Net + Dual Transformer  Mean Error Rate   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        5.55%         # 1      -  \n",
       " 1        6.73%         # 1      -  ,                              Task  Dataset                       Model  \\\n",
       " 0         Sentence Classification  ACL-ARC               Random Forest   \n",
       " 1  Citation Intent Classification  ACL-ARC  Feature-rich Random Forest   \n",
       " 2  Citation Intent Classification  SciCite  Feature-Rich Random Forest   \n",
       " 3         Sentence Classification  SciCite  Feature-Rich Random Forest   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0          F1          53.0         # 4      -  \n",
       " 1          F1          53.0         # 4      -  \n",
       " 2          F1          79.6         # 4      -  \n",
       " 3          F1          79.6         # 5      -  ,                                  Task Dataset Model Metric name  Metric value  \\\n",
       " 0  Weakly Supervised Object Detection    COCO  SPNs         MAP          55.3   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  ,                   Task                   Dataset               Model  \\\n",
       " 0  Machine Translation  IWSLT2015 English-German             ConvS2S   \n",
       " 1  Machine Translation  IWSLT2015 German-English             ConvS2S   \n",
       " 2  Machine Translation    WMT2014 English-French             ConvS2S   \n",
       " 3  Machine Translation    WMT2014 English-French  ConvS2S (ensemble)   \n",
       " 4  Machine Translation    WMT2014 English-German  ConvS2S (ensemble)   \n",
       " 5  Machine Translation    WMT2014 English-German             ConvS2S   \n",
       " 6  Machine Translation  WMT2016 English-Romanian      ConvS2S BPE40k   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0  BLEU score         26.73         # 5      -  \n",
       " 1  BLEU score         32.31         # 8      -  \n",
       " 2  BLEU score         40.46        # 11      -  \n",
       " 3  BLEU score         41.29         # 7      -  \n",
       " 4  BLEU score         26.36         # 9      -  \n",
       " 5  BLEU score         25.16        # 13      -  \n",
       " 6  BLEU score         29.88         # 1      -  ,                    Task    Dataset                     Model  \\\n",
       " 0  Image Classification  CIFAR-100            AA-Wide-ResNet   \n",
       " 1      Object Detection       COCO  AA-ResNet-10 + RetinaNet   \n",
       " 2  Image Classification   ImageNet             AA-ResNet-152   \n",
       " 3  Image Classification   ImageNet             AA-ResNet-152   \n",
       " \n",
       "           Metric name Metric value Global rank Remove  \n",
       " 0  Percentage correct         81.6         # 7      -  \n",
       " 1     Bounding Box AP         39.2        # 27      -  \n",
       " 2      Top 1 Accuracy        79.1%        # 12      -  \n",
       " 3      Top 5 Accuracy        94.6%         # 9      -  ,                  Task   Dataset                 Model Metric name  \\\n",
       " 0  Question Answering  SQuAD1.1  MEMEN (single model)          EM   \n",
       " 1  Question Answering  SQuAD1.1  MEMEN (single model)          F1   \n",
       " 2  Question Answering  SQuAD1.1      MEMEN (ensemble)          EM   \n",
       " 3  Question Answering  SQuAD1.1      MEMEN (ensemble)          F1   \n",
       " 4  Question Answering  TriviaQA                 MEMEN          EM   \n",
       " 5  Question Answering  TriviaQA                 MEMEN          F1   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0        78.234        # 45      -  \n",
       " 1        85.344        # 49      -  \n",
       " 2        75.370        # 70      -  \n",
       " 3        82.658        # 76      -  \n",
       " 4        43.160         # 5      -  \n",
       " 5        46.900         # 5      -  ,                  Task   Dataset                   Model Metric name  \\\n",
       " 0  Question Answering  SQuAD1.1  smarnet (single model)          EM   \n",
       " 1  Question Answering  SQuAD1.1  smarnet (single model)          F1   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0        71.415        # 98      -  \n",
       " 1        80.160        # 99      -  ,                    Task          Dataset  \\\n",
       " 0  Image Classification         CIFAR-10   \n",
       " 1  Image Classification         CIFAR-10   \n",
       " 2      Object Detection             COCO   \n",
       " 3      Object Detection  PASCAL VOC 2007   \n",
       " \n",
       "                                                Model         Metric name  \\\n",
       " 0                                             ResNet  Percentage correct   \n",
       " 1                                             ResNet    Percentage error   \n",
       " 2  Faster R-CNN + box refinement + context + mult...     Bounding Box AP   \n",
       " 3                                         ResNet-101                 MAP   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        93.57        # 24      -  \n",
       " 1         6.43        # 13      -  \n",
       " 2         34.9        # 30      -  \n",
       " 3        76.4%        # 10      -  ,                      Task              Dataset Model Metric name  \\\n",
       " 0  Video Super-Resolution  Vid4 - 4x upscaling  BRCN        PSNR   \n",
       " 1  Video Super-Resolution  Vid4 - 4x upscaling  BRCN        SSIM   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0        24.430        # 10      -  \n",
       " 1         0.662         # 2      -  ,                         Task  \\\n",
       " 0  Visual Question Answering   \n",
       " \n",
       "                                              Dataset  Model  \\\n",
       " 0  COCO Visual Question Answering (VQA) real imag...  N2NMN   \n",
       " \n",
       "           Metric name  Metric value Global rank Remove  \n",
       " 0  Percentage correct          64.2         # 2      -  ,                            Task           Dataset           Model  \\\n",
       " 0  Conditional Image Generation  ImageNet 128x128  Self-attention   \n",
       " 1  Conditional Image Generation  ImageNet 128x128  Self-attention   \n",
       " \n",
       "        Metric name  Metric value Global rank Remove  \n",
       " 0              FID         18.65         # 4      -  \n",
       " 1  Inception score         52.52         # 4      -  ,               Task             Dataset                        Model  \\\n",
       " 0  Pose Estimation         FLIC Elbows  Convolutional Pose Machines   \n",
       " 1  Pose Estimation         FLIC Wrists  Convolutional Pose Machines   \n",
       " 2  Pose Estimation  Leeds Sports Poses  Convolutional Pose Machines   \n",
       " 3  Pose Estimation     MPII Human Pose  Convolutional Pose Machines   \n",
       " \n",
       "          Metric name Metric value Global rank Remove  \n",
       " 0  [email protected]       97.59%         # 2      -  \n",
       " 1  [email protected]       95.03%         # 2      -  \n",
       " 2                PCK        90.5%         # 3      -  \n",
       " 3           PCKh-0.5       88.52%         # 8      -  ,                    Task        Dataset       Model           Metric name  \\\n",
       " 0    Scene Segmentation        ScanNet  PointNet++      Average Accuracy   \n",
       " 1  3D Part Segmentation  ShapeNet-Part    PointNet     Class Average IoU   \n",
       " 2  3D Part Segmentation  ShapeNet-Part    PointNet  Instance Average IoU   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        60.2%         # 2      -  \n",
       " 1         80.4         # 5      -  \n",
       " 2         83.7         # 7      -  ,           Task      Dataset                    Model  Metric name  \\\n",
       " 0  Amr Parsing  LDC2014T12:  Incremental joint model  F1 Newswire   \n",
       " 1  Amr Parsing  LDC2014T12:  Incremental joint model      F1 Full   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          0.71         # 2      -  \n",
       " 1          0.66         # 2      -  ,                                   Task  Dataset Model Metric name  \\\n",
       " 0  Emotion Recognition in Conversation  IEMOCAP  ICON          F1   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        63.5%         # 2      -  ,                  Task         Dataset Model        Metric name  Metric value  \\\n",
       " 0  Hypernym Discovery         General  CRIM                MAP         19.78   \n",
       " 1  Hypernym Discovery         General  CRIM                MRR         36.10   \n",
       " 2  Hypernym Discovery         General  CRIM  [email protected]         19.03   \n",
       " 3  Hypernym Discovery  Medical domain  CRIM                MAP         34.05   \n",
       " 4  Hypernym Discovery  Medical domain  CRIM                MRR         54.64   \n",
       " 5  Hypernym Discovery  Medical domain  CRIM  [email protected]         36.77   \n",
       " 6  Hypernym Discovery    Music domain  CRIM                MAP         40.97   \n",
       " 7  Hypernym Discovery    Music domain  CRIM                MRR         60.93   \n",
       " 8  Hypernym Discovery    Music domain  CRIM  [email protected]         41.31   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 1      -  \n",
       " 2         # 1      -  \n",
       " 3         # 1      -  \n",
       " 4         # 1      -  \n",
       " 5         # 1      -  \n",
       " 6         # 1      -  \n",
       " 7         # 1      -  \n",
       " 8         # 1      -  ,                Task   Dataset      Model Metric name  Metric value  \\\n",
       " 0  Image Generation  CIFAR-10  PixelCNN+    NLL Test          2.92   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  ,                     Task       Dataset     Model Metric name Metric value  \\\n",
       " 0  Curved Text Detection  SCUT-CTW1500  CTD+TLOC   F-Measure        73.4%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 3      -  ,                    Task   Dataset                Model     Metric name  \\\n",
       " 0  Image Classification  ImageNet  Oct-ResNet-152 + SE  Top 1 Accuracy   \n",
       " 1  Image Classification  ImageNet  Oct-ResNet-152 + SE  Top 5 Accuracy   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        82.9%         # 3      -  \n",
       " 1        96.3%         # 2      -  ,                                Task                   Dataset  \\\n",
       " 0  Unsupervised Machine Translation    WMT2014 English-French   \n",
       " 1  Unsupervised Machine Translation    WMT2014 French-English   \n",
       " 2  Unsupervised Machine Translation    WMT2016 English-German   \n",
       " 3  Unsupervised Machine Translation  WMT2016 English-Romanian   \n",
       " 4  Unsupervised Machine Translation    WMT2016 German-English   \n",
       " 5  Unsupervised Machine Translation  WMT2016 Romanian-English   \n",
       " 6               Machine Translation  WMT2016 Romanian-English   \n",
       " \n",
       "                                      Model Metric name  Metric value  \\\n",
       " 0  MLM pretraining for encoder and decoder        BLEU          33.4   \n",
       " 1  MLM pretraining for encoder and decoder        BLEU          33.3   \n",
       " 2  MLM pretraining for encoder and decoder        BLEU          26.4   \n",
       " 3  MLM pretraining for encoder and decoder        BLEU          33.3   \n",
       " 4  MLM pretraining for encoder and decoder        BLEU          34.3   \n",
       " 5  MLM pretraining for encoder and decoder        BLEU          31.8   \n",
       " 6                          MLM pretraining  BLEU score          35.3   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  \n",
       " 1         # 2      -  \n",
       " 2         # 2      -  \n",
       " 3         # 1      -  \n",
       " 4         # 2      -  \n",
       " 5         # 1      -  \n",
       " 6         # 1      -  ,                      Task                Dataset            Model Metric name  \\\n",
       " 0  Image Super-Resolution  BSD100 - 4x upscaling  Perceptual Loss        PSNR   \n",
       " 1  Image Super-Resolution  BSD100 - 4x upscaling  Perceptual Loss        SSIM   \n",
       " 2  Image Super-Resolution    Set5 - 4x upscaling  Perceptual Loss        PSNR   \n",
       " 3  Image Super-Resolution    Set5 - 4x upscaling  Perceptual Loss        SSIM   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0       24.9500        # 33      -  \n",
       " 1        0.6317        # 32      -  \n",
       " 2       27.0900        # 33      -  \n",
       " 3        0.7680        # 32      -  ,                    Task    Dataset         Model         Metric name  \\\n",
       " 0  Image Classification   CIFAR-10  Deep Complex  Percentage correct   \n",
       " 1  Image Classification  CIFAR-100  Deep Complex  Percentage correct   \n",
       " 2  Image Classification       SVHN  Deep Complex    Percentage error   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          94.4        # 19      -  \n",
       " 1          72.9        # 18      -  \n",
       " 2           3.3        # 21      -  ,               Task Dataset Model        Metric name  Metric value Global rank  \\\n",
       " 0  Link Prediction  WN18RR  M3GM                MRR        0.4983         # 1   \n",
       " 1  Link Prediction  WN18RR  M3GM  [email protected]        0.5902         # 1   \n",
       " 2  Link Prediction  WN18RR  M3GM  [email protected]        0.4537         # 1   \n",
       " \n",
       "   Remove  \n",
       " 0      -  \n",
       " 1      -  \n",
       " 2      -  ,                                 Task Dataset           Model Metric name  \\\n",
       " 0                 Unsupervised MNIST   MNIST  Adversarial AE    Accuracy   \n",
       " 1  Unsupervised image classification   MNIST  Adversarial AE    Accuracy   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          95.9         # 3      -  \n",
       " 1          95.9         # 3      -  ,                    Task   Dataset          Model         Metric name  \\\n",
       " 0  Image Classification  CIFAR-10  BinaryConnect  Percentage correct   \n",
       " 1  Image Classification     MNIST  BinaryConnect    Percentage error   \n",
       " 2  Image Classification      SVHN  BinaryConnect    Percentage error   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         91.70        # 34      -  \n",
       " 1          1.00        # 10      -  \n",
       " 2          2.15        # 15      -  ,                  Task Dataset Model                Metric name Metric value  \\\n",
       " 0  Question Answering    bAbi   QRN  Accuracy (trained on 10k)        99.7%   \n",
       " 1  Question Answering    bAbi   QRN   Accuracy (trained on 1k)        90.1%   \n",
       " 2  Question Answering    bAbi   QRN            Mean Error Rate         0.3%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 1      -  \n",
       " 2         # 1      -  ,                     Task        Dataset       Model           Metric name  \\\n",
       " 0  Semantic Segmentation       ShapeNet  PointNet++              Mean IoU   \n",
       " 1   3D Part Segmentation  ShapeNet-Part  PointNet++     Class Average IoU   \n",
       " 2   3D Part Segmentation  ShapeNet-Part  PointNet++  Instance Average IoU   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        84.6%         # 2      -  \n",
       " 1         81.9         # 4      -  \n",
       " 2         85.1         # 4      -  ,                  Task Dataset                        Model       Metric name  \\\n",
       " 0  Speech Recognition   TIMIT  Light Gated Recurrent Units  Percentage error   \n",
       " 1  Speech Recognition   TIMIT      Li-GRU + fMLLR features  Percentage error   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          16.7         # 9      -  \n",
       " 1          14.9         # 3      -  ,                         Task  \\\n",
       " 0  Visual Question Answering   \n",
       " \n",
       "                                              Dataset    Model  \\\n",
       " 0  COCO Visual Question Answering (VQA) real imag...  Up-Down   \n",
       " \n",
       "           Metric name  Metric value Global rank Remove  \n",
       " 0  Percentage correct         70.34         # 1      -  ,                                  Task           Dataset    Model  \\\n",
       " 0  Hyperspectral Image Classification      Indian Pines  CNN-MRF   \n",
       " 1  Hyperspectral Image Classification  Pavia University  CNN-MRF   \n",
       " \n",
       "         Metric name Metric value Global rank Remove  \n",
       " 0  Overall Accuracy       96.12%         # 2      -  \n",
       " 1  Overall Accuracy       96.18%         # 3      -  ,                Task Dataset                        Model Metric name  \\\n",
       " 0  Image Generation    FFHQ  StyleGAN (no instance norm)         FID   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          4.16         # 1      -  ,                  Task                          Dataset             Model  \\\n",
       " 0  Language Modelling                     Hutter Prize  3-layer AWD-LSTM   \n",
       " 1  Language Modelling                     Hutter Prize  3-layer AWD-LSTM   \n",
       " 2  Language Modelling  Penn Treebank (Character Level)  3-layer AWD-LSTM   \n",
       " 3  Language Modelling  Penn Treebank (Character Level)  3-layer AWD-LSTM   \n",
       " 4  Language Modelling  Penn Treebank (Character Level)      6-layer QRNN   \n",
       " 5  Language Modelling  Penn Treebank (Character Level)      6-layer QRNN   \n",
       " 6  Language Modelling                     WikiText-103      4-layer QRNN   \n",
       " 7  Language Modelling                     WikiText-103      4-layer QRNN   \n",
       " 8  Language Modelling                     WikiText-103      4-layer QRNN   \n",
       " \n",
       "                Metric name Metric value Global rank Remove  \n",
       " 0  Bit per Character (BPC)        1.232         # 6      -  \n",
       " 1         Number of params          47M         # 1      -  \n",
       " 2  Bit per Character (BPC)        1.175         # 3      -  \n",
       " 3         Number of params        13.8M         # 1      -  \n",
       " 4  Bit per Character (BPC)        1.187         # 4      -  \n",
       " 5         Number of params        13.8M         # 1      -  \n",
       " 6    Validation perplexity         32.0         # 5      -  \n",
       " 7          Test perplexity         33.0         # 7      -  \n",
       " 8         Number of params         151M         # 1      -  ,                  Task           Dataset  \\\n",
       " 0  Language Modelling  One Billion Word   \n",
       " 1  Language Modelling  One Billion Word   \n",
       " 2  Language Modelling  One Billion Word   \n",
       " 3  Language Modelling  One Billion Word   \n",
       " 4  Language Modelling  One Billion Word   \n",
       " 5  Language Modelling  One Billion Word   \n",
       " 6  Language Modelling      WikiText-103   \n",
       " 7  Language Modelling      WikiText-103   \n",
       " 8  Language Modelling      WikiText-103   \n",
       " \n",
       "                                        Model            Metric name  \\\n",
       " 0                  Adaptive Input Very Large                    PPL   \n",
       " 1                  Adaptive Input Very Large       Number of params   \n",
       " 2                  Adaptive Input Very Large  Validation perplexity   \n",
       " 3                       Adaptive Input Large                    PPL   \n",
       " 4                       Adaptive Input Large       Number of params   \n",
       " 5                       Adaptive Input Large  Validation perplexity   \n",
       " 6  Transformer with tied adaptive embeddings  Validation perplexity   \n",
       " 7  Transformer with tied adaptive embeddings        Test perplexity   \n",
       " 8  Transformer with tied adaptive embeddings       Number of params   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        23.02         # 2      -  \n",
       " 1         1.0B         # 1      -  \n",
       " 2        22.92         # 1      -  \n",
       " 3        23.91         # 4      -  \n",
       " 4        0.46B         # 1      -  \n",
       " 5        23.83         # 2      -  \n",
       " 6        17.97         # 1      -  \n",
       " 7        18.70         # 3      -  \n",
       " 8         247M         # 1      -  ,                 Task                    Dataset      Model Metric name  \\\n",
       " 0  Face Verification  Labeled Faces in the Wild  Ring loss    Accuracy   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0       99.52%         # 4      -  ,                       Task  Dataset    Model Metric name  Metric value  \\\n",
       " 0  Collaborative Filtering  Netflix  DeepRec        RMSE        0.9099   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  ,                               Task                         Dataset Model  \\\n",
       " 0  Aspect-Based Sentiment Analysis  SemEval 2014 Task 4 Sub Task 2  IARM   \n",
       " 1  Aspect-Based Sentiment Analysis  SemEval 2014 Task 4 Sub Task 2  IARM   \n",
       " \n",
       "         Metric name  Metric value Global rank Remove  \n",
       " 0  Restaurant (Acc)          80.0        # 17      -  \n",
       " 1      Laptop (Acc)          73.8        # 12      -  ,              Task Dataset                                      Model  \\\n",
       " 0  Face Alignment    300W  LAB + Oracle + Inter-ocular Normalisation   \n",
       " \n",
       "        Metric name  Metric value Global rank Remove  \n",
       " 0  Mean Error Rate          3.49         # 4      -  ,                  Task  Dataset   Model        Metric name  Metric value  \\\n",
       " 0  Hypernym Discovery  General  Apollo                MAP          2.68   \n",
       " 1  Hypernym Discovery  General  Apollo                MRR          6.01   \n",
       " 2  Hypernym Discovery  General  Apollo  [email protected]          2.69   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 7      -  \n",
       " 1         # 7      -  \n",
       " 2         # 7      -  ,                                       Task        Dataset Model  \\\n",
       " 0  Unsupervised Image-To-Image Translation  SVNH-to-MNIST  ADDA   \n",
       " \n",
       "                Metric name Metric value Global rank Remove  \n",
       " 0  Classification Accuracy        76.0%         # 3      -  ,                      Task     Dataset                   Model Metric name  \\\n",
       " 0  Semantic Role Labeling  CoNLL 2005             BiLSTM-Span          F1   \n",
       " 1  Semantic Role Labeling  CoNLL 2005  BiLSTM-Span (Ensemble)          F1   \n",
       " 2  Semantic Role Labeling   OntoNotes             BiLSTM-Span          F1   \n",
       " 3  Semantic Role Labeling   OntoNotes  BiLSTM-Span (Ensemble)          F1   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          87.6         # 3      -  \n",
       " 1          88.5         # 1      -  \n",
       " 2          86.2         # 2      -  \n",
       " 3          87.0         # 1      -  ,                               Task                         Dataset    Model  \\\n",
       " 0  Aspect-Based Sentiment Analysis  SemEval 2014 Task 4 Sub Task 2  TD-LSTM   \n",
       " 1  Aspect-Based Sentiment Analysis  SemEval 2014 Task 4 Sub Task 2  TD-LSTM   \n",
       " \n",
       "         Metric name  Metric value Global rank Remove  \n",
       " 0  Restaurant (Acc)         75.63        # 25      -  \n",
       " 1      Laptop (Acc)         68.13         # 1      -  ,              Task   Dataset                              Model Metric name  \\\n",
       " 0  Face Alignment  AFLW2000  Nonlinear 3D Face Morphable Model  Error rate   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0           4.7         # 1      -  ,              Task Dataset                                            Model  \\\n",
       " 0  Face Alignment    300W  DAN-Menpo + bounding box diagonal normalization   \n",
       " 1  Face Alignment    300W           DAN-Menpo + inter-ocular normalization   \n",
       " 2  Face Alignment    300W           DAN-Menpo + inter-ocular normalization   \n",
       " 3  Face Alignment    300W           DAN-Menpo + inter-ocular normalization   \n",
       " \n",
       "        Metric name Metric value Global rank Remove  \n",
       " 0  Mean Error Rate         1.42         # 1      -  \n",
       " 1  Mean Error Rate         3.44         # 3      -  \n",
       " 2          AUC0.08        57.07         # 1      -  \n",
       " 3          Failure        0.58%         # 1      -  ,                    Task    Dataset                        Model  \\\n",
       " 0  Image Classification   CIFAR-10  SENet + ShakeShake + Cutout   \n",
       " 1  Image Classification   CIFAR-10  SENet + ShakeShake + Cutout   \n",
       " 2  Image Classification  CIFAR-100   SENet + ShakeEven + Cutout   \n",
       " 3  Image Classification  CIFAR-100   SENet + ShakeEven + Cutout   \n",
       " 4  Image Classification   ImageNet                        SENet   \n",
       " 5  Image Classification   ImageNet                        SENet   \n",
       " \n",
       "           Metric name Metric value Global rank Remove  \n",
       " 0  Percentage correct        97.88         # 3      -  \n",
       " 1    Percentage error         2.12         # 3      -  \n",
       " 2  Percentage correct        84.59         # 2      -  \n",
       " 3    Percentage error        15.41         # 1      -  \n",
       " 4      Top 1 Accuracy        82.7%         # 4      -  \n",
       " 5      Top 5 Accuracy        96.2%         # 3      -  ,            Task                         Dataset     Model Metric name  \\\n",
       " 0   Atari Games                Atari 2600 Alien  C51 noop       Score   \n",
       " 1   Atari Games               Atari 2600 Amidar  C51 noop       Score   \n",
       " 2   Atari Games              Atari 2600 Assault  C51 noop       Score   \n",
       " 3   Atari Games              Atari 2600 Asterix  C51 noop       Score   \n",
       " 4   Atari Games            Atari 2600 Asteroids  C51 noop       Score   \n",
       " 5   Atari Games             Atari 2600 Atlantis  C51 noop       Score   \n",
       " 6   Atari Games           Atari 2600 Bank Heist  C51 noop       Score   \n",
       " 7   Atari Games          Atari 2600 Battle Zone  C51 noop       Score   \n",
       " 8   Atari Games           Atari 2600 Beam Rider  C51 noop       Score   \n",
       " 9   Atari Games              Atari 2600 Berzerk  C51 noop       Score   \n",
       " 10  Atari Games              Atari 2600 Bowling  C51 noop       Score   \n",
       " 11  Atari Games               Atari 2600 Boxing  C51 noop       Score   \n",
       " 12  Atari Games             Atari 2600 Breakout  C51 noop       Score   \n",
       " 13  Atari Games            Atari 2600 Centipede  C51 noop       Score   \n",
       " 14  Atari Games      Atari 2600 Chopper Command  C51 noop       Score   \n",
       " 15  Atari Games        Atari 2600 Crazy Climber  C51 noop       Score   \n",
       " 16  Atari Games         Atari 2600 Demon Attack  C51 noop       Score   \n",
       " 17  Atari Games          Atari 2600 Double Dunk  C51 noop       Score   \n",
       " 18  Atari Games               Atari 2600 Enduro  C51 noop       Score   \n",
       " 19  Atari Games        Atari 2600 Fishing Derby  C51 noop       Score   \n",
       " 20  Atari Games              Atari 2600 Freeway  C51 noop       Score   \n",
       " 21  Atari Games            Atari 2600 Frostbite  C51 noop       Score   \n",
       " 22  Atari Games               Atari 2600 Gopher  C51 noop       Score   \n",
       " 23  Atari Games             Atari 2600 Gravitar  C51 noop       Score   \n",
       " 24  Atari Games                 Atari 2600 HERO  C51 noop       Score   \n",
       " 25  Atari Games           Atari 2600 Ice Hockey  C51 noop       Score   \n",
       " 26  Atari Games           Atari 2600 James Bond  C51 noop       Score   \n",
       " 27  Atari Games             Atari 2600 Kangaroo  C51 noop       Score   \n",
       " 28  Atari Games                Atari 2600 Krull  C51 noop       Score   \n",
       " 29  Atari Games       Atari 2600 Kung-Fu Master  C51 noop       Score   \n",
       " 30  Atari Games  Atari 2600 Montezuma's Revenge  C51 noop       Score   \n",
       " 31  Atari Games           Atari 2600 Ms. Pacman  C51 noop       Score   \n",
       " 32  Atari Games       Atari 2600 Name This Game  C51 noop       Score   \n",
       " 33  Atari Games                 Atari 2600 Pong  C51 noop       Score   \n",
       " 34  Atari Games          Atari 2600 Private Eye  C51 noop       Score   \n",
       " 35  Atari Games               Atari 2600 Q*Bert  C51 noop       Score   \n",
       " 36  Atari Games           Atari 2600 River Raid  C51 noop       Score   \n",
       " 37  Atari Games          Atari 2600 Road Runner  C51 noop       Score   \n",
       " 38  Atari Games             Atari 2600 Robotank  C51 noop       Score   \n",
       " 39  Atari Games             Atari 2600 Seaquest  C51 noop       Score   \n",
       " 40  Atari Games       Atari 2600 Space Invaders  C51 noop       Score   \n",
       " 41  Atari Games          Atari 2600 Star Gunner  C51 noop       Score   \n",
       " 42  Atari Games               Atari 2600 Tennis  C51 noop       Score   \n",
       " 43  Atari Games           Atari 2600 Time Pilot  C51 noop       Score   \n",
       " 44  Atari Games            Atari 2600 Tutankham  C51 noop       Score   \n",
       " 45  Atari Games          Atari 2600 Up and Down  C51 noop       Score   \n",
       " 46  Atari Games              Atari 2600 Venture  C51 noop       Score   \n",
       " 47  Atari Games        Atari 2600 Video Pinball  C51 noop       Score   \n",
       " 48  Atari Games        Atari 2600 Wizard of Wor  C51 noop       Score   \n",
       " 49  Atari Games               Atari 2600 Zaxxon  C51 noop       Score   \n",
       " \n",
       "     Metric value Global rank Remove  \n",
       " 0         3166.0         # 7      -  \n",
       " 1         1735.0         # 6      -  \n",
       " 2         7203.0         # 8      -  \n",
       " 3       406211.0         # 1      -  \n",
       " 4         1516.0        # 12      -  \n",
       " 5       841075.0         # 6      -  \n",
       " 6          976.0        # 10      -  \n",
       " 7        28742.0        # 10      -  \n",
       " 8        14074.0        # 11      -  \n",
       " 9         1645.0         # 3      -  \n",
       " 10          81.8         # 3      -  \n",
       " 11          97.8         # 5      -  \n",
       " 12         748.0         # 3      -  \n",
       " 13        9646.0         # 3      -  \n",
       " 14       15600.0         # 2      -  \n",
       " 15      179877.0         # 1      -  \n",
       " 16      130955.0         # 1      -  \n",
       " 17           2.5         # 5      -  \n",
       " 18        3454.0         # 1      -  \n",
       " 19           8.9        # 13      -  \n",
       " 20          33.9         # 2      -  \n",
       " 21        3965.0         # 7      -  \n",
       " 22       33641.0         # 6      -  \n",
       " 23         440.0        # 10      -  \n",
       " 24       38874.0         # 1      -  \n",
       " 25          -3.5        # 14      -  \n",
       " 26        1909.0         # 4      -  \n",
       " 27       12853.0         # 7      -  \n",
       " 28        9735.0         # 5      -  \n",
       " 29       48192.0         # 3      -  \n",
       " 30           0.0        # 23      -  \n",
       " 31        3415.0         # 5      -  \n",
       " 32       12542.0         # 5      -  \n",
       " 33          20.9         # 2      -  \n",
       " 34       15095.0         # 1      -  \n",
       " 35       23784.0         # 2      -  \n",
       " 36       17322.0         # 4      -  \n",
       " 37       55839.0         # 7      -  \n",
       " 38          52.3        # 13      -  \n",
       " 39      266434.0         # 1      -  \n",
       " 40        5747.0         # 8      -  \n",
       " 41       49095.0        # 17      -  \n",
       " 42          23.1         # 2      -  \n",
       " 43        8329.0         # 8      -  \n",
       " 44         280.0         # 2      -  \n",
       " 45       15612.0        # 15      -  \n",
       " 46        1520.0         # 2      -  \n",
       " 47      949604.0         # 1      -  \n",
       " 48        9300.0         # 7      -  \n",
       " 49       10513.0         # 9      -  ,                       Task                  Dataset Model Metric name  \\\n",
       " 0   Image Super-Resolution    BSD100 - 4x upscaling  NLRN        PSNR   \n",
       " 1   Image Super-Resolution    BSD100 - 4x upscaling  NLRN        SSIM   \n",
       " 2          Image Denoising            BSD68 sigma15  NLRN        PSNR   \n",
       " 3          Image Denoising            BSD68 sigma25  NLRN        PSNR   \n",
       " 4          Image Denoising            BSD68 sigma50  NLRN        PSNR   \n",
       " 5   Image Super-Resolution     Set14 - 4x upscaling  NLRN        PSNR   \n",
       " 6   Image Super-Resolution     Set14 - 4x upscaling  NLRN        SSIM   \n",
       " 7   Image Super-Resolution      Set5 - 4x upscaling  NLRN        PSNR   \n",
       " 8   Image Super-Resolution      Set5 - 4x upscaling  NLRN        SSIM   \n",
       " 9   Image Super-Resolution  Urban100 - 4x upscaling  NLRN        PSNR   \n",
       " 10  Image Super-Resolution  Urban100 - 4x upscaling  NLRN        SSIM   \n",
       " 11         Image Denoising         Urban100 sigma50  NLRN        PSNR   \n",
       " \n",
       "     Metric value Global rank Remove  \n",
       " 0        27.4800        # 13      -  \n",
       " 1         0.7306        # 18      -  \n",
       " 2        31.8800         # 1      -  \n",
       " 3        29.4100         # 1      -  \n",
       " 4        26.4700         # 2      -  \n",
       " 5        28.3600        # 14      -  \n",
       " 6         0.7745        # 19      -  \n",
       " 7        31.9200        # 12      -  \n",
       " 8         0.8916        # 15      -  \n",
       " 9        25.7900        # 12      -  \n",
       " 10        0.7729        # 13      -  \n",
       " 11       27.4900         # 2      -  ,                  Task Dataset                         Model Metric name  \\\n",
       " 0  Keypoint Detection    COCO  PifPaf – single-scale (ours)     Test AP   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          66.7         # 2      -  ,                               Task   Dataset                          Model  \\\n",
       " 0       Nested Mention Recognition  ACE 2004  Neural transition-based model   \n",
       " 1  Nested Named Entity Recognition  ACE 2004  Neural transition-based model   \n",
       " 2       Nested Mention Recognition  ACE 2005  Neural transition-based model   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0          F1          73.3         # 1      -  \n",
       " 1          F1          73.3         # 1      -  \n",
       " 2          F1          73.0         # 1      -  ,                      Task        Dataset         Model Metric name  \\\n",
       " 0  Part-Of-Speech Tagging  Penn Treebank  Char Bi-LSTM    Accuracy   \n",
       " 1  Part-Of-Speech Tagging  Penn Treebank       Bi-LSTM    Accuracy   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         97.78         # 3      -  \n",
       " 1         97.36        # 10      -  ,                    Task    Dataset          Model         Metric name  \\\n",
       " 0  Image Classification   CIFAR-10  Fractional MP  Percentage correct   \n",
       " 1  Image Classification  CIFAR-100  Fractional MP  Percentage correct   \n",
       " 2  Image Classification      MNIST  Fractional MP    Percentage error   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          96.5        # 10      -  \n",
       " 1          73.6        # 16      -  \n",
       " 2           0.3         # 3      -  ,                Task   Dataset        Model      Metric name  Metric value  \\\n",
       " 0  Image Generation  CIFAR-10  MMD-GAN-rep  Inception score          8.29   \n",
       " 1  Image Generation  CIFAR-10  MMD-GAN-rep              FID         16.21   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  \n",
       " 1         # 1      -  ,                Task Dataset               Model Metric name  Metric value  \\\n",
       " 0  Semantic Parsing  spider  Exact Set Matching    Accuracy          19.7   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  ,                Task Dataset                        Model      Metric name  \\\n",
       " 0  Object Detection    COCO   CenterNet511 (multi-scale)  Bounding Box AP   \n",
       " 1  Object Detection    COCO  CenterNet511 (single-scale)  Bounding Box AP   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          47.0         # 3      -  \n",
       " 1          44.9         # 9      -  ,                   Task                      Dataset      Model Metric name  \\\n",
       " 0  Text Classification                      AG News    ToWE-SG       Error   \n",
       " 1   Sentiment Analysis                         IMDb    ToWE-SG    Accuracy   \n",
       " 2   Sentiment Analysis  SST-2 Binary classification  ToWE-CBOW    Accuracy   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          14.0        # 17      -  \n",
       " 1          90.8         # 9      -  \n",
       " 2          78.8        # 22      -  ,               Task           Dataset                     Model Metric name  \\\n",
       " 0  Image Denoising     BSD68 sigma10  Residual Dense Network +        PSNR   \n",
       " 1  Image Denoising     BSD68 sigma30  Residual Dense Network +        PSNR   \n",
       " 2  Image Denoising     BSD68 sigma50                      RDN+        PSNR   \n",
       " 3  Image Denoising     BSD68 sigma70  Residual Dense Network +        PSNR   \n",
       " 4  Image Denoising  Urban100 sigma30  Residual Dense Network +        PSNR   \n",
       " 5  Image Denoising  Urban100 sigma50  Residual Dense Network +        PSNR   \n",
       " 6  Image Denoising  Urban100 sigma70  Residual Dense Network +        PSNR   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         36.49         # 1      -  \n",
       " 1         30.70         # 1      -  \n",
       " 2         26.43         # 3      -  \n",
       " 3         26.88         # 1      -  \n",
       " 4         31.78         # 1      -  \n",
       " 5         29.38         # 1      -  \n",
       " 6         27.74         # 1      -  ,                                       Task        Dataset Model  \\\n",
       " 0  Unsupervised Image-To-Image Translation  SVNH-to-MNIST   DTN   \n",
       " \n",
       "                Metric name Metric value Global rank Remove  \n",
       " 0  Classification Accuracy        84.4%         # 2      -  ,                            Task        Dataset              Model Metric name  \\\n",
       " 0  Ad-Hoc Information Retrieval  TREC Robust04  Anserini BM25+RM3         MAP   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         0.302         # 1      -  ,                               Task                         Dataset Model  \\\n",
       " 0  Aspect-Based Sentiment Analysis  SemEval 2014 Task 4 Sub Task 2  MGAN   \n",
       " 1  Aspect-Based Sentiment Analysis  SemEval 2014 Task 4 Sub Task 2  MGAN   \n",
       " \n",
       "         Metric name  Metric value Global rank Remove  \n",
       " 0  Restaurant (Acc)         81.25         # 8      -  \n",
       " 1      Laptop (Acc)         75.39        # 20      -  ,                            Task   Dataset        Model Metric name  \\\n",
       " 0  Action Recognition In Videos  Charades  Timeception         MAP   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          41.1         # 2      -  ,                   Task                    Dataset    Model Metric name  \\\n",
       " 0    Face Verification  Labeled Faces in the Wild  CosFace    Accuracy   \n",
       " 1    Face Verification                   MegaFace  CosFace    Accuracy   \n",
       " 2  Face Identification                   MegaFace  CosFace    Accuracy   \n",
       " 3    Face Verification           YouTube Faces DB  CosFace    Accuracy   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0       99.73%         # 2      -  \n",
       " 1       96.65%         # 2      -  \n",
       " 2       82.72%         # 2      -  \n",
       " 3        97.6%         # 3      -  ,                          Task          Dataset                   Model  \\\n",
       " 0            Object Detection  PASCAL VOC 2007  BlitzNet512 + seg (s8)   \n",
       " 1  Real-Time Object Detection  PASCAL VOC 2007        BlitzNet512 (s8)   \n",
       " 2  Real-Time Object Detection  PASCAL VOC 2007        BlitzNet512 (s8)   \n",
       " 3  Real-Time Object Detection  PASCAL VOC 2007        BlitzNet512 (s4)   \n",
       " 4  Real-Time Object Detection  PASCAL VOC 2007        BlitzNet512 (s4)   \n",
       " \n",
       "   Metric name Metric value Global rank Remove  \n",
       " 0         MAP        81.5%         # 5      -  \n",
       " 1         MAP        81.5%         # 1      -  \n",
       " 2         FPS         19.5         # 4      -  \n",
       " 3         MAP        79.1%         # 3      -  \n",
       " 4         FPS           24         # 3      -  ,                   Task Dataset  Model Metric name  Metric value Global rank  \\\n",
       " 0  Relation Extraction  TACRED  C-GCN          F1          66.4         # 3   \n",
       " \n",
       "   Remove  \n",
       " 0      -  ,                                    Task                Dataset         Model  \\\n",
       " 0  Semi-Supervised Image Classification  CIFAR-10, 4000 Labels  Mean Teacher   \n",
       " 1  Semi-Supervised Image Classification      SVHN, 1000 labels  Mean Teacher   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0    Accuracy         93.72         # 2      -  \n",
       " 1    Accuracy         96.05         # 2      -  ,                       Task    Dataset   Model        Metric name  \\\n",
       " 0  Stereo Depth Estimation  KITTI2012  AnyNet  three pixel error   \n",
       " 1  Stereo Depth Estimation  KITTI2015  AnyNet  three pixel error   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0           6.1         # 1      -  \n",
       " 1           6.2         # 1      -  ,                      Task                  Dataset  Model Metric name  \\\n",
       " 0  Image Super-Resolution    BSD100 - 4x upscaling  SRRAM        PSNR   \n",
       " 1  Image Super-Resolution    BSD100 - 4x upscaling  SRRAM        SSIM   \n",
       " 2  Image Super-Resolution     Set14 - 4x upscaling  SRRAM        PSNR   \n",
       " 3  Image Super-Resolution     Set14 - 4x upscaling  SRRAM        SSIM   \n",
       " 4  Image Super-Resolution      Set5 - 4x upscaling  SRRAM        PSNR   \n",
       " 5  Image Super-Resolution      Set5 - 4x upscaling  SRRAM        SSIM   \n",
       " 6  Image Super-Resolution  Urban100 - 4x upscaling  SRRAM        PSNR   \n",
       " 7  Image Super-Resolution  Urban100 - 4x upscaling  SRRAM        SSIM   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0       27.5600        # 10      -  \n",
       " 1        0.7350        # 14      -  \n",
       " 2       28.5400        # 10      -  \n",
       " 3        0.7800        # 16      -  \n",
       " 4       32.1300         # 8      -  \n",
       " 5        0.8932        # 13      -  \n",
       " 6       26.0500        # 10      -  \n",
       " 7        0.7834        # 11      -  ,                    Task          Dataset        Model       Metric name  \\\n",
       " 0  Hand Pose Estimation       HANDS 2017  V2V-PoseNet  Average 3D Error   \n",
       " 1  Hand Pose Estimation       ICVL Hands  V2V-PoseNet  Average 3D Error   \n",
       " 2       Pose Estimation  ITOP front-view  V2V-PoseNet          Mean mAP   \n",
       " 3       Pose Estimation    ITOP top-view  V2V-PoseNet          Mean mAP   \n",
       " 4  Hand Pose Estimation       MSRA Hands  V2V-PoseNet  Average 3D Error   \n",
       " 5  Hand Pose Estimation        NYU Hands  V2V-PoseNet  Average 3D Error   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          9.95         # 1      -  \n",
       " 1          6.28         # 1      -  \n",
       " 2         88.74         # 1      -  \n",
       " 3         83.44         # 1      -  \n",
       " 4          7.49         # 2      -  \n",
       " 5          8.42         # 1      -  ,                          Task                           Dataset  \\\n",
       " 0  Natural Language Inference                              SNLI   \n",
       " 1  Natural Language Inference                              SNLI   \n",
       " 2  Natural Language Inference                              SNLI   \n",
       " 3          Sentiment Analysis  Yelp Fine-grained classification   \n",
       " \n",
       "                                   Model       Metric name Metric value  \\\n",
       " 0  600D BiLSTM with generalized pooling   % Test Accuracy         86.6   \n",
       " 1  600D BiLSTM with generalized pooling  % Train Accuracy         94.9   \n",
       " 2  600D BiLSTM with generalized pooling        Parameters          65m   \n",
       " 3            BiLSTM generalized pooling             Error        33.45   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 24      -  \n",
       " 1        # 10      -  \n",
       " 2         # 1      -  \n",
       " 3         # 7      -  ,                             Task Dataset    Model Metric name Metric value  \\\n",
       " 0  Multimodal Sentiment Analysis    MOSI  MMMU-BA    Accuracy       82.31%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  ,                  Task           Dataset                                 Model  \\\n",
       " 0  Question Answering  CNN / Daily Mail                            Classifier   \n",
       " 1  Question Answering  CNN / Daily Mail                            Classifier   \n",
       " 2  Question Answering  CNN / Daily Mail      Attentive + relabling + ensemble   \n",
       " 3  Question Answering  CNN / Daily Mail      Attentive + relabling + ensemble   \n",
       " 4  Question Answering  CNN / Daily Mail  AttentiveReader + bilinear attention   \n",
       " 5  Question Answering  CNN / Daily Mail  AttentiveReader + bilinear attention   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0         CNN          67.9        # 14      -  \n",
       " 1  Daily Mail          68.3         # 9      -  \n",
       " 2         CNN          77.6         # 3      -  \n",
       " 3  Daily Mail          79.2         # 3      -  \n",
       " 4         CNN          72.4        # 11      -  \n",
       " 5  Daily Mail          75.8         # 6      -  ,                   Task                     Dataset   Model Metric name  \\\n",
       " 0  Text Classification                     DBpedia  M-ACNN       Error   \n",
       " 1   Sentiment Analysis  Yelp Binary classification  M-ACNN       Error   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          1.07         # 9      -  \n",
       " 1          3.89         # 9      -  ,                              Task       Dataset Model Metric name  \\\n",
       " 0               Domain Adaptation  ImageCLEF-DA  MEDA    Accuracy   \n",
       " 1  Unsupervised Domain Adaptation  ImageCLEF-DA  MEDA    Accuracy   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          89.0         # 1      -  \n",
       " 1          89.0         # 1      -  ,           Task   Dataset    Model                    Metric name Metric value  \\\n",
       " 0  Atari Games  Atari-57  Reactor  Medium Human-Normalized Score       187.0%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 3      -  ,                      Task                Dataset  Model Metric name  \\\n",
       " 0  Image Super-Resolution  BSD100 - 4x upscaling  FAFR*        PSNR   \n",
       " 1  Image Super-Resolution   Set14 - 4x upscaling  FAFR*        PSNR   \n",
       " 2  Image Super-Resolution    Set5 - 4x upscaling  FARF*        PSNR   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         26.91        # 25      -  \n",
       " 1         27.48        # 32      -  \n",
       " 2         30.45        # 27      -  ,                           Task                          Dataset      Model  \\\n",
       " 0   Image-to-Image Translation          ADE20K Labels-to-Photos  pix2pixHD   \n",
       " 1   Image-to-Image Translation          ADE20K Labels-to-Photos  pix2pixHD   \n",
       " 2   Image-to-Image Translation          ADE20K Labels-to-Photos  pix2pixHD   \n",
       " 3   Image-to-Image Translation  ADE20K-Outdoor Labels-to-Photos  pix2pixHD   \n",
       " 4   Image-to-Image Translation  ADE20K-Outdoor Labels-to-Photos  pix2pixHD   \n",
       " 5   Image-to-Image Translation  ADE20K-Outdoor Labels-to-Photos  pix2pixHD   \n",
       " 6   Image-to-Image Translation       Cityscapes Labels-to-Photo  pix2pixHD   \n",
       " 7   Image-to-Image Translation       Cityscapes Labels-to-Photo  pix2pixHD   \n",
       " 8   Image-to-Image Translation       Cityscapes Labels-to-Photo  pix2pixHD   \n",
       " 9   Image-to-Image Translation       Cityscapes Labels-to-Photo  pix2pixHD   \n",
       " 10  Image-to-Image Translation       Cityscapes Labels-to-Photo  pix2pixHD   \n",
       " 11  Image-to-Image Translation      COCO-Stuff Labels-to-Photos  pix2pixHD   \n",
       " 12  Image-to-Image Translation      COCO-Stuff Labels-to-Photos  pix2pixHD   \n",
       " 13  Image-to-Image Translation      COCO-Stuff Labels-to-Photos  pix2pixHD   \n",
       " \n",
       "            Metric name Metric value Global rank Remove  \n",
       " 0                 mIoU         20.3         # 3      -  \n",
       " 1             Accuracy        69.2%         # 2      -  \n",
       " 2                  FID         81.8         # 3      -  \n",
       " 3                 mIoU         17.4         # 2      -  \n",
       " 4             Accuracy        71.6%         # 3      -  \n",
       " 5                  FID         97.8         # 3      -  \n",
       " 6            Class IOU          NaN         # 6      -  \n",
       " 7   Per-class Accuracy          NaN         # 5      -  \n",
       " 8   Per-pixel Accuracy        81.4%         # 2      -  \n",
       " 9                 mIoU         58.3         # 2      -  \n",
       " 10                 FID           95         # 3      -  \n",
       " 11                mIoU         14.6         # 3      -  \n",
       " 12            Accuracy        45.8%         # 2      -  \n",
       " 13                 FID        111.5         # 3      -  ,                   Task  Dataset    Model Metric name  Metric value  \\\n",
       " 0  Text Classification  AG News  L MIXED       Error          4.95   \n",
       " 1  Text Classification  DBpedia  L MIXED       Error          0.70   \n",
       " 2   Sentiment Analysis     IMDb  L MIXED    Accuracy         95.68   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 2      -  \n",
       " 2         # 2      -  ,                             Task                     Dataset       Model  \\\n",
       " 0  Few-Shot Image Classification  OMNIGLOT - 1-Shot Learning  Memory Mod   \n",
       " 1  Few-Shot Image Classification  OMNIGLOT - 5-Shot Learning  Memory Mod   \n",
       " \n",
       "   Metric name Metric value Global rank Remove  \n",
       " 0    Accuracy        98.4%         # 3      -  \n",
       " 1    Accuracy        99.6%         # 3      -  ,                      Task Dataset         Model Metric name  Metric value  \\\n",
       " 0  Common Sense Reasoning    SWAG   ESIM + ELMo         Dev          59.1   \n",
       " 1  Common Sense Reasoning    SWAG   ESIM + ELMo        Test          59.2   \n",
       " 2  Common Sense Reasoning    SWAG  ESIM + GloVe         Dev          51.9   \n",
       " 3  Common Sense Reasoning    SWAG  ESIM + GloVe        Test          52.7   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 3      -  \n",
       " 1         # 2      -  \n",
       " 2         # 4      -  \n",
       " 3         # 3      -  ,                             Task                    Dataset  \\\n",
       " 0  Synthetic-to-Real Translation  GTAV-to-Cityscapes Labels   \n",
       " \n",
       "                      Model Metric name  Metric value Global rank Remove  \n",
       " 0  Single-level Adaptation        mIoU          41.4         # 2      -  ,                      Task                  Dataset Model Metric name  \\\n",
       " 0  Image Super-Resolution    BSD100 - 4x upscaling   IDN        PSNR   \n",
       " 1  Image Super-Resolution    BSD100 - 4x upscaling   IDN        SSIM   \n",
       " 2  Image Super-Resolution     Set14 - 4x upscaling   IDN        PSNR   \n",
       " 3  Image Super-Resolution     Set14 - 4x upscaling   IDN        SSIM   \n",
       " 4  Image Super-Resolution      Set5 - 4x upscaling   IDN        PSNR   \n",
       " 5  Image Super-Resolution      Set5 - 4x upscaling   IDN        SSIM   \n",
       " 6  Image Super-Resolution  Urban100 - 4x upscaling   IDN        PSNR   \n",
       " 7  Image Super-Resolution  Urban100 - 4x upscaling   IDN        SSIM   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0       27.4100        # 16      -  \n",
       " 1        0.7297        # 20      -  \n",
       " 2       28.2500        # 19      -  \n",
       " 3        0.7730        # 21      -  \n",
       " 4       31.8200        # 14      -  \n",
       " 5        0.8903        # 18      -  \n",
       " 6       25.4100        # 18      -  \n",
       " 7        0.7632        # 17      -  ,                        Task     Dataset  \\\n",
       " 0  Noisy Speech Recognition  CHiME real   \n",
       " 1        Speech Recognition       TIMIT   \n",
       " 2        Speech Recognition       TIMIT   \n",
       " 3        Speech Recognition       TIMIT   \n",
       " 4        Speech Recognition       TIMIT   \n",
       " 5        Speech Recognition       TIMIT   \n",
       " 6        Speech Recognition       TIMIT   \n",
       " 7        Speech Recognition       TIMIT   \n",
       " 8        Speech Recognition       TIMIT   \n",
       " \n",
       "                                          Model       Metric name  \\\n",
       " 0                                       Li-GRU  Percentage error   \n",
       " 1    RNN + Dropout + BatchNorm + Monophone Reg  Percentage error   \n",
       " 2                                          GRU  Percentage error   \n",
       " 3  LiGRU + Dropout + BatchNorm + Monophone Reg  Percentage error   \n",
       " 4   LSTM + Dropout + BatchNorm + Monophone Reg  Percentage error   \n",
       " 5    GRU + Dropout + BatchNorm + Monophone Reg  Percentage error   \n",
       " 6                                       Li-GRU  Percentage error   \n",
       " 7                                         LSTM  Percentage error   \n",
       " 8                                          RNN  Percentage error   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          14.6         # 2      -  \n",
       " 1          15.9         # 4      -  \n",
       " 2          16.6         # 8      -  \n",
       " 3          14.2         # 1      -  \n",
       " 4          14.5         # 2      -  \n",
       " 5          14.9         # 3      -  \n",
       " 6          16.3         # 6      -  \n",
       " 7          16.0         # 5      -  \n",
       " 8          16.5         # 7      -  ,                         Task  \\\n",
       " 0  Visual Question Answering   \n",
       " 1  Visual Question Answering   \n",
       " \n",
       "                                              Dataset       Model  \\\n",
       " 0  COCO Visual Question Answering (VQA) real imag...  HQI+ResNet   \n",
       " 1  COCO Visual Question Answering (VQA) real imag...  HQI+ResNet   \n",
       " \n",
       "           Metric name  Metric value Global rank Remove  \n",
       " 0  Percentage correct          66.1         # 4      -  \n",
       " 1  Percentage correct          62.1         # 4      -  ,              Task      Dataset                                      Model  \\\n",
       " 0  Drug Discovery  HIV dataset  GraphConv + dummy super node + focal loss   \n",
       " 1  Drug Discovery          MUV               GraphConv + dummy super node   \n",
       " 2  Drug Discovery         PCBA               GraphConv + dummy super node   \n",
       " 3  Drug Discovery        Tox21               GraphConv + dummy super node   \n",
       " 4  Drug Discovery      ToxCast               GraphConv + dummy super node   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0         AUC         0.851         # 1      -  \n",
       " 1         AUC         0.845         # 1      -  \n",
       " 2         AUC         0.867         # 1      -  \n",
       " 3         AUC         0.854         # 1      -  \n",
       " 4         AUC         0.768         # 1      -  ,                          Task Dataset                    Model  \\\n",
       " 0  Natural Language Inference    SNLI           450D DR-BiLSTM   \n",
       " 1  Natural Language Inference    SNLI           450D DR-BiLSTM   \n",
       " 2  Natural Language Inference    SNLI           450D DR-BiLSTM   \n",
       " 3  Natural Language Inference    SNLI  450D DR-BiLSTM Ensemble   \n",
       " 4  Natural Language Inference    SNLI  450D DR-BiLSTM Ensemble   \n",
       " 5  Natural Language Inference    SNLI  450D DR-BiLSTM Ensemble   \n",
       " \n",
       "         Metric name Metric value Global rank Remove  \n",
       " 0   % Test Accuracy         88.5        # 13      -  \n",
       " 1  % Train Accuracy         94.1        # 13      -  \n",
       " 2        Parameters         7.5m         # 1      -  \n",
       " 3   % Test Accuracy         89.3         # 7      -  \n",
       " 4  % Train Accuracy         94.8        # 11      -  \n",
       " 5        Parameters          45m         # 1      -  ,                Task        Dataset            Model Metric name  Metric value  \\\n",
       " 0  CCG Supertagging        CCGBank  Low supervision    Accuracy         93.26   \n",
       " 1          Chunking  Penn Treebank  Low supervision    F1 score         95.57   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 4      -  \n",
       " 1         # 3      -  ,                               Task           Dataset Model  \\\n",
       " 0  Sequential Image Classification  Sequential MNIST  iRNN   \n",
       " 1  Sequential Image Classification  Sequential MNIST  iRNN   \n",
       " \n",
       "            Metric name Metric value Global rank Remove  \n",
       " 0  Unpermuted Accuracy          97%         # 4      -  \n",
       " 1    Permuted Accuracy          82%         # 5      -  ,                            Task           Dataset        Model  \\\n",
       " 0  Conditional Image Generation  ImageNet 128x128       BigGAN   \n",
       " 1  Conditional Image Generation  ImageNet 128x128       BigGAN   \n",
       " 2  Conditional Image Generation  ImageNet 128x128  BigGAN-deep   \n",
       " 3  Conditional Image Generation  ImageNet 128x128  BigGAN-deep   \n",
       " \n",
       "        Metric name  Metric value Global rank Remove  \n",
       " 0              FID           9.6         # 3      -  \n",
       " 1  Inception score         166.3         # 2      -  \n",
       " 2              FID           7.4         # 1      -  \n",
       " 3  Inception score         166.5         # 1      -  ,                        Task    Dataset                         Model  \\\n",
       " 0  3D Human Pose Estimation  Human3.6M  Sequence-to-sequence network   \n",
       " \n",
       "         Metric name  Metric value Global rank Remove  \n",
       " 0  Average 3D Error          66.1         # 5      -  ,                    Task   Dataset                Model Metric name  \\\n",
       " 0  Head Pose Estimation  AFLW2000  Multi-Loss ResNet50         MAE   \n",
       " 1  Head Pose Estimation      BIWI  Multi-Loss ResNet50         MAE   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         6.155         # 1      -  \n",
       " 1         4.895         # 1      -  ,                            Task Dataset       Model       Metric name  \\\n",
       " 0  Facial Action Unit Detection    BP4D  Multi-View  Average Accuracy   \n",
       " 1  Facial Action Unit Detection    BP4D  Multi-View                F1   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        81.8%         # 1      -  \n",
       " 1         57.7         # 1      -  ,                      Task                Dataset  Model Metric name  \\\n",
       " 0  Image Super-Resolution  BSD100 - 4x upscaling  JMPF+        PSNR   \n",
       " 1  Image Super-Resolution   Set14 - 4x upscaling  JMPF+        PSNR   \n",
       " 2  Image Super-Resolution    Set5 - 4x upscaling  JMPF+        PSNR   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         26.87        # 27      -  \n",
       " 1         27.37        # 33      -  \n",
       " 2         30.24        # 28      -  ,                         Task      Dataset                          Model  \\\n",
       " 0  Word Sense Disambiguation  Supervised:      Bi-LSTM<sub>att+LEX</sub>   \n",
       " 1  Word Sense Disambiguation  Supervised:      Bi-LSTM<sub>att+LEX</sub>   \n",
       " 2  Word Sense Disambiguation  Supervised:      Bi-LSTM<sub>att+LEX</sub>   \n",
       " 3  Word Sense Disambiguation  Supervised:      Bi-LSTM<sub>att+LEX</sub>   \n",
       " 4  Word Sense Disambiguation  Supervised:      Bi-LSTM<sub>att+LEX</sub>   \n",
       " 5  Word Sense Disambiguation  Supervised:  Bi-LSTM<sub>att+LEX+POS</sub>   \n",
       " 6  Word Sense Disambiguation  Supervised:  Bi-LSTM<sub>att+LEX+POS</sub>   \n",
       " 7  Word Sense Disambiguation  Supervised:  Bi-LSTM<sub>att+LEX+POS</sub>   \n",
       " 8  Word Sense Disambiguation  Supervised:  Bi-LSTM<sub>att+LEX+POS</sub>   \n",
       " 9  Word Sense Disambiguation  Supervised:  Bi-LSTM<sub>att+LEX+POS</sub>   \n",
       " \n",
       "     Metric name Metric value Global rank Remove  \n",
       " 0    Senseval 2         72.0         # 5      -  \n",
       " 1    Senseval 3         69.4         # 4      -  \n",
       " 2  SemEval 2007        63.7*         # 7      -  \n",
       " 3  SemEval 2013         66.4         # 5      -  \n",
       " 4  SemEval 2015         72.4         # 9      -  \n",
       " 5    Senseval 2         72.0         # 5      -  \n",
       " 6    Senseval 3         69.1         # 3      -  \n",
       " 7  SemEval 2007        64.8*         # 7      -  \n",
       " 8  SemEval 2013         66.9         # 8      -  \n",
       " 9  SemEval 2015         71.5         # 4      -  ,                        Task        Dataset Model Metric name  Metric value  \\\n",
       " 0  Person Re-Identification  DukeMTMC-reID   APR      Rank-1         70.69   \n",
       " 1  Person Re-Identification  DukeMTMC-reID   APR         MAP         51.88   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 14      -  \n",
       " 1        # 12      -  ,                  Task               Dataset     Model       Metric name  \\\n",
       " 0  Speech Recognition  Switchboard + Hub500  IBM 2015  Percentage error   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0           8.0         # 8      -  ,              Task    Dataset Model Metric name  Metric value Global rank  \\\n",
       " 0  Entity Linking  WebQSP-WD   VCG          F1          0.73         # 1   \n",
       " \n",
       "   Remove  \n",
       " 0      -  ,                Task   Dataset Model    Metric name  Metric value Global rank  \\\n",
       " 0  Image Generation  CIFAR-10  DRAW  Model Entropy           4.1         # 2   \n",
       " \n",
       "   Remove  \n",
       " 0      -  ,                              Task    Dataset                Model Metric name  \\\n",
       " 0  Human Grasp Contact Prediction  ContactDB    DiverseNet-VoxNet  Error rate   \n",
       " 1  Human Grasp Contact Prediction  ContactDB          sMCL-VoxNet  Error rate   \n",
       " 2  Human Grasp Contact Prediction  ContactDB  DiverseNet-PointNet  Error rate   \n",
       " 3  Human Grasp Contact Prediction  ContactDB        sMCL-PointNet  Error rate   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          8.72         # 1      -  \n",
       " 1         17.27         # 2      -  \n",
       " 2         21.82         # 3      -  \n",
       " 3         29.89         # 4      -  ,                             Task                          Dataset  \\\n",
       " 0  Few-Shot Image Classification  Mini-ImageNet - 1-Shot Learning   \n",
       " 1  Few-Shot Image Classification  Mini-ImageNet - 5-Shot Learning   \n",
       " 2  Few-Shot Image Classification       OMNIGLOT - 1-Shot Learning   \n",
       " 3  Few-Shot Image Classification       OMNIGLOT - 5-Shot Learning   \n",
       " \n",
       "                     Model Metric name Metric value Global rank Remove  \n",
       " 0  Reptile + Transduction    Accuracy       49.97%         # 6      -  \n",
       " 1  Reptile + Transduction    Accuracy       65.99%         # 7      -  \n",
       " 2  Reptile + Transduction    Accuracy       97.68%         # 5      -  \n",
       " 3  Reptile + Transduction    Accuracy       99.48%         # 5      -  ,                     Task   Dataset       Model        Metric name  \\\n",
       " 0  Instance Segmentation      COCO  Mask R-CNN  Average Precision   \n",
       " 1     Keypoint Detection      COCO  Mask R-CNN      Validation AP   \n",
       " 2     Keypoint Detection      COCO  Mask R-CNN            Test AP   \n",
       " 3       Object Detection      COCO  Mask R-CNN    Bounding Box AP   \n",
       " 4    Multi-Human Parsing  MHP v1.0  Mask R-CNN             AP 0.5   \n",
       " 5    Multi-Human Parsing  MHP v2.0  Mask R-CNN             AP 0.5   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        37.1%         # 4      -  \n",
       " 1         69.2         # 5      -  \n",
       " 2         63.1         # 4      -  \n",
       " 3         39.8        # 25      -  \n",
       " 4       52.68%         # 2      -  \n",
       " 5       14.90%         # 3      -  ,                             Task                          Dataset  \\\n",
       " 0  Few-Shot Image Classification  Mini-ImageNet - 1-Shot Learning   \n",
       " 1  Few-Shot Image Classification  Mini-ImageNet - 5-Shot Learning   \n",
       " \n",
       "             Model Metric name Metric value Global rank Remove  \n",
       " 0  MetaOptNet-SVM    Accuracy       62.64%         # 1      -  \n",
       " 1  MetaOptNet-SVM    Accuracy       78.63%         # 1      -  ,                          Task           Dataset  \\\n",
       " 0  Distant Speech Recognition  CHiME-4 real 6ch   \n",
       " 1    Noisy Speech Recognition        CHiME real   \n",
       " \n",
       "                                Model            Metric name  Metric value  \\\n",
       " 0  HMM-TDNN(LFMMI) + LSTMLM + NN-GEV  Word Error Rate (WER)          2.74   \n",
       " 1           HMM-TDNN(LFMMI) + LSTMLM       Percentage error         11.40   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 1      -  ,                            Task            Dataset                  Model  \\\n",
       " 0            Keypoint Detection               COCO                Pose-AE   \n",
       " 1  Multi-Person Pose Estimation  MPII Multi-Person  Associative Embedding   \n",
       " \n",
       "   Metric name Metric value Global rank Remove  \n",
       " 0     Test AP         62.8         # 6      -  \n",
       " 1          AP        77.5%         # 3      -  ,                   Task                 Dataset            Model Metric name  \\\n",
       " 0  Machine Translation  WMT2014 English-French  CSLM + RNN + WP  BLEU score   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         34.54        # 22      -  ,                   Task                           Dataset   Model Metric name  \\\n",
       " 0  Text Classification                           AG News  ULMFiT       Error   \n",
       " 1  Text Classification                           DBpedia  ULMFiT       Error   \n",
       " 2   Sentiment Analysis                              IMDb  ULMFiT    Accuracy   \n",
       " 3  Text Classification                            TREC-6  ULMFiT       Error   \n",
       " 4   Sentiment Analysis        Yelp Binary classification  ULMFiT       Error   \n",
       " 5   Sentiment Analysis  Yelp Fine-grained classification  ULMFiT       Error   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          5.01         # 2      -  \n",
       " 1          0.80         # 3      -  \n",
       " 2         95.40         # 4      -  \n",
       " 3          3.60         # 2      -  \n",
       " 4          2.16         # 3      -  \n",
       " 5         29.98         # 2      -  ,                      Task              Dataset    Model Metric name  \\\n",
       " 0  Video Super-Resolution  Vid4 - 4x upscaling  VSR-DUF        PSNR   \n",
       " 1  Video Super-Resolution  Vid4 - 4x upscaling  VSR-DUF        SSIM   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0        27.310         # 1      -  \n",
       " 1         0.832        # 11      -  ,                   Task             Dataset                    Model  \\\n",
       " 0  Multi-Human Parsing  PASCAL-Person-Part  Holistic instance-level   \n",
       " \n",
       "   Metric name Metric value Global rank Remove  \n",
       " 0      AP 0.5       40.60%         # 2      -  ,                  Task       Dataset               Model      Metric name  \\\n",
       " 0  Language Modelling  WikiText-103                LSTM  Test perplexity   \n",
       " 1  Language Modelling  WikiText-103  Neural cache model  Test perplexity   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          48.7        # 13      -  \n",
       " 1          40.8        # 11      -  ,                    Task Dataset   Model         Metric name  Metric value  \\\n",
       " 0  Image Classification  STL-10  Cutout  Percentage correct         87.26   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  ,                   Task             Dataset Model Metric name Metric value  \\\n",
       " 0  Multi-Human Parsing            MHP v1.0   NAN      AP 0.5       57.09%   \n",
       " 1  Multi-Human Parsing            MHP v2.0   NAN      AP 0.5       25.14%   \n",
       " 2  Multi-Human Parsing  PASCAL-Person-Part   NAN      AP 0.5       59.70%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 1      -  \n",
       " 2         # 1      -  ,                  Task   Dataset                Model Metric name  \\\n",
       " 0  Question Answering  SQuAD1.1      DCN+ (ensemble)          EM   \n",
       " 1  Question Answering  SQuAD1.1      DCN+ (ensemble)          F1   \n",
       " 2  Question Answering  SQuAD1.1  DCN+ (single model)          EM   \n",
       " 3  Question Answering  SQuAD1.1  DCN+ (single model)          F1   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0        78.852        # 39      -  \n",
       " 1        85.996        # 40      -  \n",
       " 2        74.866        # 74      -  \n",
       " 3        82.806        # 72      -  ,           Task                         Dataset   Model Metric name  \\\n",
       " 0  Atari Games  Atari 2600 Montezuma's Revenge  DQN+SR       Score   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0        1778.8         # 6      -  ,                             Task   Dataset  \\\n",
       " 0  Document Image Classification  RVL-CDIP   \n",
       " \n",
       "                                                Model Metric name Metric value  \\\n",
       " 0  Document section-based models + AlexNet transf...    Accuracy       89.80%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 4      -  ,               Task  Dataset               Model Metric name Metric value  \\\n",
       " 0  Image Retrieval  Oxf105k         DELF+FT+ATT         MAP        82.6%   \n",
       " 1  Image Retrieval  Oxf105k  DELF+FT+ATT+DIR+QE         MAP        88.5%   \n",
       " 2  Image Retrieval    Oxf5k  DELF+FT+ATT+DIR+QE         MAP        90.0%   \n",
       " 3  Image Retrieval    Oxf5k         DELF+FT+ATT         MAP        83.8%   \n",
       " 4  Image Retrieval  Par106k         DELF+FT+ATT    Accuracy        81.7%   \n",
       " 5  Image Retrieval  Par106k  DELF+FT+ATT+DIR+QE    Accuracy        92.8%   \n",
       " 6  Image Retrieval    Par6k         DELF+FT+ATT    Accuracy        85.0%   \n",
       " 7  Image Retrieval    Par6k  DELF+FT+ATT+DIR+QE    Accuracy        95.7%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 3      -  \n",
       " 1         # 1      -  \n",
       " 2         # 1      -  \n",
       " 3         # 3      -  \n",
       " 4         # 3      -  \n",
       " 5         # 1      -  \n",
       " 6         # 4      -  \n",
       " 7         # 1      -  ,                                             Task     Dataset        Model  \\\n",
       " 0                            Predicate Detection  CoNLL 2005         LISA   \n",
       " 1  Semantic Role Labeling (predicted predicates)  CoNLL 2005  LISA + ELMo   \n",
       " 2                         Semantic Role Labeling  CoNLL 2005         LISA   \n",
       " 3  Semantic Role Labeling (predicted predicates)  CoNLL 2005         LISA   \n",
       " 4  Semantic Role Labeling (predicted predicates)  CoNLL 2012         LISA   \n",
       " 5  Semantic Role Labeling (predicted predicates)  CoNLL 2012  LISA + ELMo   \n",
       " 6                            Predicate Detection  CoNLL 2012         LISA   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0          F1         98.40         # 1      -  \n",
       " 1          F1         86.90         # 1      -  \n",
       " 2          F1         86.04         # 4      -  \n",
       " 3          F1         84.99         # 3      -  \n",
       " 4          F1         82.33         # 3      -  \n",
       " 5          F1         83.38         # 1      -  \n",
       " 6          F1         97.20         # 1      -  ,                     Task          Dataset                     Model  \\\n",
       " 0  Semantic Segmentation       Cityscapes  DeepLab-CRF (ResNet-101)   \n",
       " 1  Semantic Segmentation   PASCAL Context                 DeepLabV2   \n",
       " 2  Semantic Segmentation  PASCAL VOC 2012  DeepLab-CRF (ResNet-101)   \n",
       " \n",
       "   Metric name Metric value Global rank Remove  \n",
       " 0    Mean IoU        70.4%        # 12      -  \n",
       " 1        mIoU         45.7         # 6      -  \n",
       " 2    Mean IoU        79.7%        # 10      -  ,                  Task Dataset                                     Model  \\\n",
       " 0  Speech Recognition   TIMIT  Soft Monotonic Attention (ours, offline)   \n",
       " \n",
       "         Metric name  Metric value Global rank Remove  \n",
       " 0  Percentage error          20.1        # 14      -  ,                             Task   Dataset  \\\n",
       " 0  Document Image Classification  RVL-CDIP   \n",
       " \n",
       "                                                Model Metric name Metric value  \\\n",
       " 0  Transfer Learning from AlexNet, VGG-16, GoogLe...    Accuracy       90.97%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  ,                        Task        Dataset Model Metric name  Metric value  \\\n",
       " 0  Person Re-Identification  DukeMTMC-reID   PAN      Rank-1         71.59   \n",
       " 1  Person Re-Identification  DukeMTMC-reID   PAN         MAP         51.51   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 13      -  \n",
       " 1        # 14      -  ,                         Task Dataset      Model Metric name Metric value  \\\n",
       " 0  Visual Question Answering  VQA v2  UPMC-LIP6    Accuracy       65.71%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 3      -  ,                              Task                      Dataset  \\\n",
       " 0  Named Entity Recognition (NER)         CoNLL 2003 (English)   \n",
       " 1  Named Entity Recognition (NER)  Long-tail emerging entities   \n",
       " 2  Named Entity Recognition (NER)       Ontonotes v5 (English)   \n",
       " 3          Part-Of-Speech Tagging                Penn Treebank   \n",
       " 4                        Chunking                Penn Treebank   \n",
       " \n",
       "               Model Metric name  Metric value Global rank Remove  \n",
       " 0  Flair embeddings          F1         93.09         # 2      -  \n",
       " 1  Flair embeddings          F1         50.20         # 1      -  \n",
       " 2  Flair embeddings          F1         89.30         # 1      -  \n",
       " 3  Flair embeddings    Accuracy         97.85         # 2      -  \n",
       " 4  Flair embeddings    F1 score         96.72         # 1      -  ,                     Task       Dataset     Model Metric name Metric value  \\\n",
       " 0    3D Object Detection  NYU Depth v2  SGPN-CNN         MAP        41.30   \n",
       " 1  Instance Segmentation  NYU Depth v2  SGPN-CNN         MAP         43.5   \n",
       " 2  Semantic Segmentation      ShapeNet      SGPN    Mean IoU        85.8%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 1      -  \n",
       " 2         # 1      -  ,           Task                         Dataset  Model Metric name  \\\n",
       " 0  Atari Games              Atari 2600 Freeway  MP-EB       Score   \n",
       " 1  Atari Games            Atari 2600 Frostbite  MP-EB       Score   \n",
       " 2  Atari Games  Atari 2600 Montezuma's Revenge  MP-EB       Score   \n",
       " 3  Atari Games               Atari 2600 Q*Bert  MP-EB       Score   \n",
       " 4  Atari Games              Atari 2600 Venture  MP-EB       Score   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          27.0        # 16      -  \n",
       " 1         507.0        # 17      -  \n",
       " 2         142.0        # 10      -  \n",
       " 3       15805.0         # 7      -  \n",
       " 4           0.0        # 27      -  ,                              Task  Dataset Model Metric name  Metric value  \\\n",
       " 0  Citation Intent Classification  ACL-ARC   SVM          F1          41.0   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 6      -  ,                    Task    Dataset    Model         Metric name  Metric value  \\\n",
       " 0  Image Classification   CIFAR-10  BNM NiN  Percentage correct         93.30   \n",
       " 1  Image Classification   CIFAR-10  BNM NiN    Percentage error          6.75   \n",
       " 2  Image Classification  CIFAR-100  BNM NiN  Percentage correct         71.10   \n",
       " 3  Image Classification  CIFAR-100  BNM NiN    Percentage error         28.86   \n",
       " 4  Image Classification      MNIST  BNM NiN    Percentage error          0.20   \n",
       " 5  Image Classification       SVHN  BNM NiN    Percentage error          1.81   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 26      -  \n",
       " 1        # 14      -  \n",
       " 2        # 22      -  \n",
       " 3         # 8      -  \n",
       " 4         # 2      -  \n",
       " 5        # 10      -  ,                     Task         Dataset      Model Metric name  Metric value  \\\n",
       " 0  Semantic Segmentation  PASCAL Context  Piecewise        mIoU          43.3   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 8      -  ,                       Task Dataset Model Metric name Metric value Global rank  \\\n",
       " 0  Occluded Face Detection    MAFA   FAN         MAP        88.3%         # 1   \n",
       " \n",
       "   Remove  \n",
       " 0      -  ,                          Task                      Dataset   Model  \\\n",
       " 0  Natural Language Inference                     MultiNLI  MT-DNN   \n",
       " 1  Natural Language Inference                     MultiNLI  MT-DNN   \n",
       " 2   Paraphrase Identification         Quora Question Pairs  MT-DNN   \n",
       " 3  Natural Language Inference                      SciTail  MT-DNN   \n",
       " 4  Natural Language Inference                         SNLI  MT-DNN   \n",
       " 5  Natural Language Inference                         SNLI  MT-DNN   \n",
       " 6  Natural Language Inference                         SNLI  MT-DNN   \n",
       " 7          Sentiment Analysis  SST-2 Binary classification  MT-DNN   \n",
       " \n",
       "         Metric name Metric value Global rank Remove  \n",
       " 0           Matched         86.7         # 1      -  \n",
       " 1        Mismatched         86.0         # 1      -  \n",
       " 2          Accuracy         89.6         # 1      -  \n",
       " 3          Accuracy         94.1         # 1      -  \n",
       " 4   % Test Accuracy         91.1         # 2      -  \n",
       " 5  % Train Accuracy         96.8         # 3      -  \n",
       " 6        Parameters         110m         # 1      -  \n",
       " 7          Accuracy         95.6         # 1      -  ,                  Task Dataset Model               Metric name Metric value  \\\n",
       " 0  Question Answering    bAbi  SDNC           Mean Error Rate         6.4%   \n",
       " 1  Question Answering    bAbi  LSTM  Accuracy (trained on 1k)          49%   \n",
       " 2  Question Answering    bAbi  LSTM           Mean Error Rate        28.7%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 4      -  \n",
       " 1         # 7      -  \n",
       " 2         # 7      -  ,                        Task     Dataset   Model Metric name  Metric value  \\\n",
       " 0  3D Human Pose Estimation  CHALL H80K  ResNet       MPJPE          55.3   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  ,                    Task      Dataset      Model       Metric name  \\\n",
       " 0  Pedestrian Detection  CityPersons  FRCNN+Seg  Reasonable MR^-2   \n",
       " 1  Pedestrian Detection  CityPersons  FRCNN+Seg       Small MR^-2   \n",
       " 2  Pedestrian Detection  CityPersons  FRCNN+Seg      Medium MR^-2   \n",
       " 3  Pedestrian Detection  CityPersons  FRCNN+Seg       Large MR^-2   \n",
       " 4  Pedestrian Detection  CityPersons      FRCNN  Reasonable MR^-2   \n",
       " 5  Pedestrian Detection  CityPersons      FRCNN       Small MR^-2   \n",
       " 6  Pedestrian Detection  CityPersons      FRCNN      Medium MR^-2   \n",
       " 7  Pedestrian Detection  CityPersons      FRCNN       Large MR^-2   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          14.8         # 6      -  \n",
       " 1          22.6         # 3      -  \n",
       " 2           6.7         # 3      -  \n",
       " 3           8.0         # 4      -  \n",
       " 4          15.4         # 7      -  \n",
       " 5          25.6         # 4      -  \n",
       " 6           7.2         # 4      -  \n",
       " 7           7.9         # 3      -  ,                   Task                   Dataset                  Model  \\\n",
       " 0  Machine Translation  IWSLT2015 German-English  Variational Attention   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0  BLEU score          33.1         # 4      -  ,               Task             Dataset                            Model  \\\n",
       " 0  Pose Estimation  Leeds Sports Poses  Pyramid Residual Modules (PRMs)   \n",
       " 1  Pose Estimation     MPII Human Pose  Pyramid Residual Modules (PRMs)   \n",
       " \n",
       "   Metric name Metric value Global rank Remove  \n",
       " 0         PCK        93.9%         # 1      -  \n",
       " 1    PCKh-0.5        92.0%         # 2      -  ,                   Task                    Dataset  \\\n",
       " 0    Face Verification  Labeled Faces in the Wild   \n",
       " 1    Face Verification                   MegaFace   \n",
       " 2  Face Identification                   MegaFace   \n",
       " 3    Face Verification           YouTube Faces DB   \n",
       " \n",
       "                          Model Metric name Metric value Global rank Remove  \n",
       " 0     ArcFace + MS1MV2 + R100,    Accuracy       99.83%         # 1      -  \n",
       " 1  ArcFace + MS1MV2 + R100 + R    Accuracy       98.48%         # 1      -  \n",
       " 2  ArcFace + MS1MV2 + R100 + R    Accuracy       98.35%         # 1      -  \n",
       " 3     ArcFace + MS1MV2 + R100,    Accuracy       98.02%         # 2      -  ,                    Task    Dataset      Model         Metric name  \\\n",
       " 0  Image Classification   CIFAR-10  Tuned CNN  Percentage correct   \n",
       " 1  Image Classification  CIFAR-100  Tuned CNN  Percentage correct   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          93.6        # 23      -  \n",
       " 1          72.6        # 19      -  ,                    Task   Dataset                            Model  \\\n",
       " 0  Image Classification  CIFAR-10  Deep pyramidal residual network   \n",
       " 1  Image Classification  CIFAR-10  Deep pyramidal residual network   \n",
       " \n",
       "           Metric name  Metric value Global rank Remove  \n",
       " 0  Percentage correct         96.69         # 7      -  \n",
       " 1    Percentage error          3.31         # 7      -  ,                        Task Dataset             Model Metric name  \\\n",
       " 0  Traffic Sign Recognition   GTSRB  MicronNet (fp16)    Accuracy   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        98.9%         # 2      -  ,                           Task  Dataset  \\\n",
       " 0  Human Instance Segmentation  OCHuman   \n",
       " \n",
       "                                     Model Metric name  Metric value  \\\n",
       " 0  Pose2Seg (plus ground-truth keypoints)          AP         0.552   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  ,                  Task     Dataset Model        Metric name  Metric value  \\\n",
       " 0  Question Answering  SemEvalCQA  Kelp  [email protected]         0.751   \n",
       " 1  Question Answering  SemEvalCQA  Kelp                MAP         0.792   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 4      -  \n",
       " 1         # 2      -  ,                     Task          Dataset                 Model Metric name  \\\n",
       " 0  Semantic Segmentation     NYU Depth v2    Dilated FCN-2s RGB    Mean IoU   \n",
       " 1  Semantic Segmentation  PASCAL VOC 2012  Dilated FCN-2s VGG19    Mean IoU   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        32.3%         # 1      -  \n",
       " 1          69%        # 16      -  ,                     Task         Dataset   Model Metric name  Metric value  \\\n",
       " 0  Semantic Segmentation  PASCAL Context  BoxSup        mIoU          40.5   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 10      -  ,                         Task                    Dataset     Model  \\\n",
       " 0  Sign Language Recognition  RWTH-PHOENIX-Weather 2014  SubUNets   \n",
       " \n",
       "              Metric name  Metric value Global rank Remove  \n",
       " 0  Word Error Rate (WER)          40.7         # 1      -  ,                        Task      Dataset  Model Metric name  Metric value  \\\n",
       " 0  Person Re-Identification  Market-1501  MSCAN      Rank-1         80.31   \n",
       " 1  Person Re-Identification  Market-1501  MSCAN         MAP         57.53   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 19      -  \n",
       " 1        # 21      -  ,                               Task                     Dataset         Model  \\\n",
       " 0              3D Object Detection         KITTI Cars Moderate  PointPillars   \n",
       " 1  Birds Eye View Object Detection         KITTI Cars Moderate  PointPillars   \n",
       " 2  Birds Eye View Object Detection     KITTI Cyclists Moderate  PointPillars   \n",
       " 3              3D Object Detection     KITTI Cyclists Moderate  PointPillars   \n",
       " 4  Birds Eye View Object Detection  KITTI Pedestrians Moderate  PointPillars   \n",
       " 5              3D Object Detection  KITTI Pedestrians Moderate  PointPillars   \n",
       " \n",
       "   Metric name Metric value Global rank Remove  \n",
       " 0          AP      74.99 %         # 2      -  \n",
       " 1          AP      86.10 %         # 1      -  \n",
       " 2          AP      62.25 %         # 1      -  \n",
       " 3          AP      59.07 %         # 1      -  \n",
       " 4          AP      50.23 %         # 1      -  \n",
       " 5          AP      43.53 %         # 3      -  ,                Task   Dataset           Model Metric name  Metric value  \\\n",
       " 0  Image Generation  CIFAR-10  Gated PixelCNN    NLL Test          3.03   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 4      -  ,                  Task   Dataset    Model Metric name  Metric value  \\\n",
       " 0  Passage Re-Ranking  MS MARCO  Duet v2         MRR         0.253   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  ,                         Task  \\\n",
       " 0  Visual Question Answering   \n",
       " 1  Visual Question Answering   \n",
       " 2  Visual Question Answering   \n",
       " \n",
       "                                              Dataset       Model  \\\n",
       " 0  COCO Visual Question Answering (VQA) real imag...  MCB 7 att.   \n",
       " 1  COCO Visual Question Answering (VQA) real imag...  MCB 7 att.   \n",
       " 2                                           Visual7W    MCB+Att.   \n",
       " \n",
       "           Metric name  Metric value Global rank Remove  \n",
       " 0  Percentage correct          70.1         # 1      -  \n",
       " 1  Percentage correct          66.5         # 1      -  \n",
       " 2  Percentage correct          62.2         # 2      -  ,                          Task               Dataset  \\\n",
       " 0   Word Sense Disambiguation  SemEval 2007 Task 17   \n",
       " 1   Word Sense Disambiguation  SemEval 2007 Task 17   \n",
       " 2   Word Sense Disambiguation  SemEval 2007 Task 17   \n",
       " 3   Word Sense Disambiguation  SemEval 2007 Task 17   \n",
       " 4   Word Sense Disambiguation  SemEval 2007 Task 17   \n",
       " 5   Word Sense Disambiguation   SemEval 2007 Task 7   \n",
       " 6   Word Sense Disambiguation   SemEval 2007 Task 7   \n",
       " 7   Word Sense Disambiguation   SemEval 2007 Task 7   \n",
       " 8   Word Sense Disambiguation   SemEval 2007 Task 7   \n",
       " 9   Word Sense Disambiguation   SemEval 2007 Task 7   \n",
       " 10  Word Sense Disambiguation  SemEval 2013 Task 12   \n",
       " 11  Word Sense Disambiguation  SemEval 2013 Task 12   \n",
       " 12  Word Sense Disambiguation  SemEval 2013 Task 12   \n",
       " 13  Word Sense Disambiguation  SemEval 2013 Task 12   \n",
       " 14  Word Sense Disambiguation  SemEval 2013 Task 12   \n",
       " 15  Word Sense Disambiguation            SensEval 2   \n",
       " 16  Word Sense Disambiguation            SensEval 2   \n",
       " 17  Word Sense Disambiguation            SensEval 2   \n",
       " 18  Word Sense Disambiguation            SensEval 2   \n",
       " 19  Word Sense Disambiguation            SensEval 2   \n",
       " 20  Word Sense Disambiguation     SensEval 3 Task 1   \n",
       " 21  Word Sense Disambiguation     SensEval 3 Task 1   \n",
       " 22  Word Sense Disambiguation     SensEval 3 Task 1   \n",
       " 23  Word Sense Disambiguation     SensEval 3 Task 1   \n",
       " 24  Word Sense Disambiguation     SensEval 3 Task 1   \n",
       " \n",
       "                          Model Metric name  Metric value Global rank Remove  \n",
       " 0      LSTMLP (T:SemCor, U:1K)          F1          63.5         # 4      -  \n",
       " 1   LSTMLP (T:SemCor, U:OMSTI)          F1          63.7         # 3      -  \n",
       " 2               LSTM (T:OMSTI)          F1          60.7         # 6      -  \n",
       " 3              LSTM (T:SemCor)          F1          64.2         # 2      -  \n",
       " 4       LSTMLP (T:OMSTI, U:1K)          F1          63.3         # 5      -  \n",
       " 5       LSTMLP (T:OMSTI, U:1K)          F1          83.3         # 4      -  \n",
       " 6   LSTMLP (T:SemCor, U:OMSTI)          F1          84.3         # 2      -  \n",
       " 7              LSTM (T:SemCor)          F1          82.8         # 5      -  \n",
       " 8               LSTM (T:OMSTI)          F1          81.1         # 6      -  \n",
       " 9      LSTMLP (T:SemCor, U:1K)          F1          83.6         # 3      -  \n",
       " 10      LSTMLP (T:OMSTI, U:1K)          F1          68.1         # 3      -  \n",
       " 11              LSTM (T:OMSTI)          F1          67.3         # 5      -  \n",
       " 12             LSTM (T:SemCor)          F1          67.0         # 8      -  \n",
       " 13  LSTMLP (T:SemCor, U:OMSTI)          F1          67.9         # 4      -  \n",
       " 14     LSTMLP (T:SemCor, U:1K)          F1          69.5         # 2      -  \n",
       " 15      LSTMLP (T:OMSTI, U:1K)          F1          74.4         # 2      -  \n",
       " 16             LSTM (T:SemCor)          F1          73.6         # 5      -  \n",
       " 17              LSTM (T:OMSTI)          F1          72.4         # 6      -  \n",
       " 18  LSTMLP (T:SemCor, U:OMSTI)          F1          73.9         # 3      -  \n",
       " 19     LSTMLP (T:SemCor, U:1K)          F1          73.8         # 4      -  \n",
       " 20             LSTM (T:SemCor)          F1          69.2         # 9      -  \n",
       " 21              LSTM (T:OMSTI)          F1          64.3        # 10      -  \n",
       " 22  LSTMLP (T:SemCor, U:OMSTI)          F1          71.1         # 2      -  \n",
       " 23     LSTMLP (T:SemCor, U:1K)          F1          71.8         # 1      -  \n",
       " 24      LSTMLP (T:OMSTI, U:1K)          F1          71.0         # 3      -  ,                    Task                        Dataset              Model  \\\n",
       " 0   Architecture Search  CIFAR-10 Image Classification  AmoebaNet-B + c/o   \n",
       " 1   Architecture Search  CIFAR-10 Image Classification  AmoebaNet-B + c/o   \n",
       " 2  Image Classification                       ImageNet        AmoebaNet-A   \n",
       " \n",
       "         Metric name Metric value Global rank Remove  \n",
       " 0  Percentage error         2.13         # 2      -  \n",
       " 1            Params        34.9M         # 1      -  \n",
       " 2    Top 1 Accuracy        83.9%         # 2      -  ,                    Task           Dataset   Model Metric name  Metric value  \\\n",
       " 0  Image Reconstruction  Edge-to-Handbags  PI-REC         FID         0.069   \n",
       " 1  Image Reconstruction  Edge-to-Handbags  PI-REC       LPIPS         0.168   \n",
       " 2  Image Reconstruction     Edge-to-Shoes  PI-REC         FID         0.015   \n",
       " 3  Image Reconstruction     Edge-to-Shoes  PI-REC       LPIPS         0.085   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 1      -  \n",
       " 2         # 1      -  \n",
       " 3         # 1      -  ,                          Task Dataset               Model       Metric name  \\\n",
       " 0  Natural Language Inference    SNLI           300D DMAN   % Test Accuracy   \n",
       " 1  Natural Language Inference    SNLI           300D DMAN  % Train Accuracy   \n",
       " 2  Natural Language Inference    SNLI           300D DMAN        Parameters   \n",
       " 3  Natural Language Inference    SNLI  300D DMAN Ensemble   % Test Accuracy   \n",
       " 4  Natural Language Inference    SNLI  300D DMAN Ensemble  % Train Accuracy   \n",
       " 5  Natural Language Inference    SNLI  300D DMAN Ensemble        Parameters   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0         88.8        # 10      -  \n",
       " 1         95.4         # 8      -  \n",
       " 2         9.2m         # 1      -  \n",
       " 3         89.6         # 5      -  \n",
       " 4         96.1         # 5      -  \n",
       " 5          79m         # 1      -  ,                             Task                          Dataset   Model  \\\n",
       " 0  Few-Shot Image Classification  Mini-ImageNet - 1-Shot Learning  MAML++   \n",
       " 1  Few-Shot Image Classification  Mini-ImageNet - 5-Shot Learning  MAML++   \n",
       " \n",
       "   Metric name Metric value Global rank Remove  \n",
       " 0    Accuracy       52.40%         # 4      -  \n",
       " 1    Accuracy       67.15%         # 5      -  ,                            Task           Dataset   Model      Metric name  \\\n",
       " 0  Conditional Image Generation          CIFAR-10  AC-GAN  Inception score   \n",
       " 1  Conditional Image Generation  ImageNet 128x128  AC-GAN  Inception score   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          8.25         # 4      -  \n",
       " 1         28.50         # 6      -  ,                  Task                     Dataset                    Model  \\\n",
       " 0  Language Modelling                Hutter Prize     mLSTM + dynamic eval   \n",
       " 1  Language Modelling                Hutter Prize     mLSTM + dynamic eval   \n",
       " 2  Language Modelling  Penn Treebank (Word Level)  AWD-LSTM + dynamic eval   \n",
       " 3  Language Modelling  Penn Treebank (Word Level)  AWD-LSTM + dynamic eval   \n",
       " 4  Language Modelling  Penn Treebank (Word Level)  AWD-LSTM + dynamic eval   \n",
       " 5  Language Modelling                       Text8     mLSTM + dynamic eval   \n",
       " 6  Language Modelling                       Text8     mLSTM + dynamic eval   \n",
       " 7  Language Modelling                  WikiText-2  AWD-LSTM + dynamic eval   \n",
       " 8  Language Modelling                  WikiText-2  AWD-LSTM + dynamic eval   \n",
       " 9  Language Modelling                  WikiText-2  AWD-LSTM + dynamic eval   \n",
       " \n",
       "                Metric name Metric value Global rank Remove  \n",
       " 0  Bit per Character (BPC)         1.08         # 4      -  \n",
       " 1         Number of params          46M         # 1      -  \n",
       " 2    Validation perplexity         51.6         # 5      -  \n",
       " 3          Test perplexity         51.1         # 6      -  \n",
       " 4                   Params          24M         # 1      -  \n",
       " 5  Bit per Character (BPC)         1.19         # 6      -  \n",
       " 6         Number of params          45M         # 1      -  \n",
       " 7    Validation perplexity         46.4         # 4      -  \n",
       " 8          Test perplexity         44.3         # 5      -  \n",
       " 9         Number of params          33M         # 1      -  ,                       Task                                   Dataset  \\\n",
       " 0  Dialogue State Tracking  Second dialogue state tracking challenge   \n",
       " 1  Dialogue State Tracking  Second dialogue state tracking challenge   \n",
       " 2  Dialogue State Tracking  Second dialogue state tracking challenge   \n",
       " 3  Dialogue State Tracking  Second dialogue state tracking challenge   \n",
       " 4  Dialogue State Tracking  Second dialogue state tracking challenge   \n",
       " \n",
       "         Model Metric name Metric value Global rank Remove  \n",
       " 0  Liu et al.     Request            -         # 4      -  \n",
       " 1  Liu et al.        Area           90         # 2      -  \n",
       " 2  Liu et al.        Food           84         # 2      -  \n",
       " 3  Liu et al.       Price           92         # 2      -  \n",
       " 4  Liu et al.       Joint           72         # 4      -  ,                          Task              Dataset          Model Metric name  \\\n",
       " 0  Medical Image Segmentation  iSEG 2017 Challenge  HyperDenseNet  Dice Score   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0        0.9257         # 1      -  ,        Task        Dataset Model Metric name  Metric value Global rank Remove\n",
       " 0  Chunking  Penn Treebank   JMT    F1 score         95.77         # 2      -,                      Task                  Dataset  Model Metric name  \\\n",
       " 0  Image Super-Resolution    BSD100 - 4x upscaling  ProSR        PSNR   \n",
       " 1  Image Super-Resolution     Set14 - 4x upscaling  ProSR        PSNR   \n",
       " 2  Image Super-Resolution  Urban100 - 4x upscaling  ProSR        PSNR   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         27.79         # 2      -  \n",
       " 1         28.94         # 3      -  \n",
       " 2         26.89         # 2      -  ,                  Task   Dataset                         Model Metric name  \\\n",
       " 0  Question Answering  SQuAD1.1  QANet + data augmentation ×3          EM   \n",
       " 1  Question Answering  SQuAD1.1  QANet + data augmentation ×3          F1   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          76.2        # 62      -  \n",
       " 1          84.6        # 56      -  ,                  Task                 Dataset  \\\n",
       " 0  Speech Recognition  LibriSpeech test-clean   \n",
       " \n",
       "                               Model            Metric name  Metric value  \\\n",
       " 0  Convolutional Speech Recognition  Word Error Rate (WER)          3.44   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 5      -  ,                            Task        Dataset          Model Metric name  \\\n",
       " 0  Ad-Hoc Information Retrieval  TREC Robust04  POSIT-DRMM-MV         MAP   \n",
       " 1  Ad-Hoc Information Retrieval  TREC Robust04          PACRR         MAP   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         0.272         # 9      -  \n",
       " 1         0.258        # 10      -  ,                    Task Dataset  \\\n",
       " 0  Image Classification  STL-10   \n",
       " \n",
       "                                                Model         Metric name  \\\n",
       " 0  No more meta-parameter tuning in unsupervised ...  Percentage correct   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          61.0        # 16      -  ,                             Task                    Dataset             Model  \\\n",
       " 0  Synthetic-to-Real Translation  GTAV-to-Cityscapes Labels  FCNs in the wild   \n",
       " 1     Image-to-Image Translation     SYNTHIA Fall-to-Winter  FCNs in the wild   \n",
       " 2     Image-to-Image Translation      SYNTHIA-to-Cityscapes  FCNs in the wild   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0        mIoU          27.1         # 7      -  \n",
       " 1        mIoU          59.6         # 2      -  \n",
       " 2        mIoU          20.2         # 2      -  ,                  Task   Dataset             Model Metric name  Metric value  \\\n",
       " 0  Text Summarization  GigaWord  Struct+2Way+Word     ROUGE-1         35.47   \n",
       " 1  Text Summarization  GigaWord  Struct+2Way+Word     ROUGE-2         17.66   \n",
       " 2  Text Summarization  GigaWord  Struct+2Way+Word     ROUGE-L         33.52   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 8      -  \n",
       " 1         # 5      -  \n",
       " 2         # 9      -  ,                    Task    Dataset     Model         Metric name  \\\n",
       " 0  Image Classification   CIFAR-10  DenseNet  Percentage correct   \n",
       " 1  Image Classification   CIFAR-10  DenseNet    Percentage error   \n",
       " 2  Image Classification  CIFAR-100  DenseNet  Percentage correct   \n",
       " 3  Image Classification  CIFAR-100  DenseNet    Percentage error   \n",
       " 4  Image Classification       SVHN  DenseNet    Percentage error   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         96.54         # 9      -  \n",
       " 1          3.46         # 9      -  \n",
       " 2         82.62         # 5      -  \n",
       " 3         17.18         # 3      -  \n",
       " 4          1.59         # 4      -  ,                          Task Dataset                                 Model  \\\n",
       " 0  Natural Language Inference    SNLI  Fine-Tuned LM-Pretrained Transformer   \n",
       " 1  Natural Language Inference    SNLI  Fine-Tuned LM-Pretrained Transformer   \n",
       " 2  Natural Language Inference    SNLI  Fine-Tuned LM-Pretrained Transformer   \n",
       " \n",
       "         Metric name Metric value Global rank Remove  \n",
       " 0   % Test Accuracy         89.9         # 4      -  \n",
       " 1  % Train Accuracy         96.6         # 4      -  \n",
       " 2        Parameters          85m         # 1      -  ,                          Task Dataset  \\\n",
       " 0  Natural Language Inference    SNLI   \n",
       " 1  Natural Language Inference    SNLI   \n",
       " 2  Natural Language Inference    SNLI   \n",
       " \n",
       "                                      Model       Metric name Metric value  \\\n",
       " 0  300D mLSTM word-by-word attention model   % Test Accuracy         86.1   \n",
       " 1  300D mLSTM word-by-word attention model  % Train Accuracy         92.0   \n",
       " 2  300D mLSTM word-by-word attention model        Parameters         1.9m   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 27      -  \n",
       " 1        # 23      -  \n",
       " 2         # 1      -  ,                  Task      Dataset         Model Metric name  Metric value  \\\n",
       " 0  Question Answering  NarrativeQA  MHPGM + NOIC      BLEU-1         43.63   \n",
       " 1  Question Answering  NarrativeQA  MHPGM + NOIC      BLEU-4         21.07   \n",
       " 2  Question Answering  NarrativeQA  MHPGM + NOIC      METEOR         19.03   \n",
       " 3  Question Answering  NarrativeQA  MHPGM + NOIC     Rouge-L         44.16   \n",
       " 4  Question Answering      WikiHop  MHPGM + NOIC        Test         57.90   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  \n",
       " 1         # 3      -  \n",
       " 2         # 3      -  \n",
       " 3         # 3      -  \n",
       " 4         # 3      -  ,               Task             Dataset                                 Model  \\\n",
       " 0  Pose Estimation  Leeds Sports Poses  Soft-argmax + contextual information   \n",
       " \n",
       "   Metric name Metric value Global rank Remove  \n",
       " 0         PCK        90.5%         # 3      -  ,                  Task                         Dataset  \\\n",
       " 0  Sentiment Analysis  Multi-Domain Sentiment Dataset   \n",
       " 1  Sentiment Analysis  Multi-Domain Sentiment Dataset   \n",
       " 2  Sentiment Analysis  Multi-Domain Sentiment Dataset   \n",
       " 3  Sentiment Analysis  Multi-Domain Sentiment Dataset   \n",
       " 4  Sentiment Analysis  Multi-Domain Sentiment Dataset   \n",
       " \n",
       "                      Model  Metric name  Metric value Global rank Remove  \n",
       " 0  Asymmetric tri-training          DVD         76.17         # 4      -  \n",
       " 1  Asymmetric tri-training        Books         72.97         # 4      -  \n",
       " 2  Asymmetric tri-training  Electronics         80.47         # 3      -  \n",
       " 3  Asymmetric tri-training      Kitchen         83.97         # 2      -  \n",
       " 4  Asymmetric tri-training      Average         78.39         # 3      -  ,                 Task   Dataset    Model       Metric name Metric value  \\\n",
       " 0  3D Reconstruction  Scan2CAD  3DMatch  Average Accuracy       10.29%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  ,               Task                Dataset    Model Metric name  Metric value  \\\n",
       " 0  Image Retrieval  street2shop - topwear  MILDNet    Accuracy         93.69   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  ,                  Task   Dataset     Model Metric name  Metric value  \\\n",
       " 0  Text Summarization  GigaWord  Re^3 Sum     ROUGE-1         37.04   \n",
       " 1  Text Summarization  GigaWord  Re^3 Sum     ROUGE-2         19.03   \n",
       " 2  Text Summarization  GigaWord  Re^3 Sum     ROUGE-L         34.46   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  \n",
       " 1         # 1      -  \n",
       " 2         # 2      -  ,              Task         Dataset         Model Metric name  Metric value  \\\n",
       " 0  Crowd Counting  ShanghaiTech A  Cascaded-MTL         MAE         101.3   \n",
       " 1  Crowd Counting  ShanghaiTech B  Cascaded-MTL         MAE          20.0   \n",
       " 2  Crowd Counting       UCF CC 50  Cascaded-MTL         MAE         322.8   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 1      -  \n",
       " 2         # 1      -  ,                 Task                    Dataset     Model Metric name  \\\n",
       " 0  Face Verification  Labeled Faces in the Wild  DeepId2+    Accuracy   \n",
       " 1  Face Verification           YouTube Faces DB  DeepId2+    Accuracy   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0       99.47%         # 5      -  \n",
       " 1        93.2%         # 9      -  ,                                 Task       Dataset         Model Metric name  \\\n",
       " 0  Fine-Grained Image Classification  CUB-200-2011  Bilinear-CNN    Accuracy   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        85.1%         # 8      -  ,                          Task                     Dataset   Model  \\\n",
       " 0  Image-to-Image Translation  Cityscapes Labels-to-Photo  SimGAN   \n",
       " 1  Image-to-Image Translation  Cityscapes Labels-to-Photo  SimGAN   \n",
       " 2  Image-to-Image Translation  Cityscapes Labels-to-Photo  SimGAN   \n",
       " 3  Image-to-Image Translation  Cityscapes Photo-to-Labels  SimGAN   \n",
       " 4  Image-to-Image Translation  Cityscapes Photo-to-Labels  SimGAN   \n",
       " 5  Image-to-Image Translation  Cityscapes Photo-to-Labels  SimGAN   \n",
       " \n",
       "           Metric name Metric value Global rank Remove  \n",
       " 0           Class IOU         0.04         # 4      -  \n",
       " 1  Per-class Accuracy          10%         # 3      -  \n",
       " 2  Per-pixel Accuracy          20%         # 8      -  \n",
       " 3  Per-pixel Accuracy          47%         # 3      -  \n",
       " 4  Per-class Accuracy          11%         # 4      -  \n",
       " 5           Class IOU         0.07         # 4      -  ,                   Task                 Dataset             Model Metric name  \\\n",
       " 0  Machine Translation  WMT2014 English-French  Regularized LSTM  BLEU score   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         29.03        # 23      -  ,                                    Task            Dataset Model Metric name  \\\n",
       " 0  Multivariate Time Series Forecasting  BPI challenge '12  LSTM    Accuracy   \n",
       " 1  Multivariate Time Series Forecasting           Helpdesk  LSTM    Accuracy   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0        0.7600         # 1      -  \n",
       " 1        0.7123         # 1      -  ,                  Task   Dataset               Model Metric name  Metric value  \\\n",
       " 0  Question Answering  SQuAD1.1  KAR (single model)          EM        76.125   \n",
       " 1  Question Answering  SQuAD1.1  KAR (single model)          F1        83.538   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 64      -  \n",
       " 1        # 67      -  ,                  Task                          Dataset            Model  \\\n",
       " 0  Language Modelling  Penn Treebank (Character Level)  Trellis Network   \n",
       " 1  Language Modelling  Penn Treebank (Character Level)  Trellis Network   \n",
       " 2  Language Modelling       Penn Treebank (Word Level)  Trellis Network   \n",
       " 3  Language Modelling                 Sequential MNIST  Trellis Network   \n",
       " 4  Language Modelling                     WikiText-103  Trellis Network   \n",
       " \n",
       "                Metric name Metric value Global rank Remove  \n",
       " 0  Bit per Character (BPC)        1.158         # 1      -  \n",
       " 1         Number of params        13.4M         # 1      -  \n",
       " 2          Test perplexity        54.19        # 11      -  \n",
       " 3                 Accuracy        99.20         # 1      -  \n",
       " 4          Test perplexity        29.19         # 5      -  ,                Task Dataset    Model      Metric name  Metric value  \\\n",
       " 0  Object Detection    COCO  IoU-Net  Bounding Box AP          40.6   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 23      -  ,                Task                 Dataset                 Model  \\\n",
       " 0  Speech Synthesis  North American English            Tacotron 2   \n",
       " 1  Speech Synthesis  North American English  WaveNet (Linguistic)   \n",
       " \n",
       "           Metric name  Metric value Global rank Remove  \n",
       " 0  Mean Opinion Score         4.526         # 1      -  \n",
       " 1  Mean Opinion Score         4.341         # 2      -  ,                                Task                 Dataset  \\\n",
       " 0  Unsupervised Machine Translation  WMT2014 English-French   \n",
       " 1  Unsupervised Machine Translation  WMT2014 English-German   \n",
       " 2  Unsupervised Machine Translation  WMT2014 French-English   \n",
       " 3  Unsupervised Machine Translation  WMT2014 German-English   \n",
       " 4  Unsupervised Machine Translation  WMT2016 English-German   \n",
       " 5  Unsupervised Machine Translation  WMT2016 German-English   \n",
       " \n",
       "                                      Model Metric name  Metric value  \\\n",
       " 0  SMT + NMT (tuning and joint refinement)        BLEU          36.2   \n",
       " 1  SMT + NMT (tuning and joint refinement)        BLEU          22.5   \n",
       " 2  SMT + NMT (tuning and joint refinement)        BLEU          33.5   \n",
       " 3  SMT + NMT (tuning and joint refinement)        BLEU          27.0   \n",
       " 4  SMT + NMT (tuning and joint refinement)        BLEU          26.9   \n",
       " 5  SMT + NMT (tuning and joint refinement)        BLEU          34.4   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 1      -  \n",
       " 2         # 1      -  \n",
       " 3         # 1      -  \n",
       " 4         # 1      -  \n",
       " 5         # 1      -  ,                Task    Dataset  Model        Metric name  Metric value  \\\n",
       " 0   Link Prediction      FB15k  HypER                MRR         0.790   \n",
       " 1   Link Prediction      FB15k  HypER  [email protected]         0.885   \n",
       " 2   Link Prediction      FB15k  HypER  [email protected]         0.829   \n",
       " 3   Link Prediction      FB15k  HypER  [email protected]         0.734   \n",
       " 4   Link Prediction  FB15k-237  HypER                MRR         0.341   \n",
       " 5   Link Prediction  FB15k-237  HypER  [email protected]         0.520   \n",
       " 6   Link Prediction  FB15k-237  HypER  [email protected]         0.376   \n",
       " 7   Link Prediction  FB15k-237  HypER  [email protected]         0.252   \n",
       " 8   Link Prediction       WN18  HypER                MRR         0.951   \n",
       " 9   Link Prediction       WN18  HypER  [email protected]         0.958   \n",
       " 10  Link Prediction       WN18  HypER  [email protected]         0.955   \n",
       " 11  Link Prediction       WN18  HypER  [email protected]         0.947   \n",
       " 12  Link Prediction     WN18RR  HypER                MRR         0.465   \n",
       " 13  Link Prediction     WN18RR  HypER  [email protected]         0.522   \n",
       " 14  Link Prediction     WN18RR  HypER  [email protected]         0.477   \n",
       " 15  Link Prediction     WN18RR  HypER  [email protected]         0.436   \n",
       " \n",
       "    Global rank Remove  \n",
       " 0          # 3      -  \n",
       " 1          # 3      -  \n",
       " 2          # 2      -  \n",
       " 3          # 2      -  \n",
       " 4          # 3      -  \n",
       " 5          # 3      -  \n",
       " 6          # 2      -  \n",
       " 7          # 2      -  \n",
       " 8          # 3      -  \n",
       " 9          # 3      -  \n",
       " 10         # 2      -  \n",
       " 11         # 3      -  \n",
       " 12         # 4      -  \n",
       " 13         # 4      -  \n",
       " 14         # 2      -  \n",
       " 15         # 3      -  ,                            Task            Dataset  \\\n",
       " 0  Multi-Person Pose Estimation  MPII Multi-Person   \n",
       " \n",
       "                                    Model Metric name Metric value Global rank  \\\n",
       " 0  Regional Multi-Person Pose Estimation          AP        82.1%         # 1   \n",
       " \n",
       "   Remove  \n",
       " 0      -  ,                       Task       Dataset Model Metric name  Metric value  \\\n",
       " 0  Collaborative Filtering  MovieLens 1M  NNMF        RMSE         0.843   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 6      -  ,                            Task                          Dataset  Model  \\\n",
       " 0   Retinal Vessel Segmentation                        CHASE_DB1  U-Net   \n",
       " 1   Retinal Vessel Segmentation                        CHASE_DB1  U-Net   \n",
       " 2         Pancreas Segmentation                           CT-150  U-Net   \n",
       " 3         Pancreas Segmentation                           CT-150  U-Net   \n",
       " 4         Pancreas Segmentation                           CT-150  U-Net   \n",
       " 5             Cell Segmentation                         DIC-HeLa  U-Net   \n",
       " 6   Retinal Vessel Segmentation                            DRIVE  U-Net   \n",
       " 7   Retinal Vessel Segmentation                            DRIVE  U-Net   \n",
       " 8    Medical Image Segmentation        ISBI 2012 EM Segmentation  U-Net   \n",
       " 9      Skin Cancer Segmentation  Kaggle Skin Lesion Segmentation  U-Net   \n",
       " 10     Skin Cancer Segmentation  Kaggle Skin Lesion Segmentation  U-Net   \n",
       " 11     Lung Nodule Segmentation                             LUNA  U-Net   \n",
       " 12     Lung Nodule Segmentation                             LUNA  U-Net   \n",
       " 13            Cell Segmentation                         PhC-U373  U-Net   \n",
       " 14  Retinal Vessel Segmentation                            STARE  U-Net   \n",
       " 15  Retinal Vessel Segmentation                            STARE  U-Net   \n",
       " \n",
       "       Metric name  Metric value Global rank Remove  \n",
       " 0        F1 score      0.778300         # 4      -  \n",
       " 1             AUC      0.977200         # 4      -  \n",
       " 2      Dice Score      0.814000         # 2      -  \n",
       " 3       Precision      0.848000         # 2      -  \n",
       " 4          Recall      0.806000         # 2      -  \n",
       " 5        Mean IoU      0.775600         # 1      -  \n",
       " 6        F1 score      0.814200         # 4      -  \n",
       " 7             AUC      0.975500         # 4      -  \n",
       " 8   Warping Error      0.000353         # 1      -  \n",
       " 9        F1 score      0.868200         # 3      -  \n",
       " 10            AUC      0.937100         # 3      -  \n",
       " 11       F1 score      0.965800         # 3      -  \n",
       " 12            AUC      0.978400         # 3      -  \n",
       " 13       Mean IoU      0.920300         # 1      -  \n",
       " 14       F1 score      0.837300         # 3      -  \n",
       " 15            AUC      0.989800         # 3      -  ,                              Task   Dataset                     Model  \\\n",
       " 0  Open-Domain Question Answering  SearchQA  Focused Hierarchical RNN   \n",
       " 1  Open-Domain Question Answering  SearchQA  Focused Hierarchical RNN   \n",
       " \n",
       "    Metric name  Metric value Global rank Remove  \n",
       " 0  Unigram Acc          46.8         # 3      -  \n",
       " 1    N-gram F1          53.4         # 4      -  ,                                          Task      Dataset Model Metric name  \\\n",
       " 0  3D Room Layouts From A Single Rgb Panorama  PanoContext   CFL       3DIoU   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0       78.79%         # 2      -  ,                  Task            Dataset       Model Metric name  \\\n",
       " 0  Question Answering  Natural Questions  BERT-joint   F1 (Long)   \n",
       " 1  Question Answering  Natural Questions  BERT-joint  F1 (Short)   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          66.2         # 1      -  \n",
       " 1          52.1         # 1      -  ,                                Task                 Dataset Model  \\\n",
       " 0           Document Classification                  20NEWS  RMDL   \n",
       " 1   Multi-Label Text Classification                  20NEWS  RMDL   \n",
       " 2              Image Classification                CIFAR-10  RMDL   \n",
       " 3              Image Classification                CIFAR-10  RMDL   \n",
       " 4           Document Classification                    IMDb  RMDL   \n",
       " 5              Image Classification                   MNIST  RMDL   \n",
       " 6                  Face Recognition  Olivetti Faces 5 Image  RMDL   \n",
       " 7           Document Classification           Reuters-21578  RMDL   \n",
       " 8           Document Classification               WOS-11967  RMDL   \n",
       " 9           Document Classification               WOS-46985  RMDL   \n",
       " 10          Document Classification                WOS-5736  RMDL   \n",
       " \n",
       "            Metric name  Metric value Global rank Remove  \n",
       " 0             Accuracy         87.91         # 1      -  \n",
       " 1             Accuracy         91.21         # 1      -  \n",
       " 2   Percentage correct         91.21        # 37      -  \n",
       " 3     Percentage error          8.79        # 16      -  \n",
       " 4             Accuracy         90.79         # 1      -  \n",
       " 5     Percentage error          0.18         # 1      -  \n",
       " 6             Accuracy         95.00         # 1      -  \n",
       " 7             Accuracy         90.69         # 1      -  \n",
       " 8             Accuracy         91.59         # 1      -  \n",
       " 9             Accuracy         90.69         # 1      -  \n",
       " 10            Accuracy         93.57         # 1      -  ,                    Task Dataset Model Metric name Metric value Global rank  \\\n",
       " 0  Graph Classification     D&D   AWE    Accuracy       71.51%         # 3   \n",
       " 1  Graph Classification  IMDb-B   AWE    Accuracy       74.45%         # 1   \n",
       " 2  Graph Classification   MUTAG   AWE    Accuracy       87.87%         # 2   \n",
       " \n",
       "   Remove  \n",
       " 0      -  \n",
       " 1      -  \n",
       " 2      -  ,                        Task                Dataset       Model  Metric name  \\\n",
       " 0  Brain Image Segmentation                  CREMI  U-NET MALA          VOI   \n",
       " 1  Brain Image Segmentation                  CREMI  U-NET MALA  CREMI Score   \n",
       " 2  Brain Image Segmentation  FIB-25 Synaptic Sites  U-NET MALA          VOI   \n",
       " 3  Brain Image Segmentation      FIB-25 Whole Test  U-NET MALA          VOI   \n",
       " 4  Brain Image Segmentation                  SegEM  U-NET MALA          IED   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         0.606         # 1      -  \n",
       " 1         0.289         # 1      -  \n",
       " 2         2.151         # 1      -  \n",
       " 3         1.071         # 1      -  \n",
       " 4         4.839         # 1      -  ,                     Task                            Dataset             Model  \\\n",
       " 0     Sentiment Analysis                                 MR  GRU-RNN-WORD2VEC   \n",
       " 1     Sentiment Analysis  SST-5 Fine-grained classification  GRU-RNN-WORD2VEC   \n",
       " 2  Subjectivity Analysis                               SUBJ     GRU-RNN-GLOVE   \n",
       " 3    Text Classification                             TREC-6     GRU-RNN-GLOVE   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0    Accuracy         78.26         # 6      -  \n",
       " 1    Accuracy         45.02        # 14      -  \n",
       " 2    Accuracy         91.85         # 8      -  \n",
       " 3       Error          7.00         # 7      -  ,                  Task    Dataset        Model Metric name Metric value  \\\n",
       " 0  6D Pose Estimation  YCB-Video  PointFusion    Mean AUC        83.9%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 3      -  ,                    Task   Dataset    Model     Metric name Metric value  \\\n",
       " 0  Image Classification  ImageNet  DPN-131  Top 1 Accuracy        81.5%   \n",
       " 1  Image Classification  ImageNet  DPN-131  Top 5 Accuracy        95.8%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 5      -  \n",
       " 1         # 4      -  ,                    Task Dataset                     Model         Metric name  \\\n",
       " 0  Image Classification   MNIST  Convolutional Clustering    Percentage error   \n",
       " 1  Image Classification  STL-10  Convolutional Clustering  Percentage correct   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0           1.4        # 13      -  \n",
       " 1          74.1         # 5      -  ,                  Task  Dataset              Model              Metric name  \\\n",
       " 0  Language Modelling  enwiki8         LN HM-LSTM  Bit per Character (BPC)   \n",
       " 1  Language Modelling  enwiki8         LN HM-LSTM         Number of params   \n",
       " 2  Language Modelling    Text8  LayerNorm HM-LSTM  Bit per Character (BPC)   \n",
       " 3  Language Modelling    Text8  LayerNorm HM-LSTM         Number of params   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0         1.32        # 10      -  \n",
       " 1          35M         # 1      -  \n",
       " 2         1.29         # 8      -  \n",
       " 3          35M         # 1      -  ,                      Task   Dataset Model Metric name  Metric value  \\\n",
       " 0  Recommendation Systems  Polyvore  NGNN    Accuracy        0.7813   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  ,                     Task          Dataset          Model Metric name  \\\n",
       " 0  Semantic Segmentation  PASCAL VOC 2012  DeepLabv3-JFT    Mean IoU   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        86.9%         # 2      -  ,                Task                 Dataset  Model      Metric name  \\\n",
       " 0  Image Generation                  CelebA  PGGAN              FID   \n",
       " 1  Image Generation     CelebA-HQ 1024x1024  PGGAN              FID   \n",
       " 2  Image Generation                CIFAR-10  PGGAN  Inception score   \n",
       " 3  Image Generation                    FFHQ  PGGAN              FID   \n",
       " 4  Image Generation  LSUN Bedroom 256 x 256  PGGAN              FID   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          7.30         # 2      -  \n",
       " 1          7.30         # 3      -  \n",
       " 2          8.80         # 1      -  \n",
       " 3          8.04         # 3      -  \n",
       " 4          8.34         # 3      -  ,                    Task      Dataset           Model     Metric name  \\\n",
       " 0  Image Classification  iNaturalist  IncResNetV2 SE  Top 1 Accuracy   \n",
       " 1  Image Classification  iNaturalist  IncResNetV2 SE  Top 5 Accuracy   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        67.3%         # 1      -  \n",
       " 1        87.5%         # 1      -  ,                Task   Dataset  Model Metric name  Metric value Global rank  \\\n",
       " 0  Image Generation  CIFAR-10  MSGAN         FID         28.73         # 7   \n",
       " \n",
       "   Remove  \n",
       " 0      -  ,                  Task  Dataset  Model    Metric name  Metric value  \\\n",
       " 0  Traffic Prediction  METR-LA  DCRNN  MAE @ 12 step           3.6   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  ,                          Task Dataset  \\\n",
       " 0  Natural Language Inference    SNLI   \n",
       " 1  Natural Language Inference    SNLI   \n",
       " 2  Natural Language Inference    SNLI   \n",
       " \n",
       "                                              Model       Metric name  \\\n",
       " 0  600D (300+300) Deep Gated Attn. BiLSTM encoders   % Test Accuracy   \n",
       " 1  600D (300+300) Deep Gated Attn. BiLSTM encoders  % Train Accuracy   \n",
       " 2  600D (300+300) Deep Gated Attn. BiLSTM encoders        Parameters   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0         85.5        # 32      -  \n",
       " 1         90.5        # 31      -  \n",
       " 2          12m         # 1      -  ,                   Task              Dataset      Model Metric name  \\\n",
       " 0  3D Object Detection      KITTI Cars Easy  PointRCNN          AP   \n",
       " 1  3D Object Detection      KITTI Cars Hard  PointRCNN          AP   \n",
       " 2  3D Object Detection  KITTI Cars Moderate  PointRCNN          AP   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0       84.32%         # 2      -  \n",
       " 1       67.86%         # 1      -  \n",
       " 2       75.42%         # 1      -  ,                  Task    Dataset        Model Metric name Metric value  \\\n",
       " 0  6D Pose Estimation  YCB-Video  DenseFusion    Mean AUC        93.1%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  ,                    Task Dataset Model       Metric name  Metric value  \\\n",
       " 0  Image Classification   MNIST  HOPE  Percentage error           0.4   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 4      -  ,                     Task         Dataset     Model Metric name  Metric value  \\\n",
       " 0  Semantic Segmentation  PASCAL Context  VeryDeep        mIoU          44.5   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 7      -  ,                  Task   Dataset                           Model Metric name  \\\n",
       " 0  Question Answering  SQuAD1.1  Document Reader (single model)          EM   \n",
       " 1  Question Answering  SQuAD1.1  Document Reader (single model)          F1   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0        70.733       # 106      -  \n",
       " 1        79.353       # 109      -  ,              Task              Dataset Model Metric name  Metric value  \\\n",
       " 0  Face Detection                 FDDB  DSFD          AP         0.991   \n",
       " 1  Face Detection    WIDER Face (Easy)  DSFD          AP         0.960   \n",
       " 2  Face Detection    WIDER Face (Hard)  DSFD          AP         0.900   \n",
       " 3  Face Detection  WIDER Face (Medium)  DSFD          AP         0.953   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 1      -  \n",
       " 2         # 1      -  \n",
       " 3         # 1      -  ,                  Task Dataset   Model                Metric name Metric value  \\\n",
       " 0  Question Answering    bAbi  EntNet  Accuracy (trained on 10k)        99.5%   \n",
       " 1  Question Answering    bAbi  EntNet   Accuracy (trained on 1k)        89.1%   \n",
       " 2  Question Answering    bAbi  EntNet            Mean Error Rate         9.7%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  \n",
       " 1         # 2      -  \n",
       " 2         # 6      -  ,                     Task Dataset                Model        Metric name  \\\n",
       " 0  Instance Segmentation    COCO                PANet  Average Precision   \n",
       " 1       Object Detection    COCO  PANet + ResNeXt-101    Bounding Box AP   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        42.0%         # 1      -  \n",
       " 1         47.4         # 2      -  ,                     Task       Dataset    Model Metric name Metric value  \\\n",
       " 0   Scene Text Detection          IC15  SegLink   F-Measure       75.61%   \n",
       " 1  Curved Text Detection  SCUT-CTW1500  SegLink   F-Measure        40.8%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 10      -  \n",
       " 1         # 5      -  ,           Task                         Dataset    Model Metric name  \\\n",
       " 0  Atari Games              Atari 2600 Freeway  A3C-CTS       Score   \n",
       " 1  Atari Games             Atari 2600 Gravitar  A3C-CTS       Score   \n",
       " 2  Atari Games  Atari 2600 Montezuma's Revenge  DDQN-PC       Score   \n",
       " 3  Atari Games  Atari 2600 Montezuma's Revenge  A3C-CTS       Score   \n",
       " 4  Atari Games          Atari 2600 Private Eye  A3C-CTS       Score   \n",
       " 5  Atari Games              Atari 2600 Venture  A3C-CTS       Score   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         30.48        # 10      -  \n",
       " 1        238.68        # 21      -  \n",
       " 2       3459.00         # 4      -  \n",
       " 3        273.70         # 8      -  \n",
       " 4         99.32        # 22      -  \n",
       " 5          0.00        # 27      -  ,                  Task        Dataset                         Model  \\\n",
       " 0  Dependency Parsing  Penn Treebank  BIST transition-based parser   \n",
       " 1  Dependency Parsing  Penn Treebank  BIST transition-based parser   \n",
       " 2  Dependency Parsing  Penn Treebank  BIST transition-based parser   \n",
       " 3  Dependency Parsing  Penn Treebank       BIST graph-based parser   \n",
       " 4  Dependency Parsing  Penn Treebank       BIST graph-based parser   \n",
       " 5  Dependency Parsing  Penn Treebank       BIST graph-based parser   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0         POS          97.3         # 3      -  \n",
       " 1         UAS          93.9         # 7      -  \n",
       " 2         LAS          91.9         # 7      -  \n",
       " 3         POS          97.3         # 3      -  \n",
       " 4         UAS          93.1         # 9      -  \n",
       " 5         LAS          91.0         # 9      -  ,                    Task   Dataset  \\\n",
       " 0  Image Classification  CIFAR-10   \n",
       " \n",
       "                                                Model         Metric name  \\\n",
       " 0  Improving neural networks by preventing co-ada...  Percentage correct   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          84.4        # 51      -  ,                Task                 Dataset  Model Metric name  Metric value  \\\n",
       " 0  Image Generation                CIFAR-10  FOGAN         FID          27.4   \n",
       " 1  Image Generation  LSUN Bedroom 256 x 256  FOGAN         FID          11.4   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 6      -  \n",
       " 1         # 5      -  ,                   Task                           Dataset     Model  \\\n",
       " 0  Text Classification                           AG News  fastText   \n",
       " 1   Sentiment Analysis                Amazon Review Full  FastText   \n",
       " 2   Sentiment Analysis            Amazon Review Polarity  FastText   \n",
       " 3  Text Classification                           DBpedia  FastText   \n",
       " 4   Sentiment Analysis                        Sogou News  fastText   \n",
       " 5  Text Classification                    Yahoo! Answers  FastText   \n",
       " 6   Sentiment Analysis        Yelp Binary classification  FastText   \n",
       " 7   Sentiment Analysis  Yelp Fine-grained classification  FastText   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0       Error           7.5         # 9      -  \n",
       " 1    Accuracy          60.2         # 8      -  \n",
       " 2    Accuracy          94.6         # 8      -  \n",
       " 3       Error           1.4        # 14      -  \n",
       " 4    Accuracy          96.8         # 1      -  \n",
       " 5    Accuracy          72.3         # 5      -  \n",
       " 6       Error           4.3        # 12      -  \n",
       " 7       Error          36.1        # 10      -  ,                        Task    Dataset  \\\n",
       " 0  3D Human Pose Estimation  Human3.6M   \n",
       " \n",
       "                                            Model       Metric name  \\\n",
       " 0  Projected-pose belief maps + 2D fusion layers  Average 3D Error   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         88.39         # 6      -  ,                    Task Dataset Model Metric name Metric value Global rank  \\\n",
       " 0  Scene Text Detection    IC15  SSTD   F-Measure       76.91%         # 9   \n",
       " \n",
       "   Remove  \n",
       " 0      -  ,                   Task                  Dataset                  Model  \\\n",
       " 0  Machine Translation   WMT2015 English-German  BPE word segmentation   \n",
       " 1  Machine Translation  WMT2015 English-Russian    C2-50k Segmentation   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0  BLEU score          22.8         # 4      -  \n",
       " 1  BLEU score          20.9         # 1      -  ,                           Task                      Dataset  \\\n",
       " 0  Disguised Face Verification  Disguised Faces in the Wild   \n",
       " 1  Disguised Face Verification  Disguised Faces in the Wild   \n",
       " \n",
       "                                                Model    Metric name  \\\n",
       " 0  VGG-Face model features + cosine similarity me...  GAR @0.1% FAR   \n",
       " 1  VGG-Face model features + cosine similarity me...    GAR @1% FAR   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         17.73         # 2      -  \n",
       " 1         33.76         # 2      -  ,                     Task Dataset  \\\n",
       " 0  Face Sketch Synthesis    CUFS   \n",
       " 1  Face Sketch Synthesis    CUFS   \n",
       " 2  Face Sketch Synthesis   CUFSF   \n",
       " 3  Face Sketch Synthesis   CUFSF   \n",
       " 4  Face Sketch Synthesis    CUHK   \n",
       " 5  Face Sketch Synthesis    CUHK   \n",
       " \n",
       "                                                Model Metric name Metric value  \\\n",
       " 0  Residual net + Pseudo Sketch Feature Loss + LSGAN        FSIM       72.56%   \n",
       " 1  Residual net + Pseudo Sketch Feature Loss + LSGAN        SSIM       54.63%   \n",
       " 2  Residual net + Pseudo Sketch Feature Loss + LSGAN        FSIM       71.59%   \n",
       " 3  Residual net + Pseudo Sketch Feature Loss + LSGAN        SSIM       40.85%   \n",
       " 4  Residual net + Pseudo Sketch Feature Loss + LSGAN        SSIM       63.28%   \n",
       " 5  Residual net + Pseudo Sketch Feature Loss + LSGAN        FSIM       74.23%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 1      -  \n",
       " 2         # 1      -  \n",
       " 3         # 1      -  \n",
       " 4         # 1      -  \n",
       " 5         # 1      -  ,                  Task                 Dataset                           Model  \\\n",
       " 0  Speech Recognition  LibriSpeech test-other  tdnn + chain + rnnlm rescoring   \n",
       " \n",
       "              Metric name  Metric value Global rank Remove  \n",
       " 0  Word Error Rate (WER)          7.63         # 2      -  ,                                      Task       Dataset   Model  \\\n",
       " 0  Depiction Invariant Object Recognition  Photo-Art-50  SwiDeN   \n",
       " \n",
       "         Metric name Metric value Global rank Remove  \n",
       " 0  Overall Accuracy       93.02%         # 1      -  ,                        Task      Dataset Model Metric name  Metric value  \\\n",
       " 0  3D Object Reconstruction  Data3D−R2N2   MVD      Avg F1         66.39   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  ,                   Task                   Dataset                   Model  \\\n",
       " 0  Machine Translation  IWSLT2015 German-English  Word-level LSTM w/attn   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0  BLEU score          20.2        # 15      -  ,               Task     Dataset      Model Metric name  Metric value  \\\n",
       " 0  Text Generation  LDC2016E25  Graph2Seq        BLEU            22   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  ,                  Task                          Dataset            Model  \\\n",
       " 0  Language Modelling                          enwiki8  Large FS-LSTM-4   \n",
       " 1  Language Modelling                          enwiki8  Large FS-LSTM-4   \n",
       " 2  Language Modelling                     Hutter Prize  Large FS-LSTM-4   \n",
       " 3  Language Modelling                     Hutter Prize  Large FS-LSTM-4   \n",
       " 4  Language Modelling                     Hutter Prize        FS-LSTM-4   \n",
       " 5  Language Modelling                     Hutter Prize        FS-LSTM-4   \n",
       " 6  Language Modelling  Penn Treebank (Character Level)        FS-LSTM-4   \n",
       " 7  Language Modelling  Penn Treebank (Character Level)        FS-LSTM-4   \n",
       " 8  Language Modelling  Penn Treebank (Character Level)        FS-LSTM-2   \n",
       " 9  Language Modelling  Penn Treebank (Character Level)        FS-LSTM-2   \n",
       " \n",
       "                Metric name Metric value Global rank Remove  \n",
       " 0  Bit per Character (BPC)         1.25         # 8      -  \n",
       " 1         Number of params          47M         # 1      -  \n",
       " 2  Bit per Character (BPC)        1.245         # 8      -  \n",
       " 3         Number of params          47M         # 1      -  \n",
       " 4  Bit per Character (BPC)        1.277        # 10      -  \n",
       " 5         Number of params          27M         # 1      -  \n",
       " 6  Bit per Character (BPC)        1.190         # 5      -  \n",
       " 7         Number of params          27M         # 1      -  \n",
       " 8  Bit per Character (BPC)        1.193         # 6      -  \n",
       " 9         Number of params          27M         # 1      -  ,                      Task                      Dataset  \\\n",
       " 0  Emotion Classification       SemEval 2018 Task 1E-c   \n",
       " 1      Sentiment Analysis  SST-2 Binary classification   \n",
       " \n",
       "                     Model Metric name  Metric value Global rank Remove  \n",
       " 0  Transformer (finetune)    Macro-F1          56.1         # 1      -  \n",
       " 1  Transformer (finetune)    Accuracy          90.9         # 7      -  ,                              Task               Dataset        Model  \\\n",
       " 0  Named Entity Recognition (NER)  CoNLL 2003 (English)  LM-LSTM-CRF   \n",
       " 1          Part-Of-Speech Tagging         Penn Treebank  LM-LSTM-CRF   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0          F1         91.24        # 16      -  \n",
       " 1    Accuracy         97.53         # 6      -  ,                  Task Dataset Model      Metric name Metric value Global rank  \\\n",
       " 0  Question Answering    bAbi    RR  Mean Error Rate        0.46%         # 2   \n",
       " \n",
       "   Remove  \n",
       " 0      -  ,                  Task   Dataset                  Model Metric name  \\\n",
       " 0  Question Answering  TriviaQA  Reading Twice for NLU          EM   \n",
       " 1  Question Answering  TriviaQA  Reading Twice for NLU          F1   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         50.56         # 3      -  \n",
       " 1         56.73         # 3      -  ,                               Task          Dataset  \\\n",
       " 0  Real-Time Semantic Segmentation       Cityscapes   \n",
       " 1  Real-Time Semantic Segmentation       Cityscapes   \n",
       " 2  Real-Time Semantic Segmentation       Cityscapes   \n",
       " 3            Semantic Segmentation       Cityscapes   \n",
       " 4            Semantic Segmentation  PASCAL VOC 2012   \n",
       " \n",
       "                          Model  Metric name Metric value Global rank Remove  \n",
       " 0        ENet + Lovász-Softmax         mIoU        63.1%         # 8      -  \n",
       " 1        ENet + Lovász-Softmax    Time (ms)           13         # 1      -  \n",
       " 2        ENet + Lovász-Softmax  Frame (fps)         76.9         # 1      -  \n",
       " 3        ENet + Lovász-Softmax     Mean IoU       63.06%        # 16      -  \n",
       " 4  Deeplab-v2 + Lovász-Softmax     Mean IoU        79.0%        # 11      -  ,                        Task                     Dataset  \\\n",
       " 0  Traffic Sign Recognition  Bosch Small Traffic Lights   \n",
       " 1  Traffic Sign Recognition  Bosch Small Traffic Lights   \n",
       " 2  Traffic Sign Recognition  Bosch Small Traffic Lights   \n",
       " 3  Traffic Sign Recognition       Tsinghua-Tencent 100K   \n",
       " 4  Traffic Sign Recognition       Tsinghua-Tencent 100K   \n",
       " 5  Traffic Sign Recognition       Tsinghua-Tencent 100K   \n",
       " \n",
       "                                        Model Metric name  Metric value  \\\n",
       " 0                 Background Threshold Model         MAP          0.41   \n",
       " 1                         Hierarchical Model         MAP          0.45   \n",
       " 2  Hierarchical + Background Threshold Model         MAP          0.46   \n",
       " 3  Hierarchical + Background Threshold Model         MAP          0.31   \n",
       " 4                 Background Threshold Model         MAP          0.32   \n",
       " 5                         Hierarchical Model         MAP          0.30   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 3      -  \n",
       " 1         # 2      -  \n",
       " 2         # 1      -  \n",
       " 3         # 2      -  \n",
       " 4         # 1      -  \n",
       " 5         # 3      -  ,                  Task                     Dataset  \\\n",
       " 0  Language Modelling  Penn Treebank (Word Level)   \n",
       " 1  Language Modelling  Penn Treebank (Word Level)   \n",
       " 2  Language Modelling  Penn Treebank (Word Level)   \n",
       " 3  Language Modelling                  WikiText-2   \n",
       " 4  Language Modelling                  WikiText-2   \n",
       " 5  Language Modelling                  WikiText-2   \n",
       " \n",
       "                             Model            Metric name Metric value  \\\n",
       " 0  AWD-LSTM-DOC + Partial Shuffle  Validation perplexity        53.79   \n",
       " 1  AWD-LSTM-DOC + Partial Shuffle        Test perplexity         52.0   \n",
       " 2  AWD-LSTM-DOC + Partial Shuffle                 Params          23M   \n",
       " 3  AWD-LSTM-DOC + Partial Shuffle  Validation perplexity        60.16   \n",
       " 4  AWD-LSTM-DOC + Partial Shuffle        Test perplexity        57.85   \n",
       " 5  AWD-LSTM-DOC + Partial Shuffle       Number of params          37M   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 6      -  \n",
       " 1         # 7      -  \n",
       " 2         # 1      -  \n",
       " 3         # 7      -  \n",
       " 4         # 8      -  \n",
       " 5         # 1      -  ,                         Task Dataset                         Model  \\\n",
       " 0  Chinese Word Segmentation    MSRA  Pre-trained+bigram+ LSTM+CRF   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0          F1          97.4         # 1      -  ,               Task             Dataset                                 Model  \\\n",
       " 0  Pose Estimation  Leeds Sports Poses  Stacked hourglass + Inception-resnet   \n",
       " 1  Pose Estimation     MPII Human Pose  Stacked hourglass + Inception-resnet   \n",
       " \n",
       "   Metric name Metric value Global rank Remove  \n",
       " 0         PCK        93.9%         # 1      -  \n",
       " 1    PCKh-0.5        91.2%         # 4      -  ,                   Task                           Dataset Model Metric name  \\\n",
       " 0  Text Classification                           AG News  DRNN       Error   \n",
       " 1   Sentiment Analysis                Amazon Review Full  DRNN    Accuracy   \n",
       " 2   Sentiment Analysis            Amazon Review Polarity  DRNN    Accuracy   \n",
       " 3  Text Classification                           DBpedia  DRNN       Error   \n",
       " 4  Text Classification                    Yahoo! Answers  DRNN    Accuracy   \n",
       " 5   Sentiment Analysis        Yelp Binary classification  DRNN       Error   \n",
       " 6   Sentiment Analysis  Yelp Fine-grained classification  DRNN       Error   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          5.53         # 3      -  \n",
       " 1         64.43         # 3      -  \n",
       " 2         96.49         # 4      -  \n",
       " 3          0.81         # 4      -  \n",
       " 4         76.26         # 1      -  \n",
       " 5          2.73         # 5      -  \n",
       " 6         30.85         # 4      -  ,                        Task               Dataset        Model  \\\n",
       " 0   Collaborative Filtering  Million Song Dataset  Mult-VAE PR   \n",
       " 1   Collaborative Filtering  Million Song Dataset  Mult-VAE PR   \n",
       " 2   Collaborative Filtering  Million Song Dataset     Mult-DAE   \n",
       " 3   Collaborative Filtering  Million Song Dataset     Mult-DAE   \n",
       " 4   Collaborative Filtering         MovieLens 20M  Mult-VAE PR   \n",
       " 5   Collaborative Filtering         MovieLens 20M  Mult-VAE PR   \n",
       " 6   Collaborative Filtering         MovieLens 20M     Mult-DAE   \n",
       " 7   Collaborative Filtering         MovieLens 20M     Mult-DAE   \n",
       " 8   Collaborative Filtering               Netflix  Mult-VAE PR   \n",
       " 9   Collaborative Filtering               Netflix  Mult-VAE PR   \n",
       " 10  Collaborative Filtering               Netflix     Mult-DAE   \n",
       " 11  Collaborative Filtering               Netflix     Mult-DAE   \n",
       " \n",
       "           Metric name  Metric value Global rank Remove  \n",
       " 0   [email protected]         0.266         # 1      -  \n",
       " 1   [email protected]         0.364         # 1      -  \n",
       " 2   [email protected]         0.266         # 1      -  \n",
       " 3   [email protected]         0.363         # 2      -  \n",
       " 4   [email protected]         0.395         # 1      -  \n",
       " 5   [email protected]         0.537         # 1      -  \n",
       " 6   [email protected]         0.387         # 2      -  \n",
       " 7   [email protected]         0.524         # 2      -  \n",
       " 8   [email protected]         0.351         # 1      -  \n",
       " 9   [email protected]         0.444         # 1      -  \n",
       " 10  [email protected]         0.344         # 2      -  \n",
       " 11  [email protected]         0.438         # 2      -  ,                   Task                    Dataset  \\\n",
       " 0    Face Verification  Labeled Faces in the Wild   \n",
       " 1    Face Verification                   MegaFace   \n",
       " 2    Face Verification                   MegaFace   \n",
       " 3  Face Identification                   MegaFace   \n",
       " 4  Face Identification                   MegaFace   \n",
       " 5    Face Verification           YouTube Faces DB   \n",
       " \n",
       "                            Model Metric name Metric value Global rank Remove  \n",
       " 0                     SphereFace    Accuracy       99.42%         # 6      -  \n",
       " 1      SphereFace (single model)    Accuracy      85.561%         # 5      -  \n",
       " 2  SphereFace (3-patch ensemble)    Accuracy      89.142%         # 3      -  \n",
       " 3      SphereFace (single model)    Accuracy      72.729%         # 5      -  \n",
       " 4  SphereFace (3-patch ensemble)    Accuracy      75.766%         # 3      -  \n",
       " 5                     SphereFace    Accuracy        95.0%         # 8      -  ,                  Task                          Dataset  \\\n",
       " 0  Language Modelling  Penn Treebank (Character Level)   \n",
       " 1  Language Modelling  Penn Treebank (Character Level)   \n",
       " 2  Language Modelling       Penn Treebank (Word Level)   \n",
       " 3  Language Modelling       Penn Treebank (Word Level)   \n",
       " 4  Language Modelling       Penn Treebank (Word Level)   \n",
       " 5  Language Modelling                       WikiText-2   \n",
       " 6  Language Modelling                       WikiText-2   \n",
       " 7  Language Modelling                       WikiText-2   \n",
       " \n",
       "                                           Model              Metric name  \\\n",
       " 0  Past Decode Reg. + AWD-LSTM-MoS + dyn. eval.  Bit per Character (BPC)   \n",
       " 1  Past Decode Reg. + AWD-LSTM-MoS + dyn. eval.         Number of params   \n",
       " 2  Past Decode Reg. + AWD-LSTM-MoS + dyn. eval.    Validation perplexity   \n",
       " 3  Past Decode Reg. + AWD-LSTM-MoS + dyn. eval.          Test perplexity   \n",
       " 4  Past Decode Reg. + AWD-LSTM-MoS + dyn. eval.                   Params   \n",
       " 5  Past Decode Reg. + AWD-LSTM-MoS + dyn. eval.    Validation perplexity   \n",
       " 6  Past Decode Reg. + AWD-LSTM-MoS + dyn. eval.          Test perplexity   \n",
       " 7  Past Decode Reg. + AWD-LSTM-MoS + dyn. eval.         Number of params   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        1.169         # 2      -  \n",
       " 1        13.8M         # 1      -  \n",
       " 2         48.0         # 2      -  \n",
       " 3         47.3         # 4      -  \n",
       " 4          22M         # 1      -  \n",
       " 5         42.0         # 2      -  \n",
       " 6         40.3         # 3      -  \n",
       " 7          35M         # 1      -  ,                  Task   Dataset                                      Model  \\\n",
       " 0  Question Answering  SQuAD1.1  Multi-Perspective Matching (single model)   \n",
       " 1  Question Answering  SQuAD1.1  Multi-Perspective Matching (single model)   \n",
       " 2  Question Answering  SQuAD1.1      Multi-Perspective Matching (ensemble)   \n",
       " 3  Question Answering  SQuAD1.1      Multi-Perspective Matching (ensemble)   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0          EM        70.387       # 110      -  \n",
       " 1          F1        78.784       # 111      -  \n",
       " 2          EM        73.765        # 82      -  \n",
       " 3          F1        81.257        # 90      -  ,                  Task   Dataset                Model Metric name  \\\n",
       " 0  Question Answering  SQuAD1.1  Fine-Grained Gating          EM   \n",
       " 1  Question Answering  SQuAD1.1  Fine-Grained Gating          F1   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0        62.446       # 132      -  \n",
       " 1        73.327       # 130      -  ,                         Task  \\\n",
       " 0  Visual Question Answering   \n",
       " 1  Visual Question Answering   \n",
       " \n",
       "                                              Dataset                  Model  \\\n",
       " 0  COCO Visual Question Answering (VQA) real imag...                    MRN   \n",
       " 1  COCO Visual Question Answering (VQA) real imag...  MRN + global features   \n",
       " \n",
       "           Metric name  Metric value Global rank Remove  \n",
       " 0  Percentage correct         66.33         # 3      -  \n",
       " 1  Percentage correct         61.84         # 5      -  ,                Task      Dataset     Model Metric name  Metric value  \\\n",
       " 0  Image Generation  CAT 256x256    RaSGAN         FID         32.11   \n",
       " 1  Image Generation     CIFAR-10  RSGAN-GP         FID         25.60   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 5      -  ,                               Task                         Dataset      Model  \\\n",
       " 0  Aspect-Based Sentiment Analysis  SemEval 2014 Task 4 Sub Task 2  PRET+MULT   \n",
       " 1  Aspect-Based Sentiment Analysis  SemEval 2014 Task 4 Sub Task 2  PRET+MULT   \n",
       " \n",
       "         Metric name  Metric value Global rank Remove  \n",
       " 0  Restaurant (Acc)         79.11        # 19      -  \n",
       " 1      Laptop (Acc)         71.15         # 5      -  ,                               Task Dataset   Model Metric name  Metric value  \\\n",
       " 0  Real-time Instance Segmentation  MSCOCO  YOLACT         MAP          29.8   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  ,                          Task Dataset                 Model       Metric name  \\\n",
       " 0  Natural Language Inference    SNLI  50D stacked TC-LSTMs   % Test Accuracy   \n",
       " 1  Natural Language Inference    SNLI  50D stacked TC-LSTMs  % Train Accuracy   \n",
       " 2  Natural Language Inference    SNLI  50D stacked TC-LSTMs        Parameters   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0         85.1        # 34      -  \n",
       " 1         86.7        # 42      -  \n",
       " 2         190k         # 1      -  ,                              Task               Dataset  \\\n",
       " 0              Question Answering  Children's Book Test   \n",
       " 1              Question Answering  Children's Book Test   \n",
       " 2              Question Answering  Children's Book Test   \n",
       " 3              Question Answering  Children's Book Test   \n",
       " 4              Question Answering  Children's Book Test   \n",
       " 5              Question Answering  Children's Book Test   \n",
       " 6              Question Answering      CNN / Daily Mail   \n",
       " 7              Question Answering      CNN / Daily Mail   \n",
       " 8  Open-Domain Question Answering                Quasar   \n",
       " 9  Open-Domain Question Answering                Quasar   \n",
       " \n",
       "                      Model    Metric name Metric value Global rank Remove  \n",
       " 0                      NSE    Accuracy-CN        71.9%         # 2      -  \n",
       " 1                      NSE    Accuracy-NE        73.2%         # 3      -  \n",
       " 2  GA + feature + fix L(w)    Accuracy-CN        70.7%         # 3      -  \n",
       " 3  GA + feature + fix L(w)    Accuracy-NE        74.9%         # 2      -  \n",
       " 4                GA reader    Accuracy-CN        69.4%         # 4      -  \n",
       " 5                GA reader    Accuracy-NE        71.9%         # 5      -  \n",
       " 6                GA Reader            CNN         77.9         # 2      -  \n",
       " 7                GA Reader     Daily Mail         80.9         # 1      -  \n",
       " 8                       GA  EM (Quasar-T)         26.4         # 4      -  \n",
       " 9                       GA  F1 (Quasar-T)         26.4         # 5      -  ,           Task      Dataset               Model  Metric name Metric value  \\\n",
       " 0  Amr Parsing  LDC2014T12:  Imitation learning  F1 Newswire         0.70   \n",
       " 1  Amr Parsing  LDC2014T12:  Imitation learning      F1 Full           --   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 3      -  \n",
       " 1         # 3      -  ,                               Task    Dataset           Model Metric name  \\\n",
       " 0  Aspect-Based Sentiment Analysis  Sentihood  BERT-pair-QA-B      Aspect   \n",
       " 1  Aspect-Based Sentiment Analysis  Sentihood  BERT-pair-QA-B   Sentiment   \n",
       " 2  Aspect-Based Sentiment Analysis  Sentihood  BERT-pair-QA-M      Aspect   \n",
       " 3  Aspect-Based Sentiment Analysis  Sentihood  BERT-pair-QA-M   Sentiment   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          87.9         # 1      -  \n",
       " 1          93.3         # 2      -  \n",
       " 2          86.4         # 2      -  \n",
       " 3          93.6         # 1      -  ,                  Task          Dataset  Model Metric name  Metric value  \\\n",
       " 0  Text Summarization  DUC 2004 Task 1  SEASS     ROUGE-1         29.21   \n",
       " 1  Text Summarization  DUC 2004 Task 1  SEASS     ROUGE-2          9.56   \n",
       " 2  Text Summarization  DUC 2004 Task 1  SEASS     ROUGE-L         25.51   \n",
       " 3  Text Summarization         GigaWord  SEASS     ROUGE-1         36.15   \n",
       " 4  Text Summarization         GigaWord  SEASS     ROUGE-2         17.54   \n",
       " 5  Text Summarization         GigaWord  SEASS     ROUGE-L         33.63   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 5      -  \n",
       " 1         # 5      -  \n",
       " 2         # 4      -  \n",
       " 3         # 6      -  \n",
       " 4         # 8      -  \n",
       " 5         # 7      -  ,               Task        Dataset   Model Metric name  Metric value  \\\n",
       " 0  Text Generation  Chinese Poems  SeqGAN      BLEU-2        0.7380   \n",
       " 1  Text Generation  COCO Captions  SeqGAN      BLEU-2        0.8310   \n",
       " 2  Text Generation  COCO Captions  SeqGAN      BLEU-3        0.6420   \n",
       " 3  Text Generation  COCO Captions  SeqGAN      BLEU-4        0.5210   \n",
       " 4  Text Generation  COCO Captions  SeqGAN      BLEU-5        0.4270   \n",
       " 5  Text Generation  EMNLP2017 WMT  SeqGAN      BLEU-2        0.8590   \n",
       " 6  Text Generation  EMNLP2017 WMT  SeqGAN      BLEU-3        0.6015   \n",
       " 7  Text Generation  EMNLP2017 WMT  SeqGAN      BLEU-4        0.4541   \n",
       " 8  Text Generation  EMNLP2017 WMT  SeqGAN      BLEU-5        0.4498   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 3      -  \n",
       " 1         # 3      -  \n",
       " 2         # 3      -  \n",
       " 3         # 3      -  \n",
       " 4         # 3      -  \n",
       " 5         # 2      -  \n",
       " 6         # 2      -  \n",
       " 7         # 2      -  \n",
       " 8         # 3      -  ,                        Task    Dataset                                Model  \\\n",
       " 0  3D Human Pose Estimation  Human3.6M  Weakly Supervised Transfer Learning   \n",
       " \n",
       "         Metric name  Metric value Global rank Remove  \n",
       " 0  Average 3D Error          64.9         # 4      -  ,                   Task         Dataset                 Model Metric name  \\\n",
       " 0  Text Classification         AG News  Seq2CNN with GWS(50)       Error   \n",
       " 1  Text Classification         DBpedia           Seq2CNN(50)       Error   \n",
       " 2  Text Classification  Yahoo! Answers           Seq2CNN(50)    Accuracy   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          9.64        # 16      -  \n",
       " 1          2.77        # 17      -  \n",
       " 2         55.39         # 6      -  ,                         Task  \\\n",
       " 0  Visual Question Answering   \n",
       " \n",
       "                                              Dataset Model  \\\n",
       " 0  COCO Visual Question Answering (VQA) real imag...   SAN   \n",
       " \n",
       "           Metric name  Metric value Global rank Remove  \n",
       " 0  Percentage correct          58.9         # 7      -  ,                          Task               Dataset  \\\n",
       " 0   Word Sense Disambiguation  SemEval 2007 Task 17   \n",
       " 1   Word Sense Disambiguation   SemEval 2007 Task 7   \n",
       " 2   Word Sense Disambiguation  SemEval 2013 Task 12   \n",
       " 3   Word Sense Disambiguation  SemEval 2015 Task 13   \n",
       " 4   Word Sense Disambiguation            SensEval 2   \n",
       " 5   Word Sense Disambiguation     SensEval 3 Task 1   \n",
       " 6   Word Sense Disambiguation           Supervised:   \n",
       " 7   Word Sense Disambiguation           Supervised:   \n",
       " 8   Word Sense Disambiguation           Supervised:   \n",
       " 9   Word Sense Disambiguation           Supervised:   \n",
       " 10  Word Sense Disambiguation           Supervised:   \n",
       " \n",
       "                                         Model   Metric name  Metric value  \\\n",
       " 0   SemCor+WNGT, vocabulary reduced, ensemble            F1         66.81   \n",
       " 1   SemCor+WNGT, vocabulary reduced, ensemble            F1         86.02   \n",
       " 2   SemCor+WNGT, vocabulary reduced, ensemble            F1         72.63   \n",
       " 3   SemCor+WNGT, vocabulary reduced, ensemble            F1         74.46   \n",
       " 4   SemCor+WNGT, vocabulary reduced, ensemble            F1         75.15   \n",
       " 5   SemCor+WNGT, vocabulary reduced, ensemble            F1         70.11   \n",
       " 6   SemCor+WNGT, vocabulary reduced, ensemble    Senseval 2         75.15   \n",
       " 7   SemCor+WNGT, vocabulary reduced, ensemble    Senseval 3         70.11   \n",
       " 8   SemCor+WNGT, vocabulary reduced, ensemble  SemEval 2007         66.81   \n",
       " 9   SemCor+WNGT, vocabulary reduced, ensemble  SemEval 2013         72.63   \n",
       " 10  SemCor+WNGT, vocabulary reduced, ensemble  SemEval 2015         74.46   \n",
       " \n",
       "    Global rank Remove  \n",
       " 0          # 1      -  \n",
       " 1          # 1      -  \n",
       " 2          # 1      -  \n",
       " 3          # 1      -  \n",
       " 4          # 1      -  \n",
       " 5          # 6      -  \n",
       " 6         # 10      -  \n",
       " 7          # 8      -  \n",
       " 8          # 6      -  \n",
       " 9         # 12      -  \n",
       " 10        # 11      -  ,                    Task    Dataset    Model         Metric name  Metric value  \\\n",
       " 0  Image Classification   CIFAR-10  NiN+APL  Percentage correct          92.5   \n",
       " 1  Image Classification  CIFAR-100  NiN+APL  Percentage correct          69.2   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 29      -  \n",
       " 1        # 24      -  ,              Task                   Dataset   Model Metric name  Metric value  \\\n",
       " 0  Lane Detection     Caltech Lanes Cordova  VPGNet          F1         0.884   \n",
       " 1  Lane Detection  Caltech Lanes Washington  VPGNet          F1         0.869   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 1      -  ,                    Task   Dataset    Model     Metric name Metric value  \\\n",
       " 0  Image Classification  ImageNet  PolyNet  Top 1 Accuracy        81.3%   \n",
       " 1  Image Classification  ImageNet  PolyNet  Top 5 Accuracy        95.8%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 6      -  \n",
       " 1         # 4      -  ,                  Task Dataset Model                Metric name Metric value  \\\n",
       " 0  Question Answering    bAbi  DMN+  Accuracy (trained on 10k)        97.2%   \n",
       " 1  Question Answering    bAbi  DMN+   Accuracy (trained on 1k)        66.8%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 3      -  \n",
       " 1         # 5      -  ,                                  Task Dataset              Model Metric name  \\\n",
       " 0  Weakly Supervised Object Detection    COCO  Deep Feature Maps         MAP   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          47.9         # 3      -  ,                                  Task Dataset   Model Metric name  \\\n",
       " 0  Weakly Supervised Object Detection    COCO  ProNet         MAP   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          43.5         # 4      -  ,                   Task   Dataset    Model Metric name Metric value  \\\n",
       " 0  Node Classification  Citeseer  ChebNet    Accuracy        69.8%   \n",
       " 1  Node Classification      Cora  ChebNet    Accuracy        81.2%   \n",
       " 2  Node Classification    Pubmed  ChebNet    Accuracy        74.4%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 6      -  \n",
       " 1         # 5      -  \n",
       " 2         # 7      -  ,                  Task          Dataset      Model Metric name  Metric value  \\\n",
       " 0  Text Summarization  DUC 2004 Task 1  RAS-Elman     ROUGE-1         28.97   \n",
       " 1  Text Summarization  DUC 2004 Task 1  RAS-Elman     ROUGE-2          8.26   \n",
       " 2  Text Summarization  DUC 2004 Task 1  RAS-Elman     ROUGE-L         24.06   \n",
       " 3  Text Summarization         GigaWord  RAS-Elman     ROUGE-1         33.78   \n",
       " 4  Text Summarization         GigaWord  RAS-Elman     ROUGE-2         15.97   \n",
       " 5  Text Summarization         GigaWord  RAS-Elman     ROUGE-L         31.15   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 6      -  \n",
       " 1         # 8      -  \n",
       " 2         # 6      -  \n",
       " 3        # 10      -  \n",
       " 4        # 12      -  \n",
       " 5        # 11      -  ,                     Task                      Dataset       Model Metric name  \\\n",
       " 0     Sentiment Analysis  SST-2 Binary classification      bmLSTM    Accuracy   \n",
       " 1  Subjectivity Analysis                         SUBJ  Byte mLSTM    Accuracy   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          91.8         # 4      -  \n",
       " 1          94.6         # 3      -  ,                Task          Dataset          Model      Metric name  \\\n",
       " 0  Object Detection             COCO  RefineDet512+  Bounding Box AP   \n",
       " 1  Object Detection  PASCAL VOC 2007  RefineDet512+              MAP   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0         41.8        # 19      -  \n",
       " 1        83.8%         # 2      -  ,                                          Task         Dataset       Model  \\\n",
       " 0  3D Room Layouts From A Single Rgb Panorama     PanoContext  HorizonNet   \n",
       " 1  3D Room Layouts From A Single Rgb Panorama  Stanford 2D-3D  HorizonNet   \n",
       " \n",
       "   Metric name Metric value Global rank Remove  \n",
       " 0       3DIoU       82.17%         # 1      -  \n",
       " 1       3DIoU       79.79%         # 1      -  ,                    Task        Dataset                 Model Metric name  \\\n",
       " 0  Constituency Parsing  Penn Treebank  Semi-supervised LSTM    F1 score   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          92.1        # 10      -  ,                       Task        Dataset      Model Metric name  \\\n",
       " 0  Collaborative Filtering  MovieLens 10M  I-AutoRec        RMSE   \n",
       " 1  Collaborative Filtering   MovieLens 1M  I-AutoRec        RMSE   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         0.782         # 5      -  \n",
       " 1         0.831         # 3      -  ,                  Task           Dataset  \\\n",
       " 0  Question Answering  Story Cloze Test   \n",
       " \n",
       "                                     Model Metric name  Metric value  \\\n",
       " 0  Memory chains and semantic supervision    Accuracy          78.7   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  ,                    Task               Dataset                  Model  \\\n",
       " 0  Query Wellformedness  Query Wellformedness  word-1, 2 POS-1, 2, 3   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0    Accuracy          70.7         # 1      -  , Empty DataFrame\n",
       " Columns: [Task, Dataset, Model, Metric name, Metric value, Global rank, Remove]\n",
       " Index: [],                          Task  Dataset Model Metric name  Metric value  \\\n",
       " 0  Surgical Skills Evaluation  JIGSAWS   CNN    Accuracy          0.98   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  ,                    Task    Dataset Model         Metric name  Metric value  \\\n",
       " 0  Image Classification   CIFAR-10   MIM  Percentage correct         91.50   \n",
       " 1  Image Classification  CIFAR-100   MIM  Percentage correct         70.80   \n",
       " 2  Image Classification      MNIST   MIM    Percentage error          0.40   \n",
       " 3  Image Classification       SVHN   MIM    Percentage error          1.97   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 35      -  \n",
       " 1        # 23      -  \n",
       " 2         # 4      -  \n",
       " 3        # 13      -  ,                Task Dataset               Model      Metric name  \\\n",
       " 0  Object Detection    COCO  Faster R-CNN + FPN  Bounding Box AP   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          36.2        # 29      -  ,                         Task     Dataset   Model Metric name  Metric value  \\\n",
       " 0  Facial Landmark Detection        300W  SAN GT         NME          3.98   \n",
       " 1  Facial Landmark Detection  AFLW-Front     SAN    Mean NME          1.85   \n",
       " 2  Facial Landmark Detection   AFLW-Full     SAN    Mean NME          1.91   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 1      -  \n",
       " 2         # 1      -  ,                                 Task Dataset   Model Metric name  \\\n",
       " 0                 Unsupervised MNIST   MNIST  CatGAN    Accuracy   \n",
       " 1  Unsupervised image classification   MNIST  CatGAN    Accuracy   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         95.73         # 4      -  \n",
       " 1         95.73         # 4      -  ,                                  Task          Dataset   Model Metric name  \\\n",
       " 0  Weakly Supervised Object Detection  PASCAL VOC 2007  ZLDN-L         MAP   \n",
       " 1  Weakly Supervised Object Detection  PASCAL VOC 2012  ZLDN-L         MAP   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          47.6         # 5      -  \n",
       " 1          42.9         # 4      -  ,                  Task    Dataset    Model Metric name  Metric value  \\\n",
       " 0  Keypoint Detection  Pascal3D+  StarMap    Mean PCK          78.6   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  ,                     Task Dataset                    Model Metric name  \\\n",
       " 0  Trajectory Prediction     GPS  Support Vector Machines    Accuracy   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0          88%         # 1      -  ,                    Task                     Dataset     Model Metric name  \\\n",
       " 0   3D Object Detection             KITTI Cars Easy  VoxelNet          AP   \n",
       " 1   Object Localization             KITTI Cars Easy  VoxelNet          AP   \n",
       " 2   Object Localization             KITTI Cars Hard  VoxelNet          AP   \n",
       " 3   3D Object Detection             KITTI Cars Hard  VoxelNet          AP   \n",
       " 4   3D Object Detection         KITTI Cars Moderate  VoxelNet          AP   \n",
       " 5   Object Localization         KITTI Cars Moderate  VoxelNet          AP   \n",
       " 6   3D Object Detection         KITTI Cyclists Easy  VoxelNet          AP   \n",
       " 7   Object Localization         KITTI Cyclists Easy  VoxelNet          AP   \n",
       " 8   3D Object Detection         KITTI Cyclists Hard  VoxelNet          AP   \n",
       " 9   Object Localization         KITTI Cyclists Hard   VoxelNe          AP   \n",
       " 10  3D Object Detection     KITTI Cyclists Moderate  VoxelNet          AP   \n",
       " 11  Object Localization     KITTI Cyclists Moderate  VoxelNet          AP   \n",
       " 12  Object Localization      KITTI Pedestrians Easy  VoxelNet          AP   \n",
       " 13  3D Object Detection      KITTI Pedestrians Easy  VoxelNet          AP   \n",
       " 14  Object Localization      KITTI Pedestrians Hard  VoxelNet          AP   \n",
       " 15  3D Object Detection      KITTI Pedestrians Hard  VoxelNet          AP   \n",
       " 16  Object Localization  KITTI Pedestrians Moderate  VoxelNet          AP   \n",
       " 17  3D Object Detection  KITTI Pedestrians Moderate  VoxelNet          AP   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0        77.47%         # 7      -  \n",
       " 1        89.35%         # 1      -  \n",
       " 2        77.39%         # 1      -  \n",
       " 3        57.73%         # 7      -  \n",
       " 4        65.11%         # 8      -  \n",
       " 5        79.26%         # 2      -  \n",
       " 6        61.22%         # 4      -  \n",
       " 7        66.70%         # 2      -  \n",
       " 8        44.37%         # 4      -  \n",
       " 9        50.55%         # 2      -  \n",
       " 10       48.36%         # 5      -  \n",
       " 11       54.76%         # 2      -  \n",
       " 12       46.13%         # 2      -  \n",
       " 13       39.48%         # 4      -  \n",
       " 14       38.11%         # 2      -  \n",
       " 15       31.51%         # 4      -  \n",
       " 16       40.74%         # 2      -  \n",
       " 17       33.69%         # 5      -  ,                       Task                                   Dataset  \\\n",
       " 0  Dialogue State Tracking  Second dialogue state tracking challenge   \n",
       " 1  Dialogue State Tracking                              Wizard-of-Oz   \n",
       " \n",
       "       Model Metric name  Metric value Global rank Remove  \n",
       " 0  StateNet       Joint          75.5         # 1      -  \n",
       " 1  StateNet       Joint          88.9         # 1      -  ,                        Task        Dataset  \\\n",
       " 0  Facial Beauty Prediction  ECCV HotOrNot   \n",
       " 1  Facial Beauty Prediction       SCUT-FBP   \n",
       " \n",
       "                                       Model          Metric name  \\\n",
       " 0  CNN features + Bayesian ridge regression  Pearson Correlation   \n",
       " 1  CNN features + Bayesian ridge regression                  MAE   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0        0.4680         # 1      -  \n",
       " 1        0.2595         # 1      -  ,                                     Task       Dataset                Model  \\\n",
       " 0  Volumetric Medical Image Segmentation  PROMISE 2012  Fully-connected CRF   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0  Dice Score          0.78         # 2      -  ,                               Task                         Dataset   Model  \\\n",
       " 0  Aspect-Based Sentiment Analysis  SemEval 2014 Task 4 Sub Task 2  PF-CNN   \n",
       " 1  Aspect-Based Sentiment Analysis  SemEval 2014 Task 4 Sub Task 2  PF-CNN   \n",
       " \n",
       "         Metric name  Metric value Global rank Remove  \n",
       " 0  Restaurant (Acc)         79.20        # 18      -  \n",
       " 1      Laptop (Acc)         70.06         # 4      -  ,                Task   Dataset       Model      Metric name  Metric value  \\\n",
       " 0  Image Generation  CIFAR-10  SN-SMMDGAN  Inception score           7.3   \n",
       " 1  Image Generation  CIFAR-10  SN-SMMDGAN              FID          25.0   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 7      -  \n",
       " 1         # 4      -  ,                     Task     Dataset              Model Metric name  \\\n",
       " 0  3D Object Recognition  ModelNet40  FPNN (4-FCs + NF)    Accuracy   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        88.4%         # 2      -  ,                      Task                  Dataset   Model Metric name  \\\n",
       " 0  Image Super-Resolution    BSD100 - 4x upscaling  LapSRN        PSNR   \n",
       " 1  Image Super-Resolution     Set14 - 4x upscaling   LapSR        PSNR   \n",
       " 2  Image Super-Resolution  Urban100 - 4x upscaling  LapSRN        PSNR   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         27.32        # 18      -  \n",
       " 1         28.19        # 20      -  \n",
       " 2         25.21        # 19      -  ,                   Task   Dataset Model Metric name Metric value Global rank  \\\n",
       " 0  Node Classification  Citeseer   DGI    Accuracy        71.8%         # 3   \n",
       " 1  Node Classification      Cora   DGI    Accuracy        82.3%         # 3   \n",
       " 2  Node Classification    Pubmed   DGI    Accuracy       76.80%         # 6   \n",
       " \n",
       "   Remove  \n",
       " 0      -  \n",
       " 1      -  \n",
       " 2      -  ,                    Task    Dataset  \\\n",
       " 0  Image Classification   CIFAR-10   \n",
       " 1  Image Classification  CIFAR-100   \n",
       " \n",
       "                                                Model         Metric name  \\\n",
       " 0  Spectral Representations for Convolutional Neu...  Percentage correct   \n",
       " 1  Spectral Representations for Convolutional Neu...  Percentage correct   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          91.4        # 36      -  \n",
       " 1          68.4        # 28      -  ,                  Task                      Dataset    Model Metric name  \\\n",
       " 0  Sentiment Analysis  SST-2 Binary classification  DC-MCNN    Accuracy   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         86.99        # 16      -  ,               Task          Dataset                       Model  \\\n",
       " 0  Pose Estimation      FLIC Elbows  Stacked Hourglass Networks   \n",
       " 1  Pose Estimation      FLIC Wrists  Stacked Hourglass Networks   \n",
       " 2  Pose Estimation  MPII Human Pose  Stacked Hourglass Networks   \n",
       " \n",
       "          Metric name Metric value Global rank Remove  \n",
       " 0  [email protected]        99.0%         # 1      -  \n",
       " 1  [email protected]        97.0%         # 1      -  \n",
       " 2           PCKh-0.5        90.9%         # 6      -  ,                  Task                     Dataset                       Model  \\\n",
       " 0  Language Modelling                     enwiki8  Recurrent highway networks   \n",
       " 1  Language Modelling                     enwiki8  Recurrent highway networks   \n",
       " 2  Language Modelling                Hutter Prize                   Large RHN   \n",
       " 3  Language Modelling                Hutter Prize                   Large RHN   \n",
       " 4  Language Modelling  Penn Treebank (Word Level)  Recurrent highway networks   \n",
       " 5  Language Modelling  Penn Treebank (Word Level)  Recurrent highway networks   \n",
       " 6  Language Modelling  Penn Treebank (Word Level)  Recurrent highway networks   \n",
       " 7  Language Modelling                       Text8                   Large RHN   \n",
       " 8  Language Modelling                       Text8                   Large RHN   \n",
       " \n",
       "                Metric name Metric value Global rank Remove  \n",
       " 0  Bit per Character (BPC)         1.27         # 9      -  \n",
       " 1         Number of params          46M         # 1      -  \n",
       " 2  Bit per Character (BPC)         1.27         # 9      -  \n",
       " 3         Number of params          46M         # 1      -  \n",
       " 4    Validation perplexity         67.9        # 17      -  \n",
       " 5          Test perplexity         65.4        # 20      -  \n",
       " 6                   Params          23M         # 1      -  \n",
       " 7  Bit per Character (BPC)         1.27         # 7      -  \n",
       " 8         Number of params          46M         # 1      -  ,                        Task      Dataset Model Metric name  Metric value  \\\n",
       " 0  Person Re-Identification  Market-1501  DLCE      Rank-1          79.5   \n",
       " 1  Person Re-Identification  Market-1501  DLCE         MAP          59.9   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 20      -  \n",
       " 1        # 20      -  ,                  Task                         Dataset Model  Metric name  \\\n",
       " 0  Sentiment Analysis  Multi-Domain Sentiment Dataset  VFAE          DVD   \n",
       " 1  Sentiment Analysis  Multi-Domain Sentiment Dataset  VFAE        Books   \n",
       " 2  Sentiment Analysis  Multi-Domain Sentiment Dataset  VFAE  Electronics   \n",
       " 3  Sentiment Analysis  Multi-Domain Sentiment Dataset  VFAE      Kitchen   \n",
       " 4  Sentiment Analysis  Multi-Domain Sentiment Dataset  VFAE      Average   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         76.57         # 3      -  \n",
       " 1         73.40         # 3      -  \n",
       " 2         80.53         # 2      -  \n",
       " 3         82.93         # 3      -  \n",
       " 4         78.36         # 4      -  ,                               Task     Dataset   Model      Metric name  \\\n",
       " 0            Semantic Segmentation      ADE20K  SegNet  Validation mIoU   \n",
       " 1            Semantic Segmentation      CamVid  SegNet         Mean IoU   \n",
       " 2  Real-Time Semantic Segmentation      CamVid  SegNet             mIoU   \n",
       " 3  Real-Time Semantic Segmentation      CamVid  SegNet        Time (ms)   \n",
       " 4  Real-Time Semantic Segmentation      CamVid  SegNet      Frame (fps)   \n",
       " 5            Semantic Segmentation  Cityscapes  SegNet         Mean IoU   \n",
       " 6  Real-Time Semantic Segmentation  Cityscapes  SegNet             mIoU   \n",
       " 7  Real-Time Semantic Segmentation  Cityscapes  SegNet        Time (ms)   \n",
       " 8  Real-Time Semantic Segmentation  Cityscapes  SegNet      Frame (fps)   \n",
       " 9               Scene Segmentation    SUN-RGBD  SegNet         Mean IoU   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        21.64         # 7      -  \n",
       " 1        46.4%         # 7      -  \n",
       " 2        46.4%         # 6      -  \n",
       " 3          217         # 4      -  \n",
       " 4          4.6         # 4      -  \n",
       " 5        57.0%        # 18      -  \n",
       " 6        57.0%        # 11      -  \n",
       " 7           60         # 3      -  \n",
       " 8         16.7         # 5      -  \n",
       " 9        31.84         # 2      -  ,             Task                   Dataset            Model Metric name  \\\n",
       " 0    Atari Games          Atari 2600 Alien         DQN noop       Score   \n",
       " 1    Atari Games          Atari 2600 Alien           DQN hs       Score   \n",
       " 2    Atari Games          Atari 2600 Alien  DDQN (tuned) hs       Score   \n",
       " 3    Atari Games          Atari 2600 Alien    Prior+Duel hs       Score   \n",
       " 4    Atari Games         Atari 2600 Amidar         DQN noop       Score   \n",
       " 5    Atari Games         Atari 2600 Amidar           DQN hs       Score   \n",
       " 6    Atari Games         Atari 2600 Amidar    Prior+Duel hs       Score   \n",
       " 7    Atari Games         Atari 2600 Amidar  DDQN (tuned) hs       Score   \n",
       " 8    Atari Games        Atari 2600 Assault         DQN noop       Score   \n",
       " 9    Atari Games        Atari 2600 Assault           DQN hs       Score   \n",
       " 10   Atari Games        Atari 2600 Assault    Prior+Duel hs       Score   \n",
       " 11   Atari Games        Atari 2600 Assault  DDQN (tuned) hs       Score   \n",
       " 12   Atari Games        Atari 2600 Asterix         DQN noop       Score   \n",
       " 13   Atari Games        Atari 2600 Asterix           DQN hs       Score   \n",
       " 14   Atari Games        Atari 2600 Asterix    Prior+Duel hs       Score   \n",
       " 15   Atari Games        Atari 2600 Asterix  DDQN (tuned) hs       Score   \n",
       " 16   Atari Games      Atari 2600 Asteroids           DQN hs       Score   \n",
       " 17   Atari Games      Atari 2600 Asteroids         DQN noop       Score   \n",
       " 18   Atari Games      Atari 2600 Asteroids  DDQN (tuned) hs       Score   \n",
       " 19   Atari Games      Atari 2600 Asteroids    Prior+Duel hs       Score   \n",
       " 20   Atari Games       Atari 2600 Atlantis           DQN hs       Score   \n",
       " 21   Atari Games       Atari 2600 Atlantis         DQN noop       Score   \n",
       " 22   Atari Games       Atari 2600 Atlantis    Prior+Duel hs       Score   \n",
       " 23   Atari Games       Atari 2600 Atlantis  DDQN (tuned) hs       Score   \n",
       " 24   Atari Games     Atari 2600 Bank Heist         DQN noop       Score   \n",
       " 25   Atari Games     Atari 2600 Bank Heist           DQN hs       Score   \n",
       " 26   Atari Games     Atari 2600 Bank Heist    Prior+Duel hs       Score   \n",
       " 27   Atari Games     Atari 2600 Bank Heist  DDQN (tuned) hs       Score   \n",
       " 28   Atari Games    Atari 2600 Battle Zone         DQN noop       Score   \n",
       " 29   Atari Games    Atari 2600 Battle Zone           DQN hs       Score   \n",
       " ..           ...                       ...              ...         ...   \n",
       " 170  Atari Games         Atari 2600 Tennis  DDQN (tuned) hs       Score   \n",
       " 171  Atari Games         Atari 2600 Tennis    Prior+Duel hs       Score   \n",
       " 172  Atari Games     Atari 2600 Time Pilot         DQN noop       Score   \n",
       " 173  Atari Games     Atari 2600 Time Pilot           DQN hs       Score   \n",
       " 174  Atari Games     Atari 2600 Time Pilot  DDQN (tuned) hs       Score   \n",
       " 175  Atari Games     Atari 2600 Time Pilot    Prior+Duel hs       Score   \n",
       " 176  Atari Games      Atari 2600 Tutankham         DQN noop       Score   \n",
       " 177  Atari Games      Atari 2600 Tutankham           DQN hs       Score   \n",
       " 178  Atari Games      Atari 2600 Tutankham    Prior+Duel hs       Score   \n",
       " 179  Atari Games      Atari 2600 Tutankham  DDQN (tuned) hs       Score   \n",
       " 180  Atari Games    Atari 2600 Up and Down         DQN noop       Score   \n",
       " 181  Atari Games    Atari 2600 Up and Down           DQN hs       Score   \n",
       " 182  Atari Games    Atari 2600 Up and Down    Prior+Duel hs       Score   \n",
       " 183  Atari Games    Atari 2600 Up and Down  DDQN (tuned) hs       Score   \n",
       " 184  Atari Games        Atari 2600 Venture         DQN noop       Score   \n",
       " 185  Atari Games        Atari 2600 Venture           DQN hs       Score   \n",
       " 186  Atari Games        Atari 2600 Venture    Prior+Duel hs       Score   \n",
       " 187  Atari Games        Atari 2600 Venture  DDQN (tuned) hs       Score   \n",
       " 188  Atari Games  Atari 2600 Video Pinball         DQN noop       Score   \n",
       " 189  Atari Games  Atari 2600 Video Pinball           DQN hs       Score   \n",
       " 190  Atari Games  Atari 2600 Video Pinball    Prior+Duel hs       Score   \n",
       " 191  Atari Games  Atari 2600 Video Pinball  DDQN (tuned) hs       Score   \n",
       " 192  Atari Games  Atari 2600 Wizard of Wor         DQN noop       Score   \n",
       " 193  Atari Games  Atari 2600 Wizard of Wor           DQN hs       Score   \n",
       " 194  Atari Games  Atari 2600 Wizard of Wor    Prior+Duel hs       Score   \n",
       " 195  Atari Games  Atari 2600 Wizard of Wor  DDQN (tuned) hs       Score   \n",
       " 196  Atari Games         Atari 2600 Zaxxon         DQN noop       Score   \n",
       " 197  Atari Games         Atari 2600 Zaxxon           DQN hs       Score   \n",
       " 198  Atari Games         Atari 2600 Zaxxon    Prior+Duel hs       Score   \n",
       " 199  Atari Games         Atari 2600 Zaxxon  DDQN (tuned) hs       Score   \n",
       " \n",
       "      Metric value Global rank Remove  \n",
       " 0          1620.0        # 10      -  \n",
       " 1           634.0        # 19      -  \n",
       " 2          1033.4        # 13      -  \n",
       " 3           823.7        # 17      -  \n",
       " 4           978.0         # 8      -  \n",
       " 5           178.4        # 16      -  \n",
       " 6           238.4        # 13      -  \n",
       " 7           169.1        # 19      -  \n",
       " 8          4280.4        # 14      -  \n",
       " 9          3489.3        # 17      -  \n",
       " 10        10950.6         # 4      -  \n",
       " 11         6060.8        # 10      -  \n",
       " 12         4359.0        # 17      -  \n",
       " 13         3170.5        # 19      -  \n",
       " 14       364200.0         # 3      -  \n",
       " 15        16837.0        # 13      -  \n",
       " 16         1458.7        # 13      -  \n",
       " 17         1364.5        # 14      -  \n",
       " 18         1193.2        # 15      -  \n",
       " 19         1021.9        # 18      -  \n",
       " 20       292491.0        # 17      -  \n",
       " 21       279987.0        # 18      -  \n",
       " 22       423252.0        # 10      -  \n",
       " 23       319688.0        # 16      -  \n",
       " 24          455.0        # 16      -  \n",
       " 25          312.7        # 19      -  \n",
       " 26         1004.6         # 9      -  \n",
       " 27          886.0        # 14      -  \n",
       " 28        29900.0         # 9      -  \n",
       " 29        23750.0        # 14      -  \n",
       " ..            ...         ...    ...  \n",
       " 170          -7.8        # 16      -  \n",
       " 171         -13.2        # 18      -  \n",
       " 172        4870.0        # 18      -  \n",
       " 173        4786.0        # 19      -  \n",
       " 174        6608.0        # 11      -  \n",
       " 175        4871.0        # 17      -  \n",
       " 176          68.1        # 18      -  \n",
       " 177          45.6        # 21      -  \n",
       " 178         108.6        # 15      -  \n",
       " 179          92.2        # 17      -  \n",
       " 180        9989.9        # 17      -  \n",
       " 181        8038.5        # 20      -  \n",
       " 182       22681.3        # 11      -  \n",
       " 183       19086.9        # 13      -  \n",
       " 184         163.0        # 13      -  \n",
       " 185         136.0        # 14      -  \n",
       " 186          29.0        # 21      -  \n",
       " 187          21.0        # 24      -  \n",
       " 188      196760.4        # 12      -  \n",
       " 189      154414.1        # 14      -  \n",
       " 190      447408.6         # 6      -  \n",
       " 191      367823.7         # 7      -  \n",
       " 192        2704.0        # 18      -  \n",
       " 193        1609.0        # 20      -  \n",
       " 194       10471.0         # 5      -  \n",
       " 195        6201.0        # 12      -  \n",
       " 196        5363.0        # 17      -  \n",
       " 197        4412.0        # 19      -  \n",
       " 198       11320.0         # 8      -  \n",
       " 199        8593.0        # 14      -  \n",
       " \n",
       " [200 rows x 7 columns],                                     Task       Dataset  \\\n",
       " 0  Volumetric Medical Image Segmentation  PROMISE 2012   \n",
       " \n",
       "                      Model Metric name  Metric value Global rank Remove  \n",
       " 0  V-Net + Dice-based loss  Dice Score         0.869         # 1      -  ,                          Task Dataset                           Model  \\\n",
       " 0  Natural Language Inference    SNLI  300D Residual stacked encoders   \n",
       " 1  Natural Language Inference    SNLI  300D Residual stacked encoders   \n",
       " 2  Natural Language Inference    SNLI  300D Residual stacked encoders   \n",
       " 3  Natural Language Inference    SNLI  600D Residual stacked encoders   \n",
       " 4  Natural Language Inference    SNLI  600D Residual stacked encoders   \n",
       " 5  Natural Language Inference    SNLI  600D Residual stacked encoders   \n",
       " \n",
       "         Metric name Metric value Global rank Remove  \n",
       " 0   % Test Accuracy         85.7        # 30      -  \n",
       " 1  % Train Accuracy         89.8        # 33      -  \n",
       " 2        Parameters         9.7m         # 1      -  \n",
       " 3   % Test Accuracy         86.0        # 28      -  \n",
       " 4  % Train Accuracy         91.0        # 28      -  \n",
       " 5        Parameters          29m         # 1      -  ,                  Task  Dataset Model Metric name  Metric value Global rank  \\\n",
       " 0  Question Answering  WikiHop   CFC        Test          70.6         # 1   \n",
       " \n",
       "   Remove  \n",
       " 0      -  ,                                  Task          Dataset  \\\n",
       " 0  Weakly Supervised Object Detection  PASCAL VOC 2007   \n",
       " \n",
       "                             Model Metric name  Metric value Global rank Remove  \n",
       " 0  Self-paced curriculum learning         MAP          31.3        # 14      -  ,                                Task                 Dataset  \\\n",
       " 0  Unsupervised Machine Translation  WMT2016 English-German   \n",
       " 1  Unsupervised Machine Translation  WMT2016 German-English   \n",
       " \n",
       "                            Model Metric name  Metric value Global rank Remove  \n",
       " 0  Synthetic bilingual data init        BLEU          20.0         # 5      -  \n",
       " 1  Synthetic bilingual data init        BLEU          26.7         # 3      -  ,                                    Task                Dataset         Model  \\\n",
       " 0                      Image Generation               CIFAR-10  Improved GAN   \n",
       " 1          Conditional Image Generation               CIFAR-10  Improved GAN   \n",
       " 2  Semi-Supervised Image Classification  CIFAR-10, 4000 Labels           GAN   \n",
       " 3  Semi-Supervised Image Classification      SVHN, 1000 labels           GAN   \n",
       " \n",
       "        Metric name  Metric value Global rank Remove  \n",
       " 0  Inception score          6.86        # 10      -  \n",
       " 1  Inception score          8.09         # 5      -  \n",
       " 2         Accuracy         84.41         # 6      -  \n",
       " 3         Accuracy         91.89         # 5      -  ,                                 Task                   Dataset  \\\n",
       " 0                Machine Translation    WMT2014 English-French   \n",
       " 1   Unsupervised Machine Translation    WMT2014 English-French   \n",
       " 2                Machine Translation    WMT2014 English-French   \n",
       " 3                Machine Translation    WMT2014 English-French   \n",
       " 4                Machine Translation    WMT2014 English-German   \n",
       " 5                Machine Translation    WMT2014 English-German   \n",
       " 6                Machine Translation    WMT2014 English-German   \n",
       " 7   Unsupervised Machine Translation    WMT2014 French-English   \n",
       " 8   Unsupervised Machine Translation    WMT2016 English-German   \n",
       " 9                Machine Translation  WMT2016 English-Romanian   \n",
       " 10               Machine Translation  WMT2016 English-Romanian   \n",
       " 11               Machine Translation  WMT2016 English-Romanian   \n",
       " 12               Machine Translation   WMT2016 English-Russian   \n",
       " 13               Machine Translation   WMT2016 English-Russian   \n",
       " 14               Machine Translation   WMT2016 English-Russian   \n",
       " 15  Unsupervised Machine Translation    WMT2016 German-English   \n",
       " \n",
       "                              Model Metric name  Metric value Global rank  \\\n",
       " 0                      PBSMT + NMT  BLEU score         27.60        # 25   \n",
       " 1                      PBSMT + NMT        BLEU         27.60         # 4   \n",
       " 2   Unsupervised NMT + Transformer  BLEU score         25.14        # 28   \n",
       " 3               Unsupervised PBSMT  BLEU score         28.11        # 24   \n",
       " 4   Unsupervised NMT + Transformer  BLEU score         17.16        # 22   \n",
       " 5                      PBSMT + NMT  BLEU score         20.23        # 17   \n",
       " 6               Unsupervised PBSMT  BLEU score         17.94        # 20   \n",
       " 7                      PBSMT + NMT        BLEU         27.70         # 4   \n",
       " 8                      PBSMT + NMT        BLEU         20.20         # 4   \n",
       " 9               Unsupervised PBSMT  BLEU score         21.33         # 9   \n",
       " 10  Unsupervised NMT + Transformer  BLEU score         21.18        # 10   \n",
       " 11                     PBSMT + NMT  BLEU score         25.13         # 8   \n",
       " 12                     PBSMT + NMT  BLEU score         13.76         # 2   \n",
       " 13              Unsupervised PBSMT  BLEU score         13.37         # 3   \n",
       " 14  Unsupervised NMT + Transformer  BLEU score          7.98         # 4   \n",
       " 15                           PBSMT        BLEU         25.20         # 5   \n",
       " \n",
       "    Remove  \n",
       " 0       -  \n",
       " 1       -  \n",
       " 2       -  \n",
       " 3       -  \n",
       " 4       -  \n",
       " 5       -  \n",
       " 6       -  \n",
       " 7       -  \n",
       " 8       -  \n",
       " 9       -  \n",
       " 10      -  \n",
       " 11      -  \n",
       " 12      -  \n",
       " 13      -  \n",
       " 14      -  \n",
       " 15      -  ,                               Task    Dataset                  Model  \\\n",
       " 0  Aspect-Based Sentiment Analysis  Sentihood  Sentic LSTM + TA + SA   \n",
       " 1  Aspect-Based Sentiment Analysis  Sentihood  Sentic LSTM + TA + SA   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0      Aspect         78.18         # 4      -  \n",
       " 1   Sentiment         89.32         # 4      -  ,                               Task           Dataset                 Model  \\\n",
       " 0               Question Answering  CNN / Daily Mail                 BiDAF   \n",
       " 1               Question Answering  CNN / Daily Mail                 BiDAF   \n",
       " 2               Question Answering          MS MARCO        BiDaF Baseline   \n",
       " 3               Question Answering          MS MARCO        BiDaF Baseline   \n",
       " 4               Question Answering       NarrativeQA                 BiDAF   \n",
       " 5               Question Answering       NarrativeQA                 BiDAF   \n",
       " 6               Question Answering       NarrativeQA                 BiDAF   \n",
       " 7               Question Answering       NarrativeQA                 BiDAF   \n",
       " 8   Open-Domain Question Answering            Quasar                 BiDAF   \n",
       " 9   Open-Domain Question Answering            Quasar                 BiDAF   \n",
       " 10              Question Answering          SQuAD1.1  BiDAF (single model)   \n",
       " 11              Question Answering          SQuAD1.1  BiDAF (single model)   \n",
       " 12              Question Answering          SQuAD1.1      BiDAF (ensemble)   \n",
       " 13              Question Answering          SQuAD1.1      BiDAF (ensemble)   \n",
       " \n",
       "       Metric name  Metric value Global rank Remove  \n",
       " 0             CNN        76.900         # 4      -  \n",
       " 1      Daily Mail        79.600         # 2      -  \n",
       " 2         Rouge-L        23.960         # 4      -  \n",
       " 3          BLEU-1        10.640         # 4      -  \n",
       " 4          BLEU-1        33.450         # 5      -  \n",
       " 5          BLEU-4        15.690         # 5      -  \n",
       " 6          METEOR        15.680         # 5      -  \n",
       " 7         Rouge-L        36.740         # 5      -  \n",
       " 8   EM (Quasar-T)        25.900         # 5      -  \n",
       " 9   F1 (Quasar-T)        28.500         # 4      -  \n",
       " 10             EM        67.974       # 118      -  \n",
       " 11             F1        77.323       # 120      -  \n",
       " 12             EM        73.744        # 83      -  \n",
       " 13             F1        81.525        # 87      -  ,                  Task   Dataset                             Model Metric name  \\\n",
       " 0  Question Answering  SQuAD1.1  Ruminating Reader (single model)          EM   \n",
       " 1  Question Answering  SQuAD1.1  Ruminating Reader (single model)          F1   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0        70.639       # 107      -  \n",
       " 1        79.456       # 107      -  ,              Task              Dataset  Model Metric name  Metric value  \\\n",
       " 0  Face Detection    WIDER Face (Easy)  FDNet          AP         0.950   \n",
       " 1  Face Detection    WIDER Face (Hard)  FDNet          AP         0.878   \n",
       " 2  Face Detection  WIDER Face (Medium)  FDNet          AP         0.939   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 4      -  \n",
       " 1         # 5      -  \n",
       " 2         # 4      -  ,                   Task Dataset                              Model  \\\n",
       " 0    Face Verification   IJB-A  Deep Residual Equivariant Mapping   \n",
       " 1  Face Identification   IJB-A  Deep Residual Equivariant Mapping   \n",
       " \n",
       "       Metric name Metric value Global rank Remove  \n",
       " 0  TAR @ FAR=0.01       94.40%         # 4      -  \n",
       " 1        Accuracy       94.60%         # 1      -  ,                    Task   Dataset  Model         Metric name  Metric value  \\\n",
       " 0  Image Classification  CIFAR-10  RL+NT  Percentage correct          94.6   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 18      -  ,                  Task              Dataset              Model  \\\n",
       " 0  Speech Recognition  Switchboard (300hr)  End-to-end LF-MMI   \n",
       " 1  Speech Recognition           WSJ eval92  End-to-end LF-MMI   \n",
       " 2  Speech Recognition           WSJ eval92  End-to-end LF-MMI   \n",
       " \n",
       "              Metric name  Metric value Global rank Remove  \n",
       " 0  Word Error Rate (WER)           9.3         # 1      -  \n",
       " 1       Percentage error           3.0         # 2      -  \n",
       " 2  Word Error Rate (WER)           3.0         # 1      -  ,                     Task                      Dataset      Model Metric name  \\\n",
       " 0    Text Classification                      AG News  Capsule-B       Error   \n",
       " 1     Sentiment Analysis                           CR  Capsule-B    Accuracy   \n",
       " 2     Sentiment Analysis                           MR  Capsule-B    Accuracy   \n",
       " 3     Sentiment Analysis  SST-2 Binary classification  Capsule-B    Accuracy   \n",
       " 4  Subjectivity Analysis                         SUBJ  Capsule-B    Accuracy   \n",
       " 5    Text Classification                       TREC-6  Capsule-B       Error   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0           7.4         # 8      -  \n",
       " 1          85.1         # 4      -  \n",
       " 2          82.3         # 3      -  \n",
       " 3          86.8        # 17      -  \n",
       " 4          93.8         # 5      -  \n",
       " 5           7.2         # 8      -  ,                             Task                          Dataset  \\\n",
       " 0  Few-Shot Image Classification        CUB-200 - 0-Shot Learning   \n",
       " 1  Few-Shot Image Classification  Mini-ImageNet - 1-Shot Learning   \n",
       " 2  Few-Shot Image Classification  Mini-ImageNet - 5-Shot Learning   \n",
       " 3  Few-Shot Image Classification       OMNIGLOT - 1-Shot Learning   \n",
       " 4  Few-Shot Image Classification       OMNIGLOT - 5-Shot Learning   \n",
       " \n",
       "                                         Model Metric name Metric value  \\\n",
       " 0                           Prototypical-Nets    Accuracy        54.6%   \n",
       " 1  Prototypical-Nets + C64F feature extractor    Accuracy       49.42%   \n",
       " 2  Prototypical-Nets + C64F feature extractor    Accuracy       68.20%   \n",
       " 3                           Prototypical-Nets    Accuracy        98.8%   \n",
       " 4                           Prototypical-Nets    Accuracy        99.7%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 7      -  \n",
       " 2         # 4      -  \n",
       " 3         # 1      -  \n",
       " 4         # 2      -  ,                        Task   Dataset                             Model  \\\n",
       " 0  Facial Beauty Prediction  SCUT-FBP  Combined Features + Gaussian Reg   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0         MAE        0.3931         # 2      -  ,                  Task   Dataset                  Model Metric name  \\\n",
       " 0  Question Answering  SQuAD1.1  MAMCN+ (single model)          EM   \n",
       " 1  Question Answering  SQuAD1.1  MAMCN+ (single model)          F1   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0        79.692        # 32      -  \n",
       " 1        86.727        # 29      -  ,                                 Task   Dataset      Model Metric name  \\\n",
       " 0  Fine-Grained Image Classification  CompCars  GoogLeNet    Accuracy   \n",
       " 1  Fine-Grained Image Classification  CompCars    AlexNet    Accuracy   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        91.2%         # 2      -  \n",
       " 1        81.9%         # 3      -  ,                                  Task          Dataset      Model Metric name  \\\n",
       " 0  Weakly Supervised Object Detection  PASCAL VOC 2007  WSDDN-Ens         MAP   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          39.3        # 12      -  ,                      Task        Dataset        Model Metric name  \\\n",
       " 0  Part-Of-Speech Tagging  Penn Treebank  Meta BiLSTM    Accuracy   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         97.96         # 1      -  ,                               Task           Dataset    Model  \\\n",
       " 0  Sequential Image Classification  Sequential MNIST  BN LSTM   \n",
       " 1  Sequential Image Classification  Sequential MNIST  BN LSTM   \n",
       " 2               Language Modelling             Text8  BN LSTM   \n",
       " 3               Language Modelling             Text8  BN LSTM   \n",
       " \n",
       "                Metric name Metric value Global rank Remove  \n",
       " 0      Unpermuted Accuracy          99%         # 2      -  \n",
       " 1        Permuted Accuracy        95.4%         # 1      -  \n",
       " 2  Bit per Character (BPC)         1.36         # 9      -  \n",
       " 3         Number of params          16M         # 1      -  ,                 Task                    Dataset    Model Metric name  \\\n",
       " 0  Face Verification  Labeled Faces in the Wild  DeepId2    Accuracy   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0       99.15%         # 9      -  ,                                  Task       Dataset     Model Metric name  \\\n",
       " 0  Weakly Supervised Object Detection       IconArt  MI-max-C         MAP   \n",
       " 1  Weakly Supervised Object Detection     PeopleArt    MI-max         MAP   \n",
       " 2  Weakly Supervised Object Detection  Watercolor2k    MI-max         MAP   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          13.2         # 1      -  \n",
       " 1          55.4         # 1      -  \n",
       " 2          50.1         # 1      -  ,                                 Task               Dataset           Model  \\\n",
       " 0  Conversational Response Selection       PolyAI AmazonQA  PolyAI Encoder   \n",
       " 1  Conversational Response Selection  PolyAI OpenSubtitles  PolyAI Encoder   \n",
       " 2  Conversational Response Selection         PolyAI Reddit  PolyAI Encoder   \n",
       " \n",
       "          Metric name Metric value Global rank Remove  \n",
       " 0  1-of-100 Accuracy        84.2%         # 1      -  \n",
       " 1  1-of-100 Accuracy        30.6%         # 1      -  \n",
       " 2  1-of-100 Accuracy        61.3%         # 1      -  ,                               Task      Dataset     Model    Metric name  \\\n",
       " 0               Question Answering  NarrativeQA  DecaProp         BLEU-1   \n",
       " 1               Question Answering  NarrativeQA  DecaProp         BLEU-4   \n",
       " 2               Question Answering  NarrativeQA  DecaProp         METEOR   \n",
       " 3               Question Answering  NarrativeQA  DecaProp        Rouge-L   \n",
       " 4               Question Answering       NewsQA  DecaProp             F1   \n",
       " 5               Question Answering       NewsQA  DecaProp             EM   \n",
       " 6   Open-Domain Question Answering       Quasar  DecaProp  EM (Quasar-T)   \n",
       " 7   Open-Domain Question Answering       Quasar  DecaProp  F1 (Quasar-T)   \n",
       " 8   Open-Domain Question Answering     SearchQA  DecaProp    Unigram Acc   \n",
       " 9   Open-Domain Question Answering     SearchQA  DecaProp      N-gram F1   \n",
       " 10  Open-Domain Question Answering     SearchQA  DecaProp             EM   \n",
       " 11  Open-Domain Question Answering     SearchQA  DecaProp             F1   \n",
       " \n",
       "     Metric value Global rank Remove  \n",
       " 0          44.35         # 1      -  \n",
       " 1          27.61         # 1      -  \n",
       " 2          21.80         # 1      -  \n",
       " 3          44.69         # 2      -  \n",
       " 4          66.30         # 1      -  \n",
       " 5          53.10         # 1      -  \n",
       " 6          38.60         # 2      -  \n",
       " 7          46.90         # 2      -  \n",
       " 8          62.20         # 1      -  \n",
       " 9          70.80         # 1      -  \n",
       " 10         56.80         # 2      -  \n",
       " 11         63.60         # 2      -  ,                  Task Dataset                                       Model  \\\n",
       " 0  Question Answering  QASent                                  Bigram-CNN   \n",
       " 1  Question Answering  QASent                                  Bigram-CNN   \n",
       " 2  Question Answering  QASent  Bigram-CNN (lexical overlap + dist output)   \n",
       " 3  Question Answering  QASent  Bigram-CNN (lexical overlap + dist output)   \n",
       " 4  Question Answering  TrecQA                                         CNN   \n",
       " 5  Question Answering  TrecQA                                         CNN   \n",
       " 6  Question Answering  WikiQA                                  Bigram-CNN   \n",
       " 7  Question Answering  WikiQA                                  Bigram-CNN   \n",
       " 8  Question Answering  WikiQA  Bigram-CNN (lexical overlap + dist output)   \n",
       " 9  Question Answering  WikiQA  Bigram-CNN (lexical overlap + dist output)   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0         MAP        0.5693         # 6      -  \n",
       " 1         MRR        0.6613         # 6      -  \n",
       " 2         MAP        0.7113         # 3      -  \n",
       " 3         MRR        0.7846         # 3      -  \n",
       " 4         MAP        0.7110         # 4      -  \n",
       " 5         MRR        0.7850         # 4      -  \n",
       " 6         MAP        0.6190        # 11      -  \n",
       " 7         MRR        0.6281        # 12      -  \n",
       " 8         MAP        0.6520        # 10      -  \n",
       " 9         MRR        0.6652        # 11      -  ,                                Task                 Dataset  \\\n",
       " 0  Unsupervised Machine Translation  WMT2014 English-French   \n",
       " 1  Unsupervised Machine Translation  WMT2014 English-German   \n",
       " 2  Unsupervised Machine Translation  WMT2014 French-English   \n",
       " 3  Unsupervised Machine Translation  WMT2014 German-English   \n",
       " 4  Unsupervised Machine Translation  WMT2016 English-German   \n",
       " 5  Unsupervised Machine Translation  WMT2016 German-English   \n",
       " \n",
       "                              Model Metric name  Metric value Global rank  \\\n",
       " 0  SMT as posterior regularization        BLEU          29.5         # 3   \n",
       " 1  SMT as posterior regularization        BLEU          17.0         # 2   \n",
       " 2  SMT as posterior regularization        BLEU          28.9         # 3   \n",
       " 3  SMT as posterior regularization        BLEU          20.4         # 2   \n",
       " 4  SMT as posterior regularization        BLEU          21.7         # 3   \n",
       " 5  SMT as posterior regularization        BLEU          26.3         # 4   \n",
       " \n",
       "   Remove  \n",
       " 0      -  \n",
       " 1      -  \n",
       " 2      -  \n",
       " 3      -  \n",
       " 4      -  \n",
       " 5      -  ,                       Task                Dataset              Model  \\\n",
       " 0   Image Super-Resolution  BSD100 - 4x upscaling  nearest neighbors   \n",
       " 1   Image Super-Resolution  BSD100 - 4x upscaling  nearest neighbors   \n",
       " 2   Image Super-Resolution  BSD100 - 4x upscaling  nearest neighbors   \n",
       " 3   Image Super-Resolution  BSD100 - 4x upscaling            bicubic   \n",
       " 4   Image Super-Resolution  BSD100 - 4x upscaling            bicubic   \n",
       " 5   Image Super-Resolution  BSD100 - 4x upscaling            bicubic   \n",
       " 6   Image Super-Resolution  BSD100 - 4x upscaling           SRResNet   \n",
       " 7   Image Super-Resolution  BSD100 - 4x upscaling           SRResNet   \n",
       " 8   Image Super-Resolution  BSD100 - 4x upscaling           SRResNet   \n",
       " 9   Image Super-Resolution  BSD100 - 4x upscaling              SRGAN   \n",
       " 10  Image Super-Resolution  BSD100 - 4x upscaling              SRGAN   \n",
       " 11  Image Super-Resolution  BSD100 - 4x upscaling              SRGAN   \n",
       " 12  Image Super-Resolution   Set14 - 4x upscaling            bicubic   \n",
       " 13  Image Super-Resolution   Set14 - 4x upscaling            bicubic   \n",
       " 14  Image Super-Resolution   Set14 - 4x upscaling            bicubic   \n",
       " 15  Image Super-Resolution   Set14 - 4x upscaling           SRResNet   \n",
       " 16  Image Super-Resolution   Set14 - 4x upscaling           SRResNet   \n",
       " 17  Image Super-Resolution   Set14 - 4x upscaling           SRResNet   \n",
       " 18  Image Super-Resolution   Set14 - 4x upscaling              SRGAN   \n",
       " 19  Image Super-Resolution   Set14 - 4x upscaling              SRGAN   \n",
       " 20  Image Super-Resolution   Set14 - 4x upscaling              SRGAN   \n",
       " 21  Image Super-Resolution   Set14 - 4x upscaling  nearest neighbors   \n",
       " 22  Image Super-Resolution   Set14 - 4x upscaling  nearest neighbors   \n",
       " 23  Image Super-Resolution   Set14 - 4x upscaling  nearest neighbors   \n",
       " 24  Image Super-Resolution    Set5 - 4x upscaling  nearest neighbors   \n",
       " 25  Image Super-Resolution    Set5 - 4x upscaling  nearest neighbors   \n",
       " 26  Image Super-Resolution    Set5 - 4x upscaling  nearest neighbors   \n",
       " 27  Image Super-Resolution    Set5 - 4x upscaling            bicubic   \n",
       " 28  Image Super-Resolution    Set5 - 4x upscaling            bicubic   \n",
       " 29  Image Super-Resolution    Set5 - 4x upscaling            bicubic   \n",
       " 30  Image Super-Resolution    Set5 - 4x upscaling           SRResNet   \n",
       " 31  Image Super-Resolution    Set5 - 4x upscaling           SRResNet   \n",
       " 32  Image Super-Resolution    Set5 - 4x upscaling           SRResNet   \n",
       " 33  Image Super-Resolution    Set5 - 4x upscaling              SRGAN   \n",
       " 34  Image Super-Resolution    Set5 - 4x upscaling              SRGAN   \n",
       " 35  Image Super-Resolution    Set5 - 4x upscaling              SRGAN   \n",
       " \n",
       "    Metric name  Metric value Global rank Remove  \n",
       " 0         PSNR       25.0200        # 32      -  \n",
       " 1         SSIM        0.6606        # 30      -  \n",
       " 2          MOS        1.1100         # 6      -  \n",
       " 3         PSNR       25.9400        # 29      -  \n",
       " 4         SSIM        0.6935        # 27      -  \n",
       " 5          MOS        1.4700         # 5      -  \n",
       " 6         PSNR       27.5800         # 8      -  \n",
       " 7         SSIM        0.7620         # 1      -  \n",
       " 8          MOS        2.2900         # 2      -  \n",
       " 9         PSNR       25.1600        # 31      -  \n",
       " 10        SSIM        0.6688        # 29      -  \n",
       " 11         MOS        3.5600         # 1      -  \n",
       " 12        PSNR       25.9900        # 37      -  \n",
       " 13        SSIM        0.7486        # 29      -  \n",
       " 14         MOS        1.8000         # 5      -  \n",
       " 15        PSNR       28.4900        # 11      -  \n",
       " 16        SSIM        0.8184         # 1      -  \n",
       " 17         MOS        2.9800         # 2      -  \n",
       " 18        PSNR       26.0200        # 36      -  \n",
       " 19        SSIM        0.7397        # 31      -  \n",
       " 20         MOS        3.7200         # 1      -  \n",
       " 21        PSNR       24.6400        # 38      -  \n",
       " 22        SSIM        0.7100        # 32      -  \n",
       " 23         MOS        1.2000         # 6      -  \n",
       " 24        PSNR       26.2600        # 34      -  \n",
       " 25        SSIM        0.7552        # 33      -  \n",
       " 26         MOS        1.2800         # 6      -  \n",
       " 27        PSNR       28.4300        # 32      -  \n",
       " 28        SSIM        0.8211        # 31      -  \n",
       " 29         MOS        1.9700         # 5      -  \n",
       " 30        PSNR       32.0500        # 10      -  \n",
       " 31        SSIM        0.9019         # 2      -  \n",
       " 32         MOS        3.3700         # 2      -  \n",
       " 33        PSNR       29.4000        # 30      -  \n",
       " 34        SSIM        0.8472        # 29      -  \n",
       " 35         MOS        3.5800         # 1      -  ,                  Task   Dataset            Model Metric name  Metric value  \\\n",
       " 0  Question Answering  SQuAD2.0  Unet (ensemble)          EM        71.417   \n",
       " 1  Question Answering  SQuAD2.0  Unet (ensemble)          F1        74.869   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 66      -  \n",
       " 1        # 66      -  ,                             Task                          Dataset     Model  \\\n",
       " 0  Few-Shot Image Classification  Mini-ImageNet - 1-Shot Learning  PLATIPUS   \n",
       " \n",
       "   Metric name Metric value Global rank Remove  \n",
       " 0    Accuracy       50.13%         # 5      -  ,                Task                 Dataset        Model Metric name  \\\n",
       " 0  Image Generation     CelebA-HQ 1024x1024     PG-SWGAN         FID   \n",
       " 1  Image Generation  LSUN Bedroom 256 x 256     PG-SWGAN         FID   \n",
       " 2  Video Generation            TrailerFaces  PG-SWGAN-3D         FID   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0           5.5         # 2      -  \n",
       " 1           8.0         # 2      -  \n",
       " 2         404.1         # 1      -  ,                  Task   Dataset       Model Metric name  Metric value  \\\n",
       " 0  Question Answering  TriviaQA  MemoReader          EM         67.21   \n",
       " 1  Question Answering  TriviaQA  MemoReader          F1         73.26   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 1      -  ,                  Task           Dataset  Model Metric name  Metric value  \\\n",
       " 0  Question Answering  COMPLEXQUESTIONS  WebQA          F1          53.6   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  ,                  Task        Dataset         Model Metric name  Metric value  \\\n",
       " 0  Dependency Parsing  Penn Treebank  Weiss et al.         POS         97.44   \n",
       " 1  Dependency Parsing  Penn Treebank  Weiss et al.         UAS         93.99   \n",
       " 2  Dependency Parsing  Penn Treebank  Weiss et al.         LAS         92.05   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  \n",
       " 1         # 6      -  \n",
       " 2         # 6      -  ,                  Task Dataset           Model       Metric name  Metric value  \\\n",
       " 0  Speech Recognition   TIMIT  QCNN-10L-256FM  Percentage error         19.64   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 13      -  ,                Task   Dataset Model      Metric name  Metric value  \\\n",
       " 0  Image Generation  CIFAR-10  GMAN  Inception score           6.0   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 11      -  ,                    Task   Dataset       Model     Metric name Metric value  \\\n",
       " 0  Image Classification  ImageNet  ShuffleNet  Top 1 Accuracy        70.9%   \n",
       " 1  Image Classification  ImageNet  ShuffleNet  Top 5 Accuracy        89.8%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 20      -  \n",
       " 1        # 16      -  ,                  Task  Dataset                                      Model  \\\n",
       " 0  Language Modelling  enwiki8  Transformer-XL + RMS dynamic eval + decay   \n",
       " 1  Language Modelling  enwiki8  Transformer-XL + RMS dynamic eval + decay   \n",
       " 2  Language Modelling    Text8  Transformer-XL + RMS dynamic eval + decay   \n",
       " 3  Language Modelling    Text8  Transformer-XL + RMS dynamic eval + decay   \n",
       " \n",
       "                Metric name Metric value Global rank Remove  \n",
       " 0  Bit per Character (BPC)        0.940         # 2      -  \n",
       " 1         Number of params         277M         # 1      -  \n",
       " 2  Bit per Character (BPC)        1.038         # 2      -  \n",
       " 3         Number of params         277M         # 1      -  ,                                 Task       Dataset         Model Metric name  \\\n",
       " 0  Fine-Grained Image Classification  CUB-200-2011  Inception-V3    Accuracy   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          89.6         # 1      -  ,                    Task   Dataset  \\\n",
       " 0  Image Classification  CIFAR-10   \n",
       " 1  Image Classification    STL-10   \n",
       " \n",
       "                                                Model         Metric name  \\\n",
       " 0  An Analysis of Unsupervised Pre-training in Li...  Percentage correct   \n",
       " 1  An Analysis of Unsupervised Pre-training in Li...  Percentage correct   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          86.7        # 49      -  \n",
       " 1          70.2         # 8      -  ,                   Task                   Dataset  \\\n",
       " 0  Machine Translation  IWSLT2015 German-English   \n",
       " 1  Machine Translation    WMT2014 English-French   \n",
       " 2  Machine Translation  WMT2016 English-Romanian   \n",
       " 3  Machine Translation  WMT2016 English-Romanian   \n",
       " \n",
       "                                               Model Metric name  Metric value  \\\n",
       " 0                              Conv-LSTM (deep+pos)  BLEU score          30.4   \n",
       " 1  Deep Convolutional Encoder; single-layer decoder  BLEU score          35.7   \n",
       " 2  Deep Convolutional Encoder; single-layer decoder  BLEU score          27.8   \n",
       " 3                                            BiLSTM  BLEU score          27.5   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 9      -  \n",
       " 1        # 20      -  \n",
       " 2         # 6      -  \n",
       " 3         # 7      -  ,                          Task                            Dataset  \\\n",
       " 0          Sentiment Analysis                               IMDb   \n",
       " 1  Natural Language Inference                               SNLI   \n",
       " 2  Natural Language Inference                               SNLI   \n",
       " 3  Natural Language Inference                               SNLI   \n",
       " 4          Question Answering                           SQuAD1.1   \n",
       " 5          Question Answering                           SQuAD1.1   \n",
       " 6          Sentiment Analysis        SST-2 Binary classification   \n",
       " 7          Sentiment Analysis  SST-5 Fine-grained classification   \n",
       " 8         Text Classification                             TREC-6   \n",
       " \n",
       "                                               Model       Metric name  \\\n",
       " 0                                     BCN+Char+CoVe          Accuracy   \n",
       " 1  Biattentive Classification Network + CoVe + Char   % Test Accuracy   \n",
       " 2  Biattentive Classification Network + CoVe + Char  % Train Accuracy   \n",
       " 3  Biattentive Classification Network + CoVe + Char        Parameters   \n",
       " 4                                 DCN + Char + CoVe                EM   \n",
       " 5                                 DCN + Char + CoVe                F1   \n",
       " 6                                     BCN+Char+CoVe          Accuracy   \n",
       " 7                                     BCN+Char+CoVe          Accuracy   \n",
       " 8                                              CoVe             Error   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0         91.8         # 8      -  \n",
       " 1         88.1        # 15      -  \n",
       " 2         88.5        # 39      -  \n",
       " 3          22m         # 1      -  \n",
       " 4         71.3       # 101      -  \n",
       " 5         79.9       # 103      -  \n",
       " 6         90.3         # 8      -  \n",
       " 7         53.7         # 4      -  \n",
       " 8          4.2         # 5      -  ,                          Task Dataset    Model Metric name  Metric value  \\\n",
       " 0  Natural Language Inference  V-SNLI  V-BiMPM    Accuracy         86.99   \n",
       " 1  Natural Language Inference  V-SNLI    BiMPM    Accuracy         86.41   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 2      -  ,              Task              Dataset  Model Metric name  Metric value  \\\n",
       " 0  Face Detection    WIDER Face (Easy)  LDCF+          AP         0.797   \n",
       " 1  Face Detection    WIDER Face (Hard)  LDCF+          AP         0.564   \n",
       " 2  Face Detection  WIDER Face (Medium)  LDCF+          AP         0.772   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 10      -  \n",
       " 1        # 12      -  \n",
       " 2        # 10      -  ,                                     Task   Dataset    Model  \\\n",
       " 0  Dense Pixel Correspondence Estimation  HPatches  PWC-Net   \n",
       " 1  Dense Pixel Correspondence Estimation  HPatches  PWC-Net   \n",
       " 2  Dense Pixel Correspondence Estimation  HPatches  PWC-Net   \n",
       " 3  Dense Pixel Correspondence Estimation  HPatches  PWC-Net   \n",
       " 4  Dense Pixel Correspondence Estimation  HPatches  PWC-Net   \n",
       " \n",
       "           Metric name  Metric value Global rank Remove  \n",
       " 0    Viewpoint I AEPE          4.43         # 2      -  \n",
       " 1   Viewpoint II AEPE         11.44         # 3      -  \n",
       " 2  Viewpoint III AEPE         15.47         # 3      -  \n",
       " 3   Viewpoint IV AEPE         20.17         # 3      -  \n",
       " 4    Viewpoint V AEPE         28.30         # 3      -  ,                             Task                          Dataset  \\\n",
       " 0  Few-Shot Image Classification  Mini-ImageNet - 1-Shot Learning   \n",
       " 1  Few-Shot Image Classification  Mini-ImageNet - 5-Shot Learning   \n",
       " 2  Few-Shot Image Classification       OMNIGLOT - 1-Shot Learning   \n",
       " 3  Few-Shot Image Classification       OMNIGLOT - 5-Shot Learning   \n",
       " \n",
       "                                     Model Metric name Metric value  \\\n",
       " 0  Matching Nets + C64F feature extractor    Accuracy       43.60%   \n",
       " 1  Matching Nets + C64F feature extractor    Accuracy       55.30%   \n",
       " 2                           Matching Nets    Accuracy        98.1%   \n",
       " 3                           Matching Nets    Accuracy        98.9%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 9      -  \n",
       " 1         # 9      -  \n",
       " 2         # 4      -  \n",
       " 3         # 6      -  ,                   Task                 Dataset              Model Metric name  \\\n",
       " 0  Machine Translation  WMT2014 English-French  Deep-Att + PosUnk  BLEU score   \n",
       " 1  Machine Translation  WMT2014 English-French           Deep-Att  BLEU score   \n",
       " 2  Machine Translation  WMT2014 English-German           Deep-Att  BLEU score   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          39.2        # 13      -  \n",
       " 1          35.9        # 19      -  \n",
       " 2          20.7        # 16      -  ,                         Task  \\\n",
       " 0  Visual Question Answering   \n",
       " \n",
       "                                              Dataset     Model  \\\n",
       " 0  COCO Visual Question Answering (VQA) real imag...  SMem-VQA   \n",
       " \n",
       "           Metric name  Metric value Global rank Remove  \n",
       " 0  Percentage correct         58.24         # 8      -  ,                          Task Dataset              Model      Metric name  \\\n",
       " 0            Object Detection    COCO  CornerNet-Saccade  Bounding Box AP   \n",
       " 1  Real-Time Object Detection    COCO  CornerNet-Squeeze              MAP   \n",
       " 2  Real-Time Object Detection    COCO  CornerNet-Squeeze              FPS   \n",
       " 3            Object Detection    COCO  CornerNet-Squeeze  Bounding Box AP   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0         43.2        # 14      -  \n",
       " 1        34.4%         # 3      -  \n",
       " 2           30         # 4      -  \n",
       " 3         34.4        # 32      -  ,                   Task    Dataset  \\\n",
       " 0  Lesion Segmentation  ISIC 2017   \n",
       " \n",
       "                                                Model Metric name  \\\n",
       " 0  Automatic skin lesion segmentation with fully ...    Mean IoU   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         0.765         # 1      -  ,                    Task      Dataset    Model       Metric name  Metric value  \\\n",
       " 0  Pedestrian Detection  CityPersons  TLL+MRF  Reasonable MR^-2          14.4   \n",
       " 1  Pedestrian Detection  CityPersons  TLL+MRF       Heavy MR^-2          52.0   \n",
       " 2  Pedestrian Detection  CityPersons  TLL+MRF     Partial MR^-2          15.9   \n",
       " 3  Pedestrian Detection  CityPersons  TLL+MRF        Bare MR^-2           9.2   \n",
       " 4  Pedestrian Detection  CityPersons      TLL  Reasonable MR^-2          15.5   \n",
       " 5  Pedestrian Detection  CityPersons      TLL       Heavy MR^-2          53.6   \n",
       " 6  Pedestrian Detection  CityPersons      TLL     Partial MR^-2          17.2   \n",
       " 7  Pedestrian Detection  CityPersons      TLL        Bare MR^-2          10.0   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 5      -  \n",
       " 1         # 3      -  \n",
       " 2         # 4      -  \n",
       " 3         # 5      -  \n",
       " 4         # 8      -  \n",
       " 5         # 4      -  \n",
       " 6         # 6      -  \n",
       " 7         # 6      -  ,                  Task                            Dataset            Model  \\\n",
       " 0  Sentiment Analysis  SST-5 Fine-grained classification  EDD-LG (shared)   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0    Accuracy          64.4         # 1      -  ,                            Task       Dataset  \\\n",
       " 0  Grammatical Error Correction  Unrestricted   \n",
       " 1  Grammatical Error Correction  Unrestricted   \n",
       " 2  Grammatical Error Correction  Unrestricted   \n",
       " \n",
       "                                        Model Metric name  Metric value  \\\n",
       " 0                CNN Seq2Seq + Fluency Boost        F0.5         61.34   \n",
       " 1                CNN Seq2Seq + Fluency Boost        F0.5         76.88   \n",
       " 2  CNN Seq2Seq + Fluency Boost and inference        GLEU         62.37   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  \n",
       " 1         # 1      -  \n",
       " 2         # 1      -  ,                          Task Dataset                      Model  \\\n",
       " 0  Natural Language Inference    SNLI  Stochastic Answer Network   \n",
       " 1  Natural Language Inference    SNLI  Stochastic Answer Network   \n",
       " 2  Natural Language Inference    SNLI  Stochastic Answer Network   \n",
       " \n",
       "         Metric name Metric value Global rank Remove  \n",
       " 0   % Test Accuracy         88.5        # 13      -  \n",
       " 1  % Train Accuracy         93.3        # 16      -  \n",
       " 2        Parameters         3.5m         # 1      -  ,                               Task                         Dataset Model  \\\n",
       " 0  Aspect-Based Sentiment Analysis  SemEval 2014 Task 4 Sub Task 2   RAM   \n",
       " 1  Aspect-Based Sentiment Analysis  SemEval 2014 Task 4 Sub Task 2   RAM   \n",
       " \n",
       "         Metric name  Metric value Global rank Remove  \n",
       " 0  Restaurant (Acc)         80.23        # 16      -  \n",
       " 1      Laptop (Acc)         74.49        # 14      -  ,              Task  Dataset                    Model  Metric name  \\\n",
       " 0  Drug Discovery      QM9  Gated Graph Sequence NN  Error ratio   \n",
       " 1     SQL-to-Text  WikiSQL                   GGS-NN       BLEU-4   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          1.36         # 2      -  \n",
       " 1         35.53         # 2      -  ,                    Task Dataset      Model       Metric name  Metric value  \\\n",
       " 0  Image Classification    SVHN  EraseReLU  Percentage error          1.54   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  ,                 Task Dataset Model     Metric name Metric value Global rank  \\\n",
       " 0  Face Verification   IJB-A   NAN  TAR @ FAR=0.01       94.10%         # 5   \n",
       " \n",
       "   Remove  \n",
       " 0      -  ,                      Task                  Dataset Model Metric name  \\\n",
       " 0  Image Super-Resolution    BSD100 - 4x upscaling  CARN        PSNR   \n",
       " 1  Image Super-Resolution    BSD100 - 4x upscaling  CARN        SSIM   \n",
       " 2  Image Super-Resolution     Set14 - 4x upscaling  CARN        PSNR   \n",
       " 3  Image Super-Resolution     Set14 - 4x upscaling  CARN        SSIM   \n",
       " 4  Image Super-Resolution      Set5 - 4x upscaling  CARN        PSNR   \n",
       " 5  Image Super-Resolution      Set5 - 4x upscaling  CARN        SSIM   \n",
       " 6  Image Super-Resolution  Urban100 - 4x upscaling  CARN        PSNR   \n",
       " 7  Image Super-Resolution  Urban100 - 4x upscaling  CARN        SSIM   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0       27.5800         # 8      -  \n",
       " 1        0.7349        # 15      -  \n",
       " 2       28.6000         # 8      -  \n",
       " 3        0.7806        # 14      -  \n",
       " 4       32.1300         # 8      -  \n",
       " 5        0.8937        # 12      -  \n",
       " 6       26.0700         # 9      -  \n",
       " 7        0.7837         # 9      -  ,              Task              Dataset                             Model  \\\n",
       " 0  Face Detection    WIDER Face (Easy)  Massively-large receptive fields   \n",
       " 1  Face Detection    WIDER Face (Hard)  Massively-large receptive fields   \n",
       " 2  Face Detection  WIDER Face (Medium)  Massively-large receptive fields   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0          AP         0.919         # 7      -  \n",
       " 1          AP         0.823         # 8      -  \n",
       " 2          AP         0.908         # 7      -  ,                               Task                            Dataset  \\\n",
       " 0   Citation Intent Classification                            ACL-ARC   \n",
       " 1   Named Entity Recognition (NER)               CoNLL 2003 (English)   \n",
       " 2           Coreference Resolution                         CoNLL 2012   \n",
       " 3           Semantic Role Labeling                          OntoNotes   \n",
       " 4       Natural Language Inference                               SNLI   \n",
       " 5       Natural Language Inference                               SNLI   \n",
       " 6       Natural Language Inference                               SNLI   \n",
       " 7       Natural Language Inference                               SNLI   \n",
       " 8       Natural Language Inference                               SNLI   \n",
       " 9       Natural Language Inference                               SNLI   \n",
       " 10              Question Answering                           SQuAD1.1   \n",
       " 11              Question Answering                           SQuAD1.1   \n",
       " 12              Question Answering                           SQuAD1.1   \n",
       " 13              Question Answering                           SQuAD1.1   \n",
       " 14              Question Answering                           SQuAD2.0   \n",
       " 15              Question Answering                           SQuAD2.0   \n",
       " 16              Sentiment Analysis  SST-5 Fine-grained classification   \n",
       " \n",
       "                                            Model       Metric name  \\\n",
       " 0                        BiLSTM-Attention + ELMo                F1   \n",
       " 1                                BiLSTM-CRF+ELMo                F1   \n",
       " 2                        (Lee et al., 2017)+ELMo            Avg F1   \n",
       " 3                       (He et al., 2017) + ELMo                F1   \n",
       " 4                                    ESIM + ELMo   % Test Accuracy   \n",
       " 5                                    ESIM + ELMo  % Train Accuracy   \n",
       " 6                                    ESIM + ELMo        Parameters   \n",
       " 7                           ESIM + ELMo Ensemble   % Test Accuracy   \n",
       " 8                           ESIM + ELMo Ensemble  % Train Accuracy   \n",
       " 9                           ESIM + ELMo Ensemble        Parameters   \n",
       " 10      BiDAF + Self Attention + ELMo (ensemble)                EM   \n",
       " 11      BiDAF + Self Attention + ELMo (ensemble)                F1   \n",
       " 12  BiDAF + Self Attention + ELMo (single model)                EM   \n",
       " 13  BiDAF + Self Attention + ELMo (single model)                F1   \n",
       " 14  BiDAF + Self Attention + ELMo (single model)                EM   \n",
       " 15  BiDAF + Self Attention + ELMo (single model)                F1   \n",
       " 16                                      BCN+ELMo          Accuracy   \n",
       " \n",
       "    Metric value Global rank  Extradata Remove  \n",
       " 0          54.6         # 3        NaN      -  \n",
       " 1         92.22         # 7        NaN      -  \n",
       " 2          70.4         # 2        NaN      -  \n",
       " 3          84.6         # 5        NaN      -  \n",
       " 4          88.7        # 11        NaN      -  \n",
       " 5          91.6        # 24        NaN      -  \n",
       " 6          8.0m         # 1        NaN      -  \n",
       " 7          89.3         # 7        NaN      -  \n",
       " 8          92.1        # 22        NaN      -  \n",
       " 9           40m         # 1        NaN      -  \n",
       " 10       81.003        # 22        NaN      -  \n",
       " 11       87.432        # 24        NaN      -  \n",
       " 12       78.580        # 41        NaN      -  \n",
       " 13       85.833        # 41        NaN      -  \n",
       " 14       63.372        # 82        NaN      -  \n",
       " 15       66.251        # 88        NaN      -  \n",
       " 16         54.7         # 3        NaN      -  ,                    Task   Dataset  \\\n",
       " 0  Image Classification  CIFAR-10   \n",
       " \n",
       "                                                Model         Metric name  \\\n",
       " 0  Learning with Recursive Perceptual Representat...  Percentage correct   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          79.7        # 57      -  ,                  Task  Dataset Model       Metric name Metric value  \\\n",
       " 0  Scene Segmentation  ScanNet  3DMV  Average Accuracy        75.0%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  ,                     Task Dataset  \\\n",
       " 0       Object Detection    COCO   \n",
       " 1  Instance Segmentation    COCO   \n",
       " 2     Keypoint Detection    COCO   \n",
       " \n",
       "                                                Model        Metric name  \\\n",
       " 0                           ResNeXt-152 + 1 NL block    Bounding Box AP   \n",
       " 1                           ResNeXt-152 + 1 NL block  Average Precision   \n",
       " 2  Mask R-CNN + NL blocks (4 in head, 1 in backbone)      Validation AP   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0         45.0         # 8      -  \n",
       " 1        40.3%         # 2      -  \n",
       " 2         66.5         # 6      -  ,               Task             Dataset                    Model Metric name  \\\n",
       " 0  Pose Estimation  Leeds Sports Poses  Multi-Context Attention         PCK   \n",
       " 1  Pose Estimation     MPII Human Pose  Multi-Context Attention    PCKh-0.5   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        92.6%         # 2      -  \n",
       " 1        91.5%         # 3      -  ,               Task           Dataset  Model Metric name  Metric value  \\\n",
       " 0  Image Denoising    BSD200 sigma10  RED30        PSNR       33.6300   \n",
       " 1  Image Denoising    BSD200 sigma10  RED30        SSIM        0.9319   \n",
       " 2  Image Denoising    BSD200 sigma30  RED30        PSNR       27.9500   \n",
       " 3  Image Denoising    BSD200 sigma30  RED30        SSIM        0.8019   \n",
       " 4  Image Denoising    BSD200 sigma50  RED30        PSNR       25.7500   \n",
       " 5  Image Denoising    BSD200 sigma50  RED30        SSIM        0.7167   \n",
       " 6  Image Denoising    BSD200 sigma70  RED30        PSNR       24.3700   \n",
       " 7  Image Denoising    BSD200 sigma70  RED30        SSIM        0.6551   \n",
       " 8  Image Denoising  Urban100 sigma50  RED30        PSNR       26.3200   \n",
       " 9  Image Denoising  Urban100 sigma70  RED30        PSNR       24.6300   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 1      -  \n",
       " 2         # 1      -  \n",
       " 3         # 1      -  \n",
       " 4         # 1      -  \n",
       " 5         # 1      -  \n",
       " 6         # 1      -  \n",
       " 7         # 1      -  \n",
       " 8         # 5      -  \n",
       " 9         # 3      -  ,                               Task          Dataset                 Model  \\\n",
       " 0            Semantic Segmentation           ADE20K            DilatedNet   \n",
       " 1            Semantic Segmentation           CamVid  Dilated Convolutions   \n",
       " 2  Real-Time Semantic Segmentation           CamVid            Dilation10   \n",
       " 3  Real-Time Semantic Segmentation           CamVid            Dilation10   \n",
       " 4  Real-Time Semantic Segmentation           CamVid            Dilation10   \n",
       " 5            Semantic Segmentation       Cityscapes            Dilation10   \n",
       " 6  Real-Time Semantic Segmentation       Cityscapes            Dilation10   \n",
       " 7  Real-Time Semantic Segmentation       Cityscapes            Dilation10   \n",
       " 8  Real-Time Semantic Segmentation       Cityscapes            Dilation10   \n",
       " 9            Semantic Segmentation  PASCAL VOC 2012  Dilated Convolutions   \n",
       " \n",
       "        Metric name Metric value Global rank Remove  \n",
       " 0  Validation mIoU        32.31         # 5      -  \n",
       " 1         Mean IoU        65.3%         # 4      -  \n",
       " 2             mIoU        65.3%         # 4      -  \n",
       " 3        Time (ms)          227         # 5      -  \n",
       " 4      Frame (fps)          4.4         # 5      -  \n",
       " 5         Mean IoU        67.1%        # 13      -  \n",
       " 6             mIoU        67.1%         # 6      -  \n",
       " 7        Time (ms)         4000         # 8      -  \n",
       " 8      Frame (fps)         0.25        # 10      -  \n",
       " 9         Mean IoU        67.6%        # 17      -  ,                    Task Dataset Model Metric name Metric value Global rank  \\\n",
       " 0  Scene Text Detection    IC15  FTSN   F-Measure       84.14%         # 5   \n",
       " \n",
       "   Remove  \n",
       " 0      -  ,            Task                         Dataset   Model Metric name  \\\n",
       " 0   Atari Games                Atari 2600 Alien  Gorila       Score   \n",
       " 1   Atari Games               Atari 2600 Amidar  Gorila       Score   \n",
       " 2   Atari Games              Atari 2600 Assault  Gorila       Score   \n",
       " 3   Atari Games              Atari 2600 Asterix  Gorila       Score   \n",
       " 4   Atari Games            Atari 2600 Asteroids  Gorila       Score   \n",
       " 5   Atari Games             Atari 2600 Atlantis  Gorila       Score   \n",
       " 6   Atari Games           Atari 2600 Bank Heist  Gorila       Score   \n",
       " 7   Atari Games          Atari 2600 Battle Zone  Gorila       Score   \n",
       " 8   Atari Games           Atari 2600 Beam Rider  Gorila       Score   \n",
       " 9   Atari Games              Atari 2600 Bowling  Gorila       Score   \n",
       " 10  Atari Games               Atari 2600 Boxing  Gorila       Score   \n",
       " 11  Atari Games             Atari 2600 Breakout  Gorila       Score   \n",
       " 12  Atari Games            Atari 2600 Centipede  Gorila       Score   \n",
       " 13  Atari Games      Atari 2600 Chopper Command  Gorila       Score   \n",
       " 14  Atari Games        Atari 2600 Crazy Climber  Gorila       Score   \n",
       " 15  Atari Games         Atari 2600 Demon Attack  Gorila       Score   \n",
       " 16  Atari Games          Atari 2600 Double Dunk  Gorila       Score   \n",
       " 17  Atari Games               Atari 2600 Enduro  Gorila       Score   \n",
       " 18  Atari Games        Atari 2600 Fishing Derby  Gorila       Score   \n",
       " 19  Atari Games              Atari 2600 Freeway  Gorila       Score   \n",
       " 20  Atari Games            Atari 2600 Frostbite  Gorila       Score   \n",
       " 21  Atari Games               Atari 2600 Gopher  Gorila       Score   \n",
       " 22  Atari Games             Atari 2600 Gravitar  Gorila       Score   \n",
       " 23  Atari Games                 Atari 2600 HERO  Gorila       Score   \n",
       " 24  Atari Games           Atari 2600 Ice Hockey  Gorila       Score   \n",
       " 25  Atari Games           Atari 2600 James Bond  Gorila       Score   \n",
       " 26  Atari Games             Atari 2600 Kangaroo  Gorila       Score   \n",
       " 27  Atari Games                Atari 2600 Krull  Gorila       Score   \n",
       " 28  Atari Games       Atari 2600 Kung-Fu Master  Gorila       Score   \n",
       " 29  Atari Games  Atari 2600 Montezuma's Revenge  Gorila       Score   \n",
       " 30  Atari Games           Atari 2600 Ms. Pacman  Gorila       Score   \n",
       " 31  Atari Games       Atari 2600 Name This Game  Gorila       Score   \n",
       " 32  Atari Games                 Atari 2600 Pong  Gorila       Score   \n",
       " 33  Atari Games          Atari 2600 Private Eye  Gorila       Score   \n",
       " 34  Atari Games               Atari 2600 Q*Bert  Gorila       Score   \n",
       " 35  Atari Games           Atari 2600 River Raid  Gorila       Score   \n",
       " 36  Atari Games          Atari 2600 Road Runner  Gorila       Score   \n",
       " 37  Atari Games             Atari 2600 Robotank  Gorila       Score   \n",
       " 38  Atari Games             Atari 2600 Seaquest  Gorila       Score   \n",
       " 39  Atari Games       Atari 2600 Space Invaders  Gorila       Score   \n",
       " 40  Atari Games          Atari 2600 Star Gunner  Gorila       Score   \n",
       " 41  Atari Games               Atari 2600 Tennis  Gorila       Score   \n",
       " 42  Atari Games           Atari 2600 Time Pilot  Gorila       Score   \n",
       " 43  Atari Games            Atari 2600 Tutankham  Gorila       Score   \n",
       " 44  Atari Games          Atari 2600 Up and Down  Gorila       Score   \n",
       " 45  Atari Games              Atari 2600 Venture  Gorila       Score   \n",
       " 46  Atari Games        Atari 2600 Video Pinball  Gorila       Score   \n",
       " 47  Atari Games        Atari 2600 Wizard of Wor  Gorila       Score   \n",
       " 48  Atari Games               Atari 2600 Zaxxon  Gorila       Score   \n",
       " \n",
       "     Metric value Global rank Remove  \n",
       " 0          813.5        # 18      -  \n",
       " 1          189.2        # 14      -  \n",
       " 2         1195.8        # 20      -  \n",
       " 3         3324.7        # 18      -  \n",
       " 4          933.6        # 19      -  \n",
       " 5       629166.5         # 8      -  \n",
       " 6          399.4        # 18      -  \n",
       " 7        19938.0        # 16      -  \n",
       " 8         3822.1        # 20      -  \n",
       " 9           54.0        # 10      -  \n",
       " 10          74.2        # 12      -  \n",
       " 11         313.0        # 19      -  \n",
       " 12        6296.9         # 9      -  \n",
       " 13        3191.8        # 19      -  \n",
       " 14       65451.0        # 19      -  \n",
       " 15       14880.1        # 16      -  \n",
       " 16         -11.3        # 15      -  \n",
       " 17          71.0        # 20      -  \n",
       " 18           4.6        # 14      -  \n",
       " 19          10.2        # 20      -  \n",
       " 20         426.6        # 19      -  \n",
       " 21        4373.0        # 19      -  \n",
       " 22         538.4         # 6      -  \n",
       " 23        8963.4        # 19      -  \n",
       " 24          -1.7         # 8      -  \n",
       " 25         444.0        # 18      -  \n",
       " 26        1431.0        # 17      -  \n",
       " 27        6363.1        # 16      -  \n",
       " 28       20620.0        # 19      -  \n",
       " 29          84.0        # 12      -  \n",
       " 30        1263.0        # 14      -  \n",
       " 31        9238.5        # 14      -  \n",
       " 32          16.7        # 10      -  \n",
       " 33        2598.6         # 4      -  \n",
       " 34        7089.8        # 19      -  \n",
       " 35        5310.3        # 18      -  \n",
       " 36       43079.8        # 14      -  \n",
       " 37          61.8         # 9      -  \n",
       " 38       10145.9        # 10      -  \n",
       " 39        1183.3        # 19      -  \n",
       " 40       14919.2        # 18      -  \n",
       " 41          -0.7        # 10      -  \n",
       " 42        8267.8         # 9      -  \n",
       " 43         118.5        # 13      -  \n",
       " 44        8747.7        # 18      -  \n",
       " 45         523.4         # 7      -  \n",
       " 46      112093.4        # 15      -  \n",
       " 47       10431.0         # 6      -  \n",
       " 48        6159.4        # 16      -  ,                    Task   Dataset    Model         Metric name  Metric value  \\\n",
       " 0  Image Classification  CIFAR-10  CLS-GAN  Percentage correct         91.70   \n",
       " 1  Image Classification      SVHN  CLS-GAN    Percentage error          5.98   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 34      -  \n",
       " 1        # 24      -  ,                  Task                     Dataset  \\\n",
       " 0  Language Modelling  Penn Treebank (Word Level)   \n",
       " 1  Language Modelling  Penn Treebank (Word Level)   \n",
       " 2  Language Modelling  Penn Treebank (Word Level)   \n",
       " \n",
       "                                 Model            Metric name Metric value  \\\n",
       " 0  2-layer skip-LSTM + dropout tuning  Validation perplexity         57.1   \n",
       " 1  2-layer skip-LSTM + dropout tuning        Test perplexity         55.3   \n",
       " 2  2-layer skip-LSTM + dropout tuning                 Params          24M   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 12      -  \n",
       " 1        # 14      -  \n",
       " 2         # 1      -  ,              Task      Dataset  Model Metric name Metric value Global rank  \\\n",
       " 0  Face Alignment  AFLW2000-3D  2DASL    Mean NME        3.53%         # 1   \n",
       " \n",
       "   Remove  \n",
       " 0      -  ,                  Task                      Dataset            Model  \\\n",
       " 0  Sentiment Analysis                         IMDb  Standard DR-AGG   \n",
       " 1  Sentiment Analysis                         IMDb   Reverse DR-AGG   \n",
       " 2  Sentiment Analysis  SST-2 Binary classification   Reverse DR-AGG   \n",
       " 3  Sentiment Analysis  SST-2 Binary classification  Standard DR-AGG   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0    Accuracy          45.1        # 13      -  \n",
       " 1    Accuracy          44.5        # 14      -  \n",
       " 2    Accuracy          87.2        # 15      -  \n",
       " 3    Accuracy          87.6        # 13      -  ,                Task  Dataset    Model Metric name  Metric value Global rank  \\\n",
       " 0  Super Resolution  Set5-2x  FALSR-A        PSNR         37.82         # 1   \n",
       " \n",
       "   Remove  \n",
       " 0      -  ,                  Task      Dataset    Model Metric name  Metric value  \\\n",
       " 0  Question Answering  NarrativeQA  ConZNet      BLEU-1         42.76   \n",
       " 1  Question Answering  NarrativeQA  ConZNet      BLEU-4         22.49   \n",
       " 2  Question Answering  NarrativeQA  ConZNet      METEOR         19.24   \n",
       " 3  Question Answering  NarrativeQA  ConZNet     Rouge-L         46.67   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 3      -  \n",
       " 1         # 2      -  \n",
       " 2         # 2      -  \n",
       " 3         # 1      -  ,                      Task        Dataset           Model Metric name  \\\n",
       " 0        CCG Supertagging        CCGBank  Vaswani et al.    Accuracy   \n",
       " 1  Part-Of-Speech Tagging  Penn Treebank    Feed Forward    Accuracy   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         94.24         # 3      -  \n",
       " 1         97.40         # 9      -  ,                                  Task           Dataset       Model  \\\n",
       " 0  Hyperspectral Image Classification      Indian Pines  St-SS-pGRU   \n",
       " 1  Hyperspectral Image Classification  Pavia University  St-SS-pGRU   \n",
       " \n",
       "         Metric name Metric value Global rank Remove  \n",
       " 0  Overall Accuracy       90.35%         # 3      -  \n",
       " 1  Overall Accuracy       98.44%         # 1      -  ,                      Task                  Dataset                    Model  \\\n",
       " 0  Image Super-Resolution    BSD100 - 4x upscaling  Manifold Simplification   \n",
       " 1  Image Super-Resolution    BSD100 - 4x upscaling  Manifold Simplification   \n",
       " 2  Image Super-Resolution     Set14 - 4x upscaling  Manifold Simplification   \n",
       " 3  Image Super-Resolution     Set14 - 4x upscaling  Manifold Simplification   \n",
       " 4  Image Super-Resolution      Set5 - 4x upscaling  Manifold Simplification   \n",
       " 5  Image Super-Resolution      Set5 - 4x upscaling  Manifold Simplification   \n",
       " 6  Image Super-Resolution  Urban100 - 4x upscaling  Manifold Simplification   \n",
       " 7  Image Super-Resolution  Urban100 - 4x upscaling  Manifold Simplification   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0        PSNR       27.6600         # 6      -  \n",
       " 1        SSIM        0.7380        # 10      -  \n",
       " 2        PSNR       28.8000         # 7      -  \n",
       " 3        SSIM        0.7856        # 11      -  \n",
       " 4        PSNR       32.2300         # 6      -  \n",
       " 5        SSIM        0.8952         # 9      -  \n",
       " 6        PSNR       26.4200         # 7      -  \n",
       " 7        SSIM        0.7940         # 7      -  ,               Task Dataset      Model Metric name  Metric value Global rank  \\\n",
       " 0  Text Generation  CMU-SE  STWGAN-GP      BLEU-3         0.617         # 1   \n",
       " \n",
       "   Remove  \n",
       " 0      -  ,                Task                 Dataset                     Model  \\\n",
       " 0  Speech Synthesis        Mandarin Chinese             WaveNet (L+F)   \n",
       " 1  Speech Synthesis        Mandarin Chinese  HMM-driven concatenative   \n",
       " 2  Speech Synthesis        Mandarin Chinese       LSTM-RNN parametric   \n",
       " 3  Speech Synthesis  North American English             WaveNet (L+F)   \n",
       " 4  Speech Synthesis  North American English  HMM-driven concatenative   \n",
       " 5  Speech Synthesis  North American English       LSTM-RNN parametric   \n",
       " \n",
       "           Metric name  Metric value Global rank Remove  \n",
       " 0  Mean Opinion Score          4.08         # 1      -  \n",
       " 1  Mean Opinion Score          3.47         # 3      -  \n",
       " 2  Mean Opinion Score          3.79         # 2      -  \n",
       " 3  Mean Opinion Score          4.21         # 3      -  \n",
       " 4  Mean Opinion Score          3.86         # 5      -  \n",
       " 5  Mean Opinion Score          3.67         # 6      -  ,              Task                      Dataset Model Metric name  \\\n",
       " 0  Face Detection  Annotated Faces in the Wild   SRN          AP   \n",
       " 1  Face Detection                         FDDB   SRN          AP   \n",
       " 2  Face Detection                  PASCAL Face   SRN          AP   \n",
       " 3  Face Detection            WIDER Face (Easy)   SRN          AP   \n",
       " 4  Face Detection            WIDER Face (Hard)   SRN          AP   \n",
       " 5  Face Detection          WIDER Face (Medium)   SRN          AP   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0        0.9987         # 1      -  \n",
       " 1        0.9880         # 3      -  \n",
       " 2        0.9909         # 1      -  \n",
       " 3        0.9590         # 2      -  \n",
       " 4        0.8960         # 2      -  \n",
       " 5        0.9480         # 2      -  ,                           Task        Dataset  \\\n",
       " 0  Grammatical Error Detection  CoNLL-2014 A1   \n",
       " 1  Grammatical Error Detection  CoNLL-2014 A2   \n",
       " 2  Grammatical Error Detection            FCE   \n",
       " 3       Part-Of-Speech Tagging  Penn Treebank   \n",
       " \n",
       "                                Model Metric name  Metric value Global rank  \\\n",
       " 0  Bi-LSTM + LMcost (trained on FCE)        F0.5         17.86         # 5   \n",
       " 1  Bi-LSTM + LMcost (trained on FCE)        F0.5         25.88         # 6   \n",
       " 2                   Bi-LSTM + LMcost        F0.5         48.48         # 3   \n",
       " 3                   Bi-LSTM + LMcost    Accuracy         97.43         # 8   \n",
       " \n",
       "   Remove  \n",
       " 0      -  \n",
       " 1      -  \n",
       " 2      -  \n",
       " 3      -  ,                Task Dataset               Model      Metric name  \\\n",
       " 0  Object Detection    COCO  Faster R-CNN + TDM  Bounding Box AP   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          36.8        # 28      -  ,                     Task Dataset     Model Metric name  Metric value  \\\n",
       " 0  Subjectivity Analysis    SUBJ  CNN+MCFA    Accuracy          94.8   \n",
       " 1    Text Classification  TREC-6  CNN+MCFA       Error           4.0   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  \n",
       " 1         # 4      -  ,                          Task Dataset                                Model  \\\n",
       " 0  Natural Language Inference    SNLI  600D ESIM + 300D Syntactic TreeLSTM   \n",
       " 1  Natural Language Inference    SNLI  600D ESIM + 300D Syntactic TreeLSTM   \n",
       " 2  Natural Language Inference    SNLI  600D ESIM + 300D Syntactic TreeLSTM   \n",
       " \n",
       "         Metric name Metric value Global rank Remove  \n",
       " 0   % Test Accuracy         88.6        # 12      -  \n",
       " 1  % Train Accuracy         93.5        # 15      -  \n",
       " 2        Parameters         7.7m         # 1      -  ,                    Task Dataset Model       Metric name  Metric value  \\\n",
       " 0  Image Classification    SVHN  DCNN  Percentage error          2.16   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 16      -  ,                    Task    Dataset               Model         Metric name  \\\n",
       " 0  Image Classification   CIFAR-10                 NiN  Percentage correct   \n",
       " 1  Image Classification   CIFAR-10                 NiN    Percentage error   \n",
       " 2  Image Classification  CIFAR-100                 NiN  Percentage correct   \n",
       " 3  Image Classification  CIFAR-100                 NiN    Percentage error   \n",
       " 4  Image Classification      MNIST                 NiN    Percentage error   \n",
       " 5  Image Classification       SVHN  Network in Network    Percentage error   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         91.20        # 38      -  \n",
       " 1          8.81        # 17      -  \n",
       " 2         64.30        # 39      -  \n",
       " 3         35.68        # 11      -  \n",
       " 4          0.50         # 5      -  \n",
       " 5          2.35        # 17      -  ,                Task    Dataset   Model        Metric name  Metric value  \\\n",
       " 0   Link Prediction      FB15k  TuckER                MRR         0.795   \n",
       " 1   Link Prediction      FB15k  TuckER  [email protected]         0.892   \n",
       " 2   Link Prediction      FB15k  TuckER  [email protected]         0.833   \n",
       " 3   Link Prediction      FB15k  TuckER  [email protected]         0.741   \n",
       " 4   Link Prediction  FB15k-237  TuckER                MRR         0.358   \n",
       " 5   Link Prediction  FB15k-237  TuckER  [email protected]         0.544   \n",
       " 6   Link Prediction  FB15k-237  TuckER  [email protected]         0.394   \n",
       " 7   Link Prediction  FB15k-237  TuckER  [email protected]         0.266   \n",
       " 8   Link Prediction       WN18  TuckER                MRR         0.953   \n",
       " 9   Link Prediction       WN18  TuckER  [email protected]         0.958   \n",
       " 10  Link Prediction       WN18  TuckER  [email protected]         0.955   \n",
       " 11  Link Prediction       WN18  TuckER  [email protected]         0.949   \n",
       " 12  Link Prediction     WN18RR  TuckER                MRR         0.470   \n",
       " 13  Link Prediction     WN18RR  TuckER  [email protected]         0.526   \n",
       " 14  Link Prediction     WN18RR  TuckER  [email protected]         0.482   \n",
       " 15  Link Prediction     WN18RR  TuckER  [email protected]         0.443   \n",
       " \n",
       "    Global rank Remove  \n",
       " 0          # 2      -  \n",
       " 1          # 2      -  \n",
       " 2          # 1      -  \n",
       " 3          # 1      -  \n",
       " 4          # 2      -  \n",
       " 5          # 2      -  \n",
       " 6          # 1      -  \n",
       " 7          # 1      -  \n",
       " 8          # 2      -  \n",
       " 9          # 3      -  \n",
       " 10         # 2      -  \n",
       " 11         # 2      -  \n",
       " 12         # 3      -  \n",
       " 13         # 3      -  \n",
       " 14         # 1      -  \n",
       " 15         # 2      -  ,               Task Dataset   Model        Metric name  Metric value  \\\n",
       " 0  Link Prediction  WN18RR  M-Walk                MRR         0.437   \n",
       " 1  Link Prediction  WN18RR  M-Walk  [email protected]         0.445   \n",
       " 2  Link Prediction  WN18RR  M-Walk  [email protected]         0.414   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 5      -  \n",
       " 1         # 3      -  \n",
       " 2         # 4      -  ,                        Task Dataset  Model      Metric name  Metric value  \\\n",
       " 0  Text-to-Image Generation     CUB  GAWWN              FID         67.22   \n",
       " 1  Text-to-Image Generation     CUB  GAWWN  Inception score          3.62   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 3      -  \n",
       " 1         # 4      -  ,                   Task                           Dataset      Model  \\\n",
       " 0  Text Classification                           AG News  CCCapsNet   \n",
       " 1   Sentiment Analysis                Amazon Review Full  CCCapsNet   \n",
       " 2   Sentiment Analysis            Amazon Review Polarity  CCCapsNet   \n",
       " 3  Text Classification                           DBpedia  CCCapsNet   \n",
       " 4  Text Classification                        Sogou News  CCCapsNet   \n",
       " 5  Text Classification                    Yahoo! Answers  CCCapsNet   \n",
       " 6   Sentiment Analysis        Yelp Binary classification  CCCapsNet   \n",
       " 7   Sentiment Analysis  Yelp Fine-grained classification  CCCapsNet   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0       Error          7.61        # 11      -  \n",
       " 1    Accuracy         60.95         # 7      -  \n",
       " 2    Accuracy         94.96         # 7      -  \n",
       " 3       Error          1.28        # 12      -  \n",
       " 4    Accuracy         97.25         # 1      -  \n",
       " 5    Accuracy         73.85         # 3      -  \n",
       " 6       Error          3.52         # 8      -  \n",
       " 7       Error         34.15         # 8      -  ,                 Task Dataset     Model Metric name Metric value Global rank  \\\n",
       " 0  Smile Recognition   DISFA  Deep CNN    Accuracy       99.45%         # 1   \n",
       " \n",
       "   Remove  \n",
       " 0      -  ,                   Task                    Dataset    Model     Metric name  \\\n",
       " 0    Face Verification                      IJB-C  FaceNet  TAR @ FAR=0.01   \n",
       " 1    Face Verification  Labeled Faces in the Wild  FaceNet        Accuracy   \n",
       " 2    Face Verification                   MegaFace  FaceNet        Accuracy   \n",
       " 3  Face Identification                   MegaFace  FaceNet        Accuracy   \n",
       " 4    Face Verification           YouTube Faces DB  FaceNet        Accuracy   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0       66.50%         # 3      -  \n",
       " 1       99.63%         # 3      -  \n",
       " 2       86.47%         # 4      -  \n",
       " 3       70.49%         # 6      -  \n",
       " 4       95.12%         # 7      -  ,                   Task  Dataset Model Metric name  Metric value Global rank  \\\n",
       " 0  Text Classification  AG News  VDCN       Error          8.67        # 13   \n",
       " 1  Text Classification  DBpedia  VDCN       Error          1.29        # 13   \n",
       " \n",
       "   Remove  \n",
       " 0      -  \n",
       " 1      -  ,                       Task    Dataset   Model Metric name  Metric value  \\\n",
       " 0  Document Classification  WOS-11967  HDLTex    Accuracy         86.07   \n",
       " 1  Document Classification  WOS-46985  HDLTex    Accuracy         76.58   \n",
       " 2  Document Classification   WOS-5736  HDLTex    Accuracy         90.93   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  \n",
       " 1         # 2      -  \n",
       " 2         # 2      -  ,                       Task   Dataset      Model Metric name Metric value  \\\n",
       " 0      Node Classification  Citeseer        GCN    Accuracy        70.3%   \n",
       " 1      Node Classification      Cora        GCN    Accuracy        81.5%   \n",
       " 2  Document Classification      Cora  Graph-CNN    Accuracy        81.5%   \n",
       " 3      Node Classification      NELL        GCN    Accuracy        66.0%   \n",
       " 4      Node Classification    Pubmed        GCN    Accuracy        79.0%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 5      -  \n",
       " 1         # 4      -  \n",
       " 2         # 5      -  \n",
       " 3         # 1      -  \n",
       " 4         # 4      -  ,                             Task                    Dataset Model Metric name  \\\n",
       " 0  Few-Shot Image Classification  CUB-200 - 0-Shot Learning   SJE    Accuracy   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        50.1%         # 2      -  ,                        Task      Dataset Model Metric name  Metric value  \\\n",
       " 0  Person Re-Identification  Market-1501   DJL      Rank-1          85.1   \n",
       " 1  Person Re-Identification  Market-1501   DJL         MAP          65.5   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 12      -  \n",
       " 1        # 15      -  ,                     Task          Dataset              Model Metric name  \\\n",
       " 0  Semantic Segmentation       Cityscapes          ResNet-38    Mean IoU   \n",
       " 1  Semantic Segmentation  PASCAL VOC 2012  ResNet-38 MS COCO    Mean IoU   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        80.6%         # 6      -  \n",
       " 1        84.9%         # 6      -  ,                  Task     Dataset         Model       Metric name  \\\n",
       " 0  Speech Recognition  WSJ eval92  tdnn + chain  Percentage error   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          2.32         # 1      -  ,                          Task Dataset                                  Model  \\\n",
       " 0  Natural Language Inference    SNLI  300D LSTMN with deep attention fusion   \n",
       " 1  Natural Language Inference    SNLI  300D LSTMN with deep attention fusion   \n",
       " 2  Natural Language Inference    SNLI  300D LSTMN with deep attention fusion   \n",
       " 3  Natural Language Inference    SNLI  450D LSTMN with deep attention fusion   \n",
       " 4  Natural Language Inference    SNLI  450D LSTMN with deep attention fusion   \n",
       " 5  Natural Language Inference    SNLI  450D LSTMN with deep attention fusion   \n",
       " \n",
       "         Metric name Metric value Global rank Remove  \n",
       " 0   % Test Accuracy         85.7        # 30      -  \n",
       " 1  % Train Accuracy         87.3        # 40      -  \n",
       " 2        Parameters         1.7m         # 1      -  \n",
       " 3   % Test Accuracy         86.3        # 26      -  \n",
       " 4  % Train Accuracy         88.5        # 39      -  \n",
       " 5        Parameters         3.4m         # 1      -  ,                            Task           Dataset    Model        Metric name  \\\n",
       " 0  Abstract Anaphora Resolution  The ARRAU Corpus  MR-LSTM  Average Precision   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         43.83         # 1      -  ,                  Task                     Dataset  \\\n",
       " 0  Language Modelling  Penn Treebank (Word Level)   \n",
       " 1  Language Modelling  Penn Treebank (Word Level)   \n",
       " 2  Language Modelling  Penn Treebank (Word Level)   \n",
       " 3  Language Modelling                  WikiText-2   \n",
       " 4  Language Modelling                  WikiText-2   \n",
       " 5  Language Modelling                  WikiText-2   \n",
       " \n",
       "                                      Model            Metric name  \\\n",
       " 0  AWD-LSTM 3-layer with Fraternal dropout  Validation perplexity   \n",
       " 1  AWD-LSTM 3-layer with Fraternal dropout        Test perplexity   \n",
       " 2  AWD-LSTM 3-layer with Fraternal dropout                 Params   \n",
       " 3  AWD-LSTM 3-layer with Fraternal dropout  Validation perplexity   \n",
       " 4  AWD-LSTM 3-layer with Fraternal dropout        Test perplexity   \n",
       " 5  AWD-LSTM 3-layer with Fraternal dropout       Number of params   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0         58.9        # 14      -  \n",
       " 1         56.8        # 16      -  \n",
       " 2          24M         # 1      -  \n",
       " 3         66.8        # 11      -  \n",
       " 4         64.1        # 12      -  \n",
       " 5          34M         # 1      -  ,                           Task                          Dataset  \\\n",
       " 0  Retinal Vessel Segmentation                        CHASE_DB1   \n",
       " 1  Retinal Vessel Segmentation                        CHASE_DB1   \n",
       " 2  Retinal Vessel Segmentation                            DRIVE   \n",
       " 3  Retinal Vessel Segmentation                            DRIVE   \n",
       " 4     Skin Cancer Segmentation  Kaggle Skin Lesion Segmentation   \n",
       " 5     Skin Cancer Segmentation  Kaggle Skin Lesion Segmentation   \n",
       " 6     Lung Nodule Segmentation                             LUNA   \n",
       " 7     Lung Nodule Segmentation                             LUNA   \n",
       " 8  Retinal Vessel Segmentation                            STARE   \n",
       " 9  Retinal Vessel Segmentation                            STARE   \n",
       " \n",
       "             Model Metric name  Metric value Global rank Remove  \n",
       " 0  Residual U-Net    F1 score        0.7800         # 3      -  \n",
       " 1  Residual U-Net         AUC        0.9779         # 3      -  \n",
       " 2  Residual U-Net    F1 score        0.8149         # 3      -  \n",
       " 3  Residual U-Net         AUC        0.9779         # 3      -  \n",
       " 4  Residual U-Net    F1 score        0.8799         # 2      -  \n",
       " 5  Residual U-Net         AUC        0.9396         # 2      -  \n",
       " 6  Residual U-Net    F1 score        0.9690         # 2      -  \n",
       " 7  Residual U-Net         AUC        0.9849         # 2      -  \n",
       " 8  Residual U-Net    F1 score        0.8388         # 2      -  \n",
       " 9  Residual U-Net         AUC        0.9904         # 2      -  ,                    Task         Dataset   Model Metric name  Metric value  \\\n",
       " 0  Sentence Compression  Google Dataset  BiLSTM          F1          0.80   \n",
       " 1  Sentence Compression  Google Dataset  BiLSTM          CR          0.43   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 3      -  \n",
       " 1         # 1      -  ,                            Task Dataset     Model       Metric name  \\\n",
       " 0  Facial Action Unit Detection    BP4D  Baseline  Average Accuracy   \n",
       " 1  Facial Action Unit Detection    BP4D  Baseline                F1   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        56.1%         # 2      -  \n",
       " 1         45.2         # 2      -  ,                      Task           Dataset                Model Metric name  \\\n",
       " 0  Document Summarization  CNN / Daily Mail  BERTSUM+Transformer     ROUGE-1   \n",
       " 1  Document Summarization  CNN / Daily Mail  BERTSUM+Transformer     ROUGE-2   \n",
       " 2  Document Summarization  CNN / Daily Mail  BERTSUM+Transformer     ROUGE-L   \n",
       " \n",
       "    Metric value Global rank  Extradata Remove  \n",
       " 0         43.25         # 1        NaN      -  \n",
       " 1         20.24         # 1        NaN      -  \n",
       " 2         39.63         # 1        NaN      -  ,                      Task                  Dataset   Model Metric name  \\\n",
       " 0  Image Super-Resolution    BSD100 - 4x upscaling  ENet-E        PSNR   \n",
       " 1  Image Super-Resolution    BSD100 - 4x upscaling  ENet-E        SSIM   \n",
       " 2  Image Super-Resolution     Set14 - 4x upscaling  ENet-E        PSNR   \n",
       " 3  Image Super-Resolution     Set14 - 4x upscaling  ENet-E        SSIM   \n",
       " 4  Image Super-Resolution      Set5 - 4x upscaling  ENet-E        PSNR   \n",
       " 5  Image Super-Resolution      Set5 - 4x upscaling  ENet-E        SSIM   \n",
       " 6  Image Super-Resolution  Urban100 - 4x upscaling  ENet-E        PSNR   \n",
       " 7  Image Super-Resolution  Urban100 - 4x upscaling  ENet-E        SSIM   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0       27.5000        # 11      -  \n",
       " 1        0.7326        # 17      -  \n",
       " 2       28.4200        # 12      -  \n",
       " 3        0.7774        # 17      -  \n",
       " 4       31.7400        # 15      -  \n",
       " 5        0.8869        # 20      -  \n",
       " 6       25.6600        # 14      -  \n",
       " 7        0.7703        # 15      -  ,             Task      Dataset         Model Metric name  Metric value  \\\n",
       " 0     Game of Go  ELO Ratings  AlphaGo Zero  ELO Rating          5185   \n",
       " 1  Game of Shogi  ELO Ratings     AlphaZero  ELO Rating          4650   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 1      -  ,                 Task                 Dataset   Model Metric name  \\\n",
       " 0  Transfer Learning  Amazon Review Polarity  EasyTL    Accuracy   \n",
       " 1  Transfer Learning            ImageCLEF-DA  EasyTL    Accuracy   \n",
       " 2  Transfer Learning             Office-Home  EasyTL    Accuracy   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          79.5         # 1      -  \n",
       " 1          88.2         # 1      -  \n",
       " 2          63.3         # 1      -  ,                          Task Dataset    Model           Metric name  \\\n",
       " 0  Image-to-Image Translation    RaFD  StarGAN  Classification Error   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        2.12%         # 1      -  ,                Task Dataset Model      Metric name  Metric value Global rank  \\\n",
       " 0  Object Detection    COCO  FSAF  Bounding Box AP          44.6        # 10   \n",
       " \n",
       "   Remove  \n",
       " 0      -  ,                               Task     Dataset          Model  Metric name  \\\n",
       " 0            Semantic Segmentation  Cityscapes  SwiftNetRN-18     Mean IoU   \n",
       " 1  Real-Time Semantic Segmentation  Cityscapes  SwiftNetRN-18         mIoU   \n",
       " 2  Real-Time Semantic Segmentation  Cityscapes  SwiftNetRN-18  Frame (fps)   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        75.5%         # 9      -  \n",
       " 1        75.5%         # 2      -  \n",
       " 2         39.9         # 3      -  ,                  Task  Dataset   Model        Metric name  Metric value  \\\n",
       " 0  Hypernym Discovery  General  NLP_HZ                MAP          9.37   \n",
       " 1  Hypernym Discovery  General  NLP_HZ                MRR         17.29   \n",
       " 2  Hypernym Discovery  General  NLP_HZ  [email protected]          9.19   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 3      -  \n",
       " 1         # 5      -  \n",
       " 2         # 3      -  ,                   Task                 Dataset    Model Metric name  \\\n",
       " 0  Machine Translation  WMT2014 English-French  ByteNet  BLEU score   \n",
       " 1  Machine Translation  WMT2014 English-German  ByteNet  BLEU score   \n",
       " 2  Machine Translation  WMT2015 English-German  ByteNet  BLEU score   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         23.80        # 29      -  \n",
       " 1         23.75        # 14      -  \n",
       " 2         26.26         # 1      -  ,                                    Task        Dataset Model  \\\n",
       " 0     Unsupervised image classification       CIFAR-10   IIC   \n",
       " 1     Unsupervised image classification       CIFAR-20   IIC   \n",
       " 2    Unsupervised semantic segmentation  COCO-Stuff-15   IIC   \n",
       " 3    Unsupervised semantic segmentation   COCO-Stuff-3   IIC   \n",
       " 4     Unsupervised image classification          MNIST   IIC   \n",
       " 5    Unsupervised semantic segmentation        Potsdam   IIC   \n",
       " 6    Unsupervised semantic segmentation      Potsdam-3   IIC   \n",
       " 7                  Image Classification         STL-10   IIC   \n",
       " 8  Semi-Supervised Image Classification         STL-10   IIC   \n",
       " 9     Unsupervised image classification         STL-10   IIC   \n",
       " \n",
       "           Metric name Metric value Global rank Remove  \n",
       " 0            Accuracy         61.7         # 1      -  \n",
       " 1            Accuracy         25.7         # 1      -  \n",
       " 2            Accuracy         27.7         # 1      -  \n",
       " 3            Accuracy         72.3         # 1      -  \n",
       " 4            Accuracy         99.3         # 1      -  \n",
       " 5            Accuracy         65.1         # 1      -  \n",
       " 6            Accuracy         45.4         # 1      -  \n",
       " 7  Percentage correct         88.8         # 1      -  \n",
       " 8            Accuracy         88.8         # 1      -  \n",
       " 9            Accuracy       61.00%         # 1      -  ,                   Task                 Dataset  \\\n",
       " 0  Machine Translation  WMT2014 English-French   \n",
       " 1  Machine Translation  WMT2015 English-German   \n",
       " \n",
       "                                             Model Metric name  Metric value  \\\n",
       " 0  Unsupervised attentional encoder-decoder + BPE  BLEU score         14.36   \n",
       " 1  Unsupervised attentional encoder-decoder + BPE  BLEU score          6.89   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 30      -  \n",
       " 1         # 6      -  ,                Task                 Dataset     Model         Metric name  \\\n",
       " 0  Speech Synthesis  North American English  Tacotron  Mean Opinion Score   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         4.001         # 4      -  ,                   Task                     Dataset  \\\n",
       " 0   Language Modelling  Penn Treebank (Word Level)   \n",
       " 1   Language Modelling  Penn Treebank (Word Level)   \n",
       " 2   Language Modelling  Penn Treebank (Word Level)   \n",
       " 3   Language Modelling  Penn Treebank (Word Level)   \n",
       " 4   Language Modelling  Penn Treebank (Word Level)   \n",
       " 5   Language Modelling  Penn Treebank (Word Level)   \n",
       " 6   Language Modelling                  WikiText-2   \n",
       " 7   Language Modelling                  WikiText-2   \n",
       " 8   Language Modelling                  WikiText-2   \n",
       " 9   Language Modelling                  WikiText-2   \n",
       " 10  Language Modelling                  WikiText-2   \n",
       " 11  Language Modelling                  WikiText-2   \n",
       " \n",
       "                                   Model            Metric name Metric value  \\\n",
       " 0   AWD-LSTM + continuous cache pointer  Validation perplexity         53.9   \n",
       " 1   AWD-LSTM + continuous cache pointer        Test perplexity         52.8   \n",
       " 2   AWD-LSTM + continuous cache pointer                 Params          24M   \n",
       " 3                              AWD-LSTM  Validation perplexity         60.0   \n",
       " 4                              AWD-LSTM        Test perplexity         57.3   \n",
       " 5                              AWD-LSTM                 Params          24M   \n",
       " 6   AWD-LSTM + continuous cache pointer  Validation perplexity         53.8   \n",
       " 7   AWD-LSTM + continuous cache pointer        Test perplexity         52.0   \n",
       " 8   AWD-LSTM + continuous cache pointer       Number of params          33M   \n",
       " 9                              AWD-LSTM  Validation perplexity         68.6   \n",
       " 10                             AWD-LSTM        Test perplexity         65.8   \n",
       " 11                             AWD-LSTM       Number of params          33M   \n",
       " \n",
       "    Global rank Remove  \n",
       " 0          # 7      -  \n",
       " 1          # 9      -  \n",
       " 2          # 1      -  \n",
       " 3         # 15      -  \n",
       " 4         # 17      -  \n",
       " 5          # 1      -  \n",
       " 6          # 5      -  \n",
       " 7          # 6      -  \n",
       " 8          # 1      -  \n",
       " 9         # 12      -  \n",
       " 10        # 13      -  \n",
       " 11         # 1      -  ,                      Task              Dataset  Model Metric name  \\\n",
       " 0         Image Denoising        BSD68 sigma25  N3Net        PSNR   \n",
       " 1         Image Denoising        BSD68 sigma50  N3Net        PSNR   \n",
       " 2         Image Denoising        BSD68 sigma70  N3Net        PSNR   \n",
       " 3  Image Super-Resolution  Set5 - 4x upscaling  N3Net        PSNR   \n",
       " 4         Image Denoising     Urban100 sigma30  N3Net        PSNR   \n",
       " 5         Image Denoising     Urban100 sigma50  N3Net        PSNR   \n",
       " 6         Image Denoising     Urban100 sigma70  N3Net        PSNR   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         29.30         # 2      -  \n",
       " 1         26.39         # 4      -  \n",
       " 2         25.14         # 3      -  \n",
       " 3         31.50        # 18      -  \n",
       " 4         30.19         # 2      -  \n",
       " 5         26.82         # 4      -  \n",
       " 6         25.15         # 2      -  ,               Task  Dataset    Model Metric name Metric value Global rank  \\\n",
       " 0  Image Retrieval  Oxf105k  DIR+QE*         MAP        87.8%         # 2   \n",
       " 1  Image Retrieval    Oxf5k  DIR+QE*         MAP          89%         # 2   \n",
       " 2  Image Retrieval  Par106k  DIR+QE*    Accuracy        90.5%         # 2   \n",
       " 3  Image Retrieval    Par6k  DIR+QE*    Accuracy        93.8%         # 2   \n",
       " \n",
       "   Remove  \n",
       " 0      -  \n",
       " 1      -  \n",
       " 2      -  \n",
       " 3      -  ,                   Task   Dataset      Model Metric name Metric value  \\\n",
       " 0  Multi-Human Parsing  MHP v1.0  MH-Parser      AP 0.5       50.10%   \n",
       " 1  Multi-Human Parsing  MHP v2.0  MH-Parser      AP 0.5       17.99%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 3      -  \n",
       " 1         # 2      -  ,                        Task  Dataset  \\\n",
       " 0  Table-to-text Generation  WikiBio   \n",
       " 1  Table-to-text Generation  WikiBio   \n",
       " 2  Table-to-text Generation  WikiBio   \n",
       " 3  Table-to-text Generation  WikiBio   \n",
       " \n",
       "                                                Model Metric name  \\\n",
       " 0              Field-gating Seq2seq + dual attention        BLEU   \n",
       " 1              Field-gating Seq2seq + dual attention       ROUGE   \n",
       " 2  Field-gating Seq2seq + dual attention + beam s...        BLEU   \n",
       " 3  Field-gating Seq2seq + dual attention + beam s...       ROUGE   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         44.89         # 1      -  \n",
       " 1         41.21         # 2      -  \n",
       " 2         44.71         # 2      -  \n",
       " 3         41.65         # 1      -  ,                    Task    Dataset                 Model         Metric name  \\\n",
       " 0  Image Classification   CIFAR-10  Tree+Max-Avg pooling  Percentage correct   \n",
       " 1  Image Classification  CIFAR-100  Tree+Max-Avg pooling  Percentage correct   \n",
       " 2  Image Classification      MNIST  Tree+Max-Avg pooling    Percentage error   \n",
       " 3  Image Classification       SVHN  Tree+Max-Avg pooling    Percentage error   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         94.00        # 21      -  \n",
       " 1         67.60        # 32      -  \n",
       " 2          0.30         # 3      -  \n",
       " 3          1.69         # 5      -  ,                Task    Dataset          Model        Metric name  \\\n",
       " 0   Link Prediction      FB15k  Inverse Model                 MR   \n",
       " 1   Link Prediction      FB15k  Inverse Model                MRR   \n",
       " 2   Link Prediction      FB15k  Inverse Model  [email protected]   \n",
       " 3   Link Prediction      FB15k  Inverse Model  [email protected]   \n",
       " 4   Link Prediction      FB15k  Inverse Model  [email protected]   \n",
       " 5   Link Prediction  FB15k-237          ConvE                MRR   \n",
       " 6   Link Prediction  FB15k-237          ConvE  [email protected]   \n",
       " 7   Link Prediction  FB15k-237          ConvE  [email protected]   \n",
       " 8   Link Prediction  FB15k-237          ConvE  [email protected]   \n",
       " 9   Link Prediction       WN18  Inverse Model                MRR   \n",
       " 10  Link Prediction       WN18  Inverse Model  [email protected]   \n",
       " 11  Link Prediction       WN18  Inverse Model  [email protected]   \n",
       " 12  Link Prediction       WN18  Inverse Model  [email protected]   \n",
       " 13  Link Prediction       WN18  Inverse Model                 MR   \n",
       " 14  Link Prediction     WN18RR          ConvE                MRR   \n",
       " 15  Link Prediction     WN18RR          ConvE  [email protected]   \n",
       " 16  Link Prediction     WN18RR          ConvE  [email protected]   \n",
       " 17  Link Prediction     WN18RR          ConvE  [email protected]   \n",
       " 18  Link Prediction   YAGO3-10          ConvE                MRR   \n",
       " 19  Link Prediction   YAGO3-10          ConvE  [email protected]   \n",
       " \n",
       "     Metric value Global rank Remove  \n",
       " 0       2501.000         # 1      -  \n",
       " 1          0.660         # 5      -  \n",
       " 2          0.660         # 5      -  \n",
       " 3          0.659         # 4      -  \n",
       " 4          0.658         # 4      -  \n",
       " 5          0.325         # 4      -  \n",
       " 6          0.501         # 4      -  \n",
       " 7          0.356         # 3      -  \n",
       " 8          0.237         # 3      -  \n",
       " 9          0.963         # 1      -  \n",
       " 10         0.964         # 1      -  \n",
       " 11         0.964         # 1      -  \n",
       " 12         0.953         # 1      -  \n",
       " 13       740.000         # 2      -  \n",
       " 14         0.430         # 6      -  \n",
       " 15         0.520         # 5      -  \n",
       " 16         0.440         # 4      -  \n",
       " 17         0.400         # 5      -  \n",
       " 18         0.440         # 2      -  \n",
       " 19         0.620         # 2      -  ,                                  Task          Dataset            Model  \\\n",
       " 0  Weakly Supervised Object Detection  PASCAL VOC 2007  WSDDN + context   \n",
       " 1  Weakly Supervised Object Detection  PASCAL VOC 2012  WSDDN + context   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0         MAP          36.3        # 13      -  \n",
       " 1         MAP          35.3        # 11      -  ,                         Task        Dataset                             Model  \\\n",
       " 0   Person Re-Identification  DukeMTMC-reID  IDE* + CamStyle + Random Erasing   \n",
       " 1   Person Re-Identification  DukeMTMC-reID  IDE* + CamStyle + Random Erasing   \n",
       " 2   Person Re-Identification  DukeMTMC-reID                   IDE* + CamStyle   \n",
       " 3   Person Re-Identification  DukeMTMC-reID                   IDE* + CamStyle   \n",
       " 4   Person Re-Identification  DukeMTMC-reID                              IDE*   \n",
       " 5   Person Re-Identification  DukeMTMC-reID                              IDE*   \n",
       " 6   Person Re-Identification    Market-1501  IDE* + CamStyle + Random Erasing   \n",
       " 7   Person Re-Identification    Market-1501  IDE* + CamStyle + Random Erasing   \n",
       " 8   Person Re-Identification    Market-1501                   IDE* + CamStyle   \n",
       " 9   Person Re-Identification    Market-1501                   IDE* + CamStyle   \n",
       " 10  Person Re-Identification    Market-1501                              IDE*   \n",
       " 11  Person Re-Identification    Market-1501                              IDE*   \n",
       " \n",
       "    Metric name  Metric value Global rank Remove  \n",
       " 0       Rank-1         78.32         # 7      -  \n",
       " 1          MAP         57.61         # 7      -  \n",
       " 2       Rank-1         75.27         # 9      -  \n",
       " 3          MAP         53.48        # 11      -  \n",
       " 4       Rank-1         72.31        # 12      -  \n",
       " 5          MAP         51.83        # 13      -  \n",
       " 6       Rank-1         89.49         # 6      -  \n",
       " 7          MAP         71.55         # 7      -  \n",
       " 8       Rank-1         88.12         # 9      -  \n",
       " 9          MAP         68.72        # 12      -  \n",
       " 10      Rank-1         85.66        # 11      -  \n",
       " 11         MAP         65.87        # 14      -  ,                  Task                            Dataset        Model  \\\n",
       " 0  Sentiment Analysis                                 MR  RNN-Capsule   \n",
       " 1  Sentiment Analysis  SST-5 Fine-grained classification  RNN-Capsule   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0    Accuracy          83.8         # 2      -  \n",
       " 1    Accuracy          49.3        # 10      -  ,               Task   Dataset                            Model Metric name  \\\n",
       " 0  Link Prediction  Citeseer  Variational graph auto-encoders    Accuracy   \n",
       " 1  Link Prediction      Cora  Variational graph auto-encoders    Accuracy   \n",
       " 2  Link Prediction    Pubmed  Variational graph auto-encoders    Accuracy   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0       91.40%         # 2      -  \n",
       " 1       92.00%         # 2      -  \n",
       " 2       96.50%         # 1      -  ,                      Task     Dataset      Model  \\\n",
       " 0  Visual Object Tracking  VOT2017/18  SA Siam R   \n",
       " \n",
       "                       Metric name  Metric value Global rank Remove  \n",
       " 0  Expected Average Overlap (EAO)         0.337         # 4      -  ,                  Task          Dataset                                  Model  \\\n",
       " 0  6D Pose Estimation  OccludedLINEMOD  Fully-connected CRF + geometric check   \n",
       " \n",
       "   Metric name Metric value Global rank Remove  \n",
       " 0    Accuracy        76.7%         # 2      -  ,                    Task  Dataset           Model           Metric name  \\\n",
       " 0  Pedestrian Detection  Caltech  Checkerboards+  Reasonable Miss Rate   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          17.1        # 16      -  ,              Task       Dataset  Model Metric name  Metric value Global rank  \\\n",
       " 0  Age Estimation          AFAD  CORAL         MAE          3.48         # 1   \n",
       " 1  Age Estimation          CACD  CORAL         MAE          5.35         # 1   \n",
       " 2  Age Estimation  MORPH Album2  CORAL         MAE          2.59         # 1   \n",
       " 3  Age Estimation       UTKFace  CORAL         MAE          5.39         # 1   \n",
       " \n",
       "   Remove  \n",
       " 0      -  \n",
       " 1      -  \n",
       " 2      -  \n",
       " 3      -  ,                     Task          Dataset                             Model  \\\n",
       " 0   Image Classification         ImageNet               JFT-300M Finetuning   \n",
       " 1   Image Classification         ImageNet               JFT-300M Finetuning   \n",
       " 2  Semantic Segmentation  PASCAL VOC 2012  ImageNet+JFT-300M Initialization   \n",
       " \n",
       "       Metric name Metric value Global rank Remove  \n",
       " 0  Top 1 Accuracy        79.2%        # 11      -  \n",
       " 1  Top 5 Accuracy        94.7%         # 8      -  \n",
       " 2        Mean IoU        76.5%        # 12      -  ,                    Task                     Dataset              Model  \\\n",
       " 0   3D Object Detection             KITTI Cars Easy  Frustum PointNets   \n",
       " 1   Object Localization             KITTI Cars Easy  Frustum PointNets   \n",
       " 2   Object Localization             KITTI Cars Hard  Frustum PointNets   \n",
       " 3   3D Object Detection             KITTI Cars Hard  Frustum PointNets   \n",
       " 4   Object Localization         KITTI Cars Moderate  Frustum PointNets   \n",
       " 5   3D Object Detection         KITTI Cars Moderate  Frustum PointNets   \n",
       " 6   3D Object Detection         KITTI Cyclists Easy  Frustum PointNets   \n",
       " 7   Object Localization         KITTI Cyclists Easy  Frustum PointNets   \n",
       " 8   3D Object Detection         KITTI Cyclists Hard  Frustum PointNets   \n",
       " 9   Object Localization         KITTI Cyclists Hard  Frustum PointNets   \n",
       " 10  Object Localization     KITTI Cyclists Moderate  Frustum PointNets   \n",
       " 11  3D Object Detection     KITTI Cyclists Moderate  Frustum PointNets   \n",
       " 12  Object Localization      KITTI Pedestrians Easy  Frustum PointNets   \n",
       " 13  3D Object Detection      KITTI Pedestrians Easy  Frustum PointNets   \n",
       " 14  Object Localization      KITTI Pedestrians Hard  Frustum PointNets   \n",
       " 15  3D Object Detection      KITTI Pedestrians Hard  Frustum PointNets   \n",
       " 16  Object Localization  KITTI Pedestrians Moderate  Frustum PointNets   \n",
       " 17  3D Object Detection  KITTI Pedestrians Moderate  Frustum PointNets   \n",
       " 18  3D Object Detection                    SUN-RGBD  Frustum PointNets   \n",
       " \n",
       "    Metric name Metric value Global rank Remove  \n",
       " 0           AP       81.20%         # 5      -  \n",
       " 1           AP       88.70%         # 2      -  \n",
       " 2           AP       75.33%         # 2      -  \n",
       " 3           AP       62.19%         # 5      -  \n",
       " 4           AP       84.00%         # 1      -  \n",
       " 5           AP       70.39%         # 7      -  \n",
       " 6           AP       71.96%         # 1      -  \n",
       " 7           AP       75.38%         # 1      -  \n",
       " 8           AP       50.39%         # 1      -  \n",
       " 9           AP       54.68%         # 1      -  \n",
       " 10          AP       61.96%         # 1      -  \n",
       " 11          AP       56.77%         # 2      -  \n",
       " 12          AP       58.09%         # 1      -  \n",
       " 13          AP       51.21%         # 2      -  \n",
       " 14          AP       47.20%         # 1      -  \n",
       " 15          AP       40.23%         # 3      -  \n",
       " 16          AP       50.22%         # 1      -  \n",
       " 17          AP       44.89%         # 1      -  \n",
       " 18         MAP        54.0%         # 1      -  ,                               Task                         Dataset Model  \\\n",
       " 0  Aspect-Based Sentiment Analysis  SemEval 2014 Task 4 Sub Task 2   IAN   \n",
       " 1  Aspect-Based Sentiment Analysis  SemEval 2014 Task 4 Sub Task 2   IAN   \n",
       " \n",
       "         Metric name  Metric value Global rank Remove  \n",
       " 0  Restaurant (Acc)          78.6        # 21      -  \n",
       " 1      Laptop (Acc)          72.1         # 8      -  ,                      Task     Dataset      Model  \\\n",
       " 0  Visual Object Tracking  VOT2017/18  SiamRPN++   \n",
       " \n",
       "                       Metric name  Metric value Global rank Remove  \n",
       " 0  Expected Average Overlap (EAO)         0.414         # 1      -  ,                             Task Dataset Model Metric name Metric value  \\\n",
       " 0  Multimodal Sentiment Analysis    MOSI  MARN    Accuracy        77.1%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 3      -  ,            Task                         Dataset             Model Metric name  \\\n",
       " 0   Atari Games                Atari 2600 Alien  Bootstrapped DQN       Score   \n",
       " 1   Atari Games               Atari 2600 Amidar  Bootstrapped DQN       Score   \n",
       " 2   Atari Games              Atari 2600 Assault  Bootstrapped DQN       Score   \n",
       " 3   Atari Games              Atari 2600 Asterix  Bootstrapped DQN       Score   \n",
       " 4   Atari Games            Atari 2600 Asteroids  Bootstrapped DQN       Score   \n",
       " 5   Atari Games             Atari 2600 Atlantis  Bootstrapped DQN       Score   \n",
       " 6   Atari Games           Atari 2600 Bank Heist  Bootstrapped DQN       Score   \n",
       " 7   Atari Games          Atari 2600 Battle Zone  Bootstrapped DQN       Score   \n",
       " 8   Atari Games           Atari 2600 Beam Rider  Bootstrapped DQN       Score   \n",
       " 9   Atari Games              Atari 2600 Bowling  Bootstrapped DQN       Score   \n",
       " 10  Atari Games               Atari 2600 Boxing  Bootstrapped DQN       Score   \n",
       " 11  Atari Games             Atari 2600 Breakout  Bootstrapped DQN       Score   \n",
       " 12  Atari Games            Atari 2600 Centipede  Bootstrapped DQN       Score   \n",
       " 13  Atari Games      Atari 2600 Chopper Command  Bootstrapped DQN       Score   \n",
       " 14  Atari Games        Atari 2600 Crazy Climber  Bootstrapped DQN       Score   \n",
       " 15  Atari Games         Atari 2600 Demon Attack  Bootstrapped DQN       Score   \n",
       " 16  Atari Games          Atari 2600 Double Dunk  Bootstrapped DQN       Score   \n",
       " 17  Atari Games               Atari 2600 Enduro  Bootstrapped DQN       Score   \n",
       " 18  Atari Games        Atari 2600 Fishing Derby  Bootstrapped DQN       Score   \n",
       " 19  Atari Games              Atari 2600 Freeway  Bootstrapped DQN       Score   \n",
       " 20  Atari Games            Atari 2600 Frostbite  Bootstrapped DQN       Score   \n",
       " 21  Atari Games               Atari 2600 Gopher  Bootstrapped DQN       Score   \n",
       " 22  Atari Games             Atari 2600 Gravitar  Bootstrapped DQN       Score   \n",
       " 23  Atari Games                 Atari 2600 HERO  Bootstrapped DQN       Score   \n",
       " 24  Atari Games           Atari 2600 Ice Hockey  Bootstrapped DQN       Score   \n",
       " 25  Atari Games           Atari 2600 James Bond  Bootstrapped DQN       Score   \n",
       " 26  Atari Games             Atari 2600 Kangaroo  Bootstrapped DQN       Score   \n",
       " 27  Atari Games                Atari 2600 Krull  Bootstrapped DQN       Score   \n",
       " 28  Atari Games       Atari 2600 Kung-Fu Master  Bootstrapped DQN       Score   \n",
       " 29  Atari Games  Atari 2600 Montezuma's Revenge  Bootstrapped DQN       Score   \n",
       " 30  Atari Games           Atari 2600 Ms. Pacman  Bootstrapped DQN       Score   \n",
       " 31  Atari Games       Atari 2600 Name This Game  Bootstrapped DQN       Score   \n",
       " 32  Atari Games                 Atari 2600 Pong  Bootstrapped DQN       Score   \n",
       " 33  Atari Games          Atari 2600 Private Eye  Bootstrapped DQN       Score   \n",
       " 34  Atari Games               Atari 2600 Q*Bert  Bootstrapped DQN       Score   \n",
       " 35  Atari Games           Atari 2600 River Raid  Bootstrapped DQN       Score   \n",
       " 36  Atari Games          Atari 2600 Road Runner  Bootstrapped DQN       Score   \n",
       " 37  Atari Games             Atari 2600 Robotank  Bootstrapped DQN       Score   \n",
       " 38  Atari Games             Atari 2600 Seaquest  Bootstrapped DQN       Score   \n",
       " 39  Atari Games       Atari 2600 Space Invaders  Bootstrapped DQN       Score   \n",
       " 40  Atari Games          Atari 2600 Star Gunner  Bootstrapped DQN       Score   \n",
       " 41  Atari Games               Atari 2600 Tennis  Bootstrapped DQN       Score   \n",
       " 42  Atari Games           Atari 2600 Time Pilot  Bootstrapped DQN       Score   \n",
       " 43  Atari Games            Atari 2600 Tutankham  Bootstrapped DQN       Score   \n",
       " 44  Atari Games          Atari 2600 Up and Down  Bootstrapped DQN       Score   \n",
       " 45  Atari Games              Atari 2600 Venture  Bootstrapped DQN       Score   \n",
       " 46  Atari Games        Atari 2600 Video Pinball  Bootstrapped DQN       Score   \n",
       " 47  Atari Games        Atari 2600 Wizard of Wor  Bootstrapped DQN       Score   \n",
       " 48  Atari Games               Atari 2600 Zaxxon  Bootstrapped DQN       Score   \n",
       " \n",
       "     Metric value Global rank Remove  \n",
       " 0         2436.6         # 9      -  \n",
       " 1         1272.5         # 7      -  \n",
       " 2         8047.1         # 6      -  \n",
       " 3        19713.2         # 9      -  \n",
       " 4         1032.0        # 17      -  \n",
       " 5       994500.0         # 2      -  \n",
       " 6         1208.0         # 4      -  \n",
       " 7        38666.7         # 2      -  \n",
       " 8        23429.8         # 6      -  \n",
       " 9           60.2         # 8      -  \n",
       " 10          93.2         # 7      -  \n",
       " 11         855.0         # 1      -  \n",
       " 12        4553.5        # 15      -  \n",
       " 13        4100.0        # 15      -  \n",
       " 14      137925.9         # 7      -  \n",
       " 15       82610.0         # 6      -  \n",
       " 16           3.0         # 4      -  \n",
       " 17        1591.0        # 10      -  \n",
       " 18          26.0         # 6      -  \n",
       " 19          33.9         # 2      -  \n",
       " 20        2181.4        # 12      -  \n",
       " 21       17438.4         # 9      -  \n",
       " 22         286.1        # 19      -  \n",
       " 23       21021.3         # 8      -  \n",
       " 24          -1.3         # 6      -  \n",
       " 25        1663.5         # 5      -  \n",
       " 26       14862.5         # 3      -  \n",
       " 27        8627.9         # 8      -  \n",
       " 28       36733.3         # 7      -  \n",
       " 29         100.0        # 11      -  \n",
       " 30        2983.3         # 8      -  \n",
       " 31       11501.1         # 9      -  \n",
       " 32          20.9         # 2      -  \n",
       " 33        1812.5         # 5      -  \n",
       " 34       15092.7         # 9      -  \n",
       " 35       12845.0         # 9      -  \n",
       " 36       51500.0        # 10      -  \n",
       " 37          66.6         # 1      -  \n",
       " 38        9083.1        # 11      -  \n",
       " 39        2893.0        # 10      -  \n",
       " 40       55725.0        # 14      -  \n",
       " 41           0.0         # 8      -  \n",
       " 42        9079.4         # 6      -  \n",
       " 43         214.8         # 5      -  \n",
       " 44       26231.0         # 8      -  \n",
       " 45         212.5        # 11      -  \n",
       " 46      811610.0         # 2      -  \n",
       " 47        6804.7        # 11      -  \n",
       " 48       11491.7         # 7      -  ,                                 Task Dataset                  Model  \\\n",
       " 0                 Unsupervised MNIST   MNIST  Bidirectional InfoGAN   \n",
       " 1  Unsupervised image classification   MNIST  Bidirectional InfoGAN   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0    Accuracy         96.61         # 2      -  \n",
       " 1    Accuracy         96.61         # 2      -  ,                             Task                    Dataset Model Metric name  \\\n",
       " 0  Synthetic-to-Real Translation  GTAV-to-Cityscapes Labels   CDA        mIoU   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          28.9         # 6      -  ,                   Task                 Dataset            Model  \\\n",
       " 0   Language Modelling        One Billion Word  High-Budget MoE   \n",
       " 1   Language Modelling        One Billion Word  High-Budget MoE   \n",
       " 2   Language Modelling        One Billion Word   Low-Budget MoE   \n",
       " 3   Language Modelling        One Billion Word   Low-Budget MoE   \n",
       " 4  Machine Translation  WMT2014 English-French              MoE   \n",
       " 5  Machine Translation  WMT2014 English-German              MoE   \n",
       " \n",
       "         Metric name Metric value Global rank Remove  \n",
       " 0               PPL         28.0         # 7      -  \n",
       " 1  Number of params           5B         # 1      -  \n",
       " 2               PPL         34.1        # 11      -  \n",
       " 3  Number of params           5B         # 1      -  \n",
       " 4        BLEU score        40.56        # 10      -  \n",
       " 5        BLEU score        26.03        # 12      -  ,                     Task         Dataset   Model Metric name  Metric value  \\\n",
       " 0  Semantic Segmentation  PASCAL Context  HO CRF        mIoU          41.3   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 9      -  ,                     Task     Dataset      Model Metric name Metric value  \\\n",
       " 0  Semantic Segmentation  Cityscapes  Mapillary    Mean IoU        82.0%   \n",
       " \n",
       "   Global rank  Extradata Remove  \n",
       " 0         # 2        NaN      -  ,                   Task                     Dataset  \\\n",
       " 0   Language Modelling                     enwiki8   \n",
       " 1   Language Modelling                     enwiki8   \n",
       " 2   Language Modelling                     enwiki8   \n",
       " 3   Language Modelling                     enwiki8   \n",
       " 4   Language Modelling                     enwiki8   \n",
       " 5   Language Modelling                     enwiki8   \n",
       " 6   Language Modelling                Hutter Prize   \n",
       " 7   Language Modelling                Hutter Prize   \n",
       " 8   Language Modelling                Hutter Prize   \n",
       " 9   Language Modelling                Hutter Prize   \n",
       " 10  Language Modelling                Hutter Prize   \n",
       " 11  Language Modelling                Hutter Prize   \n",
       " 12  Language Modelling            One Billion Word   \n",
       " 13  Language Modelling            One Billion Word   \n",
       " 14  Language Modelling            One Billion Word   \n",
       " 15  Language Modelling            One Billion Word   \n",
       " 16  Language Modelling  Penn Treebank (Word Level)   \n",
       " 17  Language Modelling  Penn Treebank (Word Level)   \n",
       " 18  Language Modelling  Penn Treebank (Word Level)   \n",
       " 19  Language Modelling                       Text8   \n",
       " 20  Language Modelling                       Text8   \n",
       " 21  Language Modelling                WikiText-103   \n",
       " 22  Language Modelling                WikiText-103   \n",
       " 23  Language Modelling                WikiText-103   \n",
       " 24  Language Modelling                WikiText-103   \n",
       " 25  Language Modelling                WikiText-103   \n",
       " 26  Language Modelling                WikiText-103   \n",
       " \n",
       "                          Model              Metric name Metric value  \\\n",
       " 0   Transformer-XL - 12 layers  Bit per Character (BPC)         1.06   \n",
       " 1   Transformer-XL - 12 layers         Number of params          41M   \n",
       " 2   Transformer-XL - 24 layers  Bit per Character (BPC)         0.99   \n",
       " 3   Transformer-XL - 24 layers         Number of params         277M   \n",
       " 4   Transformer-XL - 18 layers  Bit per Character (BPC)         1.03   \n",
       " 5   Transformer-XL - 18 layers         Number of params          88M   \n",
       " 6      18-layer Transformer-XL  Bit per Character (BPC)         1.03   \n",
       " 7      18-layer Transformer-XL         Number of params          88M   \n",
       " 8      12-layer Transformer-XL  Bit per Character (BPC)         1.06   \n",
       " 9      12-layer Transformer-XL         Number of params          41M   \n",
       " 10     24-layer Transformer-XL  Bit per Character (BPC)         0.99   \n",
       " 11     24-layer Transformer-XL         Number of params         277M   \n",
       " 12         Transformer-XL Base                      PPL         23.5   \n",
       " 13         Transformer-XL Base         Number of params        0.46B   \n",
       " 14        Transformer-XL Large                      PPL         21.8   \n",
       " 15        Transformer-XL Large         Number of params         0.8B   \n",
       " 16              Transformer-XL    Validation perplexity        56.72   \n",
       " 17              Transformer-XL          Test perplexity        54.55   \n",
       " 18              Transformer-XL                   Params          24M   \n",
       " 19  Transformer-XL - 24 layers  Bit per Character (BPC)         1.08   \n",
       " 20  Transformer-XL - 24 layers         Number of params         277M   \n",
       " 21        Transformer-XL Large    Validation perplexity         18.2   \n",
       " 22        Transformer-XL Large          Test perplexity         18.3   \n",
       " 23        Transformer-XL Large         Number of params         257M   \n",
       " 24     Transformer-XL Standard    Validation perplexity         23.1   \n",
       " 25     Transformer-XL Standard          Test perplexity         24.0   \n",
       " 26     Transformer-XL Standard         Number of params         151M   \n",
       " \n",
       "    Global rank Remove  \n",
       " 0          # 5      -  \n",
       " 1          # 1      -  \n",
       " 2          # 3      -  \n",
       " 3          # 1      -  \n",
       " 4          # 4      -  \n",
       " 5          # 1      -  \n",
       " 6          # 2      -  \n",
       " 7          # 1      -  \n",
       " 8          # 3      -  \n",
       " 9          # 1      -  \n",
       " 10         # 1      -  \n",
       " 11         # 1      -  \n",
       " 12         # 3      -  \n",
       " 13         # 1      -  \n",
       " 14         # 1      -  \n",
       " 15         # 1      -  \n",
       " 16        # 11      -  \n",
       " 17        # 13      -  \n",
       " 18         # 1      -  \n",
       " 19         # 3      -  \n",
       " 20         # 1      -  \n",
       " 21         # 2      -  \n",
       " 22         # 2      -  \n",
       " 23         # 1      -  \n",
       " 24         # 3      -  \n",
       " 25         # 4      -  \n",
       " 26         # 1      -  ,                               Task                         Dataset Model  \\\n",
       " 0  Aspect-Based Sentiment Analysis  SemEval 2014 Task 4 Sub Task 2  MGAN   \n",
       " 1  Aspect-Based Sentiment Analysis  SemEval 2014 Task 4 Sub Task 2  MGAN   \n",
       " \n",
       "         Metric name  Metric value Global rank Remove  \n",
       " 0  Restaurant (Acc)         81.49         # 5      -  \n",
       " 1      Laptop (Acc)         76.21        # 22      -  ,                  Task   Dataset            Model Metric name  Metric value  \\\n",
       " 0  Question Answering  MS MARCO  Deep Cascade QA     Rouge-L         52.01   \n",
       " 1  Question Answering  MS MARCO  Deep Cascade QA      BLEU-1         54.64   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  \n",
       " 1         # 1      -  ,               Task        Dataset    Model Metric name  Metric value  \\\n",
       " 0  Text Generation  Chinese Poems  LeakGAN      BLEU-2         0.881   \n",
       " 1  Text Generation  COCO Captions  LeakGAN      BLEU-2         0.950   \n",
       " 2  Text Generation  COCO Captions  LeakGAN      BLEU-3         0.880   \n",
       " 3  Text Generation  COCO Captions  LeakGAN      BLEU-4         0.778   \n",
       " 4  Text Generation  COCO Captions  LeakGAN      BLEU-5         0.686   \n",
       " 5  Text Generation  EMNLP2017 WMT  LeakGAN      BLEU-2         0.956   \n",
       " 6  Text Generation  EMNLP2017 WMT  LeakGAN      BLEU-3         0.819   \n",
       " 7  Text Generation  EMNLP2017 WMT  LeakGAN      BLEU-4         0.627   \n",
       " 8  Text Generation  EMNLP2017 WMT  LeakGAN      BLEU-5         0.498   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 1      -  \n",
       " 2         # 1      -  \n",
       " 3         # 1      -  \n",
       " 4         # 1      -  \n",
       " 5         # 1      -  \n",
       " 6         # 1      -  \n",
       " 7         # 1      -  \n",
       " 8         # 1      -  ,                  Task       Dataset                          Model  \\\n",
       " 0  Language Modelling  WikiText-103  LSTM + Hebbian + Cache + MbPA   \n",
       " 1  Language Modelling  WikiText-103  LSTM + Hebbian + Cache + MbPA   \n",
       " 2  Language Modelling  WikiText-103                 LSTM + Hebbian   \n",
       " 3  Language Modelling  WikiText-103                 LSTM + Hebbian   \n",
       " 4  Language Modelling  WikiText-103                           LSTM   \n",
       " 5  Language Modelling  WikiText-103                           LSTM   \n",
       " \n",
       "              Metric name  Metric value Global rank Remove  \n",
       " 0  Validation perplexity          29.0         # 4      -  \n",
       " 1        Test perplexity          29.2         # 6      -  \n",
       " 2  Validation perplexity          34.1         # 6      -  \n",
       " 3        Test perplexity          34.3         # 8      -  \n",
       " 4  Validation perplexity          36.0         # 7      -  \n",
       " 5        Test perplexity          36.4         # 9      -  ,                          Task  Dataset  \\\n",
       " 0  Speech Emotion Recognition  IEMOCAP   \n",
       " \n",
       "                                                Model Metric name  \\\n",
       " 0  Ensemble (Random Forests + Gradient Boosted Tr...          F1   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          71.8         # 1      -  ,                               Task     Dataset  Model  Metric name  \\\n",
       " 0  Real-Time Semantic Segmentation      CamVid  ICNet         mIoU   \n",
       " 1  Real-Time Semantic Segmentation      CamVid  ICNet    Time (ms)   \n",
       " 2  Real-Time Semantic Segmentation      CamVid  ICNet  Frame (fps)   \n",
       " 3  Real-Time Semantic Segmentation  Cityscapes  ICNet         mIoU   \n",
       " 4  Real-Time Semantic Segmentation  Cityscapes  ICNet    Time (ms)   \n",
       " 5  Real-Time Semantic Segmentation  Cityscapes  ICNet  Frame (fps)   \n",
       " 6            Semantic Segmentation  Cityscapes  ICNet     Mean IoU   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        67.1%         # 3      -  \n",
       " 1           36         # 1      -  \n",
       " 2         27.8         # 1      -  \n",
       " 3        70.6%         # 5      -  \n",
       " 4           33         # 2      -  \n",
       " 5         30.3         # 4      -  \n",
       " 6        70.6%        # 11      -  ,                    Task   Dataset                              Model  \\\n",
       " 0  Image Classification  CIFAR-10  WRN + fixup init + mixup + cutout   \n",
       " 1  Image Classification  CIFAR-10  WRN + fixup init + mixup + cutout   \n",
       " 2  Image Classification      SVHN  WRN + fixup init + mixup + cutout   \n",
       " \n",
       "           Metric name  Metric value Global rank Remove  \n",
       " 0  Percentage correct          97.7         # 4      -  \n",
       " 1    Percentage error           2.3         # 4      -  \n",
       " 2    Percentage error           1.4         # 1      -  ,                    Task   Dataset        Model     Metric name Metric value  \\\n",
       " 0  Image Classification  ImageNet  NASNET-A(6)  Top 1 Accuracy        82.7%   \n",
       " 1  Image Classification  ImageNet  NASNET-A(6)  Top 5 Accuracy        96.2%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 4      -  \n",
       " 1         # 3      -  ,                   Task     Dataset                       Model Metric name  \\\n",
       " 0  Multi-Task Learning      CelebA                     MGDA-UB       Error   \n",
       " 1  Multi-Task Learning  Cityscapes  MultiObjectiveOptimization        mIoU   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          8.25         # 1      -  \n",
       " 1         66.63         # 1      -  ,                  Task                    Dataset  \\\n",
       " 0  Speech Recognition  swb_hub_500 WER fullSWBCH   \n",
       " 1  Speech Recognition       Switchboard + Hub500   \n",
       " \n",
       "                              Model       Metric name  Metric value  \\\n",
       " 0  ResNet + BiLSTMs acoustic model  Percentage error          10.3   \n",
       " 1  ResNet + BiLSTMs acoustic model  Percentage error           5.5   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 1      -  ,                      Task     Dataset     Model  \\\n",
       " 0  Visual Object Tracking  VOT2017/18  SiamMask   \n",
       " \n",
       "                       Metric name  Metric value Global rank Remove  \n",
       " 0  Expected Average Overlap (EAO)          0.38         # 2      -  ,                    Task   Dataset    Model Metric name Metric value  \\\n",
       " 0  Graph Classification    COLLAB  CapsGNN    Accuracy       79.62%   \n",
       " 1  Graph Classification       D&D  CapsGNN    Accuracy       75.38%   \n",
       " 2  Graph Classification   ENZYMES  CapsGNN    Accuracy       54.67%   \n",
       " 3  Graph Classification    IMDb-B  CapsGNN    Accuracy       73.10%   \n",
       " 4  Graph Classification    IMDb-M  CapsGNN    Accuracy       50.27%   \n",
       " 5  Graph Classification     MUTAG  CapsGNN    Accuracy       86.67%   \n",
       " 6  Graph Classification      NCI1  CapsGNN    Accuracy       78.35%   \n",
       " 7  Graph Classification  PROTEINS  CapsGNN    Accuracy       76.28%   \n",
       " 8  Graph Classification   RE-M12K  CapsGNN    Accuracy       46.62%   \n",
       " 9  Graph Classification    RE-M5K  CapsGNN    Accuracy       52.88%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 2      -  \n",
       " 2         # 1      -  \n",
       " 3         # 2      -  \n",
       " 4         # 1      -  \n",
       " 5         # 3      -  \n",
       " 6         # 2      -  \n",
       " 7         # 1      -  \n",
       " 8         # 1      -  \n",
       " 9         # 1      -  ,                      Task     Dataset                    Model Metric name  \\\n",
       " 0  Coreference Resolution  CoNLL 2012  (Lee et al., 2017)+ELMo      Avg F1   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          73.0         # 1      -  ,                          Task Dataset                                  Model  \\\n",
       " 0  Natural Language Inference    SNLI  Distance-based Self-Attention Network   \n",
       " 1  Natural Language Inference    SNLI  Distance-based Self-Attention Network   \n",
       " 2  Natural Language Inference    SNLI  Distance-based Self-Attention Network   \n",
       " \n",
       "         Metric name Metric value Global rank Remove  \n",
       " 0   % Test Accuracy         86.3        # 26      -  \n",
       " 1  % Train Accuracy         89.6        # 34      -  \n",
       " 2        Parameters         4.7m         # 1      -  ,                 Task Dataset  Model     Metric name Metric value Global rank  \\\n",
       " 0  Face Verification   IJB-C  MN-vc  TAR @ FAR=0.01       92.70%         # 2   \n",
       " \n",
       "   Remove  \n",
       " 0      -  ,                              Task                 Dataset             Model  \\\n",
       " 0                CCG Supertagging                 CCGBank      Clark et al.   \n",
       " 1  Named Entity Recognition (NER)    CoNLL 2003 (English)  CVT + Multi-Task   \n",
       " 2  Named Entity Recognition (NER)  Ontonotes v5 (English)  CVT + Multi-Task   \n",
       " 3              Dependency Parsing           Penn Treebank  CVT + Multi-Task   \n",
       " 4              Dependency Parsing           Penn Treebank  CVT + Multi-Task   \n",
       " 5              Dependency Parsing           Penn Treebank  CVT + Multi-Task   \n",
       " \n",
       "   Metric name Metric value Global rank Remove  \n",
       " 0    Accuracy         96.1         # 1      -  \n",
       " 1          F1        92.61         # 4      -  \n",
       " 2          F1        88.81         # 2      -  \n",
       " 3         POS          ---         # 4      -  \n",
       " 4         UAS        96.61         # 1      -  \n",
       " 5         LAS        95.02         # 1      -  ,                      Task       Dataset           Model   Metric name  \\\n",
       " 0  Video Object Detection  ImageNet VID  FGFA + Seq-NMS           MAP   \n",
       " 1  Video Object Detection  ImageNet VID  FGFA + Seq-NMS  runtime (ms)   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        80.1%         # 1      -  \n",
       " 1          954         # 1      -  ,                        Task     Dataset             Model Metric name  \\\n",
       " 0  Brain Tumor Segmentation  BRATS-2015  CNN + 3D filters  Dice Score   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0          85%         # 1      -  ,                      Task      Dataset Model Metric name Metric value  \\\n",
       " 0          Face Alignment  AFLW2000-3D   PRN    Mean NME        3.62%   \n",
       " 1  3D Face Reconstruction  AFLW2000-3D   PRN    Mean NME      3.9625%   \n",
       " 2          Face Alignment    AFLW-LFPA   FPN    Mean NME        2.93%   \n",
       " 3  3D Face Reconstruction     Florence   PRN    Mean NME      3.7551%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  \n",
       " 1         # 1      -  \n",
       " 2         # 1      -  \n",
       " 3         # 1      -  ,                             Task                                Dataset  \\\n",
       " 0  Facial Expression Recognition             Real-World Affective Faces   \n",
       " 1  Facial Expression Recognition  Static Facial Expressions in the Wild   \n",
       " \n",
       "                 Model Metric name Metric value Global rank Remove  \n",
       " 0  Covariance Pooling    Accuracy        87.0%         # 1      -  \n",
       " 1  Covariance Pooling    Accuracy       58.14%         # 1      -  ,                    Task   Dataset   Model         Metric name  Metric value  \\\n",
       " 0  Image Classification  CIFAR-10  PCANet  Percentage correct          78.7   \n",
       " 1  Image Classification     MNIST  PCANet    Percentage error           0.6   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 59      -  \n",
       " 1         # 6      -  ,                    Task    Dataset           Model         Metric name  \\\n",
       " 0  Image Classification  CIFAR-100     Res2NeXt-29  Percentage correct   \n",
       " 1  Image Classification  CIFAR-100     Res2NeXt-29    Percentage error   \n",
       " 2  Image Classification   ImageNet  Res2Net-DLA-60      Top 1 Accuracy   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        83.44         # 4      -  \n",
       " 1        16.56         # 2      -  \n",
       " 2       79.47%         # 9      -  ,                        Task      Dataset Model Metric name  Metric value  \\\n",
       " 0  Person Re-Identification  Market-1501   PDF      Rank-1         84.14   \n",
       " 1  Person Re-Identification  Market-1501   PDF         MAP         63.41   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 14      -  \n",
       " 1        # 17      -  ,                      Task              Dataset      Model Metric name  \\\n",
       " 0  Video Super-Resolution  Vid4 - 4x upscaling  RBPN/6-PF        PSNR   \n",
       " 1  Video Super-Resolution  Vid4 - 4x upscaling  RBPN/6-PF        SSIM   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0        27.120         # 2      -  \n",
       " 1         0.818         # 9      -  ,                      Task   Dataset                      Model Metric name  \\\n",
       " 0  Dense Object Detection  SKU-110K  Soft-IoU + EM-Merger unit          AP   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         0.492         # 1      -  ,                              Task Dataset               Model Metric name  \\\n",
       " 0       One-Shot Object Detection    COCO  Siamese Mask R-CNN      AP 0.5   \n",
       " 1  One-Shot Instance Segmentation    COCO  Siamese Mask R-CNN      AP 0.5   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          16.3         # 1      -  \n",
       " 1          14.5         # 1      -  ,                  Task   Dataset Model Metric name  Metric value Global rank  \\\n",
       " 0  Text Summarization  GigaWord   CGU     ROUGE-1          36.3         # 4   \n",
       " 1  Text Summarization  GigaWord   CGU     ROUGE-2          18.0         # 2   \n",
       " 2  Text Summarization  GigaWord   CGU     ROUGE-L          33.8         # 5   \n",
       " \n",
       "   Remove  \n",
       " 0      -  \n",
       " 1      -  \n",
       " 2      -  ,                  Task Dataset  \\\n",
       " 0  Question Answering  QASent   \n",
       " 1  Question Answering  QASent   \n",
       " 2  Question Answering  QASent   \n",
       " 3  Question Answering  QASent   \n",
       " 4  Question Answering  WikiQA   \n",
       " 5  Question Answering  WikiQA   \n",
       " 6  Question Answering  WikiQA   \n",
       " 7  Question Answering  WikiQA   \n",
       " \n",
       "                                               Model Metric name  Metric value  \\\n",
       " 0                                  Paragraph vector         MAP        0.5213   \n",
       " 1                                  Paragraph vector         MRR        0.6023   \n",
       " 2  Paragraph vector (lexical overlap + dist output)         MAP        0.6762   \n",
       " 3  Paragraph vector (lexical overlap + dist output)         MRR        0.7514   \n",
       " 4  Paragraph vector (lexical overlap + dist output)         MAP        0.5976   \n",
       " 5  Paragraph vector (lexical overlap + dist output)         MRR        0.6058   \n",
       " 6                                  Paragraph vector         MAP        0.5110   \n",
       " 7                                  Paragraph vector         MRR        0.5160   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 7      -  \n",
       " 1         # 7      -  \n",
       " 2         # 4      -  \n",
       " 3         # 4      -  \n",
       " 4        # 12      -  \n",
       " 5        # 13      -  \n",
       " 6        # 13      -  \n",
       " 7        # 14      -  ,                  Task Dataset Model Metric name  Metric value Global rank  \\\n",
       " 0  Unsupervised MNIST   MNIST   IIC    Accuracy          99.3         # 1   \n",
       " \n",
       "   Remove  \n",
       " 0      -  ,                  Task             Dataset                Model  \\\n",
       " 0  Question Answering  AI2 Kaggle Dataset         OUR APPROACH   \n",
       " 1  Question Answering  AI2 Kaggle Dataset          IR Baseline   \n",
       " 2  Question Answering  AI2 Kaggle Dataset                 IR++   \n",
       " 3  Question Answering  AI2 Kaggle Dataset  Our Approach w/o IR   \n",
       " \n",
       "          Metric name  Metric value Global rank Remove  \n",
       " 0  [email protected]         54.00         # 4      -  \n",
       " 1  [email protected]         47.20         # 1      -  \n",
       " 2  [email protected]         50.70         # 3      -  \n",
       " 3  [email protected]         50.54         # 2      -  ,                               Task           Dataset Model  \\\n",
       " 0  Sequential Image Classification  Sequential MNIST  LSTM   \n",
       " 1  Sequential Image Classification  Sequential MNIST  LSTM   \n",
       " \n",
       "            Metric name Metric value Global rank Remove  \n",
       " 0  Unpermuted Accuracy        98.2%         # 3      -  \n",
       " 1    Permuted Accuracy          88%         # 4      -  ,                         Task Dataset           Model Metric name  \\\n",
       " 0  Facial Landmark Detection    300W  Pose-Invariant         NME   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0           6.3         # 2      -  ,                 Task           Dataset           Model Metric name  \\\n",
       " 0  Sarcasm Detection    SARC (all-bal)  Bag-of-Bigrams    Accuracy   \n",
       " 1  Sarcasm Detection    SARC (pol-bal)  Bag-of-Bigrams    Accuracy   \n",
       " 2  Sarcasm Detection  SARC (pol-unbal)    Bag-of-Words      Avg F1   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          75.8         # 2      -  \n",
       " 1          76.5         # 1      -  \n",
       " 2          27.0         # 1      -  ,                   Task                   Dataset                Model  \\\n",
       " 0  Machine Translation  IWSLT2015 English-German  Pervasive Attention   \n",
       " 1  Machine Translation  IWSLT2015 German-English  Pervasive Attention   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0  BLEU score         27.99         # 3      -  \n",
       " 1  BLEU score         34.18         # 2      -  ,                                     Task   Dataset          Model  \\\n",
       " 0  Dense Pixel Correspondence Estimation  HPatches  DeepMatching*   \n",
       " 1  Dense Pixel Correspondence Estimation  HPatches  DeepMatching*   \n",
       " 2  Dense Pixel Correspondence Estimation  HPatches  DeepMatching*   \n",
       " 3  Dense Pixel Correspondence Estimation  HPatches  DeepMatching*   \n",
       " 4  Dense Pixel Correspondence Estimation  HPatches  DeepMatching*   \n",
       " \n",
       "           Metric name  Metric value Global rank Remove  \n",
       " 0    Viewpoint I AEPE          5.84         # 3      -  \n",
       " 1   Viewpoint II AEPE          4.63         # 1      -  \n",
       " 2  Viewpoint III AEPE         12.43         # 2      -  \n",
       " 3   Viewpoint IV AEPE         12.17         # 2      -  \n",
       " 4    Viewpoint V AEPE         22.55         # 2      -  ,                    Task   Dataset         Model     Metric name Metric value  \\\n",
       " 0  Image Classification  ImageNet  Inception V3  Top 1 Accuracy        78.8%   \n",
       " 1  Image Classification  ImageNet  Inception V3  Top 5 Accuracy        94.4%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 15      -  \n",
       " 1        # 11      -  ,                         Task Dataset        Model Metric name Metric value  \\\n",
       " 0  Visual Question Answering  VQA v2  Pythia v0.1    Accuracy       70.24%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  ,              Task                      Dataset   Model Metric name  \\\n",
       " 0  Face Detection  Annotated Faces in the Wild  Conv3D          AP   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0        0.9597         # 9      -  ,                           Task                      Dataset        Model  \\\n",
       " 0  Disguised Face Verification  Disguised Faces in the Wild  DisguiseNet   \n",
       " 1  Disguised Face Verification  Disguised Faces in the Wild  DisguiseNet   \n",
       " 2  Disguised Face Verification  Disguised Faces in the Wild  DisguiseNet   \n",
       " \n",
       "      Metric name  Metric value Global rank Remove  \n",
       " 0  GAR @0.1% FAR         23.25         # 1      -  \n",
       " 1    GAR @1% FAR         60.89         # 1      -  \n",
       " 2   GAR @10% FAR         98.99         # 1      -  ,                Task         Dataset Model    Metric name  Metric value  \\\n",
       " 0  Image Generation  ImageNet 64x64   SPN  Bits per byte          3.52   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  ,               Task          Dataset                Model Metric name  \\\n",
       " 0  Pose Estimation  MPII Human Pose  Integral Regression    PCKh-0.5   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        91.0%         # 5      -  ,                Task   Dataset     Model    Metric name  Metric value  \\\n",
       " 0  Image Generation  CIFAR-10  Real NVP  Model Entropy           3.5   \n",
       " 1  Image Generation  CIFAR-10  PixelRNN  Model Entropy           3.0   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 3      -  \n",
       " 1         # 5      -  ,                 Task                    Dataset     Model Metric name  \\\n",
       " 0  Face Verification  Labeled Faces in the Wild  Git Loss    Accuracy   \n",
       " 1  Face Verification           YouTube Faces DB  Git Loss    Accuracy   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0       99.30%         # 8      -  \n",
       " 1       95.30%         # 6      -  ,                      Task     Dataset       Model Metric name  Metric value  \\\n",
       " 0  Common Sense Reasoning  Event2Mind  BiRNN 100d         Dev          4.25   \n",
       " 1  Common Sense Reasoning  Event2Mind  BiRNN 100d        Test          4.22   \n",
       " 2  Common Sense Reasoning  Event2Mind     ConvNet         Dev          4.44   \n",
       " 3  Common Sense Reasoning  Event2Mind     ConvNet        Test          4.40   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 1      -  \n",
       " 2         # 2      -  \n",
       " 3         # 2      -  ,                        Task  Dataset      Model Metric name  Metric value  \\\n",
       " 0  Table-to-text Generation  WikiBio  Table NLM        BLEU          34.7   \n",
       " 1  Table-to-text Generation  WikiBio  Table NLM       ROUGE          25.8   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 3      -  \n",
       " 1         # 3      -  ,           Task                         Dataset     Model Metric name  \\\n",
       " 0  Atari Games  Atari 2600 Montezuma's Revenge  A2C+CoEX       Score   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          6635         # 2      -  ,                    Task        Dataset                          Model  \\\n",
       " 0  Constituency Parsing  Penn Treebank  Self-attentive encoder + ELMo   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0    F1 score         95.13         # 2      -  ,                      Task                  Dataset Model Metric name  \\\n",
       " 0  Image Super-Resolution    BSD100 - 4x upscaling  DSRN        PSNR   \n",
       " 1  Image Super-Resolution    BSD100 - 4x upscaling  DSRN        SSIM   \n",
       " 2  Image Super-Resolution     Set14 - 4x upscaling  DSRN        PSNR   \n",
       " 3  Image Super-Resolution     Set14 - 4x upscaling  DSRN        SSIM   \n",
       " 4  Image Super-Resolution      Set5 - 4x upscaling  DSRN        PSNR   \n",
       " 5  Image Super-Resolution      Set5 - 4x upscaling  DSRN        SSIM   \n",
       " 6  Image Super-Resolution  Urban100 - 4x upscaling  DSRN        PSNR   \n",
       " 7  Image Super-Resolution  Urban100 - 4x upscaling  DSRN        SSIM   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0        27.250        # 20      -  \n",
       " 1         0.724        # 24      -  \n",
       " 2        28.070        # 21      -  \n",
       " 3         0.770        # 23      -  \n",
       " 4        31.400        # 19      -  \n",
       " 5         0.883        # 22      -  \n",
       " 6        25.080        # 21      -  \n",
       " 7         0.747        # 20      -  ,                      Task     Dataset  Model                     Metric name  \\\n",
       " 0  Visual Object Tracking  VOT2017/18  STRCF  Expected Average Overlap (EAO)   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         0.345         # 3      -  ,                      Task               Dataset   Model Metric name  \\\n",
       " 0  Image Super-Resolution  Set14 - 4x upscaling    SPMC        PSNR   \n",
       " 1  Image Super-Resolution  Set14 - 4x upscaling    SPMC        SSIM   \n",
       " 2  Image Super-Resolution   Set5 - 4x upscaling    SPMC        PSNR   \n",
       " 3  Image Super-Resolution   Set5 - 4x upscaling    SPMC        SSIM   \n",
       " 4  Video Super-Resolution   Vid4 - 4x upscaling  DRDVSR        PSNR   \n",
       " 5  Video Super-Resolution   Vid4 - 4x upscaling  DRDVSR        SSIM   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0        27.570        # 30      -  \n",
       " 1         0.760        # 27      -  \n",
       " 2        30.960        # 23      -  \n",
       " 3         0.870        # 26      -  \n",
       " 4        25.880         # 5      -  \n",
       " 5         0.774         # 8      -  ,                                   Task  Dataset        Model Metric name  \\\n",
       " 0  Emotion Recognition in Conversation  IEMOCAP  DialogueRNN          F1   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        64.5%         # 1      -  ,                 Task                    Dataset         Model Metric name  \\\n",
       " 0  Face Verification  Labeled Faces in the Wild  GaussianFace    Accuracy   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0       98.52%        # 11      -  ,                    Task   Dataset Model         Metric name  Metric value  \\\n",
       " 0  Image Classification  CIFAR-10  DCNN  Percentage correct            89   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 46      -  ,                            Task          Dataset    Model Metric name  \\\n",
       " 0               Pose Estimation  MPII Human Pose  DeepCut    PCKh-0.5   \n",
       " 1  Multi-Person Pose Estimation              WAF  DeepCut         AOP   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0       82.40%        # 10      -  \n",
       " 1        86.5%         # 2      -  ,                      Task                  Dataset Model Metric name  \\\n",
       " 0  Image Super-Resolution    BSD100 - 4x upscaling   RDN        PSNR   \n",
       " 1  Image Super-Resolution    BSD100 - 4x upscaling   RDN        SSIM   \n",
       " 2  Image Super-Resolution  Manga109 - 4x upscaling   RDN        PSNR   \n",
       " 3  Image Super-Resolution  Manga109 - 4x upscaling   RDN        SSIM   \n",
       " 4  Image Super-Resolution     Set14 - 4x upscaling   RDN        PSNR   \n",
       " 5  Image Super-Resolution     Set14 - 4x upscaling   RDN        SSIM   \n",
       " 6  Image Super-Resolution      Set5 - 4x upscaling   RDN        PSNR   \n",
       " 7  Image Super-Resolution      Set5 - 4x upscaling   RDN        SSIM   \n",
       " 8  Image Super-Resolution  Urban100 - 4x upscaling   RDN        PSNR   \n",
       " 9  Image Super-Resolution  Urban100 - 4x upscaling   RDN        SSIM   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0       27.7200         # 4      -  \n",
       " 1        0.7419         # 7      -  \n",
       " 2       31.0000         # 5      -  \n",
       " 3        0.9151         # 4      -  \n",
       " 4       28.8100         # 6      -  \n",
       " 5        0.7871         # 8      -  \n",
       " 6       32.4700         # 4      -  \n",
       " 7        0.8990         # 5      -  \n",
       " 8       26.6100         # 5      -  \n",
       " 9        0.8028         # 4      -  ,                       Task                  Dataset  Model Metric name  \\\n",
       " 0   Image Super-Resolution    BSD100 - 4x upscaling  MWCNN        PSNR   \n",
       " 1   Image Super-Resolution    BSD100 - 4x upscaling  MWCNN        SSIM   \n",
       " 2          Image Denoising            BSD68 sigma15  MWCNN        PSNR   \n",
       " 3          Image Denoising            BSD68 sigma25  MWCNN        PSNR   \n",
       " 4          Image Denoising            BSD68 sigma50  MWCNN        PSNR   \n",
       " 5   Image Super-Resolution     Set14 - 4x upscaling  MWCNN        PSNR   \n",
       " 6   Image Super-Resolution     Set14 - 4x upscaling  MWCNN        SSIM   \n",
       " 7   Image Super-Resolution      Set5 - 4x upscaling  MWCNN        PSNR   \n",
       " 8   Image Super-Resolution      Set5 - 4x upscaling  MWCNN        SSIM   \n",
       " 9   Image Super-Resolution  Urban100 - 4x upscaling  MWCNN        PSNR   \n",
       " 10  Image Super-Resolution  Urban100 - 4x upscaling  MWCNN        SSIM   \n",
       " 11         Image Denoising         Urban100 sigma50  MWCNN        PSNR   \n",
       " \n",
       "     Metric value Global rank Remove  \n",
       " 0        27.6200         # 7      -  \n",
       " 1         0.7355        # 12      -  \n",
       " 2        31.8600         # 2      -  \n",
       " 3        29.4100         # 1      -  \n",
       " 4        26.5300         # 1      -  \n",
       " 5        28.4100        # 13      -  \n",
       " 6         0.7816        # 13      -  \n",
       " 7        32.1200         # 9      -  \n",
       " 8         0.8941        # 10      -  \n",
       " 9        26.2700         # 8      -  \n",
       " 10        0.7890         # 8      -  \n",
       " 11       27.4200         # 3      -  ,                  Task   Dataset  \\\n",
       " 0  Text Summarization  GigaWord   \n",
       " 1  Text Summarization  GigaWord   \n",
       " 2  Text Summarization  GigaWord   \n",
       " \n",
       "                                               Model Metric name  Metric value  \\\n",
       " 0  Pointer + Coverage + EntailmentGen + QuestionGen     ROUGE-1         35.98   \n",
       " 1  Pointer + Coverage + EntailmentGen + QuestionGen     ROUGE-2         17.76   \n",
       " 2  Pointer + Coverage + EntailmentGen + QuestionGen     ROUGE-L         33.63   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 7      -  \n",
       " 1         # 3      -  \n",
       " 2         # 7      -  ,                          Task Dataset                                 Model  \\\n",
       " 0  Natural Language Inference    SNLI  100D LSTMs w/ word-by-word attention   \n",
       " 1  Natural Language Inference    SNLI  100D LSTMs w/ word-by-word attention   \n",
       " 2  Natural Language Inference    SNLI  100D LSTMs w/ word-by-word attention   \n",
       " \n",
       "         Metric name Metric value Global rank Remove  \n",
       " 0   % Test Accuracy         83.5        # 39      -  \n",
       " 1  % Train Accuracy         85.3        # 47      -  \n",
       " 2        Parameters         250k         # 1      -  ,                  Task Dataset                              Model  \\\n",
       " 0  Speech Recognition   TIMIT  Bi-LSTM + skip connections w/ CTC   \n",
       " \n",
       "         Metric name  Metric value Global rank Remove  \n",
       " 0  Percentage error          17.7        # 12      -  ,                   Task                   Dataset  \\\n",
       " 0  Machine Translation  IWSLT2015 English-German   \n",
       " 1  Machine Translation  IWSLT2015 German-English   \n",
       " 2  Machine Translation    WMT2014 English-German   \n",
       " 3  Machine Translation    WMT2014 German-English   \n",
       " 4  Machine Translation  WMT2016 English-Romanian   \n",
       " 5  Machine Translation  WMT2016 Romanian-English   \n",
       " \n",
       "                                          Model Metric name  Metric value  \\\n",
       " 0  Denoising autoencoders (non-autoregressive)  BLEU score         27.01   \n",
       " 1  Denoising autoencoders (non-autoregressive)  BLEU score         32.43   \n",
       " 2  Denoising autoencoders (non-autoregressive)  BLEU score         21.54   \n",
       " 3  Denoising autoencoders (non-autoregressive)  BLEU score         25.43   \n",
       " 4  Denoising autoencoders (non-autoregressive)  BLEU score         29.66   \n",
       " 5  Denoising autoencoders (non-autoregressive)  BLEU score         30.30   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 4      -  \n",
       " 1         # 7      -  \n",
       " 2        # 15      -  \n",
       " 3         # 1      -  \n",
       " 4         # 3      -  \n",
       " 5         # 4      -  ,                    Task      Dataset                          Model  \\\n",
       " 0  Pedestrian Detection      Caltech                            CSP   \n",
       " 1  Pedestrian Detection      Caltech      CSP + CityPersons dataset   \n",
       " 2  Pedestrian Detection  CityPersons  CSP (with offset) + ResNet-50   \n",
       " 3  Pedestrian Detection  CityPersons  CSP (with offset) + ResNet-50   \n",
       " 4  Pedestrian Detection  CityPersons  CSP (with offset) + ResNet-50   \n",
       " 5  Pedestrian Detection  CityPersons  CSP (with offset) + ResNet-50   \n",
       " 6  Pedestrian Detection  CityPersons  CSP (with offset) + ResNet-50   \n",
       " 7  Pedestrian Detection  CityPersons  CSP (with offset) + ResNet-50   \n",
       " 8  Pedestrian Detection  CityPersons  CSP (with offset) + ResNet-50   \n",
       " 9  Pedestrian Detection  CityPersons  CSP (with offset) + ResNet-50   \n",
       " \n",
       "             Metric name Metric value Global rank  Extradata Remove  \n",
       " 0  Reasonable Miss Rate          4.5         # 4        NaN      -  \n",
       " 1  Reasonable Miss Rate          3.8         # 1        NaN      -  \n",
       " 2      Reasonable MR^-2         11.0         # 1        NaN      -  \n",
       " 3           Heavy MR^-2         49.3         # 1        NaN      -  \n",
       " 4         Partial MR^-2         10.4         # 1        NaN      -  \n",
       " 5            Bare MR^-2          7.3         # 2        NaN      -  \n",
       " 6           Small MR^-2         16.0         # 1        NaN      -  \n",
       " 7          Medium MR^-2          3.7         # 1        NaN      -  \n",
       " 8           Large MR^-2          6.5         # 1        NaN      -  \n",
       " 9             Test Time    0.33s/img         # 2        NaN      -  ,                    Task      Dataset                         Model  \\\n",
       " 0  Pedestrian Detection      Caltech                        ALFNet   \n",
       " 1  Pedestrian Detection      Caltech  ALFNet + CityPersons dataset   \n",
       " 2  Pedestrian Detection  CityPersons                        ALFNet   \n",
       " 3  Pedestrian Detection  CityPersons                        ALFNet   \n",
       " 4  Pedestrian Detection  CityPersons                        ALFNet   \n",
       " 5  Pedestrian Detection  CityPersons                        ALFNet   \n",
       " 6  Pedestrian Detection  CityPersons                        ALFNet   \n",
       " 7  Pedestrian Detection  CityPersons                        ALFNet   \n",
       " 8  Pedestrian Detection  CityPersons                        ALFNet   \n",
       " 9  Pedestrian Detection  CityPersons                        ALFNet   \n",
       " \n",
       "             Metric name  Metric value Global rank  Extradata Remove  \n",
       " 0  Reasonable Miss Rate          6.10         # 7        NaN      -  \n",
       " 1  Reasonable Miss Rate          4.50         # 4        NaN      -  \n",
       " 2      Reasonable MR^-2         12.00         # 2        NaN      -  \n",
       " 3           Heavy MR^-2         51.90         # 2        NaN      -  \n",
       " 4         Partial MR^-2         11.40         # 2        NaN      -  \n",
       " 5            Bare MR^-2          8.40         # 4        NaN      -  \n",
       " 6           Small MR^-2         19.00         # 2        NaN      -  \n",
       " 7          Medium MR^-2          5.70         # 2        NaN      -  \n",
       " 8           Large MR^-2          6.60         # 2        NaN      -  \n",
       " 9             Test Time          0.27         # 1        NaN      -  ,                   Task                 Dataset  Model Metric name  \\\n",
       " 0  Machine Translation  WMT2014 English-French  RNMT+  BLEU score   \n",
       " 1  Machine Translation  WMT2014 English-German  RNMT+  BLEU score   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        41.0*        # 31      -  \n",
       " 1        28.5*        # 24      -  ,                        Task        Dataset                             Model  \\\n",
       " 0  Person Re-Identification  DukeMTMC-reID  Parameter-Free Spatial Attention   \n",
       " 1  Person Re-Identification  DukeMTMC-reID  Parameter-Free Spatial Attention   \n",
       " 2  Person Re-Identification    Market-1501  Parameter-Free Spatial Attention   \n",
       " 3  Person Re-Identification    Market-1501  Parameter-Free Spatial Attention   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0      Rank-1          89.0         # 1      -  \n",
       " 1         MAP          85.9         # 1      -  \n",
       " 2      Rank-1          94.7         # 2      -  \n",
       " 3         MAP          91.7         # 1      -  ,                   Task                   Dataset       Model Metric name  \\\n",
       " 0  Machine Translation  WMT2016 English-Romanian  GRU BPE90k  BLEU score   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          28.9         # 4      -  ,                    Task    Dataset Model         Metric name  Metric value  \\\n",
       " 0  Image Classification   CIFAR-10  CMsC  Percentage correct         93.10   \n",
       " 1  Image Classification  CIFAR-100  CMsC  Percentage correct         72.40   \n",
       " 2  Image Classification      MNIST  CMsC    Percentage error          0.30   \n",
       " 3  Image Classification       SVHN  CMsC    Percentage error          1.76   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 27      -  \n",
       " 1        # 20      -  \n",
       " 2         # 3      -  \n",
       " 3         # 8      -  ,              Task Dataset     Model Metric name  Metric value Global rank  \\\n",
       " 0  Age Estimation   FGNET  CMAAE-OR         MAE          3.62         # 1   \n",
       " 1  Age Estimation   MORPH  CMAAE-OR         MAE          1.48         # 1   \n",
       " \n",
       "   Remove  \n",
       " 0      -  \n",
       " 1      -  ,                             Task                          Dataset Model  \\\n",
       " 0              Few-Shot Learning  Mini-ImageNet - 1-Shot Learning   MTL   \n",
       " 1  Few-Shot Image Classification  Mini-ImageNet - 1-Shot Learning   MTL   \n",
       " 2  Few-Shot Image Classification  Mini-ImageNet - 5-Shot Learning   MTL   \n",
       " \n",
       "   Metric name Metric value Global rank Remove  \n",
       " 0    Accuracy        61.2%         # 1      -  \n",
       " 1    Accuracy        61.2%         # 2      -  \n",
       " 2    Accuracy        75.5%         # 2      -  ,                  Task         Dataset      Model        Metric name  \\\n",
       " 0  Hypernym Discovery         General  SJTU BCMI                MAP   \n",
       " 1  Hypernym Discovery         General  SJTU BCMI                MRR   \n",
       " 2  Hypernym Discovery         General  SJTU BCMI  [email protected]   \n",
       " 3  Hypernym Discovery  Medical domain  SJTU BCMI                MAP   \n",
       " 4  Hypernym Discovery  Medical domain  SJTU BCMI                MRR   \n",
       " 5  Hypernym Discovery  Medical domain  SJTU BCMI  [email protected]   \n",
       " 6  Hypernym Discovery    Music domain  SJTU BCMI                MAP   \n",
       " 7  Hypernym Discovery    Music domain  SJTU BCMI                MRR   \n",
       " 8  Hypernym Discovery    Music domain  SJTU BCMI  [email protected]   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          5.77         # 6      -  \n",
       " 1         10.56         # 6      -  \n",
       " 2          5.96         # 6      -  \n",
       " 3         11.69         # 6      -  \n",
       " 4         25.95         # 6      -  \n",
       " 5         11.69         # 6      -  \n",
       " 6          4.71         # 5      -  \n",
       " 7          9.15         # 5      -  \n",
       " 8          4.91         # 5      -  ,                  Task         Dataset  Model        Metric name  Metric value  \\\n",
       " 0  Hypernym Discovery  Medical domain  ADAPT                MAP          8.13   \n",
       " 1  Hypernym Discovery  Medical domain  ADAPT                MRR         20.56   \n",
       " 2  Hypernym Discovery  Medical domain  ADAPT  [email protected]          8.32   \n",
       " 3  Hypernym Discovery    Music domain  ADAPT                MAP          2.63   \n",
       " 4  Hypernym Discovery    Music domain  ADAPT                MRR          7.46   \n",
       " 5  Hypernym Discovery    Music domain  ADAPT  [email protected]          2.64   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 7      -  \n",
       " 1         # 7      -  \n",
       " 2         # 7      -  \n",
       " 3         # 6      -  \n",
       " 4         # 6      -  \n",
       " 5         # 6      -  ,             Task                   Dataset              Model Metric name  \\\n",
       " 0    Atari Games          Atari 2600 Alien  DDQN (tuned) noop       Score   \n",
       " 1    Atari Games          Atari 2600 Alien      Prior+Duel hs       Score   \n",
       " 2    Atari Games          Atari 2600 Alien          Duel noop       Score   \n",
       " 3    Atari Games          Atari 2600 Alien            Duel hs       Score   \n",
       " 4    Atari Games          Atari 2600 Alien    Prior+Duel noop       Score   \n",
       " 5    Atari Games         Atari 2600 Amidar      Prior+Duel hs       Score   \n",
       " 6    Atari Games         Atari 2600 Amidar          Duel noop       Score   \n",
       " 7    Atari Games         Atari 2600 Amidar  DDQN (tuned) noop       Score   \n",
       " 8    Atari Games         Atari 2600 Amidar            Duel hs       Score   \n",
       " 9    Atari Games         Atari 2600 Amidar    Prior+Duel noop       Score   \n",
       " 10   Atari Games        Atari 2600 Assault    Prior+Duel noop       Score   \n",
       " 11   Atari Games        Atari 2600 Assault            Duel hs       Score   \n",
       " 12   Atari Games        Atari 2600 Assault      Prior+Duel hs       Score   \n",
       " 13   Atari Games        Atari 2600 Assault  DDQN (tuned) noop       Score   \n",
       " 14   Atari Games        Atari 2600 Assault          Duel noop       Score   \n",
       " 15   Atari Games        Atari 2600 Asterix      Prior+Duel hs       Score   \n",
       " 16   Atari Games        Atari 2600 Asterix          Duel noop       Score   \n",
       " 17   Atari Games        Atari 2600 Asterix  DDQN (tuned) noop       Score   \n",
       " 18   Atari Games        Atari 2600 Asterix            Duel hs       Score   \n",
       " 19   Atari Games        Atari 2600 Asterix    Prior+Duel noop       Score   \n",
       " 20   Atari Games      Atari 2600 Asteroids          Duel noop       Score   \n",
       " 21   Atari Games      Atari 2600 Asteroids            Duel hs       Score   \n",
       " 22   Atari Games      Atari 2600 Asteroids  DDQN (tuned) noop       Score   \n",
       " 23   Atari Games      Atari 2600 Asteroids    Prior+Duel noop       Score   \n",
       " 24   Atari Games       Atari 2600 Atlantis            Duel hs       Score   \n",
       " 25   Atari Games       Atari 2600 Atlantis          Duel noop       Score   \n",
       " 26   Atari Games       Atari 2600 Atlantis  DDQN (tuned) noop       Score   \n",
       " 27   Atari Games       Atari 2600 Atlantis    Prior+Duel noop       Score   \n",
       " 28   Atari Games     Atari 2600 Bank Heist    Prior+Duel noop       Score   \n",
       " 29   Atari Games     Atari 2600 Bank Heist  DDQN (tuned) noop       Score   \n",
       " ..           ...                       ...                ...         ...   \n",
       " 178  Atari Games         Atari 2600 Tennis  DDQN (tuned) noop       Score   \n",
       " 179  Atari Games         Atari 2600 Tennis    Prior+Duel noop       Score   \n",
       " 180  Atari Games     Atari 2600 Time Pilot          Duel noop       Score   \n",
       " 181  Atari Games     Atari 2600 Time Pilot  DDQN (tuned) noop       Score   \n",
       " 182  Atari Games     Atari 2600 Time Pilot            Duel hs       Score   \n",
       " 183  Atari Games     Atari 2600 Time Pilot    Prior+Duel noop       Score   \n",
       " 184  Atari Games      Atari 2600 Tutankham    Prior+Duel noop       Score   \n",
       " 185  Atari Games      Atari 2600 Tutankham  DDQN (tuned) noop       Score   \n",
       " 186  Atari Games      Atari 2600 Tutankham          Duel noop       Score   \n",
       " 187  Atari Games      Atari 2600 Tutankham            Duel hs       Score   \n",
       " 188  Atari Games    Atari 2600 Up and Down          Duel noop       Score   \n",
       " 189  Atari Games    Atari 2600 Up and Down            Duel hs       Score   \n",
       " 190  Atari Games    Atari 2600 Up and Down  DDQN (tuned) noop       Score   \n",
       " 191  Atari Games    Atari 2600 Up and Down    Prior+Duel noop       Score   \n",
       " 192  Atari Games        Atari 2600 Venture          Duel noop       Score   \n",
       " 193  Atari Games        Atari 2600 Venture            Duel hs       Score   \n",
       " 194  Atari Games        Atari 2600 Venture  DDQN (tuned) noop       Score   \n",
       " 195  Atari Games        Atari 2600 Venture    Prior+Duel noop       Score   \n",
       " 196  Atari Games  Atari 2600 Video Pinball  DDQN (tuned) noop       Score   \n",
       " 197  Atari Games  Atari 2600 Video Pinball            Duel hs       Score   \n",
       " 198  Atari Games  Atari 2600 Video Pinball    Prior+Duel noop       Score   \n",
       " 199  Atari Games  Atari 2600 Video Pinball          Duel noop       Score   \n",
       " 200  Atari Games  Atari 2600 Wizard of Wor  DDQN (tuned) noop       Score   \n",
       " 201  Atari Games  Atari 2600 Wizard of Wor    Prior+Duel noop       Score   \n",
       " 202  Atari Games  Atari 2600 Wizard of Wor            Duel hs       Score   \n",
       " 203  Atari Games  Atari 2600 Wizard of Wor          Duel noop       Score   \n",
       " 204  Atari Games         Atari 2600 Zaxxon          Duel noop       Score   \n",
       " 205  Atari Games         Atari 2600 Zaxxon    Prior+Duel noop       Score   \n",
       " 206  Atari Games         Atari 2600 Zaxxon  DDQN (tuned) noop       Score   \n",
       " 207  Atari Games         Atari 2600 Zaxxon            Duel hs       Score   \n",
       " \n",
       "      Metric value Global rank Remove  \n",
       " 0          3747.7         # 5      -  \n",
       " 1           823.7        # 17      -  \n",
       " 2          4461.4         # 2      -  \n",
       " 3          1486.5        # 11      -  \n",
       " 4          3941.0         # 4      -  \n",
       " 5           238.4        # 13      -  \n",
       " 6          2354.5         # 2      -  \n",
       " 7          1793.3         # 5      -  \n",
       " 8           172.7        # 18      -  \n",
       " 9          2296.8         # 3      -  \n",
       " 10        11477.0         # 3      -  \n",
       " 11         3994.8        # 15      -  \n",
       " 12        10950.6         # 4      -  \n",
       " 13         5393.2        # 12      -  \n",
       " 14         4621.0        # 13      -  \n",
       " 15       364200.0         # 3      -  \n",
       " 16        28188.0         # 6      -  \n",
       " 17        17356.5        # 11      -  \n",
       " 18        15840.0        # 14      -  \n",
       " 19       375080.0         # 2      -  \n",
       " 20         2837.7         # 6      -  \n",
       " 21         2035.4         # 8      -  \n",
       " 22          734.7        # 21      -  \n",
       " 23         1192.7        # 16      -  \n",
       " 24       445360.0         # 9      -  \n",
       " 25       382572.0        # 12      -  \n",
       " 26       106056.0        # 19      -  \n",
       " 27       395762.0        # 11      -  \n",
       " 28         1503.1         # 2      -  \n",
       " 29         1030.6         # 8      -  \n",
       " ..            ...         ...    ...  \n",
       " 178         -22.8        # 19      -  \n",
       " 179           0.0         # 8      -  \n",
       " 180       11666.0         # 4      -  \n",
       " 181        8339.0         # 7      -  \n",
       " 182        6601.0        # 12      -  \n",
       " 183        7553.0        # 10      -  \n",
       " 184         245.9         # 3      -  \n",
       " 185         218.4         # 4      -  \n",
       " 186         211.4         # 6      -  \n",
       " 187          48.0        # 20      -  \n",
       " 188       44939.6         # 6      -  \n",
       " 189       24759.2         # 9      -  \n",
       " 190       22972.2        # 10      -  \n",
       " 191       33879.1         # 7      -  \n",
       " 192         497.0         # 8      -  \n",
       " 193         200.0        # 12      -  \n",
       " 194          98.0        # 15      -  \n",
       " 195          48.0        # 20      -  \n",
       " 196      309941.9         # 9      -  \n",
       " 197      110976.2        # 16      -  \n",
       " 198      479197.0         # 4      -  \n",
       " 199       98209.5        # 17      -  \n",
       " 200        7492.0         # 9      -  \n",
       " 201       12352.0         # 4      -  \n",
       " 202        7054.0        # 10      -  \n",
       " 203        7855.0         # 8      -  \n",
       " 204       12944.0         # 6      -  \n",
       " 205       13886.0         # 5      -  \n",
       " 206       10163.0        # 12      -  \n",
       " 207       10164.0        # 11      -  \n",
       " \n",
       " [208 rows x 7 columns],                              Task                      Dataset  \\\n",
       " 0  Named Entity Recognition (NER)         CoNLL 2003 (English)   \n",
       " 1            Constituency Parsing                Penn Treebank   \n",
       " 2              Sentiment Analysis  SST-2 Binary classification   \n",
       " \n",
       "                    Model Metric name  Metric value Global rank Remove  \n",
       " 0  CNN Large + fine-tune          F1          93.5         # 1      -  \n",
       " 1  CNN Large + fine-tune    F1 score          95.6         # 1      -  \n",
       " 2              CNN Large    Accuracy          94.6         # 2      -  ,                        Task        Dataset Model Metric name  Metric value  \\\n",
       " 0  Person Re-Identification  DukeMTMC-reID   GAN      Rank-1         67.68   \n",
       " 1  Person Re-Identification  DukeMTMC-reID   GAN         MAP         47.13   \n",
       " 2  Person Re-Identification    Market-1501   GAN      Rank-1         83.97   \n",
       " 3  Person Re-Identification    Market-1501   GAN         MAP         66.07   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 16      -  \n",
       " 1        # 16      -  \n",
       " 2        # 15      -  \n",
       " 3        # 13      -  ,                  Task Dataset Model Metric name  Metric value Global rank  \\\n",
       " 0  Question Answering  WikiQA   LDC         MAP        0.7058         # 4   \n",
       " 1  Question Answering  WikiQA   LDC         MRR        0.7226         # 4   \n",
       " \n",
       "   Remove  \n",
       " 0      -  \n",
       " 1      -  ,                  Task                            Dataset Model Metric name  \\\n",
       " 0  Sentiment Analysis  SST-5 Fine-grained classification  Epic    Accuracy   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          49.6         # 9      -  ,                      Task                Dataset Model Metric name  \\\n",
       " 0  Image Super-Resolution  BSD100 - 4x upscaling  ZSSR        PSNR   \n",
       " 1  Image Super-Resolution  BSD100 - 4x upscaling  ZSSR        SSIM   \n",
       " 2  Image Super-Resolution   Set14 - 4x upscaling  ZSSR        PSNR   \n",
       " 3  Image Super-Resolution   Set14 - 4x upscaling  ZSSR        SSIM   \n",
       " 4  Image Super-Resolution    Set5 - 4x upscaling  ZSSR        PSNR   \n",
       " 5  Image Super-Resolution    Set5 - 4x upscaling  ZSSR        SSIM   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0       27.1200        # 23      -  \n",
       " 1        0.7211        # 25      -  \n",
       " 2       28.0100        # 24      -  \n",
       " 3        0.7651        # 25      -  \n",
       " 4       31.1300        # 20      -  \n",
       " 5        0.8796        # 23      -  ,                 Task Dataset                Model     Metric name  \\\n",
       " 0  Face Verification   IJB-A  Template adaptation  TAR @ FAR=0.01   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0       93.90%         # 6      -  ,                 Task Dataset Model     Metric name Metric value Global rank  \\\n",
       " 0  Face Verification   IJB-A  DCNN  TAR @ FAR=0.01       83.80%        # 11   \n",
       " \n",
       "   Remove  \n",
       " 0      -  ,                  Task           Dataset                         Model  \\\n",
       " 0  Question Answering  CNN / Daily Mail  Dynamic Entity Repres. + w2v   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0         CNN          72.9        # 10      -  ,           Task  Dataset          Model Metric name  Metric value Global rank  \\\n",
       " 0  SQL-to-Text  WikiSQL  Graph2Seq-PGE      BLEU-4         38.97         # 1   \n",
       " \n",
       "   Remove  \n",
       " 0      -  ,                  Task                    Dataset          Model  \\\n",
       " 0  Speech Recognition  swb_hub_500 WER fullSWBCH  DNN + Dropout   \n",
       " 1  Speech Recognition       Switchboard + Hub500  DNN + Dropout   \n",
       " 2  Speech Recognition       Switchboard + Hub500            DNN   \n",
       " \n",
       "         Metric name  Metric value Global rank Remove  \n",
       " 0  Percentage error          19.1         # 9      -  \n",
       " 1  Percentage error          15.0        # 17      -  \n",
       " 2  Percentage error          16.0        # 18      -  ,                Task Dataset  Model      Metric name  Metric value Global rank  \\\n",
       " 0  Object Detection    COCO  M2Det  Bounding Box AP          44.2        # 11   \n",
       " \n",
       "   Remove  \n",
       " 0      -  ,                              Task  Dataset             Model Metric name  \\\n",
       " 0  Citation Intent Classification  ACL-ARC  BiLSTM-Attention          F1   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          51.8         # 5      -  ,                  Task                     Dataset  \\\n",
       " 0  Language Modelling  Penn Treebank (Word Level)   \n",
       " 1  Language Modelling  Penn Treebank (Word Level)   \n",
       " 2  Language Modelling  Penn Treebank (Word Level)   \n",
       " \n",
       "                                     Model            Metric name Metric value  \\\n",
       " 0  Tied Variational LSTM + augmented loss  Validation perplexity         75.7   \n",
       " 1  Tied Variational LSTM + augmented loss        Test perplexity         73.2   \n",
       " 2  Tied Variational LSTM + augmented loss                 Params          24M   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 18      -  \n",
       " 1        # 21      -  \n",
       " 2         # 1      -  ,              Task                      Dataset             Model Metric name  \\\n",
       " 0  Face Detection  Annotated Faces in the Wild  HyperFace-ResNet          AP   \n",
       " 1  Face Detection                         FDDB         HyperFace          AP   \n",
       " 2  Face Detection                  PASCAL Face  HyperFace-ResNet          AP   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         0.994         # 4      -  \n",
       " 1         0.901         # 7      -  \n",
       " 2         0.962         # 5      -  ,                    Task        Dataset        Model Metric name Metric value  \\\n",
       " 0  Constituency Parsing  Penn Treebank  RNN Grammar    F1 score        ﻿93.3   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 11      -  ,              Task   Dataset                             Model Metric name  \\\n",
       " 0  Lane Detection  TuSimple  Pairwise pixel supervision + FCN    Accuracy   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0       96.50%         # 2      -  ,                          Task  Dataset  \\\n",
       " 0  Natural Language Inference  SciTail   \n",
       " 1  Natural Language Inference     SNLI   \n",
       " 2  Natural Language Inference     SNLI   \n",
       " 3  Natural Language Inference     SNLI   \n",
       " 4  Natural Language Inference     SNLI   \n",
       " 5  Natural Language Inference     SNLI   \n",
       " 6  Natural Language Inference     SNLI   \n",
       " 7  Natural Language Inference     SNLI   \n",
       " 8  Natural Language Inference     SNLI   \n",
       " 9  Natural Language Inference     SNLI   \n",
       " \n",
       "                                      Model       Metric name Metric value  \\\n",
       " 0                                     CAFE          Accuracy         83.3   \n",
       " 1  300D CAFE (no cross-sentence attention)   % Test Accuracy         85.9   \n",
       " 2  300D CAFE (no cross-sentence attention)  % Train Accuracy         87.3   \n",
       " 3  300D CAFE (no cross-sentence attention)        Parameters         3.7m   \n",
       " 4                                300D CAFE   % Test Accuracy         88.5   \n",
       " 5                                300D CAFE  % Train Accuracy         89.8   \n",
       " 6                                300D CAFE        Parameters         4.7m   \n",
       " 7                       300D CAFE Ensemble   % Test Accuracy         89.3   \n",
       " 8                       300D CAFE Ensemble  % Train Accuracy         92.5   \n",
       " 9                       300D CAFE Ensemble        Parameters        17.5m   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 5      -  \n",
       " 1        # 29      -  \n",
       " 2        # 40      -  \n",
       " 3         # 1      -  \n",
       " 4        # 13      -  \n",
       " 5        # 33      -  \n",
       " 6         # 1      -  \n",
       " 7         # 7      -  \n",
       " 8        # 20      -  \n",
       " 9         # 1      -  ,                   Task     Dataset    Model        Metric name  Metric value  \\\n",
       " 0   Question Answering  SemEvalCQA  HyperQA  [email protected]         0.809   \n",
       " 1   Question Answering  SemEvalCQA  HyperQA                MAP         0.795   \n",
       " 2   Question Answering      TrecQA  HyperQA                MAP         0.770   \n",
       " 3   Question Answering      TrecQA  HyperQA                MRR         0.825   \n",
       " 4   Question Answering      WikiQA  HyperQA                MAP         0.712   \n",
       " 5   Question Answering      WikiQA  HyperQA                MRR         0.727   \n",
       " 6   Question Answering    YahooCQA      CNN  [email protected]         0.413   \n",
       " 7   Question Answering    YahooCQA      CNN                MRR         0.632   \n",
       " 8   Question Answering    YahooCQA  HyperQA  [email protected]         0.683   \n",
       " 9   Question Answering    YahooCQA  HyperQA                MRR         0.801   \n",
       " 10  Question Answering    YahooCQA     LSTM  [email protected]         0.465   \n",
       " 11  Question Answering    YahooCQA     LSTM                MRR         0.669   \n",
       " \n",
       "    Global rank Remove  \n",
       " 0          # 1      -  \n",
       " 1          # 1      -  \n",
       " 2          # 1      -  \n",
       " 3          # 1      -  \n",
       " 4          # 1      -  \n",
       " 5          # 1      -  \n",
       " 6          # 5      -  \n",
       " 7          # 5      -  \n",
       " 8          # 1      -  \n",
       " 9          # 1      -  \n",
       " 10         # 4      -  \n",
       " 11         # 4      -  ,                     Task          Dataset                 Model Metric name  \\\n",
       " 0  Semantic Segmentation  PASCAL VOC 2012  Large Kernel Matters    Mean IoU   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        83.6%         # 8      -  ,                  Task Dataset               Model       Metric name  \\\n",
       " 0  Speech Recognition   TIMIT  Bi-RNN + Attention  Percentage error   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          17.6        # 11      -  ,                       Task      Dataset     Model Metric name Metric value  \\\n",
       " 0      Node Classification  BlogCatalog  DeepWalk    Accuracy       22.50%   \n",
       " 1      Node Classification  BlogCatalog  DeepWalk    Macro-F1        0.214   \n",
       " 2      Node Classification     Citeseer  DeepWalk    Accuracy        43.2%   \n",
       " 3      Node Classification         Cora  DeepWalk    Accuracy        67.2%   \n",
       " 4  Document Classification         Cora  DeepWalk    Accuracy        67.2%   \n",
       " 5      Node Classification         NELL  DeepWalk    Accuracy        58.1%   \n",
       " 6      Node Classification       Pubmed  DeepWalk    Accuracy        65.3%   \n",
       " 7      Node Classification    Wikipedia  DeepWalk    Accuracy       19.40%   \n",
       " 8      Node Classification    Wikipedia  DeepWalk    Macro-F1        0.183   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 3      -  \n",
       " 1         # 3      -  \n",
       " 2         # 8      -  \n",
       " 3         # 9      -  \n",
       " 4         # 7      -  \n",
       " 5         # 3      -  \n",
       " 6         # 8      -  \n",
       " 7         # 3      -  \n",
       " 8         # 3      -  ,                           Task                 Dataset  \\\n",
       " 0  Cross-Lingual Bitext Mining  BUCC French-to-English   \n",
       " 1  Cross-Lingual Bitext Mining  BUCC German-to-English   \n",
       " \n",
       "                        Model Metric name  Metric value Global rank Remove  \n",
       " 0  Monolingual training data    F1 score          75.8         # 3      -  \n",
       " 1  Monolingual training data    F1 score          76.9         # 3      -  ,                    Task    Dataset                 Model         Metric name  \\\n",
       " 0  Image Classification   CIFAR-10  Maxout Network (k=2)  Percentage correct   \n",
       " 1  Image Classification   CIFAR-10  Maxout Network (k=2)    Percentage error   \n",
       " 2  Image Classification  CIFAR-100  Maxout Network (k=2)  Percentage correct   \n",
       " 3  Image Classification  CIFAR-100  Maxout Network (k=2)    Percentage error   \n",
       " 4  Image Classification      MNIST       Maxout Networks    Percentage error   \n",
       " 5  Image Classification       SVHN                Maxout    Percentage error   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         90.65        # 41      -  \n",
       " 1          9.38        # 18      -  \n",
       " 2         61.43        # 42      -  \n",
       " 3         38.57        # 12      -  \n",
       " 4          0.50         # 5      -  \n",
       " 5          2.47        # 19      -  ,                      Task                Dataset    Model Metric name  \\\n",
       " 0  Image Super-Resolution  BSD100 - 4x upscaling  SFT-GAN        PSNR   \n",
       " 1  Image Super-Resolution  BSD100 - 4x upscaling  SFT-GAN        SSIM   \n",
       " 2  Image Super-Resolution   Set14 - 4x upscaling  SFT-GAN        PSNR   \n",
       " 3  Image Super-Resolution   Set14 - 4x upscaling  SFT-GAN        SSIM   \n",
       " 4  Image Super-Resolution    Set5 - 4x upscaling  SFT-GAN        PSNR   \n",
       " 5  Image Super-Resolution    Set5 - 4x upscaling  SFT-GAN        SSIM   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0        25.330        # 30      -  \n",
       " 1         0.651        # 31      -  \n",
       " 2        26.130        # 35      -  \n",
       " 3         0.694        # 33      -  \n",
       " 4        29.820        # 29      -  \n",
       " 5         0.840        # 30      -  ,                Task             Dataset     Model Metric name Metric value  \\\n",
       " 0  Object Detection  ImageNet Detection  OverFeat         MAP        24.3%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  ,                    Task    Dataset  Model         Metric name  Metric value  \\\n",
       " 0  Image Classification   CIFAR-10  SSCNN  Percentage correct          93.7   \n",
       " 1  Image Classification  CIFAR-100  SSCNN  Percentage correct          75.7   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 22      -  \n",
       " 1        # 14      -  ,                          Task                     Dataset  Model  \\\n",
       " 0  Image-to-Image Translation  Cityscapes Labels-to-Photo  CoGAN   \n",
       " 1  Image-to-Image Translation  Cityscapes Labels-to-Photo  CoGAN   \n",
       " 2  Image-to-Image Translation  Cityscapes Labels-to-Photo  CoGAN   \n",
       " 3  Image-to-Image Translation  Cityscapes Photo-to-Labels  CoGAN   \n",
       " 4  Image-to-Image Translation  Cityscapes Photo-to-Labels  CoGAN   \n",
       " 5  Image-to-Image Translation  Cityscapes Photo-to-Labels  CoGAN   \n",
       " \n",
       "           Metric name Metric value Global rank Remove  \n",
       " 0           Class IOU         0.06         # 3      -  \n",
       " 1  Per-class Accuracy          10%         # 3      -  \n",
       " 2  Per-pixel Accuracy          40%         # 7      -  \n",
       " 3  Per-pixel Accuracy          45%         # 4      -  \n",
       " 4  Per-class Accuracy          11%         # 4      -  \n",
       " 5           Class IOU         0.08         # 3      -  ,                            Task   Dataset                Model Metric name  \\\n",
       " 0  Action Recognition In Videos  Charades  CoViAR+optical flow         MAP   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          25.2         # 4      -  ,                                                  Task         Dataset  \\\n",
       " 0                      Citation Intent Classification         ACL-ARC   \n",
       " 1                             Sentence Classification         ACL-ARC   \n",
       " 2                             Sentence Classification         ACL-ARC   \n",
       " 3                      Named Entity Recognition (NER)          BC5CDR   \n",
       " 4                      Named Entity Recognition (NER)          BC5CDR   \n",
       " 5                                 Relation Extraction        ChemProt   \n",
       " 6                                 Relation Extraction        ChemProt   \n",
       " 7   Participant Intervention Comparison Outcome Ex...         EBM-NLP   \n",
       " 8   Participant Intervention Comparison Outcome Ex...         EBM-NLP   \n",
       " 9                                  Dependency Parsing     GENIA - LAS   \n",
       " 10                                 Dependency Parsing     GENIA - LAS   \n",
       " 11                                 Dependency Parsing     GENIA - UAS   \n",
       " 12                                 Dependency Parsing     GENIA - UAS   \n",
       " 13                     Named Entity Recognition (NER)          JNLPBA   \n",
       " 14                     Named Entity Recognition (NER)          JNLPBA   \n",
       " 15                     Named Entity Recognition (NER)    NCBI-disease   \n",
       " 16                     Named Entity Recognition (NER)    NCBI-disease   \n",
       " 17                            Sentence Classification     Paper Field   \n",
       " 18                            Sentence Classification     Paper Field   \n",
       " 19                            Sentence Classification  PubMed 20k RCT   \n",
       " 20                            Sentence Classification  PubMed 20k RCT   \n",
       " 21                            Sentence Classification         SciCite   \n",
       " 22                     Citation Intent Classification         SciCite   \n",
       " 23                            Sentence Classification     ScienceCite   \n",
       " 24                            Sentence Classification     ScienceCite   \n",
       " 25                                Relation Extraction          SciERC   \n",
       " 26                     Named Entity Recognition (NER)          SciERC   \n",
       " 27                     Named Entity Recognition (NER)          SciERC   \n",
       " 28                                Relation Extraction          SciERC   \n",
       " \n",
       "                    Model Metric name  Metric value Global rank  Extradata  \\\n",
       " 0                SciBERT          F1         65.80         # 2        NaN   \n",
       " 1     SciBERT (SciVocab)          F1         65.71         # 3        NaN   \n",
       " 2   SciBERT (Base Vocab)          F1         65.79         # 2        NaN   \n",
       " 3   SciBERT (Base Vocab)          F1         88.11         # 2        NaN   \n",
       " 4     SciBERT (SciVocab)          F1         88.94         # 1        NaN   \n",
       " 5   SciBERT (Base Vocab)          F1         73.70         # 2        NaN   \n",
       " 6     SciBERT (SciVocab)          F1         76.12         # 1        NaN   \n",
       " 7     SciBERT (SciVocab)          F1         71.18         # 1        NaN   \n",
       " 8   SciBERT (Base Vocab)          F1         70.82         # 2        NaN   \n",
       " 9     SciBERT (SciVocab)          F1         91.41         # 2        NaN   \n",
       " 10  SciBERT (Base Vocab)          F1         91.26         # 3        NaN   \n",
       " 11  SciBERT (Base Vocab)          F1         92.32         # 3        NaN   \n",
       " 12    SciBERT (SciVocab)          F1         92.46         # 2        NaN   \n",
       " 13  SciBERT (Base Vocab)          F1         75.83         # 3        NaN   \n",
       " 14    SciBERT (SciVocab)          F1         75.95         # 2        NaN   \n",
       " 15    SciBERT (SciVocab)          F1         86.45         # 2        NaN   \n",
       " 16  SciBERT (Base Vocab)          F1         86.91         # 1        NaN   \n",
       " 17  SciBERT (Base Vocab)          F1         64.02         # 2        NaN   \n",
       " 18    SciBERT (SciVocab)          F1         64.07         # 1        NaN   \n",
       " 19    SciBERT (SciVocab)          F1         86.81         # 2        NaN   \n",
       " 20  SciBERT (Base Vocab)          F1         86.80         # 3        NaN   \n",
       " 21               SciBERT          F1         84.90         # 1        NaN   \n",
       " 22               SciBERT          F1         84.99         # 1        NaN   \n",
       " 23    SciBERT (SciVocab)          F1         84.99         # 1        NaN   \n",
       " 24  SciBERT (Base Vocab)          F1         84.43         # 2        NaN   \n",
       " 25    SciBERT (SciVocab)          F1         74.64         # 1        NaN   \n",
       " 26    SciBERT (SciVocab)          F1         65.50         # 1        NaN   \n",
       " 27  SciBERT (Base Vocab)          F1         65.12         # 2        NaN   \n",
       " 28  SciBERT (Base Vocab)          F1         74.42         # 2        NaN   \n",
       " \n",
       "    Remove  \n",
       " 0       -  \n",
       " 1       -  \n",
       " 2       -  \n",
       " 3       -  \n",
       " 4       -  \n",
       " 5       -  \n",
       " 6       -  \n",
       " 7       -  \n",
       " 8       -  \n",
       " 9       -  \n",
       " 10      -  \n",
       " 11      -  \n",
       " 12      -  \n",
       " 13      -  \n",
       " 14      -  \n",
       " 15      -  \n",
       " 16      -  \n",
       " 17      -  \n",
       " 18      -  \n",
       " 19      -  \n",
       " 20      -  \n",
       " 21      -  \n",
       " 22      -  \n",
       " 23      -  \n",
       " 24      -  \n",
       " 25      -  \n",
       " 26      -  \n",
       " 27      -  \n",
       " 28      -  ,                         Task                             Dataset  \\\n",
       " 0  Pain Intensity Regression  UNBC-McMaster ShoulderPain dataset   \n",
       " \n",
       "                         Model Metric name  Metric value Global rank Remove  \n",
       " 0  Regularized Deep Regressor         MAE         0.389         # 1      -  ,                 Task           Dataset Model Metric name Metric value  \\\n",
       " 0  Face Verification  YouTube Faces DB   QAN    Accuracy       96.17%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 4      -  ,                  Task Dataset                       Model  \\\n",
       " 0  Question Answering    bAbi  End-To-End Memory Networks   \n",
       " 1  Question Answering    bAbi  End-To-End Memory Networks   \n",
       " 2  Question Answering    bAbi  End-To-End Memory Networks   \n",
       " \n",
       "                  Metric name Metric value Global rank Remove  \n",
       " 0  Accuracy (trained on 10k)        93.4%         # 4      -  \n",
       " 1   Accuracy (trained on 1k)        86.1%         # 3      -  \n",
       " 2            Mean Error Rate         7.5%         # 5      -  ,                    Task        Dataset  Model           Metric name  \\\n",
       " 0  3D Part Segmentation  ShapeNet-Part  SSCNN     Class Average IoU   \n",
       " 1  3D Part Segmentation  ShapeNet-Part  SSCNN  Instance Average IoU   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          82.0         # 3      -  \n",
       " 1          84.7         # 5      -  ,                  Task                    Dataset  \\\n",
       " 0  Speech Recognition  swb_hub_500 WER fullSWBCH   \n",
       " 1  Speech Recognition       Switchboard + Hub500   \n",
       " 2  Speech Recognition       Switchboard + Hub500   \n",
       " 3  Speech Recognition       Switchboard + Hub500   \n",
       " \n",
       "                                                Model       Metric name  \\\n",
       " 0  VGG/Resnet/LACE/BiLSTM acoustic model trained ...  Percentage error   \n",
       " 1  VGG/Resnet/LACE/BiLSTM acoustic model trained ...  Percentage error   \n",
       " 2                                              RNNLM  Percentage error   \n",
       " 3                                     Microsoft 2016  Percentage error   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          11.9         # 2      -  \n",
       " 1           6.3         # 4      -  \n",
       " 2           6.9         # 7      -  \n",
       " 3           6.2         # 3      -  ,                        Task     Dataset            Model Metric name  \\\n",
       " 0  Brain Tumor Segmentation  BRATS-2013  InputCascadeCNN  Dice Score   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          0.88         # 1      -  ,                  Task          Dataset              Model Metric name  \\\n",
       " 0  Text Summarization  DUC 2004 Task 1  words-lvt5k-1sent     ROUGE-1   \n",
       " 1  Text Summarization  DUC 2004 Task 1  words-lvt5k-1sent     ROUGE-2   \n",
       " 2  Text Summarization  DUC 2004 Task 1  words-lvt5k-1sent     ROUGE-L   \n",
       " 3  Text Summarization         GigaWord  words-lvt5k-1sent     ROUGE-1   \n",
       " 4  Text Summarization         GigaWord  words-lvt5k-1sent     ROUGE-2   \n",
       " 5  Text Summarization         GigaWord  words-lvt5k-1sent     ROUGE-L   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         28.61         # 7      -  \n",
       " 1          9.42         # 6      -  \n",
       " 2         25.24         # 5      -  \n",
       " 3         36.40         # 3      -  \n",
       " 4         17.70         # 4      -  \n",
       " 5         33.71         # 6      -  ,               Task Dataset     Model        Metric name  Metric value  \\\n",
       " 0  Link Prediction    WN18  DistMult                MRR         0.822   \n",
       " 1  Link Prediction    WN18  DistMult  [email protected]         0.936   \n",
       " 2  Link Prediction    WN18  DistMult  [email protected]         0.914   \n",
       " 3  Link Prediction    WN18  DistMult  [email protected]         0.728   \n",
       " 4  Link Prediction    WN18  DistMult                 MR       902.000   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 7      -  \n",
       " 1         # 6      -  \n",
       " 2         # 5      -  \n",
       " 3         # 7      -  \n",
       " 4         # 1      -  ,                           Task             Dataset  \\\n",
       " 0  Dialogue Act Classification  Switchboard corpus   \n",
       " \n",
       "                               Model Metric name  Metric value Global rank  \\\n",
       " 0  RNN with 3 utterances in context    Accuracy         77.34         # 3   \n",
       " \n",
       "   Remove  \n",
       " 0      -  ,                    Task Dataset      Model         Metric name  Metric value  \\\n",
       " 0  Image Classification   MNIST  C-SVDDNet    Percentage error          0.40   \n",
       " 1  Image Classification  STL-10  C-SVDDNet  Percentage correct         68.23   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 4      -  \n",
       " 1        # 10      -  ,                                     Task       Dataset Model  \\\n",
       " 0  Weakly-Supervised Object Localization  CUB-200-2011   SPG   \n",
       " 1  Weakly-Supervised Object Localization  CUB-200-2011   SPG   \n",
       " 2  Weakly-Supervised Object Localization   ILSVRC 2015   SPG   \n",
       " 3  Weakly-Supervised Object Localization   ILSVRC 2016   SPG   \n",
       " \n",
       "         Metric name  Metric value Global rank Remove  \n",
       " 0  Top-1 Error Rate         53.36         # 1      -  \n",
       " 1       Top-5 Error         42.28         # 1      -  \n",
       " 2  Top-1 Error Rate         51.40         # 1      -  \n",
       " 3       Top-5 Error         40.00         # 1      -  ,                   Task   Dataset  Model Metric name Metric value Global rank  \\\n",
       " 0  Node Classification  Citeseer  MTGAE    Accuracy       71.80%         # 3   \n",
       " 1      Link Prediction  Citeseer  MTGAE    Accuracy       94.90%         # 1   \n",
       " 2  Node Classification      Cora  MTGAE    Accuracy       79.00%         # 6   \n",
       " 3      Link Prediction      Cora  MTGAE    Accuracy       94.60%         # 1   \n",
       " 4  Node Classification    Pubmed  MTGAE    Accuracy       80.40%         # 1   \n",
       " 5      Link Prediction    Pubmed  MTGAE    Accuracy       94.40%         # 2   \n",
       " \n",
       "   Remove  \n",
       " 0      -  \n",
       " 1      -  \n",
       " 2      -  \n",
       " 3      -  \n",
       " 4      -  \n",
       " 5      -  ,                    Task  Dataset  \\\n",
       " 0  Pedestrian Detection  Caltech   \n",
       " \n",
       "                                                Model           Metric name  \\\n",
       " 0  Part-level CNN + saliency and bounding box ali...  Reasonable Miss Rate   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          12.4        # 15      -  ,                 Task      Dataset   Model Metric name  Metric value  \\\n",
       " 0  Graph-to-Sequence  LDC2015E86:  GCNSEQ        BLEU         23.95   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  ,              Task   Dataset        Model Metric name Metric value Global rank  \\\n",
       " 0  Lane Detection  TuSimple  Spatial CNN    Accuracy       96.53%         # 1   \n",
       " \n",
       "   Remove  \n",
       " 0      -  ,                    Task   Dataset        Model     Metric name Metric value  \\\n",
       " 0  Image Classification  ImageNet  ResNeXt-101  Top 1 Accuracy        80.9%   \n",
       " 1  Image Classification  ImageNet  ResNeXt-101  Top 5 Accuracy        95.6%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 7      -  \n",
       " 1         # 5      -  ,                   Task                     Dataset  \\\n",
       " 0  Machine Translation    IWSLT2015 German-English   \n",
       " 1   Language Modelling  Penn Treebank (Word Level)   \n",
       " 2   Language Modelling  Penn Treebank (Word Level)   \n",
       " 3   Language Modelling  Penn Treebank (Word Level)   \n",
       " 4   Language Modelling                  WikiText-2   \n",
       " 5   Language Modelling                  WikiText-2   \n",
       " 6   Language Modelling                  WikiText-2   \n",
       " 7  Machine Translation      WMT2014 English-German   \n",
       " \n",
       "                                  Model            Metric name Metric value  \\\n",
       " 0               Transformer with FRAGE             BLEU score        33.97   \n",
       " 1  FRAGE + AWD-LSTM-MoS + dynamic eval  Validation perplexity        47.38   \n",
       " 2  FRAGE + AWD-LSTM-MoS + dynamic eval        Test perplexity        46.54   \n",
       " 3  FRAGE + AWD-LSTM-MoS + dynamic eval                 Params          22M   \n",
       " 4  FRAGE + AWD-LSTM-MoS + dynamic eval  Validation perplexity        40.85   \n",
       " 5  FRAGE + AWD-LSTM-MoS + dynamic eval        Test perplexity        39.14   \n",
       " 6  FRAGE + AWD-LSTM-MoS + dynamic eval       Number of params          35M   \n",
       " 7           Transformer Big with FRAGE             BLEU score        29.11   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 3      -  \n",
       " 1         # 1      -  \n",
       " 2         # 2      -  \n",
       " 3         # 1      -  \n",
       " 4         # 1      -  \n",
       " 5         # 2      -  \n",
       " 6         # 1      -  \n",
       " 7         # 5      -  ,                            Task             Dataset  \\\n",
       " 0               Pose Estimation  Leeds Sports Poses   \n",
       " 1               Pose Estimation     MPII Human Pose   \n",
       " 2  Multi-Person Pose Estimation   MPII Multi-Person   \n",
       " 3  Multi-Person Pose Estimation                 WAF   \n",
       " \n",
       "                                    Model Metric name Metric value Global rank  \\\n",
       " 0  ResNet-152 + intermediate supervision         PCK        90.1%         # 4   \n",
       " 1  ResNet-152 + intermediate supervision    PCKh-0.5       88.52%         # 8   \n",
       " 2                              DeeperCut          AP        59.4%         # 7   \n",
       " 3                              DeeperCut         AOP       88.10%         # 1   \n",
       " \n",
       "   Remove  \n",
       " 0      -  \n",
       " 1      -  \n",
       " 2      -  \n",
       " 3      -  ,                     Task          Dataset  \\\n",
       " 0  Semantic Segmentation       Cityscapes   \n",
       " 1  Semantic Segmentation  PASCAL VOC 2012   \n",
       " \n",
       "                                          Model Metric name Metric value  \\\n",
       " 0  Smooth Network with Channel Attention Block    Mean IoU        80.3%   \n",
       " 1  Smooth Network with Channel Attention Block    Mean IoU        86.2%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 7      -  \n",
       " 1         # 3      -  ,                    Task    Dataset Model         Metric name  Metric value  \\\n",
       " 0  Image Classification   CIFAR-10   ACN  Percentage correct          95.6   \n",
       " 1  Image Classification  CIFAR-100   ACN  Percentage correct          66.3   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 14      -  \n",
       " 1        # 35      -  ,                                  Task          Dataset  Model Metric name  \\\n",
       " 0  Weakly Supervised Object Detection             COCO  MSLPD         MAP   \n",
       " 1  Weakly Supervised Object Detection         ImageNet  MSLPD         MAP   \n",
       " 2  Weakly Supervised Object Detection  PASCAL VOC 2007  MSLPD         MAP   \n",
       " 3  Weakly Supervised Object Detection  PASCAL VOC 2012  MSLPD         MAP   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          56.6         # 1      -  \n",
       " 1          13.9         # 3      -  \n",
       " 2          41.7        # 11      -  \n",
       " 3          35.4        # 10      -  ,                            Task   Dataset     Model      Metric name  \\\n",
       " 0  Conditional Image Generation  CIFAR-10  SteinGAN  Inception score   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          6.35         # 7      -  ,                  Task               Dataset      Model  Metric name  \\\n",
       " 0  Question Answering  Children's Book Test  EpiReader  Accuracy-CN   \n",
       " 1  Question Answering  Children's Book Test  EpiReader  Accuracy-NE   \n",
       " 2  Question Answering      CNN / Daily Mail  EpiReader          CNN   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        67.4%         # 7      -  \n",
       " 1        69.7%         # 8      -  \n",
       " 2           74         # 9      -  ,                  Task   Dataset      Model       Metric name Metric value  \\\n",
       " 0  Face Anti-Spoofing  MSU-MFSD  Color LBP  Equal Error Rate        10.8%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  ,                  Task               Dataset            Model  \\\n",
       " 0  Speech Recognition  Switchboard + Hub500         CNN-LSTM   \n",
       " 1  Speech Recognition  Switchboard + Hub500  Microsoft 2016b   \n",
       " \n",
       "         Metric name  Metric value Global rank Remove  \n",
       " 0  Percentage error           6.6         # 5      -  \n",
       " 1  Percentage error           5.8         # 2      -  ,                       Task         Dataset                         Model  \\\n",
       " 0  Sentence Classification  PubMed 20k RCT  Hierarchical Neural Networks   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0          F1          92.6         # 1      -  ,                              Task        Dataset                   Model  \\\n",
       " 0   Click-Through Rate Prediction         Amazon             Wide & Deep   \n",
       " 1   Click-Through Rate Prediction      Bing News             Wide & Deep   \n",
       " 2   Click-Through Rate Prediction      Bing News             Wide & Deep   \n",
       " 3   Click-Through Rate Prediction       Company*  Wide & Deep (FM & DNN)   \n",
       " 4   Click-Through Rate Prediction       Company*  Wide & Deep (FM & DNN)   \n",
       " 5   Click-Through Rate Prediction       Company*  Wide & Deep (LR & DNN)   \n",
       " 6   Click-Through Rate Prediction       Company*  Wide & Deep (LR & DNN)   \n",
       " 7   Click-Through Rate Prediction         Criteo  Wide & Deep (FM & DNN)   \n",
       " 8   Click-Through Rate Prediction         Criteo  Wide & Deep (FM & DNN)   \n",
       " 9   Click-Through Rate Prediction         Criteo  Wide & Deep (LR & DNN)   \n",
       " 10  Click-Through Rate Prediction         Criteo  Wide & Deep (LR & DNN)   \n",
       " 11  Click-Through Rate Prediction       Dianping             Wide & Deep   \n",
       " 12  Click-Through Rate Prediction       Dianping             Wide & Deep   \n",
       " 13  Click-Through Rate Prediction  MovieLens 20M             Wide & Deep   \n",
       " \n",
       "    Metric name  Metric value Global rank Remove  \n",
       " 0          AUC       0.86370         # 5      -  \n",
       " 1          AUC       0.83770         # 2      -  \n",
       " 2     Log Loss       0.26680         # 2      -  \n",
       " 3          AUC       0.86610         # 6      -  \n",
       " 4     Log Loss       0.02640         # 6      -  \n",
       " 5          AUC       0.86730         # 3      -  \n",
       " 6     Log Loss       0.02634         # 3      -  \n",
       " 7          AUC       0.78500         # 8      -  \n",
       " 8     Log Loss       0.45382         # 6      -  \n",
       " 9          AUC       0.79810         # 5      -  \n",
       " 10    Log Loss       0.46772         # 8      -  \n",
       " 11         AUC       0.83610         # 4      -  \n",
       " 12    Log Loss       0.33640         # 3      -  \n",
       " 13         AUC       0.73040         # 5      -  ,                               Task                         Dataset      Model  \\\n",
       " 0  Aspect-Based Sentiment Analysis  SemEval 2014 Task 4 Sub Task 2  SA-LSTM-P   \n",
       " 1  Aspect-Based Sentiment Analysis  SemEval 2014 Task 4 Sub Task 2  SA-LSTM-P   \n",
       " \n",
       "         Metric name  Metric value Global rank Remove  \n",
       " 0  Restaurant (Acc)          81.6         # 4      -  \n",
       " 1      Laptop (Acc)          75.1        # 17      -  ,                       Task            Dataset  Model Metric name  \\\n",
       " 0  Data-to-Text Generation  E2E NLG Challenge  Zhang        BLEU   \n",
       " 1  Data-to-Text Generation  E2E NLG Challenge  Zhang        NIST   \n",
       " 2  Data-to-Text Generation  E2E NLG Challenge  Zhang      METEOR   \n",
       " 3  Data-to-Text Generation  E2E NLG Challenge  Zhang     ROUGE-L   \n",
       " 4  Data-to-Text Generation  E2E NLG Challenge  Zhang       CIDEr   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0       65.4500         # 5      -  \n",
       " 1        8.1804         # 6      -  \n",
       " 2       43.9200         # 7      -  \n",
       " 3       70.8300         # 1      -  \n",
       " 4        2.1012         # 5      -  ,                                 Task       Dataset Model Metric name  \\\n",
       " 0  Fine-Grained Image Classification      CompCars   A3M    Accuracy   \n",
       " 1  Fine-Grained Image Classification  CUB-200-2011   A3M    Accuracy   \n",
       " 2           Person Re-Identification   Market-1501   A3M      Rank-1   \n",
       " 3           Person Re-Identification   Market-1501   A3M         MAP   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        95.4%         # 1      -  \n",
       " 1        86.2%         # 6      -  \n",
       " 2        86.54        # 10      -  \n",
       " 3        68.97        # 10      -  ,                    Task   Dataset         Model     Metric name Metric value  \\\n",
       " 0  Image Classification  ImageNet  Inception V2  Top 1 Accuracy        74.8%   \n",
       " 1  Image Classification  ImageNet  Inception V2  Top 5 Accuracy        92.2%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 19      -  \n",
       " 1        # 14      -  ,                    Task  Dataset   Model           Metric name  Metric value  \\\n",
       " 0  Pedestrian Detection  Caltech  TA-CNN  Reasonable Miss Rate          20.9   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 17      -  ,                  Task    Dataset                      Model Metric name  \\\n",
       " 0  Keypoint Detection  Pascal3D+  CNN + viewpoint estimates    Mean PCK   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          68.8         # 3      -  ,                  Task Dataset  \\\n",
       " 0  Question Answering    CoQA   \n",
       " 1  Question Answering    CoQA   \n",
       " 2  Question Answering    CoQA   \n",
       " 3  Question Answering    CoQA   \n",
       " 4  Question Answering    CoQA   \n",
       " 5  Question Answering    CoQA   \n",
       " \n",
       "                                                Model    Metric name  \\\n",
       " 0                        Vanilla DrQA (single model)      In-domain   \n",
       " 1                        Vanilla DrQA (single model)  Out-of-domain   \n",
       " 2                        Vanilla DrQA (single model)        Overall   \n",
       " 3  DrQA + seq2seq with copy attention (single model)      In-domain   \n",
       " 4  DrQA + seq2seq with copy attention (single model)  Out-of-domain   \n",
       " 5  DrQA + seq2seq with copy attention (single model)        Overall   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          54.5         # 8      -  \n",
       " 1          47.9         # 8      -  \n",
       " 2          52.6         # 8      -  \n",
       " 3          67.0         # 7      -  \n",
       " 4          60.4         # 7      -  \n",
       " 5          65.1         # 7      -  ,                  Task     Dataset      Model        Metric name  Metric value  \\\n",
       " 0  Question Answering  SemEvalCQA     AP-CNN  [email protected]        0.7550   \n",
       " 1  Question Answering  SemEvalCQA     AP-CNN                MAP        0.7710   \n",
       " 2  Question Answering      WikiQA     AP-CNN                MAP        0.6886   \n",
       " 3  Question Answering      WikiQA     AP-CNN                MRR        0.6957   \n",
       " 4  Question Answering    YahooCQA  AP-BiLSTM  [email protected]        0.5680   \n",
       " 5  Question Answering    YahooCQA  AP-BiLSTM                MRR        0.7310   \n",
       " 6  Question Answering    YahooCQA     AP-CNN  [email protected]        0.5600   \n",
       " 7  Question Answering    YahooCQA     AP-CNN                MRR        0.7260   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  \n",
       " 1         # 5      -  \n",
       " 2         # 6      -  \n",
       " 3         # 9      -  \n",
       " 4         # 2      -  \n",
       " 5         # 2      -  \n",
       " 6         # 3      -  \n",
       " 7         # 3      -  ,                    Task    Dataset            Model         Metric name  \\\n",
       " 0  Image Classification   CIFAR-10     Fitnet4-LSUV  Percentage correct   \n",
       " 1  Image Classification  CIFAR-100     Fitnet4-LSUV  Percentage correct   \n",
       " 2  Image Classification      MNIST  Fitnet-LSUV-SVM    Percentage error   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          94.2        # 20      -  \n",
       " 1          72.3        # 21      -  \n",
       " 2           0.4         # 4      -  ,                  Task                         Dataset  \\\n",
       " 0  Sentiment Analysis  Multi-Domain Sentiment Dataset   \n",
       " 1  Sentiment Analysis  Multi-Domain Sentiment Dataset   \n",
       " 2  Sentiment Analysis  Multi-Domain Sentiment Dataset   \n",
       " 3  Sentiment Analysis  Multi-Domain Sentiment Dataset   \n",
       " 4  Sentiment Analysis  Multi-Domain Sentiment Dataset   \n",
       " \n",
       "                      Model  Metric name  Metric value Global rank Remove  \n",
       " 0  Multi-task tri-training          DVD         78.14         # 2      -  \n",
       " 1  Multi-task tri-training        Books         74.86         # 2      -  \n",
       " 2  Multi-task tri-training  Electronics         81.45         # 1      -  \n",
       " 3  Multi-task tri-training      Kitchen         82.14         # 4      -  \n",
       " 4  Multi-task tri-training      Average         79.15         # 2      -  ,                  Task                 Dataset                   Model  \\\n",
       " 0  Speech Recognition  LibriSpeech test-clean  Model Unit Exploration   \n",
       " \n",
       "              Metric name  Metric value Global rank Remove  \n",
       " 0  Word Error Rate (WER)           3.6         # 6      -  ,              Task                      Dataset Model Metric name  \\\n",
       " 0  Face Detection  Annotated Faces in the Wild   STN          AP   \n",
       " 1  Face Detection                  PASCAL Face   STN          AP   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0        0.9835         # 7      -  \n",
       " 1        0.9410         # 6      -  ,                  Task                          Dataset  \\\n",
       " 0  Language Modelling                          enwiki8   \n",
       " 1  Language Modelling                          enwiki8   \n",
       " 2  Language Modelling  Penn Treebank (Character Level)   \n",
       " 3  Language Modelling  Penn Treebank (Character Level)   \n",
       " \n",
       "                     Model              Metric name Metric value Global rank  \\\n",
       " 0           Hypernetworks  Bit per Character (BPC)         1.34        # 11   \n",
       " 1           Hypernetworks         Number of params          27M         # 1   \n",
       " 2  2-layer Norm HyperLSTM  Bit per Character (BPC)        1.219         # 8   \n",
       " 3  2-layer Norm HyperLSTM         Number of params        14.4M         # 1   \n",
       " \n",
       "   Remove  \n",
       " 0      -  \n",
       " 1      -  \n",
       " 2      -  \n",
       " 3      -  ,                        Task              Dataset           Model  \\\n",
       " 0  Medical Object Detection  Barrett’s Esophagus  Sliding Window   \n",
       " \n",
       "      Metric name Metric value Global rank Remove  \n",
       " 0  Mean Accuracy          74%         # 2      -  ,                    Task                        Dataset              Model  \\\n",
       " 0  Image Classification                       CIFAR-10  Proxyless-G + c/o   \n",
       " 1  Image Classification                       CIFAR-10  Proxyless-G + c/o   \n",
       " 2   Architecture Search  CIFAR-10 Image Classification  Proxyless-G + c/o   \n",
       " 3   Architecture Search  CIFAR-10 Image Classification  Proxyless-G + c/o   \n",
       " \n",
       "           Metric name Metric value Global rank Remove  \n",
       " 0  Percentage correct        97.92         # 2      -  \n",
       " 1    Percentage error         2.08         # 2      -  \n",
       " 2    Percentage error         2.08         # 1      -  \n",
       " 3              Params         5.7M         # 1      -  ,              Task              Dataset       Model Metric name  Metric value  \\\n",
       " 0  Face Detection                 FDDB  Face R-FCN          AP         0.990   \n",
       " 1  Face Detection    WIDER Face (Easy)  Face R-FCN          AP         0.943   \n",
       " 2  Face Detection    WIDER Face (Hard)  Face R-FCN          AP         0.876   \n",
       " 3  Face Detection  WIDER Face (Medium)  Face R-FCN          AP         0.931   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  \n",
       " 1         # 5      -  \n",
       " 2         # 6      -  \n",
       " 3         # 5      -  ,                     Task Dataset      Model Metric name  Metric value  \\\n",
       " 0  Pancreas Segmentation  CT-150  Att U-Net  Dice Score         0.840   \n",
       " 1  Pancreas Segmentation  CT-150  Att U-Net   Precision         0.849   \n",
       " 2  Pancreas Segmentation  CT-150  Att U-Net      Recall         0.841   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 1      -  \n",
       " 2         # 1      -  ,                         Task               Dataset      Model Metric name  \\\n",
       " 0  Paraphrase Identification  Quora Question Pairs  pt-DecAtt    Accuracy   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          88.4         # 4      -  ,                      Task     Dataset      Model Metric name  Metric value  \\\n",
       " 0  Semantic Role Labeling  CoNLL 2005  Li et al.          F1          87.7   \n",
       " 1  Semantic Role Labeling   OntoNotes  Li et al.          F1          86.0   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  \n",
       " 1         # 3      -  ,                    Task    Dataset                      Model  \\\n",
       " 0  Image Classification   CIFAR-10  GPIPE + transfer learning   \n",
       " 1  Image Classification   CIFAR-10  GPIPE + transfer learning   \n",
       " 2  Image Classification  CIFAR-100                      GPIPE   \n",
       " 3  Image Classification   ImageNet                      GPIPE   \n",
       " 4  Image Classification   ImageNet                      GPIPE   \n",
       " \n",
       "           Metric name Metric value Global rank Remove  \n",
       " 0  Percentage correct           99         # 1      -  \n",
       " 1    Percentage error            1         # 1      -  \n",
       " 2  Percentage correct         91.3         # 1      -  \n",
       " 3      Top 1 Accuracy        84.3%         # 1      -  \n",
       " 4      Top 5 Accuracy          97%         # 1      -  ,                            Task   Dataset   Model Metric name  Metric value  \\\n",
       " 0  Action Recognition In Videos  Charades  LFB NL         MAP          42.5   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  ,                  Task           Dataset                       Model  \\\n",
       " 0  Language Modelling  One Billion Word  LSTM-8192-1024 + CNN Input   \n",
       " 1  Language Modelling  One Billion Word  LSTM-8192-1024 + CNN Input   \n",
       " 2  Language Modelling  One Billion Word              LSTM-8192-1024   \n",
       " 3  Language Modelling  One Billion Word              LSTM-8192-1024   \n",
       " \n",
       "         Metric name Metric value Global rank Remove  \n",
       " 0               PPL         30.0         # 8      -  \n",
       " 1  Number of params        1.04B         # 1      -  \n",
       " 2               PPL         30.6         # 9      -  \n",
       " 3  Number of params         1.8B         # 1      -  ,                  Task                     Dataset               Model  \\\n",
       " 0  Language Modelling  Penn Treebank (Word Level)  Differentiable NAS   \n",
       " 1  Language Modelling  Penn Treebank (Word Level)  Differentiable NAS   \n",
       " 2  Language Modelling  Penn Treebank (Word Level)  Differentiable NAS   \n",
       " \n",
       "              Metric name Metric value Global rank Remove  \n",
       " 0  Validation perplexity         58.3        # 13      -  \n",
       " 1        Test perplexity         56.1        # 15      -  \n",
       " 2                 Params          23M         # 1      -  ,                   Task                           Dataset  Model Metric name  \\\n",
       " 0  Text Classification                           AG News  DPCNN       Error   \n",
       " 1   Sentiment Analysis                Amazon Review Full  DPCNN    Accuracy   \n",
       " 2   Sentiment Analysis            Amazon Review Polarity  DPCNN    Accuracy   \n",
       " 3  Text Classification                           DBpedia  DPCNN       Error   \n",
       " 4   Sentiment Analysis        Yelp Binary classification  DPCNN       Error   \n",
       " 5   Sentiment Analysis  Yelp Fine-grained classification  DPCNN       Error   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          6.87         # 5      -  \n",
       " 1         65.19         # 2      -  \n",
       " 2         96.68         # 2      -  \n",
       " 3          0.88         # 6      -  \n",
       " 4          2.64         # 4      -  \n",
       " 5         30.58         # 3      -  ,                       Task                  Dataset  \\\n",
       " 0   Image Super-Resolution    BSD100 - 4x upscaling   \n",
       " 1   Image Super-Resolution    BSD100 - 4x upscaling   \n",
       " 2   Image Super-Resolution  Manga109 - 4x upscaling   \n",
       " 3   Image Super-Resolution  Manga109 - 4x upscaling   \n",
       " 4   Image Super-Resolution  Manga109 - 4x upscaling   \n",
       " 5   Image Super-Resolution  Manga109 - 4x upscaling   \n",
       " 6   Image Super-Resolution     Set14 - 4x upscaling   \n",
       " 7   Image Super-Resolution     Set14 - 4x upscaling   \n",
       " 8   Image Super-Resolution      Set5 - 4x upscaling   \n",
       " 9   Image Super-Resolution      Set5 - 4x upscaling   \n",
       " 10  Image Super-Resolution  Urban100 - 4x upscaling   \n",
       " 11  Image Super-Resolution  Urban100 - 4x upscaling   \n",
       " 12  Image Super-Resolution  Urban100 - 4x upscaling   \n",
       " 13  Image Super-Resolution  Urban100 - 4x upscaling   \n",
       " \n",
       "                                        Model Metric name  Metric value  \\\n",
       " 0   SRGAN + Residual-in-Residual Dense Block        PSNR       27.8500   \n",
       " 1   SRGAN + Residual-in-Residual Dense Block        SSIM        0.7455   \n",
       " 2                                    bicubic        PSNR       24.8900   \n",
       " 3                                    bicubic        SSIM        0.7866   \n",
       " 4   SRGAN + Residual-in-Residual Dense Block        PSNR       31.6600   \n",
       " 5   SRGAN + Residual-in-Residual Dense Block        SSIM        0.9196   \n",
       " 6   SRGAN + Residual-in-Residual Dense Block        PSNR       28.9900   \n",
       " 7   SRGAN + Residual-in-Residual Dense Block        SSIM        0.7917   \n",
       " 8   SRGAN + Residual-in-Residual Dense Block        PSNR       32.7300   \n",
       " 9   SRGAN + Residual-in-Residual Dense Block        SSIM        0.9011   \n",
       " 10  SRGAN + Residual-in-Residual Dense Block        PSNR       27.0300   \n",
       " 11  SRGAN + Residual-in-Residual Dense Block        SSIM        0.8153   \n",
       " 12                                   bicubic        PSNR       23.1400   \n",
       " 13                                   bicubic        SSIM        0.6577   \n",
       " \n",
       "    Global rank Remove  \n",
       " 0          # 1      -  \n",
       " 1          # 3      -  \n",
       " 2          # 8      -  \n",
       " 3          # 9      -  \n",
       " 4          # 1      -  \n",
       " 5          # 1      -  \n",
       " 6          # 1      -  \n",
       " 7          # 4      -  \n",
       " 8          # 2      -  \n",
       " 9          # 3      -  \n",
       " 10         # 1      -  \n",
       " 11         # 1      -  \n",
       " 12        # 23      -  \n",
       " 13        # 22      -  ,                           Task        Dataset  \\\n",
       " 0  Grammatical Error Detection  CoNLL-2014 A1   \n",
       " 1  Grammatical Error Detection  CoNLL-2014 A1   \n",
       " 2  Grammatical Error Detection  CoNLL-2014 A2   \n",
       " 3  Grammatical Error Detection  CoNLL-2014 A2   \n",
       " 4  Grammatical Error Detection            FCE   \n",
       " \n",
       "                                Model Metric name  Metric value Global rank  \\\n",
       " 0  Bi-LSTM + POS (unrestricted data)        F0.5          36.1         # 1   \n",
       " 1     Bi-LSTM + POS (trained on FCE)        F0.5          17.5         # 6   \n",
       " 2  Bi-LSTM + POS (unrestricted data)        F0.5          45.1         # 1   \n",
       " 3     Bi-LSTM + POS (trained on FCE)        F0.5          26.2         # 5   \n",
       " 4               Bi-LSTM + err POS GR        F0.5          47.7         # 4   \n",
       " \n",
       "   Remove  \n",
       " 0      -  \n",
       " 1      -  \n",
       " 2      -  \n",
       " 3      -  \n",
       " 4      -  ,                           Task                          Dataset Model  \\\n",
       " 0   Image-to-Image Translation          ADE20K Labels-to-Photos   CRN   \n",
       " 1   Image-to-Image Translation          ADE20K Labels-to-Photos   CRN   \n",
       " 2   Image-to-Image Translation          ADE20K Labels-to-Photos   CRN   \n",
       " 3   Image-to-Image Translation  ADE20K-Outdoor Labels-to-Photos   CRN   \n",
       " 4   Image-to-Image Translation  ADE20K-Outdoor Labels-to-Photos   CRN   \n",
       " 5   Image-to-Image Translation  ADE20K-Outdoor Labels-to-Photos   CRN   \n",
       " 6   Image-to-Image Translation       Cityscapes Labels-to-Photo   CRN   \n",
       " 7   Image-to-Image Translation       Cityscapes Labels-to-Photo   CRN   \n",
       " 8   Image-to-Image Translation       Cityscapes Labels-to-Photo   CRN   \n",
       " 9   Image-to-Image Translation       Cityscapes Labels-to-Photo   CRN   \n",
       " 10  Image-to-Image Translation       Cityscapes Labels-to-Photo   CRN   \n",
       " 11  Image-to-Image Translation      COCO-Stuff Labels-to-Photos   CRN   \n",
       " 12  Image-to-Image Translation      COCO-Stuff Labels-to-Photos   CRN   \n",
       " 13  Image-to-Image Translation      COCO-Stuff Labels-to-Photos   CRN   \n",
       " \n",
       "            Metric name Metric value Global rank Remove  \n",
       " 0                 mIoU         22.4         # 2      -  \n",
       " 1             Accuracy        68.8%         # 3      -  \n",
       " 2                  FID         73.3         # 2      -  \n",
       " 3                 mIoU         16.5         # 3      -  \n",
       " 4             Accuracy        68.6%         # 4      -  \n",
       " 5                  FID         99.0         # 4      -  \n",
       " 6            Class IOU          NaN         # 6      -  \n",
       " 7   Per-class Accuracy          NaN         # 5      -  \n",
       " 8   Per-pixel Accuracy        77.1%         # 3      -  \n",
       " 9                 mIoU         52.4         # 3      -  \n",
       " 10                 FID        104.7         # 4      -  \n",
       " 11                mIoU         23.7         # 2      -  \n",
       " 12            Accuracy        40.4%         # 3      -  \n",
       " 13                 FID         70.4         # 2      -  ,                  Task Dataset                      Model Metric name  \\\n",
       " 0  Question Answering   CliCR     Gated-Attention Reader          F1   \n",
       " 1  Question Answering   CliCR  Stanford Attentive Reader          F1   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          33.9         # 1      -  \n",
       " 1          27.2         # 2      -  ,                      Task     Dataset       Model Metric name  Metric value  \\\n",
       " 0  Coreference Resolution  CoNLL 2012  Lee et al.      Avg F1          67.2   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 3      -  ,                          Task Dataset  \\\n",
       " 0  Natural Language Inference    SNLI   \n",
       " 1  Natural Language Inference    SNLI   \n",
       " 2  Natural Language Inference    SNLI   \n",
       " 3  Natural Language Inference    SNLI   \n",
       " 4  Natural Language Inference    SNLI   \n",
       " 5  Natural Language Inference    SNLI   \n",
       " \n",
       "                                                Model       Metric name  \\\n",
       " 0                  200D decomposable attention model   % Test Accuracy   \n",
       " 1                  200D decomposable attention model  % Train Accuracy   \n",
       " 2                  200D decomposable attention model        Parameters   \n",
       " 3  200D decomposable attention model with intra-s...   % Test Accuracy   \n",
       " 4  200D decomposable attention model with intra-s...  % Train Accuracy   \n",
       " 5  200D decomposable attention model with intra-s...        Parameters   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0         86.3        # 26      -  \n",
       " 1         89.5        # 35      -  \n",
       " 2         380k         # 1      -  \n",
       " 3         86.8        # 21      -  \n",
       " 4         90.5        # 31      -  \n",
       " 5         580k         # 1      -  ,                                 Task        Dataset   Model Metric name  \\\n",
       " 0  Fine-Grained Image Classification   CUB-200-2011  WS-DAN    Accuracy   \n",
       " 1  Fine-Grained Image Classification  FGVC Aircraft  WS-DAN    Accuracy   \n",
       " 2  Fine-Grained Image Classification  Stanford Cars  WS-DAN    Accuracy   \n",
       " 3  Fine-Grained Image Classification  Stanford Dogs  WS-DAN    Accuracy   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        89.3%         # 2      -  \n",
       " 1        93.0%         # 1      -  \n",
       " 2        94.5%         # 1      -  \n",
       " 3         92.1         # 1      -  ,                  Task   Dataset    Model Metric name  Metric value  \\\n",
       " 0  Text Summarization  GigaWord  FTSum_g     ROUGE-1         37.27   \n",
       " 1  Text Summarization  GigaWord  FTSum_g     ROUGE-2         17.65   \n",
       " 2  Text Summarization  GigaWord  FTSum_g     ROUGE-L         34.24   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 6      -  \n",
       " 2         # 3      -  ,                       Task                                   Dataset  \\\n",
       " 0  Dialogue State Tracking  Second dialogue state tracking challenge   \n",
       " 1  Dialogue State Tracking  Second dialogue state tracking challenge   \n",
       " 2  Dialogue State Tracking  Second dialogue state tracking challenge   \n",
       " 3  Dialogue State Tracking  Second dialogue state tracking challenge   \n",
       " 4  Dialogue State Tracking  Second dialogue state tracking challenge   \n",
       " 5  Dialogue State Tracking                              Wizard-of-Oz   \n",
       " 6  Dialogue State Tracking                              Wizard-of-Oz   \n",
       " \n",
       "           Model Metric name Metric value Global rank Remove  \n",
       " 0  Zhong et al.     Request         97.5         # 1      -  \n",
       " 1  Zhong et al.        Area            -         # 3      -  \n",
       " 2  Zhong et al.        Food            -         # 3      -  \n",
       " 3  Zhong et al.       Price            -         # 4      -  \n",
       " 4  Zhong et al.       Joint         74.5         # 2      -  \n",
       " 5  Zhong et al.     Request         97.1         # 1      -  \n",
       " 6  Zhong et al.       Joint         88.1         # 2      -  ,                     Task Dataset              Model        Metric name  \\\n",
       " 0  Instance Segmentation    COCO  MultiPath Network  Average Precision   \n",
       " 1       Object Detection    COCO  MultiPath Network    Bounding Box AP   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        25.0%         # 5      -  \n",
       " 1         33.2        # 34      -  ,              Task              Dataset                   Model Metric name  \\\n",
       " 0  Face Detection    WIDER Face (Easy)           Two-stage CNN          AP   \n",
       " 1  Face Detection    WIDER Face (Easy)          Faceness-WIDER          AP   \n",
       " 2  Face Detection    WIDER Face (Easy)  Multiscale Cascade CNN          AP   \n",
       " 3  Face Detection    WIDER Face (Hard)           Two-stage CNN          AP   \n",
       " 4  Face Detection    WIDER Face (Hard)  Multiscale Cascade CNN          AP   \n",
       " 5  Face Detection    WIDER Face (Hard)          Faceness-WIDER          AP   \n",
       " 6  Face Detection  WIDER Face (Medium)          Faceness-WIDER          AP   \n",
       " 7  Face Detection  WIDER Face (Medium)           Two-stage CNN          AP   \n",
       " 8  Face Detection  WIDER Face (Medium)  Multiscale Cascade CNN          AP   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         0.657        # 14      -  \n",
       " 1         0.716        # 11      -  \n",
       " 2         0.711        # 12      -  \n",
       " 3         0.304        # 15      -  \n",
       " 4         0.400        # 13      -  \n",
       " 5         0.315        # 14      -  \n",
       " 6         0.604        # 12      -  \n",
       " 7         0.589        # 13      -  \n",
       " 8         0.636        # 11      -  ,              Task                      Dataset      Model Metric name  \\\n",
       " 0  Face Detection  Annotated Faces in the Wild  FaceBoxes          AP   \n",
       " 1  Face Detection                         FDDB  FaceBoxes          AP   \n",
       " 2  Face Detection                  PASCAL Face  FaceBoxes          AP   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0        0.9891         # 6      -  \n",
       " 1        0.9600         # 6      -  \n",
       " 2        0.9630         # 4      -  ,                    Task    Dataset        Model         Metric name  \\\n",
       " 0  Image Classification   CIFAR-10  SimpleNetv2  Percentage correct   \n",
       " 1  Image Classification  CIFAR-100  SimpleNetv2  Percentage correct   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         96.29        # 12      -  \n",
       " 1         80.29        # 10      -  ,                   Task                        Dataset          Model  \\\n",
       " 0  Architecture Search  CIFAR-10 Image Classification     ENAS + c/o   \n",
       " 1  Architecture Search  CIFAR-10 Image Classification     ENAS + c/o   \n",
       " 2   Language Modelling     Penn Treebank (Word Level)  Efficient NAS   \n",
       " 3   Language Modelling     Penn Treebank (Word Level)  Efficient NAS   \n",
       " 4   Language Modelling     Penn Treebank (Word Level)  Efficient NAS   \n",
       " \n",
       "              Metric name Metric value Global rank Remove  \n",
       " 0       Percentage error         2.89         # 6      -  \n",
       " 1                 Params         4.6M         # 1      -  \n",
       " 2  Validation perplexity         60.8        # 16      -  \n",
       " 3        Test perplexity         58.6        # 18      -  \n",
       " 4                 Params          24M         # 1      -  ,              Task              Dataset       Model Metric name  Metric value  \\\n",
       " 0  Face Detection                 FDDB  PyramidBox          AP         0.987   \n",
       " 1  Face Detection    WIDER Face (Easy)  PyramidBox          AP         0.956   \n",
       " 2  Face Detection    WIDER Face (Hard)  PyramidBox          AP         0.887   \n",
       " 3  Face Detection  WIDER Face (Medium)  PyramidBox          AP         0.946   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 4      -  \n",
       " 1         # 3      -  \n",
       " 2         # 4      -  \n",
       " 3         # 3      -  ,                        Task      Dataset Model Metric name  Metric value  \\\n",
       " 0  Person Re-Identification  Market-1501   SSM      Rank-1         82.21   \n",
       " 1  Person Re-Identification  Market-1501   SSM         MAP         68.80   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 17      -  \n",
       " 1        # 11      -  ,                              Task               Dataset        Model  \\\n",
       " 0  Named Entity Recognition (NER)  CoNLL 2003 (English)  Ma and Hovy   \n",
       " 1          Part-Of-Speech Tagging         Penn Treebank  Ma and Hovy   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0          F1         91.21        # 17      -  \n",
       " 1    Accuracy         97.55         # 5      -  ,                  Task           Dataset                   Model Metric name  \\\n",
       " 0  Question Answering  Story Cloze Test  Hidden Coherence Model    Accuracy   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          77.6         # 3      -  ,                         Task  \\\n",
       " 0  Visual Question Answering   \n",
       " 1  Visual Question Answering   \n",
       " 2  Visual Question Answering   \n",
       " 3  Visual Question Answering   \n",
       " 4  Visual Question Answering   \n",
       " 5  Visual Question Answering   \n",
       " \n",
       "                                              Dataset  \\\n",
       " 0  COCO Visual Question Answering (VQA) real imag...   \n",
       " 1  COCO Visual Question Answering (VQA) real imag...   \n",
       " 2                                             VQA v2   \n",
       " 3                                             VQA v2   \n",
       " 4                                             VQA v2   \n",
       " 5                                             VQA v2   \n",
       " \n",
       "                                         Model         Metric name  \\\n",
       " 0                                         MCB  Percentage correct   \n",
       " 1                                   d-LSTM+nI  Percentage correct   \n",
       " 2                                         MCB            Accuracy   \n",
       " 3                          Deeper LSTM Q Norm            Accuracy   \n",
       " 4      LSTM Language Model only (blind model)            Accuracy   \n",
       " 5  Prior (most common answer in training set)            Accuracy   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        62.27         # 4      -  \n",
       " 1        54.22         # 5      -  \n",
       " 2       62.27%         # 4      -  \n",
       " 3       54.22%         # 5      -  \n",
       " 4       44.26%         # 6      -  \n",
       " 5       25.98%         # 7      -  ,                          Task                            Dataset  \\\n",
       " 0   Paraphrase Identification               Quora Question Pairs   \n",
       " 1  Natural Language Inference                               SNLI   \n",
       " 2          Sentiment Analysis        SST-2 Binary classification   \n",
       " 3          Sentiment Analysis  SST-5 Fine-grained classification   \n",
       " \n",
       "                       Model      Metric name  Metric value Global rank Remove  \n",
       " 0               Bi-CAS-LSTM         Accuracy          88.6         # 3      -  \n",
       " 1  300D 2-layer Bi-CAS-LSTM  % Test Accuracy          87.0        # 20      -  \n",
       " 2               Bi-CAS-LSTM         Accuracy          91.3         # 5      -  \n",
       " 3               Bi-CAS-LSTM         Accuracy          53.6         # 5      -  ,                     Task     Dataset                      Model Metric name  \\\n",
       " 0  3D Object Recognition  ModelNet40  Variational Shape Learner    Accuracy   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        84.5%         # 3      -  ,                       Task                  Dataset  Model Metric name  \\\n",
       " 0   Image Super-Resolution    BSD100 - 4x upscaling  SRFBN        PSNR   \n",
       " 1   Image Super-Resolution    BSD100 - 4x upscaling  SRFBN        SSIM   \n",
       " 2   Image Super-Resolution    BSD100 - 4x upscaling  SRFBN         MOS   \n",
       " 3   Image Super-Resolution  Manga109 - 4x upscaling  SRFBN        PSNR   \n",
       " 4   Image Super-Resolution  Manga109 - 4x upscaling  SRFBN        SSIM   \n",
       " 5   Image Super-Resolution     Set14 - 4x upscaling  SRFBN        PSNR   \n",
       " 6   Image Super-Resolution     Set14 - 4x upscaling  SRFBN        SSIM   \n",
       " 7   Image Super-Resolution      Set5 - 4x upscaling  SRFBN        PSNR   \n",
       " 8   Image Super-Resolution      Set5 - 4x upscaling  SRFBN        SSIM   \n",
       " 9   Image Super-Resolution      Set5 - 4x upscaling  SRFBN         MOS   \n",
       " 10  Image Super-Resolution  Urban100 - 4x upscaling  SRFBN        PSNR   \n",
       " 11  Image Super-Resolution  Urban100 - 4x upscaling  SRFBN        SSIM   \n",
       " \n",
       "     Metric value Global rank Remove  \n",
       " 0        27.7200         # 4      -  \n",
       " 1         0.7409         # 8      -  \n",
       " 2            NaN         # 7      -  \n",
       " 3        31.1500         # 3      -  \n",
       " 4         0.9160         # 3      -  \n",
       " 5        28.8100         # 6      -  \n",
       " 6         0.7868         # 9      -  \n",
       " 7        32.4700         # 4      -  \n",
       " 8         0.8983         # 6      -  \n",
       " 9            NaN         # 7      -  \n",
       " 10       26.6000         # 6      -  \n",
       " 11        0.8015         # 5      -  ,                    Task   Dataset     Model     Metric name Metric value  \\\n",
       " 0  Image Classification  ImageNet  Xception  Top 1 Accuracy          79%   \n",
       " 1  Image Classification  ImageNet  Xception  Top 5 Accuracy        94.5%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 13      -  \n",
       " 1        # 10      -  ,                      Task               Dataset Model Metric name  \\\n",
       " 0  Image Super-Resolution  Set14 - 4x upscaling   PFF        PSNR   \n",
       " 1  Image Super-Resolution  Set14 - 4x upscaling   PFF        SSIM   \n",
       " 2  Image Super-Resolution   Set5 - 4x upscaling   PFF        PSNR   \n",
       " 3  Image Super-Resolution   Set5 - 4x upscaling   PFF        SSIM   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0       28.9800         # 2      -  \n",
       " 1        0.7904         # 5      -  \n",
       " 2       32.7400         # 1      -  \n",
       " 3        0.9021         # 1      -  ,                  Task       Dataset                     Model  \\\n",
       " 0  Language Modelling       enwiki8               Large mLSTM   \n",
       " 1  Language Modelling       enwiki8               Large mLSTM   \n",
       " 2  Language Modelling  Hutter Prize  Large mLSTM +emb +WN +VD   \n",
       " 3  Language Modelling  Hutter Prize  Large mLSTM +emb +WN +VD   \n",
       " 4  Language Modelling         Text8       Unregularised mLSTM   \n",
       " 5  Language Modelling         Text8       Unregularised mLSTM   \n",
       " 6  Language Modelling         Text8  Large mLSTM +emb +WN +VD   \n",
       " 7  Language Modelling         Text8  Large mLSTM +emb +WN +VD   \n",
       " \n",
       "                Metric name Metric value Global rank Remove  \n",
       " 0  Bit per Character (BPC)         1.24         # 7      -  \n",
       " 1         Number of params          46M         # 1      -  \n",
       " 2  Bit per Character (BPC)         1.24         # 7      -  \n",
       " 3         Number of params          46M         # 1      -  \n",
       " 4  Bit per Character (BPC)         1.40        # 10      -  \n",
       " 5         Number of params          45M         # 1      -  \n",
       " 6  Bit per Character (BPC)         1.27         # 7      -  \n",
       " 7         Number of params          45M         # 1      -  ,               Task          Dataset   Model Metric name  Metric value  \\\n",
       " 0  Text Generation  Yahoo Questions  SA-VAE         NLL        327.50   \n",
       " 1  Text Generation  Yahoo Questions  SA-VAE          KL          7.19   \n",
       " 2  Text Generation  Yahoo Questions  SA-VAE  Perplexity         60.40   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  \n",
       " 1         # 2      -  \n",
       " 2         # 2      -  ,                          Task Dataset  \\\n",
       " 0  Natural Language Inference    SNLI   \n",
       " 1  Natural Language Inference    SNLI   \n",
       " 2  Natural Language Inference    SNLI   \n",
       " 3  Natural Language Inference    SNLI   \n",
       " 4  Natural Language Inference    SNLI   \n",
       " 5  Natural Language Inference    SNLI   \n",
       " 6  Natural Language Inference    SNLI   \n",
       " 7  Natural Language Inference    SNLI   \n",
       " 8  Natural Language Inference    SNLI   \n",
       " \n",
       "                                                Model       Metric name  \\\n",
       " 0  Densely-Connected Recurrent and Co-Attentive N...   % Test Accuracy   \n",
       " 1  Densely-Connected Recurrent and Co-Attentive N...  % Train Accuracy   \n",
       " 2  Densely-Connected Recurrent and Co-Attentive N...        Parameters   \n",
       " 3  Densely-Connected Recurrent and Co-Attentive N...   % Test Accuracy   \n",
       " 4  Densely-Connected Recurrent and Co-Attentive N...  % Train Accuracy   \n",
       " 5  Densely-Connected Recurrent and Co-Attentive N...        Parameters   \n",
       " 6  Densely-Connected Recurrent and Co-Attentive N...   % Test Accuracy   \n",
       " 7  Densely-Connected Recurrent and Co-Attentive N...  % Train Accuracy   \n",
       " 8  Densely-Connected Recurrent and Co-Attentive N...        Parameters   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0         86.5        # 25      -  \n",
       " 1         91.4        # 25      -  \n",
       " 2         5.6m         # 1      -  \n",
       " 3         88.9         # 9      -  \n",
       " 4         93.1        # 18      -  \n",
       " 5         6.7m         # 1      -  \n",
       " 6         90.1         # 3      -  \n",
       " 7         95.0         # 9      -  \n",
       " 8        53.3m         # 1      -  ,                             Task                    Dataset  \\\n",
       " 0  Synthetic-to-Real Translation  GTAV-to-Cityscapes Labels   \n",
       " 1     Image-to-Image Translation      SYNTHIA-to-Cityscapes   \n",
       " \n",
       "                           Model Metric name  Metric value Global rank Remove  \n",
       " 0  superpixel + color constancy        mIoU          31.4         # 5      -  \n",
       " 1  superpixel + color constancy        mIoU          29.7         # 1      -  ,                           Task                     Dataset          Model  \\\n",
       " 0     Noisy Speech Recognition                 CHiME clean  Deep Speech 2   \n",
       " 1     Noisy Speech Recognition                  CHiME real  Deep Speech 2   \n",
       " 2           Speech Recognition      LibriSpeech test-other  Deep Speech 2   \n",
       " 3  Accented Speech Recognition  VoxForge American-Canadian  Deep Speech 2   \n",
       " 4  Accented Speech Recognition       VoxForge Commonwealth  Deep Speech 2   \n",
       " 5  Accented Speech Recognition           VoxForge European  Deep Speech 2   \n",
       " 6  Accented Speech Recognition             VoxForge Indian  Deep Speech 2   \n",
       " 7           Speech Recognition                  WSJ eval92  Deep Speech 2   \n",
       " 8           Speech Recognition                  WSJ eval93  Deep Speech 2   \n",
       " \n",
       "              Metric name  Metric value Global rank Remove  \n",
       " 0       Percentage error          3.34         # 1      -  \n",
       " 1       Percentage error         21.79         # 3      -  \n",
       " 2  Word Error Rate (WER)         13.25         # 5      -  \n",
       " 3       Percentage error          7.55         # 1      -  \n",
       " 4       Percentage error         13.56         # 1      -  \n",
       " 5       Percentage error         17.55         # 1      -  \n",
       " 6       Percentage error         22.44         # 1      -  \n",
       " 7       Percentage error          3.60         # 4      -  \n",
       " 8       Percentage error          4.98         # 1      -  ,                  Task   Dataset                                  Model  \\\n",
       " 0  Question Answering  SQuAD1.1  BiDAF + Self Attention (single model)   \n",
       " 1  Question Answering  SQuAD1.1  BiDAF + Self Attention (single model)   \n",
       " 2  Question Answering  TriviaQA                                 S-Norm   \n",
       " 3  Question Answering  TriviaQA                                 S-Norm   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0          EM        72.139        # 93      -  \n",
       " 1          F1        81.048        # 91      -  \n",
       " 2          EM        66.370         # 2      -  \n",
       " 3          F1        71.320         # 2      -  ,                       Task Dataset            Model Metric name  Metric value  \\\n",
       " 0  Human Part Segmentation    CIHP  PGN + ResNet101    Mean IoU          55.8   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  ,               Task        Dataset                     Model    Metric name  \\\n",
       " 0  Gaze Estimation      MPII Gaze  RT-GENE 2 model ensemble  Angular Error   \n",
       " 1  Gaze Estimation      MPII Gaze      RT-GENE single model  Angular Error   \n",
       " 2  Gaze Estimation      MPII Gaze  RT-GENE 4 model ensemble  Angular Error   \n",
       " 3  Gaze Estimation        RT-GENE  RT-GENE 4 model ensemble  Angular Error   \n",
       " 4  Gaze Estimation  UT Multi-view  RT-GENE 4 model ensemble  Angular Error   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0           4.6         # 2      -  \n",
       " 1           4.8         # 3      -  \n",
       " 2           4.3         # 1      -  \n",
       " 3           7.7         # 1      -  \n",
       " 4           5.1         # 1      -  ,                                  Task           Dataset    Model  \\\n",
       " 0  Hyperspectral Image Classification      Indian Pines  BASSNet   \n",
       " 1  Hyperspectral Image Classification  Pavia University  BASSNet   \n",
       " \n",
       "         Metric name Metric value Global rank Remove  \n",
       " 0  Overall Accuracy       96.77%         # 1      -  \n",
       " 1  Overall Accuracy       97.48%         # 2      -  ,                     Task       Dataset      Model Metric name Metric value  \\\n",
       " 0   Scene Text Detection          IC15  PSENet-1s   F-Measure       87.08%   \n",
       " 1   Scene Text Detection      IC17-MLT  PSENet-1s   F-Measure       72.45%   \n",
       " 2  Curved Text Detection  SCUT-CTW1500  PSENet-1s   F-Measure       81.17%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  \n",
       " 1         # 1      -  \n",
       " 2         # 1      -  ,                                    Task                Dataset    Model  \\\n",
       " 0  Semi-Supervised Image Classification  CIFAR-10, 4000 Labels  Γ-model   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0    Accuracy          79.6         # 7      -  ,                  Task          Dataset Model Metric name  Metric value  \\\n",
       " 0  Text Summarization  DUC 2004 Task 1  DRGD     ROUGE-1         31.79   \n",
       " 1  Text Summarization  DUC 2004 Task 1  DRGD     ROUGE-2         10.75   \n",
       " 2  Text Summarization  DUC 2004 Task 1  DRGD     ROUGE-L         27.48   \n",
       " 3  Text Summarization         GigaWord  DRGD     ROUGE-1         36.27   \n",
       " 4  Text Summarization         GigaWord  DRGD     ROUGE-2         17.57   \n",
       " 5  Text Summarization         GigaWord  DRGD     ROUGE-L         33.62   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 3      -  \n",
       " 1         # 2      -  \n",
       " 2         # 3      -  \n",
       " 3         # 5      -  \n",
       " 4         # 7      -  \n",
       " 5         # 8      -  ,                          Task Dataset  \\\n",
       " 0  Natural Language Inference    SNLI   \n",
       " 1  Natural Language Inference    SNLI   \n",
       " 2  Natural Language Inference    SNLI   \n",
       " 3  Natural Language Inference    SNLI   \n",
       " 4  Natural Language Inference    SNLI   \n",
       " 5  Natural Language Inference    SNLI   \n",
       " \n",
       "                                          Model       Metric name Metric value  \\\n",
       " 0            600D Dynamic Self-Attention Model   % Test Accuracy         86.8   \n",
       " 1            600D Dynamic Self-Attention Model  % Train Accuracy         87.3   \n",
       " 2            600D Dynamic Self-Attention Model        Parameters         2.1m   \n",
       " 3  2400D Multiple-Dynamic Self-Attention Model   % Test Accuracy         87.4   \n",
       " 4  2400D Multiple-Dynamic Self-Attention Model  % Train Accuracy         89.0   \n",
       " 5  2400D Multiple-Dynamic Self-Attention Model        Parameters         7.0m   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 21      -  \n",
       " 1        # 40      -  \n",
       " 2         # 1      -  \n",
       " 3        # 18      -  \n",
       " 4        # 38      -  \n",
       " 5         # 1      -  ,                     Task Dataset           Model      Metric name  \\\n",
       " 0  Semantic Segmentation  CamVid  FC-DenseNet103  Global Accuracy   \n",
       " 1  Semantic Segmentation  CamVid  FC-DenseNet103         Mean IoU   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        91.5%         # 1      -  \n",
       " 1        66.9%         # 3      -  ,                  Task         Dataset     Model        Metric name  \\\n",
       " 0  Hypernym Discovery         General  balAPInc                MAP   \n",
       " 1  Hypernym Discovery         General  balAPInc                MRR   \n",
       " 2  Hypernym Discovery         General  balAPInc  [email protected]   \n",
       " 3  Hypernym Discovery  Medical domain  balAPInc                MAP   \n",
       " 4  Hypernym Discovery  Medical domain  balAPInc                MRR   \n",
       " 5  Hypernym Discovery  Medical domain  balAPInc  [email protected]   \n",
       " 6  Hypernym Discovery    Music domain  balAPInc                MAP   \n",
       " 7  Hypernym Discovery    Music domain  balAPInc                MRR   \n",
       " 8  Hypernym Discovery    Music domain  balAPInc  [email protected]   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          1.36         # 8      -  \n",
       " 1          3.18         # 8      -  \n",
       " 2          1.30         # 8      -  \n",
       " 3          0.91         # 8      -  \n",
       " 4          2.10         # 8      -  \n",
       " 5          1.08         # 8      -  \n",
       " 6          1.95         # 7      -  \n",
       " 7          5.01         # 7      -  \n",
       " 8          2.15         # 7      -  ,              Task              Dataset                  Model Metric name  \\\n",
       " 0  Face Detection    WIDER Face (Easy)  Multitask Cascade CNN          AP   \n",
       " 1  Face Detection    WIDER Face (Hard)  Multitask Cascade CNN          AP   \n",
       " 2  Face Detection  WIDER Face (Medium)  Multitask Cascade CNN          AP   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         0.851         # 9      -  \n",
       " 1         0.607        # 11      -  \n",
       " 2         0.820         # 9      -  ,                                         Task  \\\n",
       " 0                Semantic Textual Similarity   \n",
       " 1                Semantic Textual Similarity   \n",
       " 2                Semantic Textual Similarity   \n",
       " 3                Semantic Textual Similarity   \n",
       " 4                 Natural Language Inference   \n",
       " 5                 Natural Language Inference   \n",
       " 6                 Natural Language Inference   \n",
       " 7   Cross-Lingual Natural Language Inference   \n",
       " 8   Cross-Lingual Natural Language Inference   \n",
       " 9   Cross-Lingual Natural Language Inference   \n",
       " 10  Cross-Lingual Natural Language Inference   \n",
       " 11  Cross-Lingual Natural Language Inference   \n",
       " 12  Cross-Lingual Natural Language Inference   \n",
       " \n",
       "                               Dataset                          Model  \\\n",
       " 0                            SentEval                      InferSent   \n",
       " 1                            SentEval                      InferSent   \n",
       " 2                            SentEval                      InferSent   \n",
       " 3                            SentEval                      InferSent   \n",
       " 4                                SNLI  4096D BiLSTM with max-pooling   \n",
       " 5                                SNLI  4096D BiLSTM with max-pooling   \n",
       " 6                                SNLI  4096D BiLSTM with max-pooling   \n",
       " 7    XNLI Zero-Shot English-to-French                         X-CBOW   \n",
       " 8    XNLI Zero-Shot English-to-French                       X-BiLSTM   \n",
       " 9    XNLI Zero-Shot English-to-German                         X-CBOW   \n",
       " 10   XNLI Zero-Shot English-to-German                       X-BiLSTM   \n",
       " 11  XNLI Zero-Shot English-to-Spanish                       X-BiLSTM   \n",
       " 12  XNLI Zero-Shot English-to-Spanish                         X-CBOW   \n",
       " \n",
       "          Metric name Metric value Global rank Remove  \n",
       " 0               MRPC    76.2/83.1         # 1      -  \n",
       " 1             SICK-R        0.884         # 2      -  \n",
       " 2             SICK-E         86.3         # 2      -  \n",
       " 3                STS    75.8/75.5         # 1      -  \n",
       " 4    % Test Accuracy         84.5        # 37      -  \n",
       " 5   % Train Accuracy         85.6        # 46      -  \n",
       " 6         Parameters          40m         # 1      -  \n",
       " 7           Accuracy        60.3%         # 3      -  \n",
       " 8           Accuracy        67.7%         # 2      -  \n",
       " 9           Accuracy        61.0%         # 4      -  \n",
       " 10          Accuracy        67.7%         # 3      -  \n",
       " 11          Accuracy        68.7%         # 3      -  \n",
       " 12          Accuracy        60.7%         # 4      -  ,                  Task                            Dataset          Model  \\\n",
       " 0  Sentiment Analysis        SST-2 Binary classification        Emo2Vec   \n",
       " 1  Sentiment Analysis        SST-2 Binary classification  GloVe+Emo2Vec   \n",
       " 2  Sentiment Analysis  SST-5 Fine-grained classification        Emo2Vec   \n",
       " 3  Sentiment Analysis  SST-5 Fine-grained classification  GloVe+Emo2Vec   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0    Accuracy          81.2        # 21      -  \n",
       " 1    Accuracy          82.3        # 20      -  \n",
       " 2    Accuracy          41.6        # 17      -  \n",
       " 3    Accuracy          43.6        # 16      -  ,                         Task  \\\n",
       " 0  Visual Question Answering   \n",
       " 1  Visual Question Answering   \n",
       " \n",
       "                                              Dataset Model  \\\n",
       " 0  COCO Visual Question Answering (VQA) real imag...   FDA   \n",
       " 1  COCO Visual Question Answering (VQA) real imag...   FDA   \n",
       " \n",
       "           Metric name  Metric value Global rank Remove  \n",
       " 0  Percentage correct          64.2         # 5      -  \n",
       " 1  Percentage correct          59.5         # 6      -  ,                   Task                   Dataset                  Model  \\\n",
       " 0  Machine Translation  IWSLT2015 English-German  NPMT + language model   \n",
       " 1  Machine Translation  IWSLT2015 German-English  NPMT + language model   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0  BLEU score         25.36         # 6      -  \n",
       " 1  BLEU score         30.08        # 10      -  ,                              Task               Dataset        Model  \\\n",
       " 0  Named Entity Recognition (NER)  CoNLL 2003 (English)  Yang et al.   \n",
       " 1          Part-Of-Speech Tagging         Penn Treebank  Yang et al.   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0          F1         91.26        # 15      -  \n",
       " 1    Accuracy         97.55         # 5      -  ,                   Task                 Dataset        Model       Metric name  \\\n",
       " 0   Language Modelling        One Billion Word  DynamicConv               PPL   \n",
       " 1   Language Modelling        One Billion Word  DynamicConv  Number of params   \n",
       " 2  Machine Translation  WMT2014 English-French  DynamicConv        BLEU score   \n",
       " 3  Machine Translation  WMT2014 English-French    LightConv        BLEU score   \n",
       " 4  Machine Translation  WMT2014 English-German  DynamicConv        BLEU score   \n",
       " 5  Machine Translation  WMT2014 English-German    LightConv        BLEU score   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        26.67         # 6      -  \n",
       " 1        0.34B         # 1      -  \n",
       " 2         43.2         # 2      -  \n",
       " 3         43.1         # 3      -  \n",
       " 4         29.7         # 2      -  \n",
       " 5         28.9         # 6      -  ,                        Task        Dataset Model Metric name  Metric value  \\\n",
       " 0  Person Re-Identification  DukeMTMC-reID   BOW      Rank-1         25.13   \n",
       " 1  Person Re-Identification  DukeMTMC-reID   BOW         MAP         12.17   \n",
       " 2  Person Re-Identification    Market-1501   BOW      Rank-1         34.40   \n",
       " 3  Person Re-Identification    Market-1501   BOW         MAP         14.09   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 19      -  \n",
       " 1        # 19      -  \n",
       " 2        # 25      -  \n",
       " 3        # 25      -  ,           Task                         Dataset Model Metric name  \\\n",
       " 0  Atari Games             Atari 2600 Gravitar   RND       Score   \n",
       " 1  Atari Games  Atari 2600 Montezuma's Revenge   RND       Score   \n",
       " 2  Atari Games             Atari 2600 Pitfall!   RND       Score   \n",
       " 3  Atari Games          Atari 2600 Private Eye   RND       Score   \n",
       " 4  Atari Games              Atari 2600 Solaris   RND       Score   \n",
       " 5  Atari Games              Atari 2600 Venture   RND       Score   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          3906         # 1      -  \n",
       " 1          8152         # 1      -  \n",
       " 2            -3         # 2      -  \n",
       " 3          8666         # 2      -  \n",
       " 4          3282         # 2      -  \n",
       " 5          1859         # 1      -  ,                   Task                 Dataset      Model Metric name  \\\n",
       " 0  Machine Translation  WMT2014 English-French       LSTM  BLEU score   \n",
       " 1  Machine Translation  WMT2014 English-French  SMT+LSTM5  BLEU score   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         34.81        # 21      -  \n",
       " 1         36.50        # 17      -  ,                              Task      Dataset                    Model  \\\n",
       " 0              Question Answering  NarrativeQA   BiAttention + DCU-LSTM   \n",
       " 1              Question Answering  NarrativeQA   BiAttention + DCU-LSTM   \n",
       " 2              Question Answering  NarrativeQA   BiAttention + DCU-LSTM   \n",
       " 3              Question Answering  NarrativeQA   BiAttention + DCU-LSTM   \n",
       " 4  Open-Domain Question Answering     SearchQA  Bi-Attention + DCU-LSTM   \n",
       " 5  Open-Domain Question Answering     SearchQA  Bi-Attention + DCU-LSTM   \n",
       " 6  Open-Domain Question Answering     SearchQA  Bi-Attention + DCU-LSTM   \n",
       " 7  Open-Domain Question Answering     SearchQA  Bi-Attention + DCU-LSTM   \n",
       " \n",
       "    Metric name Metric value Global rank Remove  \n",
       " 0       BLEU-1        36.55         # 4      -  \n",
       " 1       BLEU-4        19.79         # 4      -  \n",
       " 2       METEOR        17.87         # 4      -  \n",
       " 3      Rouge-L        41.44         # 4      -  \n",
       " 4  Unigram Acc         49.4         # 2      -  \n",
       " 5    N-gram F1         59.5         # 2      -  \n",
       " 6           EM            -         # 4      -  \n",
       " 7           F1            -         # 4      -  ,                    Task    Dataset                     Model  \\\n",
       " 0  Image Classification   CIFAR-10  DNN+Probabilistic Maxout   \n",
       " 1  Image Classification  CIFAR-100  DNN+Probabilistic Maxout   \n",
       " \n",
       "           Metric name  Metric value Global rank Remove  \n",
       " 0  Percentage correct          90.6        # 42      -  \n",
       " 1  Percentage correct          61.9        # 41      -  ,               Task        Dataset              Model Metric name  \\\n",
       " 0  Image Denoising  BSD68 sigma15  Deep CNN Denoiser        PSNR   \n",
       " 1  Image Denoising  BSD68 sigma25  Deep CNN Denoiser        PSNR   \n",
       " 2  Image Denoising  BSD68 sigma50  Deep CNN Denoiser        PSNR   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         31.63         # 4      -  \n",
       " 1         29.15         # 5      -  \n",
       " 2         26.19         # 7      -  ,               Task Dataset    Model        Metric name  Metric value  \\\n",
       " 0  Link Prediction    WN18  ANALOGY                MRR         0.942   \n",
       " 1  Link Prediction    WN18  ANALOGY  [email protected]         0.947   \n",
       " 2  Link Prediction    WN18  ANALOGY  [email protected]         0.944   \n",
       " 3  Link Prediction    WN18  ANALOGY  [email protected]         0.939   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 5      -  \n",
       " 1         # 4      -  \n",
       " 2         # 3      -  \n",
       " 3         # 4      -  ,                    Task    Dataset             Model         Metric name  \\\n",
       " 0  Image Classification   CIFAR-10  Stochastic Depth  Percentage correct   \n",
       " 1  Image Classification   CIFAR-10  Stochastic Depth    Percentage error   \n",
       " 2  Image Classification  CIFAR-100  Stochastic Depth  Percentage correct   \n",
       " 3  Image Classification  CIFAR-100  Stochastic Depth    Percentage error   \n",
       " 4  Image Classification       SVHN  Stochastic Depth    Percentage error   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         94.77        # 17      -  \n",
       " 1          5.23        # 12      -  \n",
       " 2         75.42        # 15      -  \n",
       " 3         24.58         # 7      -  \n",
       " 4          1.75         # 7      -  ,                Task   Dataset Model    Metric name  Metric value Global rank  \\\n",
       " 0  Image Generation  CIFAR-10  NICE  Model Entropy           4.5         # 1   \n",
       " \n",
       "   Remove  \n",
       " 0      -  ,                  Task Dataset                     Model Metric name  \\\n",
       " 0  Question Answering  WikiQA  Key-Value Memory Network         MAP   \n",
       " 1  Question Answering  WikiQA  Key-Value Memory Network         MRR   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0        0.7069         # 3      -  \n",
       " 1        0.7265         # 2      -  ,                     Task         Dataset   Model      Metric name  \\\n",
       " 0  Semantic Segmentation          ADE20K     FCN  Validation mIoU   \n",
       " 1  Semantic Segmentation  PASCAL Context  FCN-8s             mIoU   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         29.39         # 6      -  \n",
       " 1         37.80        # 13      -  ,                     Task         Dataset                   Model Metric name  \\\n",
       " 0  Semantic Segmentation      Cityscapes  Dual Attention Network    Mean IoU   \n",
       " 1  Semantic Segmentation  PASCAL Context  Dual Attention Network        mIoU   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        81.5%         # 4      -  \n",
       " 1         52.6         # 2      -  ,                  Task   Dataset                 Model Metric name  \\\n",
       " 0  Question Answering  SQuAD1.1  RaSoR (single model)          EM   \n",
       " 1  Question Answering  SQuAD1.1  RaSoR (single model)          F1   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0        70.849       # 105      -  \n",
       " 1        78.741       # 112      -  ,                        Task Dataset    Model      Metric name  Metric value  \\\n",
       " 0  Text-to-Image Generation    COCO  AttnGAN  Inception score         25.89   \n",
       " 1  Text-to-Image Generation     CUB  AttnGAN  Inception score          4.36   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 1      -  ,                Task   Dataset   Model      Metric name  Metric value  \\\n",
       " 0  Image Generation  CIFAR-10  LR-GAN  Inception score          7.17   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 8      -  ,                            Task          Dataset     Model    Metric name  \\\n",
       " 0  Multi-Person Pose Estimation             COCO  HRNet-48             AP   \n",
       " 1               Pose Estimation             COCO  HRNet-48       Mean mAP   \n",
       " 2            Keypoint Detection             COCO  HRNet-48  Validation AP   \n",
       " 3            Keypoint Detection             COCO  HRNet-48        Test AP   \n",
       " 4            Keypoint Detection             COCO  HRNet-32  Validation AP   \n",
       " 5               Pose Estimation  MPII Human Pose  HRNet-32       PCKh-0.5   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        0.770         # 1      -  \n",
       " 1         77.0         # 1      -  \n",
       " 2         76.3         # 1      -  \n",
       " 3         75.5         # 1      -  \n",
       " 4         75.8         # 2      -  \n",
       " 5        92.3%         # 1      -  ,                             Task               Dataset Model Metric name  \\\n",
       " 0  Safety Perception Recognition  Google Street Images   CNN    Accuracy   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0          81%         # 1      -  ,                    Task   Dataset Model         Metric name  Metric value  \\\n",
       " 0  Image Classification  CIFAR-10  APAC  Percentage correct          89.7   \n",
       " 1  Image Classification     MNIST  APAC    Percentage error           0.2   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 44      -  \n",
       " 1         # 2      -  ,           Task      Dataset                                       Model  \\\n",
       " 0  Amr Parsing  LDC2014T12:  Transition-based+improved aligner+ensemble   \n",
       " 1  Amr Parsing  LDC2014T12:  Transition-based+improved aligner+ensemble   \n",
       " \n",
       "    Metric name  Metric value Global rank Remove  \n",
       " 0  F1 Newswire          0.73         # 1      -  \n",
       " 1      F1 Full          0.68         # 1      -  ,                 Task         Dataset    Model Metric name  Metric value  \\\n",
       " 0  Sarcasm Detection  SARC (all-bal)  CASCADE    Accuracy            77   \n",
       " 1  Sarcasm Detection  SARC (pol-bal)  CASCADE    Accuracy            74   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 2      -  ,                  Task   Dataset                Model Metric name  \\\n",
       " 0  Question Answering  SQuAD1.1      jNet (ensemble)          EM   \n",
       " 1  Question Answering  SQuAD1.1      jNet (ensemble)          F1   \n",
       " 2  Question Answering  SQuAD1.1  jNet (single model)          EM   \n",
       " 3  Question Answering  SQuAD1.1  jNet (single model)          F1   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0        73.010        # 88      -  \n",
       " 1        81.517        # 88      -  \n",
       " 2        70.607       # 108      -  \n",
       " 3        79.821       # 105      -  ,                     Task          Dataset                      Model  \\\n",
       " 0  Semantic Segmentation       Cityscapes  DeepLabv3+ (Xception-JFT)   \n",
       " 1  Semantic Segmentation  PASCAL VOC 2012  DeepLabv3+ (Xception-JFT)   \n",
       " \n",
       "   Metric name Metric value Global rank  Extradata Remove  \n",
       " 0    Mean IoU        82.1%         # 1        NaN      -  \n",
       " 1    Mean IoU        89.0%         # 1        NaN      -  ,                             Task                          Dataset Model  \\\n",
       " 0  Few-Shot Image Classification  Mini-ImageNet - 1-Shot Learning  MAML   \n",
       " 1  Few-Shot Image Classification  Mini-ImageNet - 5-Shot Learning  MAML   \n",
       " 2  Few-Shot Image Classification       OMNIGLOT - 1-Shot Learning  MAML   \n",
       " 3  Few-Shot Image Classification       OMNIGLOT - 5-Shot Learning  MAML   \n",
       " \n",
       "   Metric name Metric value Global rank Remove  \n",
       " 0    Accuracy       48.70%         # 8      -  \n",
       " 1    Accuracy       63.10%         # 8      -  \n",
       " 2    Accuracy        98.7%         # 2      -  \n",
       " 3    Accuracy        99.9%         # 1      -  ,                               Task                         Dataset  \\\n",
       " 0  Aspect-Based Sentiment Analysis  SemEval 2014 Task 4 Sub Task 2   \n",
       " 1  Aspect-Based Sentiment Analysis  SemEval 2014 Task 4 Sub Task 2   \n",
       " \n",
       "                 Model       Metric name  Metric value Global rank Remove  \n",
       " 0  LSTM+SynATT+TarRep  Restaurant (Acc)         80.63        # 15      -  \n",
       " 1  LSTM+SynATT+TarRep      Laptop (Acc)         71.94         # 7      -  ,                    Task Dataset    Model         Metric name  Metric value  \\\n",
       " 0  Image Classification  STL-10  CC-GAN²  Percentage correct         77.79   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 3      -  ,                       Task         Dataset                       Model  \\\n",
       " 0  Human Part Segmentation            CIHP  Parsing R-CNN + ResNext101   \n",
       " 1          Pose Estimation  DensePose-COCO  Parsing R-CNN + ResNext101   \n",
       " 2  Human Part Segmentation        MHP v2.0  Parsing R-CNN + ResNext101   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0    Mean IoU          61.1         # 1      -  \n",
       " 1          AP          61.6         # 1      -  \n",
       " 2    Mean IoU          41.8         # 1      -  ,                   Task                   Dataset  \\\n",
       " 0  Machine Translation     WMT2016 Czech-English   \n",
       " 1  Machine Translation     WMT2016 English-Czech   \n",
       " 2  Machine Translation    WMT2016 English-German   \n",
       " 3  Machine Translation  WMT2016 English-Romanian   \n",
       " 4  Machine Translation   WMT2016 English-Russian   \n",
       " 5  Machine Translation    WMT2016 German-English   \n",
       " 6  Machine Translation  WMT2016 Romanian-English   \n",
       " 7  Machine Translation   WMT2016 Russian-English   \n",
       " \n",
       "                                Model Metric name  Metric value Global rank  \\\n",
       " 0  Attentional encoder-decoder + BPE  BLEU score          31.4         # 1   \n",
       " 1  Attentional encoder-decoder + BPE  BLEU score          25.8         # 1   \n",
       " 2  Attentional encoder-decoder + BPE  BLEU score          34.2         # 1   \n",
       " 3                              BiGRU  BLEU score          28.1         # 5   \n",
       " 4  Attentional encoder-decoder + BPE  BLEU score          26.0         # 1   \n",
       " 5  Attentional encoder-decoder + BPE  BLEU score          38.6         # 1   \n",
       " 6  Attentional encoder-decoder + BPE  BLEU score          33.3         # 2   \n",
       " 7  Attentional encoder-decoder + BPE  BLEU score          28.0         # 1   \n",
       " \n",
       "   Remove  \n",
       " 0      -  \n",
       " 1      -  \n",
       " 2      -  \n",
       " 3      -  \n",
       " 4      -  \n",
       " 5      -  \n",
       " 6      -  \n",
       " 7      -  ,                             Task                          Dataset  \\\n",
       " 0  Few-Shot Image Classification  Mini-ImageNet - 1-Shot Learning   \n",
       " 1  Few-Shot Image Classification  Mini-ImageNet - 5-Shot Learning   \n",
       " \n",
       "                                                Model Metric name Metric value  \\\n",
       " 0  Cosine similarity function + C64F feature extr...    Accuracy       56.20%   \n",
       " 1  Cosine similarity function + C128F feature ext...    Accuracy       73.00%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 3      -  \n",
       " 1         # 3      -  ,                      Task     Dataset      Model Metric name  Metric value  \\\n",
       " 0     Predicate Detection  CoNLL 2005    DeepSRL          F1          96.4   \n",
       " 1  Semantic Role Labeling   OntoNotes  He et al.          F1          81.7   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  \n",
       " 1         # 8      -  ,                              Task       Dataset     Model Metric name  \\\n",
       " 0  Unsupervised Domain Adaptation  ImageCLEF-DA  IAFN+ENT    Accuracy   \n",
       " 1  Unsupervised Domain Adaptation     Office-31  IAFN+ENT    Accuracy   \n",
       " 2  Unsupervised Domain Adaptation     VisDA2017      IAFN    Accuracy   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          88.9         # 2      -  \n",
       " 1          87.1         # 1      -  \n",
       " 2          76.1         # 1      -  ,                                 Task Dataset                  Model  \\\n",
       " 0                 Unsupervised MNIST   MNIST  PixelGAN Autoencoders   \n",
       " 1  Unsupervised image classification   MNIST  PixelGAN Autoencoders   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0    Accuracy         94.73         # 6      -  \n",
       " 1    Accuracy         94.73         # 6      -  ,                  Task   Dataset                                        Model  \\\n",
       " 0  Question Answering  SQuAD1.1  Reinforced Mnemonic Reader (ensemble model)   \n",
       " 1  Question Answering  SQuAD1.1  Reinforced Mnemonic Reader (ensemble model)   \n",
       " 2  Question Answering  SQuAD1.1    Reinforced Mnemonic Reader (single model)   \n",
       " 3  Question Answering  SQuAD1.1    Reinforced Mnemonic Reader (single model)   \n",
       " 4  Question Answering  SQuAD1.1               Mnemonic Reader (single model)   \n",
       " 5  Question Answering  SQuAD1.1               Mnemonic Reader (single model)   \n",
       " 6  Question Answering  SQuAD1.1                   Mnemonic Reader (ensemble)   \n",
       " 7  Question Answering  SQuAD1.1                   Mnemonic Reader (ensemble)   \n",
       " 8  Question Answering  TriviaQA                              Mnemonic Reader   \n",
       " 9  Question Answering  TriviaQA                              Mnemonic Reader   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0          EM        82.283        # 15      -  \n",
       " 1          F1        88.533        # 16      -  \n",
       " 2          EM        79.545        # 34      -  \n",
       " 3          F1        86.654        # 32      -  \n",
       " 4          EM        70.995       # 103      -  \n",
       " 5          F1        80.146       # 100      -  \n",
       " 6          EM        74.268        # 78      -  \n",
       " 7          F1        82.371        # 79      -  \n",
       " 8          EM        46.940         # 4      -  \n",
       " 9          F1        52.850         # 4      -  ,                    Task            Dataset   Model           Metric name  \\\n",
       " 0  Pedestrian Detection            Caltech  MS-CNN  Reasonable Miss Rate   \n",
       " 1        Face Detection  WIDER Face (Hard)   MSCNN                    AP   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         9.950        # 13      -  \n",
       " 1         0.809         # 9      -  ,                        Task        Dataset        Model Metric name  \\\n",
       " 0  Person Re-Identification  DukeMTMC-reID  LOMO + XQDA      Rank-1   \n",
       " 1  Person Re-Identification  DukeMTMC-reID  LOMO + XQDA         MAP   \n",
       " 2  Person Re-Identification    Market-1501  LOMO + XQDA      Rank-1   \n",
       " 3  Person Re-Identification    Market-1501  LOMO + XQDA         MAP   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         30.75        # 18      -  \n",
       " 1         17.04        # 18      -  \n",
       " 2         43.79        # 24      -  \n",
       " 3         22.22        # 24      -  ,                     Task       Dataset Model Metric name Metric value  \\\n",
       " 0   Scene Text Detection          IC15  EAST   F-Measure       80.72%   \n",
       " 1  Curved Text Detection  SCUT-CTW1500  EAST   F-Measure        60.4%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 7      -  \n",
       " 1         # 4      -  ,                               Task     Dataset Model  Metric name  \\\n",
       " 0            Semantic Segmentation  Cityscapes  FRRN     Mean IoU   \n",
       " 1  Real-Time Semantic Segmentation  Cityscapes  FRRN         mIoU   \n",
       " 2  Real-Time Semantic Segmentation  Cityscapes  FRRN    Time (ms)   \n",
       " 3  Real-Time Semantic Segmentation  Cityscapes  FRRN  Frame (fps)   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        71.8%        # 10      -  \n",
       " 1        71.8%         # 4      -  \n",
       " 2          469         # 4      -  \n",
       " 3          2.1         # 6      -  ,                   Task                       Dataset       Model Metric name  \\\n",
       " 0  Relation Extraction  Wikipedia-Wikidata relations  ContextAtt  Error rate   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         0.159         # 1      -  ,                 Task   Dataset     Model       Metric name Metric value  \\\n",
       " 0  3D Reconstruction  Scan2CAD  Scan2CAD  Average Accuracy       31.68%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  ,                  Task     Dataset   Model        Metric name  Metric value  \\\n",
       " 0  Question Answering  SemEvalCQA  ConvKN  [email protected]         0.755   \n",
       " 1  Question Answering  SemEvalCQA  ConvKN                MAP         0.777   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  \n",
       " 1         # 4      -  ,                        Task     Dataset                    Model Metric name  \\\n",
       " 0  Brain Tumor Segmentation  BRATS-2015  Multi-Scale 3D + FC-CRF  Dice Score   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0          84%         # 2      -  ,                Task          Dataset Model Metric name Metric value  \\\n",
       " 0  Object Detection  PASCAL VOC 2007  OHEM         MAP        78.9%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 7      -  ,                  Task   Dataset              Model Metric name  Metric value  \\\n",
       " 0  Text Summarization  GigaWord  Seq2seq + E2T_cnn     ROUGE-1         37.04   \n",
       " 1  Text Summarization  GigaWord  Seq2seq + E2T_cnn     ROUGE-2         16.66   \n",
       " 2  Text Summarization  GigaWord  Seq2seq + E2T_cnn     ROUGE-L         34.93   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  \n",
       " 1        # 11      -  \n",
       " 2         # 1      -  ,                    Task        Dataset   Model           Metric name  \\\n",
       " 0  3D Part Segmentation  ShapeNet-Part  Kd-net     Class Average IoU   \n",
       " 1  3D Part Segmentation  ShapeNet-Part  Kd-net  Instance Average IoU   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          77.4         # 6      -  \n",
       " 1          82.3         # 8      -  ,                Task   Dataset  Model      Metric name  Metric value  \\\n",
       " 0  Image Generation  CIFAR-10  BEGAN  Inception score          5.62   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 12      -  ,                             Task      Dataset                         Model  \\\n",
       " 0  Facial Expression Recognition  Cohn-Kanade  Sequential forward selection   \n",
       " \n",
       "   Metric name Metric value Global rank Remove  \n",
       " 0    Accuracy        88.7%         # 1      -  ,                    Task   Dataset  Model         Metric name  Metric value  \\\n",
       " 0  Image Classification  CIFAR-10  ReNet  Percentage correct         87.70   \n",
       " 1  Image Classification     MNIST  ReNet    Percentage error          0.50   \n",
       " 2  Image Classification      SVHN  ReNet    Percentage error          2.38   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 48      -  \n",
       " 1         # 5      -  \n",
       " 2        # 18      -  ,                   Task   Dataset         Model Metric name Metric value  \\\n",
       " 0  Node Classification  Citeseer  alpha-LoNGAE    Accuracy       71.60%   \n",
       " 1  Node Classification      Cora  alpha-LoNGAE    Accuracy       78.30%   \n",
       " 2  Node Classification    Pubmed  alpha-LoNGAE    Accuracy       79.40%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 4      -  \n",
       " 1         # 7      -  \n",
       " 2         # 3      -  ,                          Task Dataset  Model           Metric name  \\\n",
       " 0  Image-to-Image Translation    RaFD  IcGAN  Classification Error   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        8.07%         # 4      -  ,                               Task                            Dataset  \\\n",
       " 0              Text Classification                            AG News   \n",
       " 1   Named Entity Recognition (NER)               CoNLL 2003 (English)   \n",
       " 2              Text Classification                            DBpedia   \n",
       " 3               Sentiment Analysis                                 MR   \n",
       " 4               Sentiment Analysis        SST-2 Binary classification   \n",
       " 5               Sentiment Analysis  SST-5 Fine-grained classification   \n",
       " 6            Subjectivity Analysis                               SUBJ   \n",
       " 7              Text Classification                             TREC-6   \n",
       " 8              Text Classification                     Yahoo! Answers   \n",
       " 9               Sentiment Analysis         Yelp Binary classification   \n",
       " 10              Sentiment Analysis   Yelp Fine-grained classification   \n",
       " \n",
       "           Model Metric name  Metric value Global rank Remove  \n",
       " 0   SWEM-concat       Error          7.34         # 7      -  \n",
       " 1      SWEM-CRF          F1         86.28        # 19      -  \n",
       " 2   SWEM-concat       Error          1.43        # 15      -  \n",
       " 3   SWEM-concat    Accuracy         78.20         # 7      -  \n",
       " 4   SWEM-concat    Accuracy         84.30        # 19      -  \n",
       " 5   SWEM-concat    Accuracy         46.10        # 12      -  \n",
       " 6   SWEM-concat    Accuracy         93.00         # 7      -  \n",
       " 7     SWEM-aver       Error          7.80         # 9      -  \n",
       " 8   SWEM-concat    Accuracy         73.53         # 4      -  \n",
       " 9     SWEM-hier       Error          4.19        # 11      -  \n",
       " 10    SWEM-hier       Error         36.21        # 11      -  ,                  Task  Dataset      Model Metric name  Metric value  \\\n",
       " 0  Question Answering  WikiHop  Coref-GRU        Test          59.3   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  ,              Task   Dataset    Model Metric name Metric value Global rank  \\\n",
       " 0  Lane Detection  TuSimple  LaneNet    Accuracy        96.4%         # 3   \n",
       " \n",
       "   Remove  \n",
       " 0      -  ,                         Task  \\\n",
       " 0  Visual Question Answering   \n",
       " 1  Visual Question Answering   \n",
       " \n",
       "                                              Dataset             Model  \\\n",
       " 0  COCO Visual Question Answering (VQA) real imag...  iBOWIMG baseline   \n",
       " 1  COCO Visual Question Answering (VQA) real imag...  iBOWIMG baseline   \n",
       " \n",
       "           Metric name  Metric value Global rank Remove  \n",
       " 0  Percentage correct         61.97         # 7      -  \n",
       " 1  Percentage correct         55.89        # 10      -  ,                   Task                 Dataset                      Model  \\\n",
       " 0  Machine Translation  WMT2016 English-German  Linguistic Input Features   \n",
       " 1  Machine Translation  WMT2016 German-English  Linguistic Input Features   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0  BLEU score          28.4         # 2      -  \n",
       " 1  BLEU score          32.9         # 2      -  ,                      Task      Dataset        Model Metric name Metric value  \\\n",
       " 0    Head Pose Estimation     AFLW2000        3DDFA         MAE        7.393   \n",
       " 1          Face Alignment  AFLW2000-3D  3DDFA + SDM    Mean NME        4.94%   \n",
       " 2  3D Face Reconstruction  AFLW2000-3D        3DDFA    Mean NME      5.3695%   \n",
       " 3    Head Pose Estimation         BIWI        3DDFA         MAE       19.068   \n",
       " 4  3D Face Reconstruction     Florence        3DDFA    Mean NME      6.3833%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  \n",
       " 1         # 5      -  \n",
       " 2         # 2      -  \n",
       " 3         # 4      -  \n",
       " 4         # 3      -  ,                   Task  Dataset  Model Metric name  Metric value Global rank  \\\n",
       " 0  Text Classification   20NEWS   SGCN    Accuracy          88.5         # 1   \n",
       " 1   Sentiment Analysis       MR   SGCN    Accuracy          75.9        # 10   \n",
       " 2  Text Classification  Ohsumed   SGCN    Accuracy          68.5         # 1   \n",
       " 3  Text Classification      R52   SGCN    Accuracy          94.0         # 1   \n",
       " 4  Text Classification       R8   SGCN    Accuracy          97.2         # 1   \n",
       " 5  Relation Extraction   TACRED  C-SGC          F1          67.0         # 2   \n",
       " \n",
       "    Extradata Remove  \n",
       " 0        NaN      -  \n",
       " 1        NaN      -  \n",
       " 2        NaN      -  \n",
       " 3        NaN      -  \n",
       " 4        NaN      -  \n",
       " 5        NaN      -  ,                  Task Dataset      Model Metric name  Metric value  \\\n",
       " 0  Keypoint Detection    COCO  PersonLab     Test AP          66.5   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 3      -  ,                   Task                   Dataset      Model Metric name  \\\n",
       " 0  Machine Translation  IWSLT2015 English-German  RNNsearch  BLEU score   \n",
       " 1  Machine Translation  IWSLT2015 German-English  RNNsearch  BLEU score   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         25.04         # 7      -  \n",
       " 1         29.98        # 11      -  ,                   Task                   Dataset Model Metric name  \\\n",
       " 0  Machine Translation  IWSLT2015 German-English  DCCL  BLEU score   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         29.56        # 12      -  ,                  Task    Dataset   Model Metric name  Metric value  \\\n",
       " 0  6D Pose Estimation  OCCLUSION  SSD-6D         MAP          0.38   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  ,                    Task     Dataset          Model       Metric name  \\\n",
       " 0  Hand Pose Estimation  ICVL Hands  Pose Guidance  Average 3D Error   \n",
       " 1  Hand Pose Estimation  MSRA Hands  Pose Guidance  Average 3D Error   \n",
       " 2  Hand Pose Estimation   NYU Hands  Pose Guidance  Average 3D Error   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0           6.8         # 2      -  \n",
       " 1           8.6         # 3      -  \n",
       " 2          11.8         # 3      -  ,                    Task    Dataset                     Model  \\\n",
       " 0  Image Classification   CIFAR-10  Exponential Linear Units   \n",
       " 1  Image Classification  CIFAR-100  Exponential Linear Units   \n",
       " \n",
       "           Metric name  Metric value Global rank Remove  \n",
       " 0  Percentage correct          93.5        # 25      -  \n",
       " 1  Percentage correct          75.7        # 14      -  ,                Task   Dataset     Model Metric name  Metric value Global rank  \\\n",
       " 0  Image Generation  CIFAR-10  Deep GMM    NLL Test           4.0         # 9   \n",
       " \n",
       "   Remove  \n",
       " 0      -  ,                 Task   Dataset             Model Metric name  Metric value  \\\n",
       " 0  Facial Inpainting  VggFace2  SymmFCNet (Full)        PSNR         27.81   \n",
       " 1  Facial Inpainting   WebFace  SymmFCNet (Full)        PSNR         27.22   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 1      -  ,                     Task         Dataset                              Model  \\\n",
       " 0  Semantic Segmentation          ADE20K                       EncNet + JPU   \n",
       " 1  Semantic Segmentation          ADE20K                       EncNet + JPU   \n",
       " 2  Semantic Segmentation  PASCAL Context  Joint Pyramid Upsampling + EncNet   \n",
       " \n",
       "        Metric name  Metric value Global rank Remove  \n",
       " 0  Validation mIoU       44.3400         # 3      -  \n",
       " 1       Test Score        0.5584         # 1      -  \n",
       " 2             mIoU       53.1000         # 1      -  ,                  Task Dataset                         Model Metric name  \\\n",
       " 0  Sentiment Analysis    IMDb  Virtual adversarial training    Accuracy   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          94.1         # 6      -  ,                      Task   Dataset               Model       Metric name  \\\n",
       " 0  3D Face Reconstruction  Florence  Unsupervised-3DMMR  Average 3D Error   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0           1.5         # 2      -  ,                            Task       Dataset        Model Metric name  \\\n",
       " 0  Grammatical Error Correction    Restricted  CNN Seq2Seq        F0.5   \n",
       " 1  Grammatical Error Correction    Restricted  CNN Seq2Seq        F0.5   \n",
       " 2  Grammatical Error Correction  _Restricted_  CNN Seq2Seq        GLEU   \n",
       " \n",
       "                           Metric value Global rank Remove  \n",
       " 0                                54.79         # 5      -  \n",
       " 1  70.14 (measured by Ge et al., 2018)         # 6      -  \n",
       " 2                                57.47         # 3      -  ,                  Task Dataset          Model Metric name  Metric value  \\\n",
       " 0  Sentiment Analysis    IMDb  seq2-bown-CNN    Accuracy         92.33   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 7      -  ,                            Task            Dataset  \\\n",
       " 0  Multi-Person Pose Estimation  MPII Multi-Person   \n",
       " \n",
       "                                Model Metric name Metric value Global rank  \\\n",
       " 0  Local Joint-to-Person Association          AP        62.2%         # 6   \n",
       " \n",
       "   Remove  \n",
       " 0      -  ,                    Task    Dataset               Model         Metric name  \\\n",
       " 0  Image Classification   CIFAR-10  Evolution ensemble  Percentage correct   \n",
       " 1  Image Classification   CIFAR-10           Evolution  Percentage correct   \n",
       " 2  Image Classification  CIFAR-100           Evolution  Percentage correct   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          95.6        # 14      -  \n",
       " 1          94.6        # 18      -  \n",
       " 2          77.0        # 13      -  ,                          Task Dataset                          Model  \\\n",
       " 0  Natural Language Inference    SNLI  300D Gumbel TreeLSTM encoders   \n",
       " 1  Natural Language Inference    SNLI  300D Gumbel TreeLSTM encoders   \n",
       " 2  Natural Language Inference    SNLI  300D Gumbel TreeLSTM encoders   \n",
       " 3  Natural Language Inference    SNLI  600D Gumbel TreeLSTM encoders   \n",
       " 4  Natural Language Inference    SNLI  600D Gumbel TreeLSTM encoders   \n",
       " 5  Natural Language Inference    SNLI  600D Gumbel TreeLSTM encoders   \n",
       " \n",
       "         Metric name Metric value Global rank Remove  \n",
       " 0   % Test Accuracy         85.6        # 31      -  \n",
       " 1  % Train Accuracy         91.2        # 26      -  \n",
       " 2        Parameters         2.9m         # 1      -  \n",
       " 3   % Test Accuracy         86.0        # 28      -  \n",
       " 4  % Train Accuracy         93.1        # 18      -  \n",
       " 5        Parameters          10m         # 1      -  ,                           Task  \\\n",
       " 0  Dialogue Act Classification   \n",
       " 1  Dialogue Act Classification   \n",
       " \n",
       "                                           Dataset    Model Metric name  \\\n",
       " 0  ICSI Meeting Recorder Dialog Act (MRDA) corpus  CRF-ASN    Accuracy   \n",
       " 1                              Switchboard corpus  CRF-ASN    Accuracy   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          91.7         # 1      -  \n",
       " 1          81.3         # 1      -  ,              Task Dataset    Model      Metric name  Metric value Global rank  \\\n",
       " 0  Face Alignment    300W  SIR-LAN  Mean Error Rate          2.83         # 2   \n",
       " \n",
       "   Remove  \n",
       " 0      -  ,                 Task Dataset                    Model     Metric name  \\\n",
       " 0  Face Verification   IJB-A  Deep CNN + COTS matcher  TAR @ FAR=0.01   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0       73.30%        # 13      -  ,                  Task        Dataset  Model Metric name  Metric value  \\\n",
       " 0  Dependency Parsing  Penn Treebank  jPTDP         POS         97.97   \n",
       " 1  Dependency Parsing  Penn Treebank  jPTDP         UAS         94.51   \n",
       " 2  Dependency Parsing  Penn Treebank  jPTDP         LAS         92.87   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 4      -  \n",
       " 2         # 3      -  ,                Task Dataset                                            Model  \\\n",
       " 0  Causal Inference    IDHP  OLS with separate regressors for each treatment   \n",
       " 1  Causal Inference    IDHP                 OLS with treatments as a feature   \n",
       " 2  Causal Inference    IDHP                                             BART   \n",
       " 3  Causal Inference    IDHP                                    Random Forest   \n",
       " 4  Causal Inference    IDHP                                    Causal Forest   \n",
       " 5  Causal Inference    IDHP                                           TARNet   \n",
       " 6  Causal Inference    IDHP                         Balancing Neural Network   \n",
       " 7  Causal Inference    IDHP                                             k-NN   \n",
       " 8  Causal Inference    IDHP                      Balancing Linear Regression   \n",
       " 9  Causal Inference    IDHP                 Counterfactual Regression + WASS   \n",
       " \n",
       "                       Metric name  Metric value Global rank Remove  \n",
       " 0  Average Treatment Effect Error          0.31         # 3      -  \n",
       " 1  Average Treatment Effect Error          0.94         # 9      -  \n",
       " 2  Average Treatment Effect Error          0.34         # 4      -  \n",
       " 3  Average Treatment Effect Error          0.96        # 10      -  \n",
       " 4  Average Treatment Effect Error          0.40         # 5      -  \n",
       " 5  Average Treatment Effect Error          0.28         # 2      -  \n",
       " 6  Average Treatment Effect Error          0.42         # 6      -  \n",
       " 7  Average Treatment Effect Error          0.79         # 7      -  \n",
       " 8  Average Treatment Effect Error          0.93         # 8      -  \n",
       " 9  Average Treatment Effect Error          0.27         # 1      -  ,                        Task      Dataset     Model Metric name  Metric value  \\\n",
       " 0  Person Re-Identification  Market-1501  PartLoss      Rank-1          88.2   \n",
       " 1  Person Re-Identification  Market-1501  PartLoss         MAP          69.3   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 8      -  \n",
       " 1         # 8      -  ,                  Task  Dataset             Model Metric name Metric value  \\\n",
       " 0  6D Pose Estimation  LineMOD  PoseCNN + DeepIM    Accuracy        97.5%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  ,                  Task                            Dataset Model Metric name  \\\n",
       " 0  Sentiment Analysis        SST-2 Binary classification  RNTN    Accuracy   \n",
       " 1  Sentiment Analysis  SST-5 Fine-grained classification  RNTN    Accuracy   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          85.4        # 18      -  \n",
       " 1          45.7        # 13      -  ,                  Task                 Dataset  \\\n",
       " 0  Speech Recognition  LibriSpeech test-other   \n",
       " \n",
       "                                          Model            Metric name  \\\n",
       " 0  deep 1d convs + ctc + external lm rescoring  Word Error Rate (WER)   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          8.79         # 3      -  ,                       Task Dataset  Model Metric name Metric value  \\\n",
       " 0  Document Classification    Cora  MoNet    Accuracy        81.7%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 4      -  ,                                          Task         Dataset     Model  \\\n",
       " 0  3D Room Layouts From A Single Rgb Panorama     PanoContext  DuLa-Net   \n",
       " 1  3D Room Layouts From A Single Rgb Panorama      Realtor360  DuLa-Net   \n",
       " 2  3D Room Layouts From A Single Rgb Panorama  Stanford 2D-3D  DuLa-Net   \n",
       " \n",
       "   Metric name Metric value Global rank Remove  \n",
       " 0       3DIoU       77.42%         # 3      -  \n",
       " 1       3DIoU       77.20%         # 1      -  \n",
       " 2       3DIoU       79.36%         # 2      -  ,                    Task    Dataset        Model         Metric name  \\\n",
       " 0  Image Classification   CIFAR-10  ResNet-1001  Percentage correct   \n",
       " 1  Image Classification   CIFAR-10  ResNet-1001    Percentage error   \n",
       " 2  Image Classification  CIFAR-100  ResNet-1001  Percentage correct   \n",
       " 3  Image Classification  CIFAR-100  ResNet-1001    Percentage error   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         95.40        # 16      -  \n",
       " 1          4.62        # 11      -  \n",
       " 2         77.30        # 12      -  \n",
       " 3         22.71         # 6      -  ,                       Task            Dataset Model Metric name  Metric value  \\\n",
       " 0  Data-to-Text Generation  E2E NLG Challenge  TGen        BLEU       65.9300   \n",
       " 1  Data-to-Text Generation  E2E NLG Challenge  TGen        NIST        8.6094   \n",
       " 2  Data-to-Text Generation  E2E NLG Challenge  TGen      METEOR       44.8300   \n",
       " 3  Data-to-Text Generation  E2E NLG Challenge  TGen     ROUGE-L       68.5000   \n",
       " 4  Data-to-Text Generation  E2E NLG Challenge  TGen       CIDEr        2.2338   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 3      -  \n",
       " 1         # 3      -  \n",
       " 2         # 4      -  \n",
       " 3         # 3      -  \n",
       " 4         # 3      -  ,                                                  Task  \\\n",
       " 0   Multimodal Unsupervised Image-To-Image Transla...   \n",
       " 1   Multimodal Unsupervised Image-To-Image Transla...   \n",
       " 2                          Image-to-Image Translation   \n",
       " 3                          Image-to-Image Translation   \n",
       " 4                          Image-to-Image Translation   \n",
       " 5                          Image-to-Image Translation   \n",
       " 6                          Image-to-Image Translation   \n",
       " 7                          Image-to-Image Translation   \n",
       " 8   Multimodal Unsupervised Image-To-Image Transla...   \n",
       " 9   Multimodal Unsupervised Image-To-Image Transla...   \n",
       " 10  Multimodal Unsupervised Image-To-Image Transla...   \n",
       " 11  Multimodal Unsupervised Image-To-Image Transla...   \n",
       " 12                         Image-to-Image Translation   \n",
       " \n",
       "                        Dataset     Model           Metric name Metric value  \\\n",
       " 0                Cats-and-Dogs  CycleGAN                   CIS        0.076   \n",
       " 1                Cats-and-Dogs  CycleGAN                    IS        0.813   \n",
       " 2   Cityscapes Labels-to-Photo  CycleGAN             Class IOU         0.11   \n",
       " 3   Cityscapes Labels-to-Photo  CycleGAN    Per-class Accuracy          17%   \n",
       " 4   Cityscapes Labels-to-Photo  CycleGAN    Per-pixel Accuracy          52%   \n",
       " 5   Cityscapes Photo-to-Labels  CycleGAN    Per-pixel Accuracy          58%   \n",
       " 6   Cityscapes Photo-to-Labels  CycleGAN    Per-class Accuracy          22%   \n",
       " 7   Cityscapes Photo-to-Labels  CycleGAN             Class IOU         0.16   \n",
       " 8             Edge-to-Handbags  CycleGAN               Quality        40.8%   \n",
       " 9             Edge-to-Handbags  CycleGAN             Diversity        0.012   \n",
       " 10               Edge-to-Shoes  CycleGAN               Quality        36.0%   \n",
       " 11               Edge-to-Shoes  CycleGAN             Diversity        0.010   \n",
       " 12                        RaFD  CycleGAN  Classification Error        5.99%   \n",
       " \n",
       "    Global rank Remove  \n",
       " 0          # 3      -  \n",
       " 1          # 3      -  \n",
       " 2          # 2      -  \n",
       " 3          # 2      -  \n",
       " 4          # 6      -  \n",
       " 5          # 2      -  \n",
       " 6          # 2      -  \n",
       " 7          # 2      -  \n",
       " 8          # 3      -  \n",
       " 9          # 4      -  \n",
       " 10         # 4      -  \n",
       " 11         # 4      -  \n",
       " 12         # 3      -  ,                  Task Dataset                       Model      Metric name  \\\n",
       " 0    Object Detection    COCO  CenterNet-HG (multi-scale)  Bounding Box AP   \n",
       " 1    Object Detection    COCO               CenterNet-DLA  Bounding Box AP   \n",
       " 2  Keypoint Detection    COCO                       HG-jd          Test AP   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          45.1         # 7      -  \n",
       " 1          41.6        # 20      -  \n",
       " 2          63.0         # 5      -  ,                          Task          Dataset Model Metric name Metric value  \\\n",
       " 0            Object Detection  PASCAL VOC 2007  YOLO         MAP        63.4%   \n",
       " 1  Real-Time Object Detection  PASCAL VOC 2007  YOLO         MAP        63.4%   \n",
       " 2  Real-Time Object Detection  PASCAL VOC 2007  YOLO         FPS           46   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 18      -  \n",
       " 1         # 6      -  \n",
       " 2         # 2      -  ,                               Task           Dataset               Model  \\\n",
       " 0  3D Medical Imaging Segmentation  TCIA Pancreas-CT  Multi-class 3D FCN   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0  Dice Score          76.8         # 2      -  ,                    Task   Dataset            Model Metric name  Metric value  \\\n",
       " 0  Head Pose Estimation  AFLW2000  FAN (12 points)         MAE         9.116   \n",
       " 1  Head Pose Estimation      BIWI  FAN (12 points)         MAE         7.882   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 3      -  \n",
       " 1         # 2      -  ,                          Task               Dataset           Model  \\\n",
       " 0   Paraphrase Identification  Quora Question Pairs           BiMPM   \n",
       " 1  Natural Language Inference                  SNLI           BiMPM   \n",
       " 2  Natural Language Inference                  SNLI           BiMPM   \n",
       " 3  Natural Language Inference                  SNLI           BiMPM   \n",
       " 4  Natural Language Inference                  SNLI  BiMPM Ensemble   \n",
       " 5  Natural Language Inference                  SNLI  BiMPM Ensemble   \n",
       " 6  Natural Language Inference                  SNLI  BiMPM Ensemble   \n",
       " \n",
       "         Metric name Metric value Global rank Remove  \n",
       " 0          Accuracy        88.17         # 5      -  \n",
       " 1   % Test Accuracy         87.5        # 17      -  \n",
       " 2  % Train Accuracy         90.9        # 29      -  \n",
       " 3        Parameters         1.6m         # 1      -  \n",
       " 4   % Test Accuracy         88.8        # 10      -  \n",
       " 5  % Train Accuracy         93.2        # 17      -  \n",
       " 6        Parameters         6.4m         # 1      -  ,                          Task        Dataset    Model         Metric name  \\\n",
       " 0  Image-to-Image Translation  Aerial-to-Map  DualGAN  Per-pixel Accuracy   \n",
       " 1  Image-to-Image Translation  Aerial-to-Map  DualGAN  Per-class Accuracy   \n",
       " 2  Image-to-Image Translation  Aerial-to-Map  DualGAN           Class IOU   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0          42%         # 2      -  \n",
       " 1          22%         # 2      -  \n",
       " 2         0.09         # 2      -  ,               Task          Dataset         Model Metric name Metric value  \\\n",
       " 0  Pose Estimation  MPII Human Pose  Tucker T-Net    PCKh-0.5        87.5%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 9      -  ,                    Task    Dataset                Model Metric name  \\\n",
       " 0  Language Acquisition  SLAM 2018  Context Based Model         AUC   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         0.821         # 1      -  ,                   Task                 Dataset           Model Metric name  \\\n",
       " 0  Machine Translation  WMT2014 English-French  LSTM6 + PosUnk  BLEU score   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          37.5        # 15      -  ,                  Task                 Dataset  Model            Metric name  \\\n",
       " 0  Speech Recognition  LibriSpeech test-other  Snips  Word Error Rate (WER)   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          16.5         # 7      -  ,                          Task Dataset         Model       Metric name  \\\n",
       " 0  Natural Language Inference    SNLI  100D DF-LSTM   % Test Accuracy   \n",
       " 1  Natural Language Inference    SNLI  100D DF-LSTM  % Train Accuracy   \n",
       " 2  Natural Language Inference    SNLI  100D DF-LSTM        Parameters   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0         84.6        # 36      -  \n",
       " 1         85.2        # 48      -  \n",
       " 2         320k         # 1      -  ,                           Task        Dataset                        Model  \\\n",
       " 0  Grammatical Error Detection  CoNLL-2014 A1     Bi-LSTM (trained on FCE)   \n",
       " 1  Grammatical Error Detection  CoNLL-2014 A1  Bi-LSTM (unrestricted data)   \n",
       " 2  Grammatical Error Detection  CoNLL-2014 A2     Bi-LSTM (trained on FCE)   \n",
       " 3  Grammatical Error Detection  CoNLL-2014 A2  Bi-LSTM (unrestricted data)   \n",
       " 4  Grammatical Error Detection            FCE                      Bi-LSTM   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0        F0.5          16.4         # 7      -  \n",
       " 1        F0.5          34.3         # 2      -  \n",
       " 2        F0.5          23.9         # 7      -  \n",
       " 3        F0.5          44.0         # 2      -  \n",
       " 4        F0.5          41.1         # 6      -  ,                 Task Dataset                            Model     Metric name  \\\n",
       " 0  Face Verification   IJB-A  Deep multi-pose representations  TAR @ FAR=0.01   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0       78.70%        # 12      -  ,                              Task               Dataset   Model Metric name  \\\n",
       " 0  Named Entity Recognition (NER)  CoNLL 2003 (English)  S-LSTM          F1   \n",
       " 1              Sentiment Analysis                  IMDb  S-LSTM    Accuracy   \n",
       " 2              Sentiment Analysis                    MR  S-LSTM    Accuracy   \n",
       " 3          Part-Of-Speech Tagging         Penn Treebank  S-LSTM    Accuracy   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         91.57        # 11      -  \n",
       " 1         87.15        # 12      -  \n",
       " 2         76.20         # 9      -  \n",
       " 3         97.55         # 5      -  ,                    Task    Dataset       Model         Metric name  \\\n",
       " 0  Image Classification   CIFAR-10  ResNet+ELU  Percentage correct   \n",
       " 1  Image Classification  CIFAR-100  ResNet+ELU  Percentage correct   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          94.4        # 19      -  \n",
       " 1          73.5        # 17      -  ,                                        Task  \\\n",
       " 0               Cross-Lingual Bitext Mining   \n",
       " 1               Cross-Lingual Bitext Mining   \n",
       " 2     Cross-Lingual Document Classification   \n",
       " 3     Cross-Lingual Document Classification   \n",
       " 4     Cross-Lingual Document Classification   \n",
       " 5  Cross-Lingual Natural Language Inference   \n",
       " 6  Cross-Lingual Natural Language Inference   \n",
       " 7  Cross-Lingual Natural Language Inference   \n",
       " \n",
       "                               Dataset  \\\n",
       " 0              BUCC French-to-English   \n",
       " 1              BUCC German-to-English   \n",
       " 2   MLDoc Zero-Shot English-to-French   \n",
       " 3   MLDoc Zero-Shot English-to-German   \n",
       " 4  MLDoc Zero-Shot English-to-Spanish   \n",
       " 5    XNLI Zero-Shot English-to-French   \n",
       " 6    XNLI Zero-Shot English-to-German   \n",
       " 7   XNLI Zero-Shot English-to-Spanish   \n",
       " \n",
       "                                         Model Metric name Metric value  \\\n",
       " 0  Massively Multilingual Sentence Embeddings    F1 score        93.91   \n",
       " 1  Massively Multilingual Sentence Embeddings    F1 score        96.19   \n",
       " 2  Massively Multilingual Sentence Embeddings    Accuracy       77.95%   \n",
       " 3  Massively Multilingual Sentence Embeddings    Accuracy       84.78%   \n",
       " 4  Massively Multilingual Sentence Embeddings    Accuracy       77.33%   \n",
       " 5                                      BiLSTM    Accuracy        71.9%   \n",
       " 6                                      BiLSTM    Accuracy        72.6%   \n",
       " 7                                      BiLSTM    Accuracy        72.9%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 1      -  \n",
       " 2         # 1      -  \n",
       " 3         # 1      -  \n",
       " 4         # 1      -  \n",
       " 5         # 1      -  \n",
       " 6         # 1      -  \n",
       " 7         # 2      -  ,                        Task        Dataset   Model Metric name  Metric value  \\\n",
       " 0  Person Re-Identification  DukeMTMC-reID  SVDNet      Rank-1          76.7   \n",
       " 1  Person Re-Identification  DukeMTMC-reID  SVDNet         MAP          56.8   \n",
       " 2  Person Re-Identification    Market-1501  SVDNet      Rank-1          82.3   \n",
       " 3  Person Re-Identification    Market-1501  SVDNet         MAP          62.1   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 8      -  \n",
       " 1         # 8      -  \n",
       " 2        # 16      -  \n",
       " 3        # 19      -  ,                  Task   Dataset                     Model Metric name  \\\n",
       " 0  Question Answering  SQuAD1.1      FusionNet (ensemble)          EM   \n",
       " 1  Question Answering  SQuAD1.1      FusionNet (ensemble)          F1   \n",
       " 2  Question Answering  SQuAD1.1  FusionNet (single model)          EM   \n",
       " 3  Question Answering  SQuAD1.1  FusionNet (single model)          F1   \n",
       " 4  Question Answering  SQuAD2.0    FusionNet++ (ensemble)          EM   \n",
       " 5  Question Answering  SQuAD2.0    FusionNet++ (ensemble)          F1   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0        78.978        # 38      -  \n",
       " 1        86.016        # 38      -  \n",
       " 2        75.968        # 66      -  \n",
       " 3        83.900        # 65      -  \n",
       " 4        70.300        # 70      -  \n",
       " 5        72.484        # 75      -  ,                         Task  \\\n",
       " 0  Visual Question Answering   \n",
       " 1  Visual Question Answering   \n",
       " \n",
       "                                              Dataset      Model  \\\n",
       " 0  COCO Visual Question Answering (VQA) abstract ...  Graph VQA   \n",
       " 1  COCO Visual Question Answering (VQA) abstract ...  Graph VQA   \n",
       " \n",
       "           Metric name  Metric value Global rank Remove  \n",
       " 0  Percentage correct         74.37         # 1      -  \n",
       " 1  Percentage correct         70.42         # 1      -  ,                       Task        Dataset    Model Metric name  Metric value  \\\n",
       " 0  Collaborative Filtering  MovieLens 10M  CF-NADE        RMSE         0.771   \n",
       " 1  Collaborative Filtering   MovieLens 1M  CF-NADE        RMSE         0.829   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  \n",
       " 1         # 2      -  ,                          Task                     Dataset    Model  \\\n",
       " 0  Image-to-Image Translation               Aerial-to-Map     cGAN   \n",
       " 1  Image-to-Image Translation               Aerial-to-Map     cGAN   \n",
       " 2  Image-to-Image Translation               Aerial-to-Map     cGAN   \n",
       " 3  Image-to-Image Translation  Cityscapes Labels-to-Photo  pix2pix   \n",
       " 4  Image-to-Image Translation  Cityscapes Labels-to-Photo  pix2pix   \n",
       " 5  Image-to-Image Translation  Cityscapes Labels-to-Photo  pix2pix   \n",
       " 6  Image-to-Image Translation  Cityscapes Photo-to-Labels  pix2pix   \n",
       " 7  Image-to-Image Translation  Cityscapes Photo-to-Labels  pix2pix   \n",
       " 8  Image-to-Image Translation  Cityscapes Photo-to-Labels  pix2pix   \n",
       " \n",
       "           Metric name Metric value Global rank Remove  \n",
       " 0  Per-pixel Accuracy          70%         # 1      -  \n",
       " 1  Per-class Accuracy          46%         # 1      -  \n",
       " 2           Class IOU         0.26         # 1      -  \n",
       " 3           Class IOU         0.18         # 1      -  \n",
       " 4  Per-class Accuracy          25%         # 1      -  \n",
       " 5  Per-pixel Accuracy          71%         # 5      -  \n",
       " 6  Per-pixel Accuracy          85%         # 1      -  \n",
       " 7  Per-class Accuracy          40%         # 1      -  \n",
       " 8           Class IOU         0.32         # 1      -  ,                         Task                      Dataset            Model  \\\n",
       " 0  Sign Language Translation  RWTH-PHOENIX-Weather 2014 T  Sign2Gloss2Text   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0      BLEU-4         19.26         # 1      -  ,                    Task   Dataset        Model     Metric name Metric value  \\\n",
       " 0  Image Classification  ImageNet  RandWire-WS  Top 1 Accuracy        80.1%   \n",
       " 1  Image Classification  ImageNet  RandWire-WS  Top 5 Accuracy        94.8%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 8      -  \n",
       " 1         # 7      -  ,                       Task       Dataset        Model  \\\n",
       " 0  Optical Flow Estimation  Sintel-clean  LiteFlowNet   \n",
       " 1  Optical Flow Estimation  Sintel-final  LiteFlowNet   \n",
       " \n",
       "                Metric name  Metric value Global rank Remove  \n",
       " 0  Average End-Point Error          4.54         # 2      -  \n",
       " 1  Average End-Point Error          5.38         # 2      -  ,                                  Task          Dataset Model Metric name  \\\n",
       " 0  Weakly Supervised Object Detection         ImageNet  WCCN         MAP   \n",
       " 1  Weakly Supervised Object Detection  PASCAL VOC 2007  WCCN         MAP   \n",
       " 2  Weakly Supervised Object Detection  PASCAL VOC 2012  WCCN         MAP   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          16.3         # 2      -  \n",
       " 1          42.8        # 10      -  \n",
       " 2          37.9         # 8      -  ,                  Task               Dataset       Model  Metric name  \\\n",
       " 0  Question Answering  Children's Book Test  AoA reader  Accuracy-CN   \n",
       " 1  Question Answering  Children's Book Test  AoA reader  Accuracy-NE   \n",
       " 2  Question Answering      CNN / Daily Mail  AoA Reader          CNN   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        69.4%         # 4      -  \n",
       " 1          72%         # 4      -  \n",
       " 2         74.4         # 8      -  ,                                     Task   Dataset                 Model  \\\n",
       " 0  Dense Pixel Correspondence Estimation  HPatches  DGC-Net aff+tps+homo   \n",
       " 1  Dense Pixel Correspondence Estimation  HPatches  DGC-Net aff+tps+homo   \n",
       " 2  Dense Pixel Correspondence Estimation  HPatches  DGC-Net aff+tps+homo   \n",
       " 3  Dense Pixel Correspondence Estimation  HPatches  DGC-Net aff+tps+homo   \n",
       " 4  Dense Pixel Correspondence Estimation  HPatches  DGC-Net aff+tps+homo   \n",
       " \n",
       "           Metric name  Metric value Global rank Remove  \n",
       " 0    Viewpoint I AEPE          1.55         # 1      -  \n",
       " 1   Viewpoint II AEPE          5.53         # 2      -  \n",
       " 2  Viewpoint III AEPE          8.98         # 1      -  \n",
       " 3   Viewpoint IV AEPE         11.66         # 1      -  \n",
       " 4    Viewpoint V AEPE         16.70         # 1      -  ,                 Task Dataset           Model     Metric name Metric value  \\\n",
       " 0  Face Verification   IJB-A  All-in-one CNN  TAR @ FAR=0.01       92.20%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 7      -  ,                          Task      Dataset              Model   Metric name  \\\n",
       " 0   Word Sense Disambiguation  Supervised:                GAS    Senseval 2   \n",
       " 1   Word Sense Disambiguation  Supervised:                GAS    Senseval 3   \n",
       " 2   Word Sense Disambiguation  Supervised:                GAS  SemEval 2007   \n",
       " 3   Word Sense Disambiguation  Supervised:                GAS  SemEval 2013   \n",
       " 4   Word Sense Disambiguation  Supervised:                GAS  SemEval 2015   \n",
       " 5   Word Sense Disambiguation  Supervised:                GAS    Senseval 2   \n",
       " 6   Word Sense Disambiguation  Supervised:                GAS    Senseval 3   \n",
       " 7   Word Sense Disambiguation  Supervised:                GAS  SemEval 2007   \n",
       " 8   Word Sense Disambiguation  Supervised:                GAS  SemEval 2013   \n",
       " 9   Word Sense Disambiguation  Supervised:                GAS  SemEval 2015   \n",
       " 10  Word Sense Disambiguation  Supervised:  GAS<sub>ext</sub>    Senseval 2   \n",
       " 11  Word Sense Disambiguation  Supervised:  GAS<sub>ext</sub>    Senseval 3   \n",
       " 12  Word Sense Disambiguation  Supervised:  GAS<sub>ext</sub>  SemEval 2007   \n",
       " 13  Word Sense Disambiguation  Supervised:  GAS<sub>ext</sub>  SemEval 2013   \n",
       " 14  Word Sense Disambiguation  Supervised:  GAS<sub>ext</sub>  SemEval 2015   \n",
       " 15  Word Sense Disambiguation  Supervised:  GAS<sub>ext</sub>    Senseval 2   \n",
       " 16  Word Sense Disambiguation  Supervised:  GAS<sub>ext</sub>    Senseval 3   \n",
       " 17  Word Sense Disambiguation  Supervised:  GAS<sub>ext</sub>  SemEval 2007   \n",
       " 18  Word Sense Disambiguation  Supervised:  GAS<sub>ext</sub>  SemEval 2013   \n",
       " 19  Word Sense Disambiguation  Supervised:  GAS<sub>ext</sub>  SemEval 2015   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          72.0         # 5      -  \n",
       " 1          70.0         # 6      -  \n",
       " 2           --*         # 7      -  \n",
       " 3          66.7         # 6      -  \n",
       " 4          71.6         # 5      -  \n",
       " 5          72.1         # 6      -  \n",
       " 6          70.2         # 9      -  \n",
       " 7           --*         # 7      -  \n",
       " 8            67         # 9      -  \n",
       " 9          71.8         # 6      -  \n",
       " 10         72.4         # 8      -  \n",
       " 11         70.1         # 7      -  \n",
       " 12          --*         # 7      -  \n",
       " 13         67.1        # 10      -  \n",
       " 14         72.1         # 8      -  \n",
       " 15         72.2         # 7      -  \n",
       " 16         70.5        # 10      -  \n",
       " 17          --*         # 7      -  \n",
       " 18         67.2        # 11      -  \n",
       " 19         72.6        # 10      -  ,                Task Dataset      Model      Metric name  Metric value  \\\n",
       " 0  Object Detection    COCO  CornerNet  Bounding Box AP          42.1   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 18      -  ,           Task                    Dataset     Model Metric name  Metric value  \\\n",
       " 0  Atari Games      Atari 2600 Beam Rider  DQN best       Score          5184   \n",
       " 1  Atari Games        Atari 2600 Breakout  DQN best       Score           225   \n",
       " 2  Atari Games          Atari 2600 Enduro  DQN best       Score           661   \n",
       " 3  Atari Games            Atari 2600 Pong  DQN best       Score            21   \n",
       " 4  Atari Games          Atari 2600 Q*Bert  DQN best       Score          4500   \n",
       " 5  Atari Games        Atari 2600 Seaquest  DQN best       Score          1740   \n",
       " 6  Atari Games  Atari 2600 Space Invaders  DQN best       Score          1075   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 19      -  \n",
       " 1        # 20      -  \n",
       " 2        # 14      -  \n",
       " 3         # 1      -  \n",
       " 4        # 21      -  \n",
       " 5        # 17      -  \n",
       " 6        # 20      -  ,                   Task Dataset    Model Metric name  Metric value Global rank  \\\n",
       " 0  Relation Extraction  TACRED  PA-LSTM          F1          65.1         # 4   \n",
       " \n",
       "   Remove  \n",
       " 0      -  ,                           Task                      Dataset  \\\n",
       " 0           Sentiment Analysis                           CR   \n",
       " 1           Sentiment Analysis                         MPQA   \n",
       " 2           Sentiment Analysis                           MR   \n",
       " 3           Sentiment Analysis  SST-2 Binary classification   \n",
       " 4  Semantic Textual Similarity                STS Benchmark   \n",
       " 5        Subjectivity Analysis                         SUBJ   \n",
       " 6          Text Classification                       TREC-6   \n",
       " \n",
       "                   Model          Metric name  Metric value Global rank Remove  \n",
       " 0  USE_T+CNN (w2v w.e.)             Accuracy        87.450         # 2      -  \n",
       " 1  USE_T+DAN (w2v w.e.)             Accuracy        88.140         # 1      -  \n",
       " 2             USE_T+CNN             Accuracy        81.590         # 5      -  \n",
       " 3  USE_T+CNN (lrn w.e.)             Accuracy        87.210        # 14      -  \n",
       " 4                 USE_T  Pearson Correlation         0.782         # 1      -  \n",
       " 5                   USE             Accuracy        93.900         # 4      -  \n",
       " 6             USE_T+CNN                Error         1.930         # 1      -  ,                    Task   Dataset  Model         Metric name  Metric value  \\\n",
       " 0  Image Classification  CIFAR-10  GP EI  Percentage correct          90.5   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 43      -  ,                   Task      Dataset Model Metric name Metric value  \\\n",
       " 0  Node Classification  BlogCatalog  LINE    Accuracy       20.50%   \n",
       " 1  Node Classification  BlogCatalog  LINE    Macro-F1        0.192   \n",
       " 2  Node Classification    Wikipedia  LINE    Accuracy       17.50%   \n",
       " 3  Node Classification    Wikipedia  LINE    Macro-F1        0.164   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 5      -  \n",
       " 1         # 5      -  \n",
       " 2         # 5      -  \n",
       " 3         # 5      -  ,                          Task               Dataset  \\\n",
       " 0   Paraphrase Identification  Quora Question Pairs   \n",
       " 1  Natural Language Inference                  SNLI   \n",
       " 2  Natural Language Inference                  SNLI   \n",
       " 3  Natural Language Inference                  SNLI   \n",
       " 4  Natural Language Inference                  SNLI   \n",
       " 5  Natural Language Inference                  SNLI   \n",
       " 6  Natural Language Inference                  SNLI   \n",
       " \n",
       "                                                Model       Metric name  \\\n",
       " 0                                               DIIN          Accuracy   \n",
       " 1  448D Densely Interactive Inference Network (DI...   % Test Accuracy   \n",
       " 2  448D Densely Interactive Inference Network (DI...  % Train Accuracy   \n",
       " 3  448D Densely Interactive Inference Network (DI...        Parameters   \n",
       " 4  448D Densely Interactive Inference Network (DI...   % Test Accuracy   \n",
       " 5  448D Densely Interactive Inference Network (DI...  % Train Accuracy   \n",
       " 6  448D Densely Interactive Inference Network (DI...        Parameters   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        89.06         # 2      -  \n",
       " 1         88.0        # 16      -  \n",
       " 2         91.2        # 26      -  \n",
       " 3         4.4m         # 1      -  \n",
       " 4         88.9         # 9      -  \n",
       " 5         92.3        # 21      -  \n",
       " 6          17m         # 1      -  ,                   Task                 Dataset                 Model  \\\n",
       " 0  Machine Translation  WMT2014 English-French  Transformer Big + BT   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0  BLEU score          45.6         # 1      -  ,                  Task   Dataset Model Metric name  Metric value Global rank  \\\n",
       " 0  Question Answering  MS MARCO  VNET     Rouge-L         51.63         # 3   \n",
       " 1  Question Answering  MS MARCO  VNET      BLEU-1         54.37         # 2   \n",
       " \n",
       "   Remove  \n",
       " 0      -  \n",
       " 1      -  ,                          Task                                  Dataset  \\\n",
       " 0  Object Proposal Generation  PASCAL VOC 2012, 60 proposals per image   \n",
       " \n",
       "       Model     Metric name  Metric value Global rank Remove  \n",
       " 0  inst-DML  Average Recall         0.667         # 2      -  ,                                  Task          Dataset            Model  \\\n",
       " 0  Weakly Supervised Object Detection  PASCAL VOC 2007  pipeline method   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0         MAP          51.2         # 3      -  ,                        Task      Dataset    Model Metric name  Metric value  \\\n",
       " 0  3D Object Reconstruction  Data3D−R2N2  3D-R2N2      Avg F1         39.01   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 4      -  ,                Task   Dataset     Model Metric name  Metric value Global rank  \\\n",
       " 0  Image Generation  CIFAR-10  PixelRNN    NLL Test          3.00         # 3   \n",
       " 1  Image Generation  CIFAR-10  PixelCNN    NLL Test          3.14         # 5   \n",
       " 2  Image Generation  CIFAR-10      NICE    NLL Test          4.48        # 11   \n",
       " \n",
       "   Remove  \n",
       " 0      -  \n",
       " 1      -  \n",
       " 2      -  ,                               Task                         Dataset  \\\n",
       " 0  Aspect-Based Sentiment Analysis  SemEval 2014 Task 4 Sub Task 2   \n",
       " 1  Aspect-Based Sentiment Analysis  SemEval 2014 Task 4 Sub Task 2   \n",
       " \n",
       "                    Model       Metric name  Metric value Global rank Remove  \n",
       " 0  BILSTM-ATT-G (TSSVAE)  Restaurant (Acc)         81.10        # 11      -  \n",
       " 1  BILSTM-ATT-G (TSSVAE)      Laptop (Acc)         75.34        # 19      -  ,                      Task                Dataset Model Metric name  \\\n",
       " 0  Image Super-Resolution  BSD100 - 4x upscaling  DRCN        PSNR   \n",
       " 1  Image Super-Resolution  BSD100 - 4x upscaling  DRCN        SSIM   \n",
       " 2  Image Super-Resolution  BSD100 - 4x upscaling  DRCN         MOS   \n",
       " 3  Image Super-Resolution   Set14 - 4x upscaling  DRCN        PSNR   \n",
       " 4  Image Super-Resolution   Set14 - 4x upscaling  DRCN        SSIM   \n",
       " 5  Image Super-Resolution   Set14 - 4x upscaling  DRCN         MOS   \n",
       " 6  Image Super-Resolution    Set5 - 4x upscaling  DRCN        PSNR   \n",
       " 7  Image Super-Resolution    Set5 - 4x upscaling  DRCN        SSIM   \n",
       " 8  Image Super-Resolution    Set5 - 4x upscaling  DRCN         MOS   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0       27.2100        # 21      -  \n",
       " 1        0.7493         # 2      -  \n",
       " 2        2.1200         # 3      -  \n",
       " 3       28.0200        # 23      -  \n",
       " 4        0.8074         # 2      -  \n",
       " 5        2.8400         # 3      -  \n",
       " 6       31.5200        # 16      -  \n",
       " 7        0.8938        # 11      -  \n",
       " 8        3.2600         # 3      -  ,                   Task                           Dataset           Model  \\\n",
       " 0  Text Classification                           AG News  Char-level CNN   \n",
       " 1  Text Classification                           DBpedia  Char-level CNN   \n",
       " 2   Sentiment Analysis        Yelp Binary classification  Char-level CNN   \n",
       " 3   Sentiment Analysis  Yelp Fine-grained classification  Char-level CNN   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0       Error          9.51        # 15      -  \n",
       " 1       Error          1.55        # 16      -  \n",
       " 2       Error          4.88        # 15      -  \n",
       " 3       Error         37.95        # 12      -  ,                    Task    Dataset               Model         Metric name  \\\n",
       " 0  Image Classification  CIFAR-100  NiN+Superclass+CDJ  Percentage correct   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0            69        # 26      -  ,                   Task                     Dataset Model Metric name  \\\n",
       " 0  3D Object Detection             KITTI Cars Easy  IPOD          AP   \n",
       " 1  3D Object Detection             KITTI Cars Hard  IPOD          AP   \n",
       " 2  3D Object Detection         KITTI Cars Moderate  IPOD          AP   \n",
       " 3  3D Object Detection         KITTI Cyclists Easy  IPOD          AP   \n",
       " 4  3D Object Detection         KITTI Cyclists Hard  IPOD          AP   \n",
       " 5  3D Object Detection     KITTI Cyclists Moderate  IPOD          AP   \n",
       " 6  3D Object Detection      KITTI Pedestrians Easy  IPOD          AP   \n",
       " 7  3D Object Detection      KITTI Pedestrians Hard  IPOD          AP   \n",
       " 8  3D Object Detection  KITTI Pedestrians Moderate  IPOD          AP   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0       79.75%         # 6      -  \n",
       " 1       66.33%         # 3      -  \n",
       " 2       72.57%         # 5      -  \n",
       " 3       71.40%         # 2      -  \n",
       " 4       48.34%         # 2      -  \n",
       " 5       53.46%         # 3      -  \n",
       " 6       56.92%         # 1      -  \n",
       " 7       42.39%         # 1      -  \n",
       " 8       44.68%         # 2      -  ,                             Task                    Dataset  \\\n",
       " 0  Synthetic-to-Real Translation  GTAV-to-Cityscapes Labels   \n",
       " \n",
       "                             Model Metric name  Metric value Global rank Remove  \n",
       " 0  Domain adaptation + ResNet-101        mIoU          43.2         # 1      -  ,                          Task                          Dataset Model  \\\n",
       " 0  Image-to-Image Translation  ADE20K-Outdoor Labels-to-Photos  SIMS   \n",
       " 1  Image-to-Image Translation  ADE20K-Outdoor Labels-to-Photos  SIMS   \n",
       " 2  Image-to-Image Translation  ADE20K-Outdoor Labels-to-Photos  SIMS   \n",
       " 3  Image-to-Image Translation       Cityscapes Labels-to-Photo  SIMS   \n",
       " 4  Image-to-Image Translation       Cityscapes Labels-to-Photo  SIMS   \n",
       " 5  Image-to-Image Translation       Cityscapes Labels-to-Photo  SIMS   \n",
       " 6  Image-to-Image Translation       Cityscapes Labels-to-Photo  SIMS   \n",
       " 7  Image-to-Image Translation       Cityscapes Labels-to-Photo  SIMS   \n",
       " \n",
       "           Metric name Metric value Global rank Remove  \n",
       " 0                mIoU         13.1         # 4      -  \n",
       " 1            Accuracy        74.7%         # 2      -  \n",
       " 2                 FID         67.7         # 2      -  \n",
       " 3           Class IOU          NaN         # 6      -  \n",
       " 4  Per-class Accuracy          NaN         # 5      -  \n",
       " 5  Per-pixel Accuracy        75.5%         # 4      -  \n",
       " 6                mIoU         47.2         # 4      -  \n",
       " 7                 FID         49.7         # 1      -  ,                    Task Dataset           Model         Metric name  \\\n",
       " 0  Image Classification  STL-10  DFF Committees  Percentage correct   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          68.0        # 11      -  ,                        Task  Dataset        Model      Metric name  \\\n",
       " 0  Text-to-Image Generation  MS-COCO  StackGAN+OP  Inception score   \n",
       " 1  Text-to-Image Generation  MS-COCO   AttnGAN+OP  Inception score   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         12.12         # 2      -  \n",
       " 1         24.76         # 1      -  ,                    Task    Dataset                   Model  \\\n",
       " 0  Image Classification   CIFAR-10  Universum Prescription   \n",
       " 1  Image Classification  CIFAR-100  Universum Prescription   \n",
       " \n",
       "           Metric name  Metric value Global rank Remove  \n",
       " 0  Percentage correct          93.3        # 26      -  \n",
       " 1  Percentage correct          67.2        # 34      -  ,                    Task Dataset      Model Metric name Metric value  \\\n",
       " 0  Graph Classification     D&D  GCAPS-CNN    Accuracy       77,62%   \n",
       " 1  Graph Classification  IMDb-B  GCAPS-CNN    Accuracy       71.69%   \n",
       " 2  Graph Classification    NCI1  GCAPS-CNN    Accuracy       82.72%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 4      -  \n",
       " 1         # 3      -  \n",
       " 2         # 1      -  ,                  Task    Dataset                 Model Metric name  \\\n",
       " 0  6D Pose Estimation    LineMOD  Single-shot deep CNN    Accuracy   \n",
       " 1  6D Pose Estimation  OCCLUSION  Single-shot deep CNN         MAP   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0       90.37%         # 3      -  \n",
       " 1         0.48         # 1      -  ,                Task   Dataset      Model Metric name  Metric value  \\\n",
       " 0  Image Generation  CIFAR-10  Conv DRAW    NLL Test          3.58   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 8      -  ,                   Task                 Dataset              Model Metric name  \\\n",
       " 0   Question Answering                SQuAD1.1                SRU          EM   \n",
       " 1   Question Answering                SQuAD1.1                SRU          F1   \n",
       " 2  Machine Translation  WMT2014 English-German  Transformer + SRU  BLEU score   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          71.4        # 99      -  \n",
       " 1          80.2        # 98      -  \n",
       " 2          28.4         # 7      -  ,                  Task  Dataset                           Model Metric name  \\\n",
       " 0  6D Pose Estimation  LineMOD  Keypoint detector localization    Accuracy   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        94.5%         # 2      -  ,                              Task        Dataset Model Metric name  \\\n",
       " 0   Click-Through Rate Prediction         Amazon   PNN         AUC   \n",
       " 1   Click-Through Rate Prediction      Bing News   PNN         AUC   \n",
       " 2   Click-Through Rate Prediction      Bing News   PNN    Log Loss   \n",
       " 3   Click-Through Rate Prediction       Company*  OPNN         AUC   \n",
       " 4   Click-Through Rate Prediction       Company*  OPNN    Log Loss   \n",
       " 5   Click-Through Rate Prediction       Company*  IPNN         AUC   \n",
       " 6   Click-Through Rate Prediction       Company*  IPNN    Log Loss   \n",
       " 7   Click-Through Rate Prediction       Company*  PNN*         AUC   \n",
       " 8   Click-Through Rate Prediction       Company*  PNN*    Log Loss   \n",
       " 9   Click-Through Rate Prediction         Criteo  OPNN         AUC   \n",
       " 10  Click-Through Rate Prediction         Criteo  OPNN    Log Loss   \n",
       " 11  Click-Through Rate Prediction         Criteo  PNN*         AUC   \n",
       " 12  Click-Through Rate Prediction         Criteo  PNN*    Log Loss   \n",
       " 13  Click-Through Rate Prediction         Criteo  IPNN         AUC   \n",
       " 14  Click-Through Rate Prediction         Criteo  IPNN    Log Loss   \n",
       " 15  Click-Through Rate Prediction       Dianping   PNN         AUC   \n",
       " 16  Click-Through Rate Prediction       Dianping   PNN    Log Loss   \n",
       " 17  Click-Through Rate Prediction        iPinYou  PNN*         AUC   \n",
       " 18  Click-Through Rate Prediction        iPinYou  OPNN         AUC   \n",
       " 19  Click-Through Rate Prediction        iPinYou  IPNN         AUC   \n",
       " 20  Click-Through Rate Prediction  MovieLens 20M   PNN         AUC   \n",
       " \n",
       "     Metric value Global rank Remove  \n",
       " 0        0.86790         # 4      -  \n",
       " 1        0.83210         # 4      -  \n",
       " 2        0.27750         # 4      -  \n",
       " 3        0.86580         # 7      -  \n",
       " 4        0.02641         # 7      -  \n",
       " 5        0.86640         # 5      -  \n",
       " 6        0.02637         # 5      -  \n",
       " 7        0.86720         # 4      -  \n",
       " 8        0.02636         # 4      -  \n",
       " 9        0.79820         # 4      -  \n",
       " 10       0.45256         # 4      -  \n",
       " 11       0.79870         # 3      -  \n",
       " 12       0.45214         # 3      -  \n",
       " 13       0.79720         # 6      -  \n",
       " 14       0.45323         # 5      -  \n",
       " 15       0.84450         # 3      -  \n",
       " 16       0.34240         # 4      -  \n",
       " 17       0.76610         # 3      -  \n",
       " 18       0.81740         # 1      -  \n",
       " 19       0.79140         # 2      -  \n",
       " 20       0.73210         # 4      -  ,                                Task                 Dataset  \\\n",
       " 0               Machine Translation  WMT2014 English-French   \n",
       " 1               Machine Translation  WMT2014 English-German   \n",
       " 2               Machine Translation  WMT2014 French-English   \n",
       " 3  Unsupervised Machine Translation  WMT2014 French-English   \n",
       " 4               Machine Translation  WMT2014 German-English   \n",
       " 5               Machine Translation  WMT2016 English-German   \n",
       " 6               Machine Translation  WMT2016 German-English   \n",
       " \n",
       "                                             Model Metric name  Metric value  \\\n",
       " 0  SMT + iterative backtranslation (unsupervised)  BLEU score         26.22   \n",
       " 1  SMT + iterative backtranslation (unsupervised)  BLEU score         14.08   \n",
       " 2  SMT + iterative backtranslation (unsupervised)  BLEU score         25.87   \n",
       " 3                                             SMT        BLEU         25.90   \n",
       " 4  SMT + iterative backtranslation (unsupervised)  BLEU score         17.43   \n",
       " 5  SMT + iterative backtranslation (unsupervised)  BLEU score         18.23   \n",
       " 6  SMT + iterative backtranslation (unsupervised)  BLEU score         23.05   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 27      -  \n",
       " 1        # 23      -  \n",
       " 2         # 1      -  \n",
       " 3         # 5      -  \n",
       " 4         # 3      -  \n",
       " 5         # 3      -  \n",
       " 6         # 3      -  ,                Task Dataset                             Model  \\\n",
       " 0  Object Detection    COCO  ResNet-101 + Group Normalization   \n",
       " \n",
       "        Metric name  Metric value Global rank Remove  \n",
       " 0  Bounding Box AP          42.3        # 17      -  ,                  Task                            Dataset        Model  \\\n",
       " 0  Sentiment Analysis  SST-5 Fine-grained classification  Bi-LSTM+2+5   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0    Accuracy          50.4         # 8      -  ,                  Task                 Dataset                   Model  \\\n",
       " 0  Speech Recognition  LibriSpeech test-clean       LAS + SpecAugment   \n",
       " 1  Speech Recognition  LibriSpeech test-clean                     LAS   \n",
       " 2  Speech Recognition  LibriSpeech test-other       LAS + SpecAugment   \n",
       " 3  Speech Recognition    Switchboard + Hub500  LAS + SpecAugment (SM)   \n",
       " \n",
       "              Metric name  Metric value Global rank Remove  \n",
       " 0  Word Error Rate (WER)           2.5         # 1      -  \n",
       " 1  Word Error Rate (WER)           3.2         # 4      -  \n",
       " 2  Word Error Rate (WER)           5.8         # 1      -  \n",
       " 3       Percentage error           6.8         # 6      -  ,                       Task   Dataset     Model Metric name Metric value  \\\n",
       " 0      Node Classification  Citeseer  LGCN sub    Accuracy        73.0%   \n",
       " 1      Node Classification      Cora  LGCN sub    Accuracy       83.30%   \n",
       " 2  Document Classification      Cora      LGCN    Accuracy        83.3%   \n",
       " 3      Node Classification    Pubmed  LGCN sub    Accuracy       79.50%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 1      -  \n",
       " 2         # 2      -  \n",
       " 3         # 2      -  ,                  Task           Dataset                Model  \\\n",
       " 0  Language Modelling  One Billion Word  Sparse Non-Negative   \n",
       " 1  Language Modelling  One Billion Word  Sparse Non-Negative   \n",
       " \n",
       "         Metric name Metric value Global rank Remove  \n",
       " 0               PPL         52.9        # 15      -  \n",
       " 1  Number of params          33B         # 1      -  ,                        Task      Dataset Model Metric name  Metric value  \\\n",
       " 0  3D Object Reconstruction  Data3D−R2N2  N3MR      Avg F1          33.8   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 5      -  ,                  Task       Dataset                Model Metric name  \\\n",
       " 0  Question Answering  WebQuestions  Subgraph embeddings          F1   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        39.2%         # 2      -  ,                            Task      Dataset    Model      Metric name  \\\n",
       " 0              Image Generation  CAT 256x256  WGAN-GP              FID   \n",
       " 1              Image Generation     CIFAR-10  WGAN-GP  Inception score   \n",
       " 2              Image Generation     CIFAR-10  WGAN-GP              FID   \n",
       " 3  Conditional Image Generation     CIFAR-10  WGAN-GP  Inception score   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0        155.46         # 2      -  \n",
       " 1          7.86         # 6      -  \n",
       " 2         29.30         # 8      -  \n",
       " 3          8.67         # 2      -  ,             Task                    Dataset              Model Metric name  \\\n",
       " 0    Atari Games           Atari 2600 Alien        A3C LSTM hs       Score   \n",
       " 1    Atari Games           Atari 2600 Alien          A3C FF hs       Score   \n",
       " 2    Atari Games           Atari 2600 Alien  A3C FF (1 day) hs       Score   \n",
       " 3    Atari Games          Atari 2600 Amidar        A3C LSTM hs       Score   \n",
       " 4    Atari Games          Atari 2600 Amidar          A3C FF hs       Score   \n",
       " 5    Atari Games          Atari 2600 Amidar  A3C FF (1 day) hs       Score   \n",
       " 6    Atari Games         Atari 2600 Assault  A3C FF (1 day) hs       Score   \n",
       " 7    Atari Games         Atari 2600 Assault          A3C FF hs       Score   \n",
       " 8    Atari Games         Atari 2600 Assault        A3C LSTM hs       Score   \n",
       " 9    Atari Games         Atari 2600 Asterix          A3C FF hs       Score   \n",
       " 10   Atari Games         Atari 2600 Asterix        A3C LSTM hs       Score   \n",
       " 11   Atari Games         Atari 2600 Asterix  A3C FF (1 day) hs       Score   \n",
       " 12   Atari Games       Atari 2600 Asteroids          A3C FF hs       Score   \n",
       " 13   Atari Games       Atari 2600 Asteroids        A3C LSTM hs       Score   \n",
       " 14   Atari Games       Atari 2600 Asteroids  A3C FF (1 day) hs       Score   \n",
       " 15   Atari Games        Atari 2600 Atlantis  A3C FF (1 day) hs       Score   \n",
       " 16   Atari Games        Atari 2600 Atlantis          A3C FF hs       Score   \n",
       " 17   Atari Games        Atari 2600 Atlantis        A3C LSTM hs       Score   \n",
       " 18   Atari Games      Atari 2600 Bank Heist        A3C LSTM hs       Score   \n",
       " 19   Atari Games      Atari 2600 Bank Heist          A3C FF hs       Score   \n",
       " 20   Atari Games      Atari 2600 Bank Heist  A3C FF (1 day) hs       Score   \n",
       " 21   Atari Games     Atari 2600 Battle Zone        A3C LSTM hs       Score   \n",
       " 22   Atari Games     Atari 2600 Battle Zone          A3C FF hs       Score   \n",
       " 23   Atari Games     Atari 2600 Battle Zone  A3C FF (1 day) hs       Score   \n",
       " 24   Atari Games      Atari 2600 Beam Rider        A3C LSTM hs       Score   \n",
       " 25   Atari Games      Atari 2600 Beam Rider          A3C FF hs       Score   \n",
       " 26   Atari Games      Atari 2600 Beam Rider  A3C FF (1 day) hs       Score   \n",
       " 27   Atari Games         Atari 2600 Berzerk  A3C FF (1 day) hs       Score   \n",
       " 28   Atari Games         Atari 2600 Berzerk          A3C FF hs       Score   \n",
       " 29   Atari Games         Atari 2600 Berzerk        A3C LSTM hs       Score   \n",
       " ..           ...                        ...                ...         ...   \n",
       " 120  Atari Games  Atari 2600 Space Invaders  A3C FF (1 day) hs       Score   \n",
       " 121  Atari Games  Atari 2600 Space Invaders          A3C FF hs       Score   \n",
       " 122  Atari Games  Atari 2600 Space Invaders        A3C LSTM hs       Score   \n",
       " 123  Atari Games     Atari 2600 Star Gunner        A3C LSTM hs       Score   \n",
       " 124  Atari Games     Atari 2600 Star Gunner          A3C FF hs       Score   \n",
       " 125  Atari Games     Atari 2600 Star Gunner  A3C FF (1 day) hs       Score   \n",
       " 126  Atari Games          Atari 2600 Tennis          A3C FF hs       Score   \n",
       " 127  Atari Games          Atari 2600 Tennis        A3C LSTM hs       Score   \n",
       " 128  Atari Games          Atari 2600 Tennis  A3C FF (1 day) hs       Score   \n",
       " 129  Atari Games      Atari 2600 Time Pilot        A3C LSTM hs       Score   \n",
       " 130  Atari Games      Atari 2600 Time Pilot          A3C FF hs       Score   \n",
       " 131  Atari Games      Atari 2600 Time Pilot  A3C FF (1 day) hs       Score   \n",
       " 132  Atari Games       Atari 2600 Tutankham        A3C LSTM hs       Score   \n",
       " 133  Atari Games       Atari 2600 Tutankham  A3C FF (1 day) hs       Score   \n",
       " 134  Atari Games       Atari 2600 Tutankham          A3C FF hs       Score   \n",
       " 135  Atari Games     Atari 2600 Up and Down        A3C LSTM hs       Score   \n",
       " 136  Atari Games     Atari 2600 Up and Down          A3C FF hs       Score   \n",
       " 137  Atari Games     Atari 2600 Up and Down  A3C FF (1 day) hs       Score   \n",
       " 138  Atari Games         Atari 2600 Venture          A3C FF hs       Score   \n",
       " 139  Atari Games         Atari 2600 Venture        A3C LSTM hs       Score   \n",
       " 140  Atari Games         Atari 2600 Venture  A3C FF (1 day) hs       Score   \n",
       " 141  Atari Games   Atari 2600 Video Pinball  A3C FF (1 day) hs       Score   \n",
       " 142  Atari Games   Atari 2600 Video Pinball          A3C FF hs       Score   \n",
       " 143  Atari Games   Atari 2600 Video Pinball        A3C LSTM hs       Score   \n",
       " 144  Atari Games   Atari 2600 Wizard of Wor          A3C FF hs       Score   \n",
       " 145  Atari Games   Atari 2600 Wizard of Wor        A3C LSTM hs       Score   \n",
       " 146  Atari Games   Atari 2600 Wizard of Wor  A3C FF (1 day) hs       Score   \n",
       " 147  Atari Games          Atari 2600 Zaxxon  A3C FF (1 day) hs       Score   \n",
       " 148  Atari Games          Atari 2600 Zaxxon        A3C LSTM hs       Score   \n",
       " 149  Atari Games          Atari 2600 Zaxxon          A3C FF hs       Score   \n",
       " \n",
       "      Metric value Global rank Remove  \n",
       " 0           945.3        # 15      -  \n",
       " 1           518.4        # 20      -  \n",
       " 2           182.1        # 21      -  \n",
       " 3           173.0        # 17      -  \n",
       " 4           263.9        # 12      -  \n",
       " 5           283.9        # 11      -  \n",
       " 6          3746.1        # 16      -  \n",
       " 7          5474.9        # 11      -  \n",
       " 8         14497.9         # 2      -  \n",
       " 9         22140.5         # 8      -  \n",
       " 10        17244.5        # 12      -  \n",
       " 11         6723.0        # 15      -  \n",
       " 12         4474.5         # 2      -  \n",
       " 13         5093.1         # 1      -  \n",
       " 14         3009.4         # 3      -  \n",
       " 15       772392.0         # 7      -  \n",
       " 16       911091.0         # 4      -  \n",
       " 17       875822.0         # 5      -  \n",
       " 18          932.8        # 13      -  \n",
       " 19          970.1        # 11      -  \n",
       " 20          946.0        # 12      -  \n",
       " 21        20760.0        # 15      -  \n",
       " 22        12950.0        # 19      -  \n",
       " 23        11340.0        # 20      -  \n",
       " 24        24622.2         # 5      -  \n",
       " 25        22707.9         # 8      -  \n",
       " 26        13235.9        # 13      -  \n",
       " 27         1433.4         # 5      -  \n",
       " 28          817.9        # 14      -  \n",
       " 29          862.2        # 13      -  \n",
       " ..            ...         ...    ...  \n",
       " 120        2214.7        # 15      -  \n",
       " 121       15730.5         # 3      -  \n",
       " 122       23846.0         # 2      -  \n",
       " 123      164766.0         # 1      -  \n",
       " 124      138218.0         # 2      -  \n",
       " 125       64393.0         # 8      -  \n",
       " 126          -6.3        # 14      -  \n",
       " 127          -6.4        # 15      -  \n",
       " 128         -10.2        # 17      -  \n",
       " 129       27202.0         # 1      -  \n",
       " 130       12679.0         # 2      -  \n",
       " 131        5825.0        # 15      -  \n",
       " 132         144.2        # 11      -  \n",
       " 133          26.1        # 22      -  \n",
       " 134         156.3        # 10      -  \n",
       " 135      105728.7         # 1      -  \n",
       " 136       74705.7         # 3      -  \n",
       " 137       54525.4         # 5      -  \n",
       " 138          23.0        # 23      -  \n",
       " 139          25.0        # 22      -  \n",
       " 140          19.0        # 25      -  \n",
       " 141      185852.6        # 13      -  \n",
       " 142      331628.1         # 8      -  \n",
       " 143      470310.5         # 5      -  \n",
       " 144       17244.0         # 3      -  \n",
       " 145       18082.0         # 2      -  \n",
       " 146        5278.0        # 14      -  \n",
       " 147        2659.0        # 21      -  \n",
       " 148       23519.0         # 2      -  \n",
       " 149       24622.0         # 1      -  \n",
       " \n",
       " [150 rows x 7 columns],                Task   Dataset    Model      Metric name  Metric value  \\\n",
       " 0  Image Generation  CIFAR-10  MSG-GAN  Inception score          7.96   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 4      -  ,                   Task                 Dataset    Model Metric name  \\\n",
       " 0  Machine Translation  WMT2014 English-French  GNMT+RL  BLEU score   \n",
       " 1  Machine Translation  WMT2014 English-German  GNMT+RL  BLEU score   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         39.92        # 12      -  \n",
       " 1         26.30        # 10      -  ,                         Task   Dataset  Model Metric name  Metric value  \\\n",
       " 0  Object Skeleton Detection  SK-LARGE  Hi-Fi   F-Measure         0.724   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  ,                           Task  \\\n",
       " 0  Dialogue Act Classification   \n",
       " 1  Dialogue Act Classification   \n",
       " \n",
       "                                           Dataset        Model Metric name  \\\n",
       " 0  ICSI Meeting Recorder Dialog Act (MRDA) corpus  Bi-LSTM-CRF    Accuracy   \n",
       " 1                              Switchboard corpus  Bi-LSTM-CRF    Accuracy   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          90.9         # 2      -  \n",
       " 1          79.2         # 2      -  ,                             Task        Dataset                  Model  \\\n",
       " 0  Click-Through Rate Prediction         Amazon  DIN + Dice Activation   \n",
       " 1  Click-Through Rate Prediction         Amazon                    DIN   \n",
       " 2  Click-Through Rate Prediction  MovieLens 20M                    DIN   \n",
       " 3  Click-Through Rate Prediction  MovieLens 20M  DIN + Dice Activation   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0         AUC        0.8871         # 1      -  \n",
       " 1         AUC        0.8818         # 2      -  \n",
       " 2         AUC        0.7337         # 2      -  \n",
       " 3         AUC        0.7348         # 1      -  ,                                 Task       Dataset  \\\n",
       " 0  Fine-Grained Image Classification  CUB-200-2011   \n",
       " \n",
       "                              Model Metric name Metric value Global rank Remove  \n",
       " 0  Hierarchical Semantic Embedding    Accuracy        88.1%         # 4      -  ,                                       Task                    Dataset  \\\n",
       " 0            Synthetic-to-Real Translation  GTAV-to-Cityscapes Labels   \n",
       " 1            Synthetic-to-Real Translation  GTAV-to-Cityscapes Labels   \n",
       " 2            Synthetic-to-Real Translation  GTAV-to-Cityscapes Labels   \n",
       " 3  Unsupervised Image-To-Image Translation              SVNH-to-MNIST   \n",
       " 4               Image-to-Image Translation     SYNTHIA Fall-to-Winter   \n",
       " 5               Image-to-Image Translation     SYNTHIA Fall-to-Winter   \n",
       " 6               Image-to-Image Translation     SYNTHIA Fall-to-Winter   \n",
       " \n",
       "                Model              Metric name Metric value Global rank Remove  \n",
       " 0  CyCADA pixel+feat                     mIoU         39.5         # 3      -  \n",
       " 1  CyCADA pixel+feat                    fwIOU         72.4         # 1      -  \n",
       " 2  CyCADA pixel+feat       Per-pixel Accuracy        82.3%         # 1      -  \n",
       " 3  CyCADA pixel+feat  Classification Accuracy        90.4%         # 1      -  \n",
       " 4             CyCADA                     mIoU         63.3         # 1      -  \n",
       " 5             CyCADA       Per-pixel Accuracy        92.1%         # 1      -  \n",
       " 6             CyCADA                    fwIOU         85.7         # 1      -  ,                  Task     Dataset  \\\n",
       " 0  Question Answering  MCTest-160   \n",
       " 1  Question Answering  MCTest-500   \n",
       " 2  Question Answering  MCTest-500   \n",
       " \n",
       "                                                Model Metric name Metric value  \\\n",
       " 0  syntax, frame, coreference, and word embedding...    Accuracy       75.27%   \n",
       " 1  syntax, frame, coreference, and word embedding...    Accuracy       69.94%   \n",
       " 2                              Parallel-Hierarchical    Accuracy          71%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 2      -  \n",
       " 2         # 1      -  ,                      Task               Dataset    Model Metric name  \\\n",
       " 0  Image Super-Resolution  Set14 - 4x upscaling  MSSRNet        PSNR   \n",
       " 1  Image Super-Resolution  Set14 - 4x upscaling  MSSRNet        SSIM   \n",
       " 2  Image Super-Resolution   Set5 - 4x upscaling  MSSRNet        PSNR   \n",
       " 3  Image Super-Resolution   Set5 - 4x upscaling  MSSRNet        SSIM   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0       27.8300        # 26      -  \n",
       " 1        0.7631        # 26      -  \n",
       " 2       31.1000        # 21      -  \n",
       " 3        0.8777        # 25      -  ,                              Task               Dataset  \\\n",
       " 0  Named Entity Recognition (NER)  CoNLL 2003 (English)   \n",
       " 1              Sentiment Analysis                  IMDb   \n",
       " \n",
       "                     Model Metric name  Metric value Global rank Remove  \n",
       " 0  LSTM with dynamic skip          F1         91.56        # 12      -  \n",
       " 1  LSTM with dynamic skip    Accuracy         90.10        # 10      -  ,                            Task   Dataset Model      Metric name  \\\n",
       " 0  Conditional Image Generation  CIFAR-10  SGAN  Inception score   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          8.59         # 3      -  ,                      Task        Dataset    Model   Metric name  Metric value  \\\n",
       " 0  Part-Of-Speech Tagging  Penn Treebank  Bi-LSTM      Accuracy         97.22   \n",
       " 1  Part-Of-Speech Tagging             UD  Bi-LSTM  Avg accuracy         96.40   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 12      -  \n",
       " 1         # 2      -  ,                        Task        Dataset Model Metric name  Metric value  \\\n",
       " 0  Person Re-Identification  DukeMTMC-reID   MGN      Rank-1          88.7   \n",
       " 1  Person Re-Identification  DukeMTMC-reID   MGN         MAP          78.4   \n",
       " 2  Person Re-Identification    Market-1501   MGN      Rank-1          95.7   \n",
       " 3  Person Re-Identification    Market-1501   MGN         MAP          86.9   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  \n",
       " 1         # 2      -  \n",
       " 2         # 1      -  \n",
       " 3         # 2      -  ,                 Task Dataset                           Model     Metric name  \\\n",
       " 0  Face Verification   IJB-A  Synthesis as data augmentation  TAR @ FAR=0.01   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0       88.60%        # 10      -  ,                   Task   Dataset                          Model  \\\n",
       " 0  Multi-Armed Bandits  Mushroom  NeuralLinear FullPosterior-MR   \n",
       " 1  Multi-Armed Bandits  Mushroom        Linear FullPosterior-MR   \n",
       " \n",
       "          Metric name  Metric value Global rank Remove  \n",
       " 0  Cumulative regret          1.92         # 2      -  \n",
       " 1  Cumulative regret          1.82         # 1      -  ,                        Task     Dataset  \\\n",
       " 0  Brain Tumor Segmentation  BRATS-2015   \n",
       " \n",
       "                                                Model Metric name Metric value  \\\n",
       " 0  U-Net + more filters + data augmentation + dic...  Dice Score          85%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  ,                Task   Dataset         Model      Metric name  Metric value  \\\n",
       " 0  Image Generation  CIFAR-10  CEGAN-Ent-VI  Inception score          7.07   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 9      -  ,                   Task                 Dataset  \\\n",
       " 0  Machine Translation  WMT2014 English-French   \n",
       " 1  Machine Translation  WMT2014 English-German   \n",
       " \n",
       "                                                Model Metric name  \\\n",
       " 0  Transformer (big) + Relative Position Represen...  BLEU score   \n",
       " 1  Transformer (big) + Relative Position Represen...  BLEU score   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          41.5         # 4      -  \n",
       " 1          29.2         # 4      -  ,                              Task               Dataset  \\\n",
       " 0              Question Answering  Children's Book Test   \n",
       " 1              Question Answering  Children's Book Test   \n",
       " 2              Question Answering  Children's Book Test   \n",
       " 3              Question Answering  Children's Book Test   \n",
       " 4              Question Answering      CNN / Daily Mail   \n",
       " 5              Question Answering      CNN / Daily Mail   \n",
       " 6              Question Answering      CNN / Daily Mail   \n",
       " 7              Question Answering      CNN / Daily Mail   \n",
       " 8  Open-Domain Question Answering              SearchQA   \n",
       " 9  Open-Domain Question Answering              SearchQA   \n",
       " \n",
       "                         Model  Metric name Metric value Global rank Remove  \n",
       " 0             AS reader (avg)  Accuracy-CN        68.9%         # 5      -  \n",
       " 1             AS reader (avg)  Accuracy-NE        70.6%         # 7      -  \n",
       " 2          AS reader (greedy)  Accuracy-CN        67.5%         # 6      -  \n",
       " 3          AS reader (greedy)  Accuracy-NE          71%         # 6      -  \n",
       " 4    AS Reader (single model)          CNN         69.5        # 12      -  \n",
       " 5    AS Reader (single model)   Daily Mail         73.9         # 7      -  \n",
       " 6  AS Reader (ensemble model)          CNN         75.4         # 6      -  \n",
       " 7  AS Reader (ensemble model)   Daily Mail         77.7         # 4      -  \n",
       " 8                         ASR  Unigram Acc         41.3         # 4      -  \n",
       " 9                         ASR    N-gram F1         22.8         # 5      -  ,                               Task    Dataset       Model Metric name  \\\n",
       " 0  Aspect-Based Sentiment Analysis  Sentihood  Liu et al.      Aspect   \n",
       " 1  Aspect-Based Sentiment Analysis  Sentihood  Liu et al.   Sentiment   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          78.5         # 3      -  \n",
       " 1          91.0         # 3      -  ,               Task         Dataset                  Model Metric name  \\\n",
       " 0  Pose Estimation  DensePose-COCO  DensePose + keypoints          AP   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          55.8         # 2      -  ,                  Task Dataset         Model Metric name  Metric value  \\\n",
       " 0  Question Answering  NewsQA  MINIMAL(Dyn)          F1          63.2   \n",
       " 1  Question Answering  NewsQA  MINIMAL(Dyn)          EM          50.1   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 3      -  \n",
       " 1         # 2      -  ,                       Task        Dataset      Model Metric name  \\\n",
       " 0  Collaborative Filtering  MovieLens 10M  Sparse FC        RMSE   \n",
       " 1  Collaborative Filtering   MovieLens 1M  Sparse FC        RMSE   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         0.769         # 1      -  \n",
       " 1         0.824         # 1      -  ,                     Task    Dataset     Model Metric name  Metric value  \\\n",
       " 0  Cross-Modal Retrieval  COCO 2014  Text2Vis         DCG         2.447   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  ,                Task Dataset         Model      Metric name  Metric value  \\\n",
       " 0  Object Detection    COCO  Faster R-CNN  Bounding Box AP          34.7   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0        # 31      -  ,                    Task Dataset    Model Metric name Metric value Global rank  \\\n",
       " 0  Scene Text Detection    IC15  WordSup   F-Measure       78.16%         # 8   \n",
       " \n",
       "   Remove  \n",
       " 0      -  ,              Task      Dataset  Model Metric name Metric value Global rank  \\\n",
       " 0  Face Alignment  AFLW2000-3D  3DSTN    Mean NME        4.49%         # 3   \n",
       " \n",
       "   Remove  \n",
       " 0      -  ,                   Task                        Dataset                Model  \\\n",
       " 0  Architecture Search  CIFAR-10 Image Classification  PathLevel EAS + c/o   \n",
       " 1  Architecture Search  CIFAR-10 Image Classification  PathLevel EAS + c/o   \n",
       " \n",
       "         Metric name Metric value Global rank Remove  \n",
       " 0  Percentage error         2.30         # 3      -  \n",
       " 1            Params        14.3M         # 1      -  ,                  Task                    Dataset  \\\n",
       " 0  Speech Recognition  swb_hub_500 WER fullSWBCH   \n",
       " 1  Speech Recognition       Switchboard + Hub500   \n",
       " 2  Speech Recognition       Switchboard + Hub500   \n",
       " \n",
       "                                                Model       Metric name  \\\n",
       " 0  RNN + VGG + LSTM acoustic model trained on SWB...  Percentage error   \n",
       " 1                                           IBM 2016  Percentage error   \n",
       " 2  RNN + VGG + LSTM acoustic model trained on SWB...  Percentage error   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          12.2         # 3      -  \n",
       " 1           6.9         # 7      -  \n",
       " 2           6.6         # 5      -  ,                    Task  Dataset     Model           Metric name  \\\n",
       " 0  Pedestrian Detection  Caltech  SDS-RCNN  Reasonable Miss Rate   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          7.36         # 9      -  ,                  Task                            Dataset         Model  \\\n",
       " 0  Sentiment Analysis        SST-2 Binary classification  CNN-RNF-LSTM   \n",
       " 1  Sentiment Analysis  SST-5 Fine-grained classification  CNN-RNF-LSTM   \n",
       " \n",
       "   Metric name  Metric value Global rank Remove  \n",
       " 0    Accuracy          90.0         # 9      -  \n",
       " 1    Accuracy          53.4         # 6      -  ,                  Task          Dataset  \\\n",
       " 0  Text Summarization  DUC 2004 Task 1   \n",
       " 1  Text Summarization  DUC 2004 Task 1   \n",
       " 2  Text Summarization  DUC 2004 Task 1   \n",
       " \n",
       "                                      Model Metric name  Metric value  \\\n",
       " 0  Transformer+LRPE+PE+Re-ranking+Ensemble     ROUGE-1         32.85   \n",
       " 1  Transformer+LRPE+PE+Re-ranking+Ensemble     ROUGE-2         11.78   \n",
       " 2  Transformer+LRPE+PE+Re-ranking+Ensemble     ROUGE-L         28.52   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  \n",
       " 1         # 1      -  \n",
       " 2         # 1      -  ,              Task                      Dataset Model Metric name  \\\n",
       " 0  Face Detection  Annotated Faces in the Wild  S3FD          AP   \n",
       " 1  Face Detection                         FDDB  S3FD          AP   \n",
       " 2  Face Detection                  PASCAL Face  S3FD          AP   \n",
       " 3  Face Detection            WIDER Face (Easy)  S3FD          AP   \n",
       " 4  Face Detection            WIDER Face (Hard)  S3FD          AP   \n",
       " 5  Face Detection          WIDER Face (Medium)  S3FD          AP   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0        0.9985         # 2      -  \n",
       " 1        0.9830         # 5      -  \n",
       " 2        0.9849         # 3      -  \n",
       " 3        0.9280         # 6      -  \n",
       " 4        0.8400         # 7      -  \n",
       " 5        0.9130         # 6      -  ,                                         Task  \\\n",
       " 0             Named Entity Recognition (NER)   \n",
       " 1             Named Entity Recognition (NER)   \n",
       " 2                         Question Answering   \n",
       " 3                         Question Answering   \n",
       " 4                         Question Answering   \n",
       " 5                         Question Answering   \n",
       " 6                         Question Answering   \n",
       " 7                         Question Answering   \n",
       " 8                         Question Answering   \n",
       " 9                    Sentence Classification   \n",
       " 10                Natural Language Inference   \n",
       " 11                        Question Answering   \n",
       " 12                        Question Answering   \n",
       " 13                        Question Answering   \n",
       " 14                        Question Answering   \n",
       " 15                        Question Answering   \n",
       " 16                        Question Answering   \n",
       " 17                    Common Sense Reasoning   \n",
       " 18                    Common Sense Reasoning   \n",
       " 19                    Common Sense Reasoning   \n",
       " 20                    Common Sense Reasoning   \n",
       " 21  Cross-Lingual Natural Language Inference   \n",
       " 22  Cross-Lingual Natural Language Inference   \n",
       " \n",
       "                               Dataset                                Model  \\\n",
       " 0                CoNLL 2003 (English)                           BERT Large   \n",
       " 1                CoNLL 2003 (English)                            BERT Base   \n",
       " 2                                CoQA    BERT-base finetune (single model)   \n",
       " 3                                CoQA    BERT-base finetune (single model)   \n",
       " 4                                CoQA    BERT-base finetune (single model)   \n",
       " 5                                CoQA  BERT Large Augmented (single model)   \n",
       " 6                                CoQA  BERT Large Augmented (single model)   \n",
       " 7                                CoQA  BERT Large Augmented (single model)   \n",
       " 8                Quora Question Pairs                  BERT (single model)   \n",
       " 9                             SciCite                                 BERT   \n",
       " 10                            SciTail                                 BERT   \n",
       " 11                           SQuAD1.1                      BERT (ensemble)   \n",
       " 12                           SQuAD1.1                      BERT (ensemble)   \n",
       " 13                           SQuAD1.1                  BERT (single model)   \n",
       " 14                           SQuAD1.1                  BERT (single model)   \n",
       " 15                           SQuAD2.0                  BERT (single model)   \n",
       " 16                           SQuAD2.0                  BERT (single model)   \n",
       " 17                               SWAG                           BERT Large   \n",
       " 18                               SWAG                           BERT Large   \n",
       " 19                               SWAG                            BERT Base   \n",
       " 20                               SWAG                            BERT Base   \n",
       " 21   XNLI Zero-Shot English-to-German                                 BERT   \n",
       " 22  XNLI Zero-Shot English-to-Spanish                                 BERT   \n",
       " \n",
       "       Metric name Metric value Global rank Remove  \n",
       " 0              F1         92.8         # 3      -  \n",
       " 1              F1         92.4         # 5      -  \n",
       " 2       In-domain         79.8         # 3      -  \n",
       " 3   Out-of-domain         74.1         # 3      -  \n",
       " 4         Overall         78.1         # 3      -  \n",
       " 5       In-domain         82.5         # 1      -  \n",
       " 6   Out-of-domain         77.6         # 1      -  \n",
       " 7         Overall         81.1         # 1      -  \n",
       " 8        Accuracy        72.1%         # 1      -  \n",
       " 9              F1         84.4         # 2      -  \n",
       " 10       Accuracy         92.0         # 2      -  \n",
       " 11             EM       87.433         # 1      -  \n",
       " 12             F1       93.160         # 1      -  \n",
       " 13             EM       85.083         # 4      -  \n",
       " 14             F1       91.835         # 3      -  \n",
       " 15             EM       80.005        # 41      -  \n",
       " 16             F1       83.061        # 43      -  \n",
       " 17            Dev         86.6         # 1      -  \n",
       " 18           Test         86.3         # 1      -  \n",
       " 19            Dev         81.6         # 2      -  \n",
       " 20           Test            -         # 4      -  \n",
       " 21       Accuracy        70.5%         # 2      -  \n",
       " 22       Accuracy        74.3%         # 1      -  ,                  Task        Dataset         Model Metric name  Metric value  \\\n",
       " 0  Dependency Parsing  Penn Treebank  Andor et al.         POS         97.44   \n",
       " 1  Dependency Parsing  Penn Treebank  Andor et al.         UAS         94.61   \n",
       " 2  Dependency Parsing  Penn Treebank  Andor et al.         LAS         92.79   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 2      -  \n",
       " 1         # 3      -  \n",
       " 2         # 4      -  ,                               Task     Dataset    Model  Metric name  \\\n",
       " 0  Real-Time Semantic Segmentation      CamVid  BiSeNet         mIoU   \n",
       " 1            Semantic Segmentation      CamVid  BiSeNet     Mean IoU   \n",
       " 2  Real-Time Semantic Segmentation  Cityscapes  BiSeNet         mIoU   \n",
       " 3  Real-Time Semantic Segmentation  Cityscapes  BiSeNet  Frame (fps)   \n",
       " 4            Semantic Segmentation  Cityscapes  BiSeNet     Mean IoU   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        68.7%         # 2      -  \n",
       " 1        68.7%         # 2      -  \n",
       " 2        74.7%         # 3      -  \n",
       " 3         65.5         # 2      -  \n",
       " 4        78.9%         # 8      -  ,                  Task           Dataset         Model Metric name  \\\n",
       " 0  Language Modelling  One Billion Word  BIG G-LSTM-2         PPL   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0          36.0        # 12      -  ,                         Task      Dataset Model   Metric name  Metric value  \\\n",
       " 0  Word Sense Disambiguation  Supervised:  ELMo    Senseval 2          71.6   \n",
       " 1  Word Sense Disambiguation  Supervised:  ELMo    Senseval 3          69.6   \n",
       " 2  Word Sense Disambiguation  Supervised:  ELMo  SemEval 2007          62.2   \n",
       " 3  Word Sense Disambiguation  Supervised:  ELMo  SemEval 2013          66.2   \n",
       " 4  Word Sense Disambiguation  Supervised:  ELMo  SemEval 2015          71.3   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 3      -  \n",
       " 1         # 5      -  \n",
       " 2         # 4      -  \n",
       " 3         # 4      -  \n",
       " 4         # 3      -  ,                  Task    Dataset    Model Metric name  Metric value  \\\n",
       " 0  Keypoint Detection  Pascal3D+  ConvNet    Mean PCK          48.5   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 4      -  ,                    Task             Dataset         Model     Metric name  \\\n",
       " 0  Image Classification            ImageNet  Inception V1  Top 1 Accuracy   \n",
       " 1  Image Classification            ImageNet  Inception V1  Top 5 Accuracy   \n",
       " 2      Object Detection  ImageNet Detection  Inception V1             MAP   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        69.8%        # 22      -  \n",
       " 1        89.9%        # 15      -  \n",
       " 2        43.9%         # 1      -  ,                      Task                  Dataset   Model Metric name  \\\n",
       " 0  Image Super-Resolution    BSD100 - 4x upscaling  MemNet        PSNR   \n",
       " 1  Image Super-Resolution    BSD100 - 4x upscaling  MemNet        SSIM   \n",
       " 2  Image Super-Resolution  Manga109 - 4x upscaling  MemNet        PSNR   \n",
       " 3  Image Super-Resolution  Manga109 - 4x upscaling  MemNet        SSIM   \n",
       " 4  Image Super-Resolution     Set14 - 4x upscaling  MemNet        PSNR   \n",
       " 5  Image Super-Resolution     Set14 - 4x upscaling  MemNet        SSIM   \n",
       " 6  Image Super-Resolution      Set5 - 4x upscaling  MemNet        PSNR   \n",
       " 7  Image Super-Resolution      Set5 - 4x upscaling  MemNet        SSIM   \n",
       " 8  Image Super-Resolution  Urban100 - 4x upscaling  MemNet        PSNR   \n",
       " 9  Image Super-Resolution  Urban100 - 4x upscaling  MemNet        SSIM   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0       27.4000        # 17      -  \n",
       " 1        0.7281        # 22      -  \n",
       " 2       29.4200         # 6      -  \n",
       " 3        0.8942         # 7      -  \n",
       " 4       28.2600        # 18      -  \n",
       " 5        0.7723        # 22      -  \n",
       " 6       31.7400        # 15      -  \n",
       " 7        0.8893        # 19      -  \n",
       " 8       25.5000        # 16      -  \n",
       " 9        0.7630        # 18      -  ,                   Task  Dataset     Model Metric name  Metric value  \\\n",
       " 0  Text Classification   20NEWS  Text GCN    Accuracy         86.34   \n",
       " 1   Sentiment Analysis       MR  Text GCN    Accuracy         76.74   \n",
       " 2  Text Classification  Ohsumed  Text GCN    Accuracy         68.36   \n",
       " 3  Text Classification      R52  Text GCN    Accuracy         93.56   \n",
       " 4  Text Classification       R8  Text GCN    Accuracy         97.07   \n",
       " \n",
       "   Global rank  Extradata Remove  \n",
       " 0         # 2        NaN      -  \n",
       " 1         # 8        NaN      -  \n",
       " 2         # 2        NaN      -  \n",
       " 3         # 2        NaN      -  \n",
       " 4         # 2        NaN      -  ,                              Task Dataset       Model Metric name  \\\n",
       " 0  Age-Invariant Face Recognition  CACDVS  DeepVisage    Accuracy   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0       99.13%         # 4      -  ,                               Task          Dataset Model  Metric name  \\\n",
       " 0  Real-Time Semantic Segmentation       Cityscapes   FCN         mIoU   \n",
       " 1  Real-Time Semantic Segmentation       Cityscapes   FCN    Time (ms)   \n",
       " 2  Real-Time Semantic Segmentation       Cityscapes   FCN  Frame (fps)   \n",
       " 3            Semantic Segmentation       Cityscapes   FCN     Mean IoU   \n",
       " 4            Semantic Segmentation  PASCAL VOC 2012   FCN     Mean IoU   \n",
       " 5               Scene Segmentation         SUN-RGBD   FCN     Mean IoU   \n",
       " \n",
       "   Metric value Global rank Remove  \n",
       " 0        65.3%         # 7      -  \n",
       " 1          500         # 5      -  \n",
       " 2            2         # 7      -  \n",
       " 3        65.3%        # 14      -  \n",
       " 4        67.2%        # 18      -  \n",
       " 5        27.39         # 3      -  ,                 Task               Dataset  \\\n",
       " 0  Entity Resolution  CoNLL 2003 (English)   \n",
       " \n",
       "                                                Model Metric name  \\\n",
       " 0  deep joint entity disambiguation w/ neural att...    Accuracy   \n",
       " \n",
       "    Metric value Global rank  Extradata Remove  \n",
       " 0         92.22         # 1        NaN      -  ,                            Task            Dataset                 Model  \\\n",
       " 0  Multi-Person Pose Estimation  MPII Multi-Person  Articulated Tracking   \n",
       " \n",
       "   Metric name Metric value Global rank Remove  \n",
       " 0          AP        74.3%         # 5      -  ,                Task     Dataset                 Model Metric name  \\\n",
       " 0  Stance Detection  RumourEval  Kochkina et al. 2017    Accuracy   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         0.784         # 1      -  ,                               Task           Dataset        Model  \\\n",
       " 0  Sequential Image Classification  Sequential MNIST  Dilated GRU   \n",
       " 1  Sequential Image Classification  Sequential MNIST  Dilated GRU   \n",
       " \n",
       "            Metric name Metric value Global rank Remove  \n",
       " 0  Unpermuted Accuracy        99.2%         # 1      -  \n",
       " 1    Permuted Accuracy        94.6%         # 2      -  ,                          Task               Dataset  Model      Metric name  \\\n",
       " 0  Natural Language Inference              MultiNLI  aESIM          Matched   \n",
       " 1  Natural Language Inference              MultiNLI  aESIM       Mismatched   \n",
       " 2  Natural Language Inference  Quora Question Pairs  aESIM         Accuracy   \n",
       " 3  Natural Language Inference                  SNLI  aESIM  % Test Accuracy   \n",
       " \n",
       "    Metric value Global rank Remove  \n",
       " 0         73.90         # 3      -  \n",
       " 1         73.90         # 3      -  \n",
       " 2         88.01         # 1      -  \n",
       " 3         88.10        # 15      -  ,                         Task Dataset  \\\n",
       " 0  Visual Question Answering  VQA v2   \n",
       " \n",
       "                                                Model Metric name Metric value  \\\n",
       " 0  Image features from bottom-up attention, adapt...    Accuracy       70.34%   \n",
       " \n",
       "   Global rank Remove  \n",
       " 0         # 1      -  , ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "y = pd.read_html(model_data)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>Metric name</th>\n",
       "      <th>Metric value</th>\n",
       "      <th>Global rank</th>\n",
       "      <th>Remove</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Text Summarization</td>\n",
       "      <td>GigaWord</td>\n",
       "      <td>Struct+2Way+Word</td>\n",
       "      <td>ROUGE-1</td>\n",
       "      <td>35.47</td>\n",
       "      <td># 8</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Text Summarization</td>\n",
       "      <td>GigaWord</td>\n",
       "      <td>Struct+2Way+Word</td>\n",
       "      <td>ROUGE-2</td>\n",
       "      <td>17.66</td>\n",
       "      <td># 5</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Text Summarization</td>\n",
       "      <td>GigaWord</td>\n",
       "      <td>Struct+2Way+Word</td>\n",
       "      <td>ROUGE-L</td>\n",
       "      <td>33.52</td>\n",
       "      <td># 9</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Task   Dataset             Model Metric name  Metric value  \\\n",
       "0  Text Summarization  GigaWord  Struct+2Way+Word     ROUGE-1         35.47   \n",
       "1  Text Summarization  GigaWord  Struct+2Way+Word     ROUGE-2         17.66   \n",
       "2  Text Summarization  GigaWord  Struct+2Way+Word     ROUGE-L         33.52   \n",
       "\n",
       "  Global rank Remove  \n",
       "0         # 8      -  \n",
       "1         # 5      -  \n",
       "2         # 9      -  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[316]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'High-Fidelity Image Generation With Fewer Labels'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_data[1319]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1320"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paper_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
