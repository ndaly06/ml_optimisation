{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports the deeppalov models\n",
    "from deeppavlov import build_model, configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-13 00:01:57.499 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/deeppavlov_data/squad_model_1.4_cpu_compatible.tar.gz download because of matching hashes\n",
      "2019-05-13 00:02:04.562 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/embeddings/wiki-news-300d-1M.vec download because of matching hashes\n",
      "2019-05-13 00:02:04.870 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/embeddings/wiki-news-300d-1M-char.vec download because of matching hashes\n",
      "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed\n",
      "[nltk_data]     (_ssl.c:777)>\n",
      "[nltk_data] Error loading stopwords: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed\n",
      "[nltk_data]     (_ssl.c:777)>\n",
      "[nltk_data] Error loading perluniprops: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed\n",
      "[nltk_data]     (_ssl.c:777)>\n",
      "[nltk_data] Error loading nonbreaking_prefixes: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed\n",
      "[nltk_data]     (_ssl.c:777)>\n",
      "2019-05-13 00:02:12.676 INFO in 'deeppavlov.models.preprocessors.squad_preprocessor'['squad_preprocessor'] at line 310: SquadVocabEmbedder: loading saved tokens vocab from /Users/nialdaly/.deeppavlov/models/squad_model/emb/vocab_embedder.pckl\n",
      "2019-05-13 00:02:13.836 INFO in 'deeppavlov.models.preprocessors.squad_preprocessor'['squad_preprocessor'] at line 310: SquadVocabEmbedder: loading saved chars vocab from /Users/nialdaly/.deeppavlov/models/squad_model/emb/char_vocab_embedder.pckl\n",
      "Using TensorFlow backend.\n",
      "2019-05-13 00:02:24.986 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 614: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/nialdaly/Documents/ml_optimisation/deeppavlov_nlp/env/lib/python3.6/site-packages/deeppavlov/core/layers/tf_layers.py:808: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "seq_dim is deprecated, use seq_axis instead\n",
      "WARNING:tensorflow:From /Users/nialdaly/Documents/ml_optimisation/deeppavlov_nlp/env/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:454: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "batch_dim is deprecated, use batch_axis instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-13 00:02:39.51 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 614: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "2019-05-13 00:02:39.355 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 614: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "2019-05-13 00:02:39.697 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 614: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/nialdaly/Documents/ml_optimisation/deeppavlov_nlp/env/lib/python3.6/site-packages/deeppavlov/models/squad/squad.py:211: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-13 00:03:11.996 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [loading model from /Users/nialdaly/.deeppavlov/models/squad_model/model]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/nialdaly/.deeppavlov/models/squad_model/model\n"
     ]
    }
   ],
   "source": [
    "# initialises the model\n",
    "model = build_model(configs.squad.squad, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['93.2']\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "context = ['We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT representations can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE benchmark to 80.4% (7.6% absolute improvement), MultiNLI accuracy to 86.7 (5.6% absolute improvement) and the SQuAD v1.1 question answering Test F1 to 93.2 (1.5% absolute improvement), outperforming human performance by 2.0%.']\n",
    "question = ['What is the squad v11 score?']\n",
    "\n",
    "#\n",
    "result = model(context, question)\n",
    "\n",
    "#\n",
    "print(result[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeppavlov_nlp_demo",
   "language": "python",
   "name": "deeppavlov_nlp_demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
