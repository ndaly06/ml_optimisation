{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports the deeppalov models\n",
    "from deeppavlov import build_model, configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-13 13:21:41.580 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/embeddings/wiki-news-300d-1M.vec download because of matching hashes\n",
      "2019-05-13 13:21:44.334 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/deeppavlov_data/squad_model_1.4_cpu_compatible.tar.gz download because of matching hashes\n",
      "2019-05-13 13:21:44.699 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/embeddings/wiki-news-300d-1M-char.vec download because of matching hashes\n",
      "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed\n",
      "[nltk_data]     (_ssl.c:777)>\n",
      "[nltk_data] Error loading stopwords: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed\n",
      "[nltk_data]     (_ssl.c:777)>\n",
      "[nltk_data] Error loading perluniprops: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed\n",
      "[nltk_data]     (_ssl.c:777)>\n",
      "[nltk_data] Error loading nonbreaking_prefixes: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed\n",
      "[nltk_data]     (_ssl.c:777)>\n",
      "2019-05-13 13:22:13.78 INFO in 'deeppavlov.models.preprocessors.squad_preprocessor'['squad_preprocessor'] at line 310: SquadVocabEmbedder: loading saved tokens vocab from /Users/nialdaly/.deeppavlov/models/squad_model/emb/vocab_embedder.pckl\n",
      "2019-05-13 13:22:14.311 INFO in 'deeppavlov.models.preprocessors.squad_preprocessor'['squad_preprocessor'] at line 310: SquadVocabEmbedder: loading saved chars vocab from /Users/nialdaly/.deeppavlov/models/squad_model/emb/char_vocab_embedder.pckl\n",
      "Using TensorFlow backend.\n",
      "2019-05-13 13:22:49.405 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 614: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/nialdaly/Documents/ml_optimisation/deeppavlov_nlp/env/lib/python3.6/site-packages/deeppavlov/core/layers/tf_layers.py:808: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "seq_dim is deprecated, use seq_axis instead\n",
      "WARNING:tensorflow:From /Users/nialdaly/Documents/ml_optimisation/deeppavlov_nlp/env/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:454: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "batch_dim is deprecated, use batch_axis instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-13 13:23:14.152 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 614: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "2019-05-13 13:23:14.579 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 614: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "2019-05-13 13:23:14.837 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 614: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/nialdaly/Documents/ml_optimisation/deeppavlov_nlp/env/lib/python3.6/site-packages/deeppavlov/models/squad/squad.py:211: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-13 13:23:44.533 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [loading model from /Users/nialdaly/.deeppavlov/models/squad_model/model]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/nialdaly/.deeppavlov/models/squad_model/model\n"
     ]
    }
   ],
   "source": [
    "# initialises the model\n",
    "model = build_model(configs.squad.squad, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5.6%']\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "context = ['We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT representations can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE benchmark to 80.4% (7.6% absolute improvement), MultiNLI accuracy to 86.7 (5.6% absolute improvement) and the SQuAD v1.1 question answering Test F1 to 93.2 (1.5% absolute improvement), outperforming human performance by 2.0%.']\n",
    "question = ['What is the improvement on MultiNLI?']\n",
    "\n",
    "#\n",
    "result = model(context, question)\n",
    "\n",
    "#\n",
    "print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['93.2']\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "context = ['We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT representations can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE benchmark to 80.4% (7.6% absolute improvement), MultiNLI accuracy to 86.7 (5.6% absolute improvement) and the SQuAD v1.1 question answering Test F1 to 93.2 (1.5% absolute improvement), outperforming human performance by 2.0%.']\n",
    "question = ['What is the squad v11 score?']\n",
    "\n",
    "#\n",
    "result = model(context, question)\n",
    "\n",
    "#\n",
    "print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = [\"A cross-party Brexit deal will not get through Parliament unless it is subject to a fresh public vote, shadow Brexit secretary Sir Keir Starmer says. Talks between Labour and ministers over leaving the EU have been going on for a month with little sign of progress. Sir Keir told the Guardian that without a new referendum, up to 150 Labour MPs would vote against any agreement made. Foreign Secretary Jeremy Hunt said it was a 'crunch week' for the talks ahead of European elections on 23 May. He said his view had not changed that another referendum would be a 'betrayal' and everyone's focus should be on delivering on the result of the 2016 Brexit vote. The UK was due to leave the EU on 29 March, but the deadline was pushed back to 31 October after MPs rejected Theresa May's proposed deal three times.\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = ['How long have talks between labour and ministers been going on?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model(context, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a month']\n"
     ]
    }
   ],
   "source": [
    "print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a month'], [228], [10268841.0]]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['dan'], [32], [875.8544311523438]]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "\n",
    "context = ['the dog is called. he is called dan']\n",
    "question = [\"what is the cat's name?\"]\n",
    "\n",
    "#\n",
    "result = model(context, question)\n",
    "\n",
    "#\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeppavlov_nlp_demo",
   "language": "python",
   "name": "deeppavlov_nlp_demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
